Job started at Sat Apr 19 20:17:54 CDT 2025
Running on g015.grace.hprc.tamu.edu
Sat Apr 19 20:17:54 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:3B:00.0 Off |                  Off |
| N/A   17C    P0              30W / 250W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
INFO:get_data:Preparing dataset.
INFO:get_data:Loading dataset from Hugging Face...
INFO:get_data:Selecting 100000 documents from the dataset
INFO:get_data:Selected 100000 documents
INFO:get_data:Processing dataset...
INFO:datasets_modules.datasets.allenai--peS2o.ec8083364779e2c9ddb5f8b9c57210835b0c10f70093da8d531994aa0e5285ee.peS2o:generating examples from = https://huggingface.co/datasets/allenai/peS2o/resolve/636a503e44a3ca1b58e01fb61eab0825cd574de0/data/v2/train-00000-of-00020.json.gz
INFO:get_data:Data preparation complete.
INFO:get_data:Using data from ./data/data.txt



Started at 2025-04-19 20:18:53
('batch_size', 64)
('data_file', 'data.txt')
('data_path', './data/')
('dropout', 0.1)
('embed_dim', 256)
('epochs', 48)
('forward_mul', 4)
('gen_tokens_len', 256)
('input_text', 'You')
('load_model', False)
('load_tokenizer', False)
('lr', 0.001)
('max_merged_tokens', 5000)
('model_path', './saved_models')
('n_heads', 8)
('n_layers', 8)
('n_workers', 2)
('network_type', 'llama')
('temperature', 1.0)
('test_only', False)
('top_k', 10)
('top_p', 0.6)
('train_tokens_len', 64)
('warmup_epochs', 5)

Tokenizing data file...
33315753 tokens created from the file. Each epoch will have 520558 batches.
Number of trainable parameters in the model: 30932569
Number of tokens per parameters: 1.0770.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 1/48	It: 1/8134	batch_loss: 9.0145	batch_accuracy: 0.02%	lr:0.000010
Ep: 1/48	It: 51/8134	batch_loss: 8.8158	batch_accuracy: 2.37%	lr:0.000011
Ep: 1/48	It: 101/8134	batch_loss: 8.5631	batch_accuracy: 4.27%	lr:0.000012
Ep: 1/48	It: 151/8134	batch_loss: 8.2337	batch_accuracy: 7.86%	lr:0.000014
Ep: 1/48	It: 201/8134	batch_loss: 7.9097	batch_accuracy: 8.08%	lr:0.000015
Ep: 1/48	It: 251/8134	batch_loss: 7.6615	batch_accuracy: 9.18%	lr:0.000016
Ep: 1/48	It: 301/8134	batch_loss: 7.6320	batch_accuracy: 7.62%	lr:0.000017
Ep: 1/48	It: 351/8134	batch_loss: 7.5485	batch_accuracy: 6.42%	lr:0.000019
Ep: 1/48	It: 401/8134	batch_loss: 7.3976	batch_accuracy: 7.37%	lr:0.000020
Ep: 1/48	It: 451/8134	batch_loss: 7.2407	batch_accuracy: 7.59%	lr:0.000021
Ep: 1/48	It: 501/8134	batch_loss: 7.1821	batch_accuracy: 7.45%	lr:0.000022
Ep: 1/48	It: 551/8134	batch_loss: 7.0628	batch_accuracy: 9.11%	lr:0.000023
Ep: 1/48	It: 601/8134	batch_loss: 7.0298	batch_accuracy: 8.91%	lr:0.000025
Ep: 1/48	It: 651/8134	batch_loss: 6.9697	batch_accuracy: 8.67%	lr:0.000026
Ep: 1/48	It: 701/8134	batch_loss: 6.9617	batch_accuracy: 9.35%	lr:0.000027
Ep: 1/48	It: 751/8134	batch_loss: 6.8295	batch_accuracy: 10.94%	lr:0.000028
Ep: 1/48	It: 801/8134	batch_loss: 6.8868	batch_accuracy: 9.28%	lr:0.000029
Ep: 1/48	It: 851/8134	batch_loss: 6.7976	batch_accuracy: 10.64%	lr:0.000031
Ep: 1/48	It: 901/8134	batch_loss: 6.7801	batch_accuracy: 10.72%	lr:0.000032
Ep: 1/48	It: 951/8134	batch_loss: 6.6744	batch_accuracy: 11.30%	lr:0.000033
Ep: 1/48	It: 1001/8134	batch_loss: 6.5863	batch_accuracy: 12.40%	lr:0.000034
Ep: 1/48	It: 1051/8134	batch_loss: 6.5965	batch_accuracy: 12.74%	lr:0.000036
Ep: 1/48	It: 1101/8134	batch_loss: 6.5889	batch_accuracy: 11.79%	lr:0.000037
Ep: 1/48	It: 1151/8134	batch_loss: 6.4574	batch_accuracy: 12.18%	lr:0.000038
Ep: 1/48	It: 1201/8134	batch_loss: 6.5166	batch_accuracy: 11.84%	lr:0.000039
Ep: 1/48	It: 1251/8134	batch_loss: 6.4037	batch_accuracy: 13.21%	lr:0.000040
Ep: 1/48	It: 1301/8134	batch_loss: 6.4653	batch_accuracy: 11.67%	lr:0.000042
Ep: 1/48	It: 1351/8134	batch_loss: 6.2035	batch_accuracy: 14.21%	lr:0.000043
Ep: 1/48	It: 1401/8134	batch_loss: 6.1221	batch_accuracy: 15.11%	lr:0.000044
Ep: 1/48	It: 1451/8134	batch_loss: 6.0796	batch_accuracy: 14.99%	lr:0.000045
Ep: 1/48	It: 1501/8134	batch_loss: 6.0624	batch_accuracy: 14.84%	lr:0.000047
Ep: 1/48	It: 1551/8134	batch_loss: 6.1605	batch_accuracy: 14.28%	lr:0.000048
Ep: 1/48	It: 1601/8134	batch_loss: 6.0807	batch_accuracy: 13.40%	lr:0.000049
Ep: 1/48	It: 1651/8134	batch_loss: 6.0042	batch_accuracy: 15.14%	lr:0.000050
Ep: 1/48	It: 1701/8134	batch_loss: 5.9059	batch_accuracy: 16.09%	lr:0.000051
Ep: 1/48	It: 1751/8134	batch_loss: 5.8030	batch_accuracy: 16.63%	lr:0.000053
Ep: 1/48	It: 1801/8134	batch_loss: 5.7931	batch_accuracy: 16.55%	lr:0.000054
Ep: 1/48	It: 1851/8134	batch_loss: 5.6981	batch_accuracy: 17.02%	lr:0.000055
Ep: 1/48	It: 1901/8134	batch_loss: 5.7059	batch_accuracy: 18.04%	lr:0.000056
Ep: 1/48	It: 1951/8134	batch_loss: 5.7693	batch_accuracy: 15.62%	lr:0.000057
Ep: 1/48	It: 2001/8134	batch_loss: 5.6917	batch_accuracy: 17.16%	lr:0.000059
Ep: 1/48	It: 2051/8134	batch_loss: 5.6511	batch_accuracy: 17.41%	lr:0.000060
Ep: 1/48	It: 2101/8134	batch_loss: 5.5285	batch_accuracy: 19.31%	lr:0.000061
Ep: 1/48	It: 2151/8134	batch_loss: 5.5947	batch_accuracy: 17.70%	lr:0.000062
Ep: 1/48	It: 2201/8134	batch_loss: 5.5121	batch_accuracy: 18.31%	lr:0.000064
Ep: 1/48	It: 2251/8134	batch_loss: 5.5563	batch_accuracy: 17.92%	lr:0.000065
Ep: 1/48	It: 2301/8134	batch_loss: 5.4403	batch_accuracy: 19.70%	lr:0.000066
Ep: 1/48	It: 2351/8134	batch_loss: 5.5568	batch_accuracy: 16.67%	lr:0.000067
Ep: 1/48	It: 2401/8134	batch_loss: 5.3938	batch_accuracy: 19.12%	lr:0.000068
Ep: 1/48	It: 2451/8134	batch_loss: 5.3905	batch_accuracy: 19.09%	lr:0.000070
Ep: 1/48	It: 2501/8134	batch_loss: 5.4315	batch_accuracy: 18.29%	lr:0.000071
Ep: 1/48	It: 2551/8134	batch_loss: 5.3628	batch_accuracy: 18.38%	lr:0.000072
Ep: 1/48	It: 2601/8134	batch_loss: 5.3004	batch_accuracy: 19.46%	lr:0.000073
Ep: 1/48	It: 2651/8134	batch_loss: 5.3981	batch_accuracy: 17.80%	lr:0.000075
Ep: 1/48	It: 2701/8134	batch_loss: 5.4345	batch_accuracy: 17.33%	lr:0.000076
Ep: 1/48	It: 2751/8134	batch_loss: 5.3821	batch_accuracy: 18.51%	lr:0.000077
Ep: 1/48	It: 2801/8134	batch_loss: 5.2219	batch_accuracy: 19.68%	lr:0.000078
Ep: 1/48	It: 2851/8134	batch_loss: 5.1984	batch_accuracy: 19.02%	lr:0.000079
Ep: 1/48	It: 2901/8134	batch_loss: 5.1907	batch_accuracy: 20.34%	lr:0.000081
Ep: 1/48	It: 2951/8134	batch_loss: 5.1525	batch_accuracy: 19.92%	lr:0.000082
Ep: 1/48	It: 3001/8134	batch_loss: 5.2297	batch_accuracy: 17.85%	lr:0.000083
Ep: 1/48	It: 3051/8134	batch_loss: 5.2344	batch_accuracy: 18.19%	lr:0.000084
Ep: 1/48	It: 3101/8134	batch_loss: 5.2268	batch_accuracy: 20.02%	lr:0.000085
Ep: 1/48	It: 3151/8134	batch_loss: 5.1915	batch_accuracy: 19.31%	lr:0.000087
Ep: 1/48	It: 3201/8134	batch_loss: 5.1803	batch_accuracy: 19.19%	lr:0.000088
Ep: 1/48	It: 3251/8134	batch_loss: 5.1683	batch_accuracy: 18.87%	lr:0.000089
Ep: 1/48	It: 3301/8134	batch_loss: 5.0446	batch_accuracy: 20.31%	lr:0.000090
Ep: 1/48	It: 3351/8134	batch_loss: 5.1281	batch_accuracy: 19.63%	lr:0.000092
Ep: 1/48	It: 3401/8134	batch_loss: 5.0800	batch_accuracy: 20.34%	lr:0.000093
Ep: 1/48	It: 3451/8134	batch_loss: 5.0629	batch_accuracy: 21.07%	lr:0.000094
Ep: 1/48	It: 3501/8134	batch_loss: 5.0612	batch_accuracy: 19.82%	lr:0.000095
Ep: 1/48	It: 3551/8134	batch_loss: 5.0231	batch_accuracy: 20.41%	lr:0.000096
Ep: 1/48	It: 3601/8134	batch_loss: 5.0355	batch_accuracy: 21.17%	lr:0.000098
Ep: 1/48	It: 3651/8134	batch_loss: 4.9526	batch_accuracy: 20.83%	lr:0.000099
Ep: 1/48	It: 3701/8134	batch_loss: 4.9271	batch_accuracy: 20.87%	lr:0.000100
Ep: 1/48	It: 3751/8134	batch_loss: 4.9519	batch_accuracy: 20.92%	lr:0.000101
Ep: 1/48	It: 3801/8134	batch_loss: 4.9899	batch_accuracy: 20.34%	lr:0.000103
Ep: 1/48	It: 3851/8134	batch_loss: 4.9184	batch_accuracy: 21.39%	lr:0.000104
Ep: 1/48	It: 3901/8134	batch_loss: 4.9257	batch_accuracy: 20.87%	lr:0.000105
Ep: 1/48	It: 3951/8134	batch_loss: 4.9135	batch_accuracy: 21.12%	lr:0.000106
Ep: 1/48	It: 4001/8134	batch_loss: 4.8865	batch_accuracy: 22.00%	lr:0.000107
Ep: 1/48	It: 4051/8134	batch_loss: 4.9574	batch_accuracy: 20.87%	lr:0.000109
Ep: 1/48	It: 4101/8134	batch_loss: 4.8684	batch_accuracy: 19.87%	lr:0.000110
Ep: 1/48	It: 4151/8134	batch_loss: 5.0060	batch_accuracy: 19.85%	lr:0.000111
Ep: 1/48	It: 4201/8134	batch_loss: 4.8103	batch_accuracy: 22.90%	lr:0.000112
Ep: 1/48	It: 4251/8134	batch_loss: 4.8283	batch_accuracy: 21.12%	lr:0.000113
Ep: 1/48	It: 4301/8134	batch_loss: 4.8171	batch_accuracy: 22.56%	lr:0.000115
Ep: 1/48	It: 4351/8134	batch_loss: 4.7831	batch_accuracy: 21.09%	lr:0.000116
Ep: 1/48	It: 4401/8134	batch_loss: 4.8693	batch_accuracy: 21.44%	lr:0.000117
Ep: 1/48	It: 4451/8134	batch_loss: 4.8011	batch_accuracy: 21.90%	lr:0.000118
Ep: 1/48	It: 4501/8134	batch_loss: 4.7439	batch_accuracy: 22.24%	lr:0.000120
Ep: 1/48	It: 4551/8134	batch_loss: 4.8282	batch_accuracy: 21.07%	lr:0.000121
Ep: 1/48	It: 4601/8134	batch_loss: 4.8863	batch_accuracy: 21.61%	lr:0.000122
Ep: 1/48	It: 4651/8134	batch_loss: 4.7910	batch_accuracy: 21.58%	lr:0.000123
Ep: 1/48	It: 4701/8134	batch_loss: 4.7643	batch_accuracy: 22.34%	lr:0.000124
Ep: 1/48	It: 4751/8134	batch_loss: 4.7617	batch_accuracy: 22.05%	lr:0.000126
Ep: 1/48	It: 4801/8134	batch_loss: 4.8321	batch_accuracy: 21.68%	lr:0.000127
Ep: 1/48	It: 4851/8134	batch_loss: 4.6610	batch_accuracy: 24.19%	lr:0.000128
Ep: 1/48	It: 4901/8134	batch_loss: 4.6885	batch_accuracy: 22.73%	lr:0.000129
Ep: 1/48	It: 4951/8134	batch_loss: 4.7201	batch_accuracy: 22.85%	lr:0.000131
Ep: 1/48	It: 5001/8134	batch_loss: 4.8066	batch_accuracy: 22.31%	lr:0.000132
Ep: 1/48	It: 5051/8134	batch_loss: 4.7404	batch_accuracy: 22.19%	lr:0.000133
Ep: 1/48	It: 5101/8134	batch_loss: 4.6929	batch_accuracy: 22.31%	lr:0.000134
Ep: 1/48	It: 5151/8134	batch_loss: 4.6189	batch_accuracy: 22.85%	lr:0.000135
Ep: 1/48	It: 5201/8134	batch_loss: 4.6315	batch_accuracy: 23.66%	lr:0.000137
Ep: 1/48	It: 5251/8134	batch_loss: 4.6714	batch_accuracy: 22.61%	lr:0.000138
Ep: 1/48	It: 5301/8134	batch_loss: 4.5712	batch_accuracy: 23.75%	lr:0.000139
Ep: 1/48	It: 5351/8134	batch_loss: 4.5654	batch_accuracy: 24.98%	lr:0.000140
Ep: 1/48	It: 5401/8134	batch_loss: 4.6481	batch_accuracy: 23.12%	lr:0.000141
Ep: 1/48	It: 5451/8134	batch_loss: 4.7204	batch_accuracy: 21.41%	lr:0.000143
Ep: 1/48	It: 5501/8134	batch_loss: 4.6676	batch_accuracy: 22.71%	lr:0.000144
Ep: 1/48	It: 5551/8134	batch_loss: 4.6191	batch_accuracy: 23.51%	lr:0.000145
Ep: 1/48	It: 5601/8134	batch_loss: 4.4803	batch_accuracy: 24.61%	lr:0.000146
Ep: 1/48	It: 5651/8134	batch_loss: 4.4986	batch_accuracy: 24.95%	lr:0.000148
Ep: 1/48	It: 5701/8134	batch_loss: 4.5751	batch_accuracy: 22.90%	lr:0.000149
Ep: 1/48	It: 5751/8134	batch_loss: 4.5794	batch_accuracy: 24.41%	lr:0.000150
Ep: 1/48	It: 5801/8134	batch_loss: 4.5852	batch_accuracy: 22.97%	lr:0.000151
Ep: 1/48	It: 5851/8134	batch_loss: 4.4122	batch_accuracy: 26.44%	lr:0.000152
Ep: 1/48	It: 5901/8134	batch_loss: 4.4202	batch_accuracy: 25.27%	lr:0.000154
Ep: 1/48	It: 5951/8134	batch_loss: 4.5856	batch_accuracy: 23.78%	lr:0.000155
Ep: 1/48	It: 6001/8134	batch_loss: 4.5370	batch_accuracy: 24.15%	lr:0.000156
Ep: 1/48	It: 6051/8134	batch_loss: 4.5279	batch_accuracy: 25.20%	lr:0.000157
Ep: 1/48	It: 6101/8134	batch_loss: 4.5386	batch_accuracy: 23.97%	lr:0.000159
Ep: 1/48	It: 6151/8134	batch_loss: 4.4158	batch_accuracy: 24.95%	lr:0.000160
Ep: 1/48	It: 6201/8134	batch_loss: 4.5227	batch_accuracy: 23.71%	lr:0.000161
Ep: 1/48	It: 6251/8134	batch_loss: 4.4546	batch_accuracy: 25.17%	lr:0.000162
Ep: 1/48	It: 6301/8134	batch_loss: 4.4052	batch_accuracy: 25.66%	lr:0.000163
Ep: 1/48	It: 6351/8134	batch_loss: 4.4358	batch_accuracy: 25.32%	lr:0.000165
Ep: 1/48	It: 6401/8134	batch_loss: 4.4554	batch_accuracy: 25.20%	lr:0.000166
Ep: 1/48	It: 6451/8134	batch_loss: 4.3734	batch_accuracy: 25.66%	lr:0.000167
Ep: 1/48	It: 6501/8134	batch_loss: 4.4158	batch_accuracy: 24.15%	lr:0.000168
Ep: 1/48	It: 6551/8134	batch_loss: 4.4165	batch_accuracy: 26.49%	lr:0.000169
Ep: 1/48	It: 6601/8134	batch_loss: 4.3803	batch_accuracy: 25.00%	lr:0.000171
Ep: 1/48	It: 6651/8134	batch_loss: 4.3903	batch_accuracy: 25.54%	lr:0.000172
Ep: 1/48	It: 6701/8134	batch_loss: 4.4792	batch_accuracy: 24.58%	lr:0.000173
Ep: 1/48	It: 6751/8134	batch_loss: 4.3660	batch_accuracy: 26.73%	lr:0.000174
Ep: 1/48	It: 6801/8134	batch_loss: 4.4130	batch_accuracy: 25.85%	lr:0.000176
Ep: 1/48	It: 6851/8134	batch_loss: 4.4689	batch_accuracy: 25.00%	lr:0.000177
Ep: 1/48	It: 6901/8134	batch_loss: 4.4521	batch_accuracy: 25.02%	lr:0.000178
Ep: 1/48	It: 6951/8134	batch_loss: 4.2972	batch_accuracy: 27.27%	lr:0.000179
Ep: 1/48	It: 7001/8134	batch_loss: 4.3692	batch_accuracy: 26.17%	lr:0.000180
Ep: 1/48	It: 7051/8134	batch_loss: 4.3684	batch_accuracy: 26.25%	lr:0.000182
Ep: 1/48	It: 7101/8134	batch_loss: 4.3615	batch_accuracy: 26.34%	lr:0.000183
Ep: 1/48	It: 7151/8134	batch_loss: 4.5082	batch_accuracy: 23.27%	lr:0.000184
Ep: 1/48	It: 7201/8134	batch_loss: 4.5358	batch_accuracy: 24.17%	lr:0.000185
Ep: 1/48	It: 7251/8134	batch_loss: 4.2838	batch_accuracy: 26.56%	lr:0.000187
Ep: 1/48	It: 7301/8134	batch_loss: 4.3999	batch_accuracy: 25.54%	lr:0.000188
Ep: 1/48	It: 7351/8134	batch_loss: 4.3172	batch_accuracy: 26.32%	lr:0.000189
Ep: 1/48	It: 7401/8134	batch_loss: 4.4623	batch_accuracy: 24.49%	lr:0.000190
Ep: 1/48	It: 7451/8134	batch_loss: 4.4126	batch_accuracy: 24.83%	lr:0.000191
Ep: 1/48	It: 7501/8134	batch_loss: 4.4586	batch_accuracy: 25.17%	lr:0.000193
Ep: 1/48	It: 7551/8134	batch_loss: 4.4425	batch_accuracy: 25.05%	lr:0.000194
Ep: 1/48	It: 7601/8134	batch_loss: 4.3212	batch_accuracy: 26.27%	lr:0.000195
Ep: 1/48	It: 7651/8134	batch_loss: 4.2495	batch_accuracy: 27.27%	lr:0.000196
Ep: 1/48	It: 7701/8134	batch_loss: 4.3264	batch_accuracy: 26.44%	lr:0.000197
Ep: 1/48	It: 7751/8134	batch_loss: 4.3890	batch_accuracy: 24.85%	lr:0.000199
Ep: 1/48	It: 7801/8134	batch_loss: 4.4136	batch_accuracy: 25.34%	lr:0.000200
Ep: 1/48	It: 7851/8134	batch_loss: 4.4073	batch_accuracy: 25.78%	lr:0.000201
Ep: 1/48	It: 7901/8134	batch_loss: 4.3411	batch_accuracy: 26.05%	lr:0.000202
Ep: 1/48	It: 7951/8134	batch_loss: 4.2996	batch_accuracy: 27.61%	lr:0.000204
Ep: 1/48	It: 8001/8134	batch_loss: 4.2137	batch_accuracy: 27.42%	lr:0.000205
Ep: 1/48	It: 8051/8134	batch_loss: 4.2871	batch_accuracy: 26.56%	lr:0.000206
Ep: 1/48	It: 8101/8134	batch_loss: 4.3892	batch_accuracy: 25.05%	lr:0.000207
Ep: 1/48	It: 8134/8134	batch_loss: 4.3121	batch_accuracy: 26.02%	lr:0.000208


Generated text for input text "You" is:
You, in a variety of areas. Act, and F, in-simple studies were used to determine the impact of this study instructional status, and in the study of the authors, and to the extent of the study in order to the impact of the quality of life, and their use. The results of the study showed that the performance of a test group is an increase in both groups. Results of the data are given, and a decrease in both of the mean age of women's disease and the other factors, with a decrease in number of cases, as well as in the other hand. The results of this study indicate that the incidence of disease in children with lower respiratory diseases is associated with a significant increase in the risk of the risk of disease progression.
<eot>
<sot>
A new approach to the role of human cancer in the management of patients with chronic pain.

OBJECTIVE
To study the effect of the use of a prospective and clinical trials in a prospective clinical diagnosis in clinical practice and treatment of acute and chronic kidney disease (DCT) in the United States. This is based on the clinical outcome, as a clinical trial in an attempt to assess the prevalence of cardiovascular risk factors and in the management of patients


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 2/48	It: 1/8134	batch_loss: 4.2867	batch_accuracy: 27.03%	lr:0.000208
Ep: 2/48	It: 51/8134	batch_loss: 4.1792	batch_accuracy: 28.88%	lr:0.000209
Ep: 2/48	It: 101/8134	batch_loss: 4.3024	batch_accuracy: 25.98%	lr:0.000210
Ep: 2/48	It: 151/8134	batch_loss: 4.2325	batch_accuracy: 26.59%	lr:0.000212
Ep: 2/48	It: 201/8134	batch_loss: 4.2989	batch_accuracy: 27.00%	lr:0.000213
Ep: 2/48	It: 251/8134	batch_loss: 4.2897	batch_accuracy: 27.05%	lr:0.000214
Ep: 2/48	It: 301/8134	batch_loss: 4.3502	batch_accuracy: 25.29%	lr:0.000215
Ep: 2/48	It: 351/8134	batch_loss: 4.3220	batch_accuracy: 26.42%	lr:0.000217
Ep: 2/48	It: 401/8134	batch_loss: 4.3215	batch_accuracy: 26.22%	lr:0.000218
Ep: 2/48	It: 451/8134	batch_loss: 4.1589	batch_accuracy: 28.05%	lr:0.000219
Ep: 2/48	It: 501/8134	batch_loss: 4.2157	batch_accuracy: 27.83%	lr:0.000220
Ep: 2/48	It: 551/8134	batch_loss: 4.1987	batch_accuracy: 27.76%	lr:0.000221
Ep: 2/48	It: 601/8134	batch_loss: 4.2481	batch_accuracy: 25.88%	lr:0.000223
Ep: 2/48	It: 651/8134	batch_loss: 4.2715	batch_accuracy: 27.25%	lr:0.000224
Ep: 2/48	It: 701/8134	batch_loss: 4.2376	batch_accuracy: 27.08%	lr:0.000225
Ep: 2/48	It: 751/8134	batch_loss: 4.1695	batch_accuracy: 27.69%	lr:0.000226
Ep: 2/48	It: 801/8134	batch_loss: 4.3403	batch_accuracy: 26.49%	lr:0.000227
Ep: 2/48	It: 851/8134	batch_loss: 4.2440	batch_accuracy: 27.88%	lr:0.000229
Ep: 2/48	It: 901/8134	batch_loss: 4.1862	batch_accuracy: 28.88%	lr:0.000230
Ep: 2/48	It: 951/8134	batch_loss: 4.2106	batch_accuracy: 26.71%	lr:0.000231
Ep: 2/48	It: 1001/8134	batch_loss: 4.2339	batch_accuracy: 26.61%	lr:0.000232
Ep: 2/48	It: 1051/8134	batch_loss: 4.1398	batch_accuracy: 28.22%	lr:0.000234
Ep: 2/48	It: 1101/8134	batch_loss: 4.3693	batch_accuracy: 25.88%	lr:0.000235
Ep: 2/48	It: 1151/8134	batch_loss: 4.1667	batch_accuracy: 27.15%	lr:0.000236
Ep: 2/48	It: 1201/8134	batch_loss: 4.2277	batch_accuracy: 27.05%	lr:0.000237
Ep: 2/48	It: 1251/8134	batch_loss: 4.1926	batch_accuracy: 27.61%	lr:0.000238
Ep: 2/48	It: 1301/8134	batch_loss: 4.3043	batch_accuracy: 26.07%	lr:0.000240
Ep: 2/48	It: 1351/8134	batch_loss: 4.1354	batch_accuracy: 28.10%	lr:0.000241
Ep: 2/48	It: 1401/8134	batch_loss: 4.1642	batch_accuracy: 28.93%	lr:0.000242
Ep: 2/48	It: 1451/8134	batch_loss: 4.1316	batch_accuracy: 28.03%	lr:0.000243
Ep: 2/48	It: 1501/8134	batch_loss: 4.1581	batch_accuracy: 26.86%	lr:0.000245
Ep: 2/48	It: 1551/8134	batch_loss: 4.2154	batch_accuracy: 26.61%	lr:0.000246
Ep: 2/48	It: 1601/8134	batch_loss: 4.1490	batch_accuracy: 28.71%	lr:0.000247
Ep: 2/48	It: 1651/8134	batch_loss: 4.2706	batch_accuracy: 27.17%	lr:0.000248
Ep: 2/48	It: 1701/8134	batch_loss: 4.0593	batch_accuracy: 28.93%	lr:0.000249
Ep: 2/48	It: 1751/8134	batch_loss: 4.0811	batch_accuracy: 29.91%	lr:0.000251
Ep: 2/48	It: 1801/8134	batch_loss: 4.2028	batch_accuracy: 27.49%	lr:0.000252
Ep: 2/48	It: 1851/8134	batch_loss: 4.1025	batch_accuracy: 28.17%	lr:0.000253
Ep: 2/48	It: 1901/8134	batch_loss: 4.0824	batch_accuracy: 28.86%	lr:0.000254
Ep: 2/48	It: 1951/8134	batch_loss: 4.0477	batch_accuracy: 29.32%	lr:0.000255
Ep: 2/48	It: 2001/8134	batch_loss: 4.0888	batch_accuracy: 29.25%	lr:0.000257
Ep: 2/48	It: 2051/8134	batch_loss: 4.1329	batch_accuracy: 28.76%	lr:0.000258
Ep: 2/48	It: 2101/8134	batch_loss: 4.0484	batch_accuracy: 29.39%	lr:0.000259
Ep: 2/48	It: 2151/8134	batch_loss: 4.0803	batch_accuracy: 29.74%	lr:0.000260
Ep: 2/48	It: 2201/8134	batch_loss: 4.2754	batch_accuracy: 26.34%	lr:0.000262
Ep: 2/48	It: 2251/8134	batch_loss: 4.1377	batch_accuracy: 29.37%	lr:0.000263
Ep: 2/48	It: 2301/8134	batch_loss: 4.0457	batch_accuracy: 28.98%	lr:0.000264
Ep: 2/48	It: 2351/8134	batch_loss: 4.1838	batch_accuracy: 27.95%	lr:0.000265
Ep: 2/48	It: 2401/8134	batch_loss: 4.2399	batch_accuracy: 26.25%	lr:0.000266
Ep: 2/48	It: 2451/8134	batch_loss: 4.2066	batch_accuracy: 26.56%	lr:0.000268
Ep: 2/48	It: 2501/8134	batch_loss: 4.2066	batch_accuracy: 27.32%	lr:0.000269
Ep: 2/48	It: 2551/8134	batch_loss: 4.1767	batch_accuracy: 28.08%	lr:0.000270
Ep: 2/48	It: 2601/8134	batch_loss: 4.0092	batch_accuracy: 30.13%	lr:0.000271
Ep: 2/48	It: 2651/8134	batch_loss: 4.1302	batch_accuracy: 26.98%	lr:0.000273
Ep: 2/48	It: 2701/8134	batch_loss: 4.1153	batch_accuracy: 28.76%	lr:0.000274
Ep: 2/48	It: 2751/8134	batch_loss: 4.1555	batch_accuracy: 27.71%	lr:0.000275
Ep: 2/48	It: 2801/8134	batch_loss: 4.2181	batch_accuracy: 28.34%	lr:0.000276
Ep: 2/48	It: 2851/8134	batch_loss: 4.1431	batch_accuracy: 27.91%	lr:0.000277
Ep: 2/48	It: 2901/8134	batch_loss: 4.0673	batch_accuracy: 28.69%	lr:0.000279
Ep: 2/48	It: 2951/8134	batch_loss: 4.0358	batch_accuracy: 28.78%	lr:0.000280
Ep: 2/48	It: 3001/8134	batch_loss: 4.0101	batch_accuracy: 28.64%	lr:0.000281
Ep: 2/48	It: 3051/8134	batch_loss: 4.1488	batch_accuracy: 28.59%	lr:0.000282
Ep: 2/48	It: 3101/8134	batch_loss: 4.1090	batch_accuracy: 28.44%	lr:0.000283
Ep: 2/48	It: 3151/8134	batch_loss: 3.9569	batch_accuracy: 30.71%	lr:0.000285
Ep: 2/48	It: 3201/8134	batch_loss: 4.1743	batch_accuracy: 29.66%	lr:0.000286
Ep: 2/48	It: 3251/8134	batch_loss: 4.1150	batch_accuracy: 28.93%	lr:0.000287
Ep: 2/48	It: 3301/8134	batch_loss: 4.0791	batch_accuracy: 29.39%	lr:0.000288
Ep: 2/48	It: 3351/8134	batch_loss: 4.0768	batch_accuracy: 28.64%	lr:0.000290
Ep: 2/48	It: 3401/8134	batch_loss: 3.9815	batch_accuracy: 31.27%	lr:0.000291
Ep: 2/48	It: 3451/8134	batch_loss: 4.0893	batch_accuracy: 27.39%	lr:0.000292
Ep: 2/48	It: 3501/8134	batch_loss: 4.0933	batch_accuracy: 28.88%	lr:0.000293
Ep: 2/48	It: 3551/8134	batch_loss: 4.0813	batch_accuracy: 28.34%	lr:0.000294
Ep: 2/48	It: 3601/8134	batch_loss: 4.0592	batch_accuracy: 28.78%	lr:0.000296
Ep: 2/48	It: 3651/8134	batch_loss: 3.9907	batch_accuracy: 29.93%	lr:0.000297
Ep: 2/48	It: 3701/8134	batch_loss: 4.0804	batch_accuracy: 28.74%	lr:0.000298
Ep: 2/48	It: 3751/8134	batch_loss: 4.1042	batch_accuracy: 28.59%	lr:0.000299
Ep: 2/48	It: 3801/8134	batch_loss: 4.0596	batch_accuracy: 29.30%	lr:0.000301
Ep: 2/48	It: 3851/8134	batch_loss: 4.0293	batch_accuracy: 29.86%	lr:0.000302
Ep: 2/48	It: 3901/8134	batch_loss: 4.0275	batch_accuracy: 29.05%	lr:0.000303
Ep: 2/48	It: 3951/8134	batch_loss: 4.0746	batch_accuracy: 29.20%	lr:0.000304
Ep: 2/48	It: 4001/8134	batch_loss: 4.1321	batch_accuracy: 27.34%	lr:0.000305
Ep: 2/48	It: 4051/8134	batch_loss: 4.0618	batch_accuracy: 29.32%	lr:0.000307
Ep: 2/48	It: 4101/8134	batch_loss: 4.1720	batch_accuracy: 28.34%	lr:0.000308
Ep: 2/48	It: 4151/8134	batch_loss: 4.0564	batch_accuracy: 29.59%	lr:0.000309
Ep: 2/48	It: 4201/8134	batch_loss: 4.0004	batch_accuracy: 29.10%	lr:0.000310
Ep: 2/48	It: 4251/8134	batch_loss: 3.9673	batch_accuracy: 31.05%	lr:0.000311
Ep: 2/48	It: 4301/8134	batch_loss: 3.9706	batch_accuracy: 30.03%	lr:0.000313
Ep: 2/48	It: 4351/8134	batch_loss: 4.0619	batch_accuracy: 28.49%	lr:0.000314
Ep: 2/48	It: 4401/8134	batch_loss: 4.0380	batch_accuracy: 29.91%	lr:0.000315
Ep: 2/48	It: 4451/8134	batch_loss: 3.9886	batch_accuracy: 29.88%	lr:0.000316
Ep: 2/48	It: 4501/8134	batch_loss: 4.1812	batch_accuracy: 27.95%	lr:0.000318
Ep: 2/48	It: 4551/8134	batch_loss: 3.9994	batch_accuracy: 30.35%	lr:0.000319
Ep: 2/48	It: 4601/8134	batch_loss: 4.0146	batch_accuracy: 29.54%	lr:0.000320
Ep: 2/48	It: 4651/8134	batch_loss: 4.0005	batch_accuracy: 30.27%	lr:0.000321
Ep: 2/48	It: 4701/8134	batch_loss: 3.9389	batch_accuracy: 30.64%	lr:0.000322
Ep: 2/48	It: 4751/8134	batch_loss: 3.9192	batch_accuracy: 29.69%	lr:0.000324
Ep: 2/48	It: 4801/8134	batch_loss: 4.0376	batch_accuracy: 29.66%	lr:0.000325
Ep: 2/48	It: 4851/8134	batch_loss: 4.1625	batch_accuracy: 28.10%	lr:0.000326
Ep: 2/48	It: 4901/8134	batch_loss: 4.0134	batch_accuracy: 30.88%	lr:0.000327
Ep: 2/48	It: 4951/8134	batch_loss: 4.0905	batch_accuracy: 28.86%	lr:0.000329
Ep: 2/48	It: 5001/8134	batch_loss: 4.0378	batch_accuracy: 28.56%	lr:0.000330
Ep: 2/48	It: 5051/8134	batch_loss: 3.9681	batch_accuracy: 28.00%	lr:0.000331
Ep: 2/48	It: 5101/8134	batch_loss: 4.0675	batch_accuracy: 28.12%	lr:0.000332
Ep: 2/48	It: 5151/8134	batch_loss: 3.9155	batch_accuracy: 31.25%	lr:0.000333
Ep: 2/48	It: 5201/8134	batch_loss: 3.9936	batch_accuracy: 29.54%	lr:0.000335
Ep: 2/48	It: 5251/8134	batch_loss: 4.0418	batch_accuracy: 28.69%	lr:0.000336
Ep: 2/48	It: 5301/8134	batch_loss: 4.1317	batch_accuracy: 28.86%	lr:0.000337
Ep: 2/48	It: 5351/8134	batch_loss: 3.8665	batch_accuracy: 31.74%	lr:0.000338
Ep: 2/48	It: 5401/8134	batch_loss: 3.9510	batch_accuracy: 30.59%	lr:0.000339
Ep: 2/48	It: 5451/8134	batch_loss: 4.0315	batch_accuracy: 29.64%	lr:0.000341
Ep: 2/48	It: 5501/8134	batch_loss: 3.9633	batch_accuracy: 29.86%	lr:0.000342
Ep: 2/48	It: 5551/8134	batch_loss: 4.0927	batch_accuracy: 28.64%	lr:0.000343
Ep: 2/48	It: 5601/8134	batch_loss: 4.0188	batch_accuracy: 29.93%	lr:0.000344
Ep: 2/48	It: 5651/8134	batch_loss: 4.0769	batch_accuracy: 29.74%	lr:0.000346
Ep: 2/48	It: 5701/8134	batch_loss: 4.0237	batch_accuracy: 29.61%	lr:0.000347
Ep: 2/48	It: 5751/8134	batch_loss: 3.9638	batch_accuracy: 29.81%	lr:0.000348
Ep: 2/48	It: 5801/8134	batch_loss: 3.9521	batch_accuracy: 29.57%	lr:0.000349
Ep: 2/48	It: 5851/8134	batch_loss: 4.0007	batch_accuracy: 29.83%	lr:0.000350
Ep: 2/48	It: 5901/8134	batch_loss: 3.9455	batch_accuracy: 30.57%	lr:0.000352
Ep: 2/48	It: 5951/8134	batch_loss: 4.0451	batch_accuracy: 29.32%	lr:0.000353
Ep: 2/48	It: 6001/8134	batch_loss: 3.8848	batch_accuracy: 31.79%	lr:0.000354
Ep: 2/48	It: 6051/8134	batch_loss: 4.0019	batch_accuracy: 29.88%	lr:0.000355
Ep: 2/48	It: 6101/8134	batch_loss: 3.8571	batch_accuracy: 31.79%	lr:0.000357
Ep: 2/48	It: 6151/8134	batch_loss: 3.9684	batch_accuracy: 30.79%	lr:0.000358
Ep: 2/48	It: 6201/8134	batch_loss: 4.0279	batch_accuracy: 28.88%	lr:0.000359
Ep: 2/48	It: 6251/8134	batch_loss: 4.0555	batch_accuracy: 28.91%	lr:0.000360
Ep: 2/48	It: 6301/8134	batch_loss: 4.0392	batch_accuracy: 29.64%	lr:0.000361
Ep: 2/48	It: 6351/8134	batch_loss: 3.9277	batch_accuracy: 30.83%	lr:0.000363
Ep: 2/48	It: 6401/8134	batch_loss: 4.0453	batch_accuracy: 29.66%	lr:0.000364
Ep: 2/48	It: 6451/8134	batch_loss: 3.9101	batch_accuracy: 31.86%	lr:0.000365
Ep: 2/48	It: 6501/8134	batch_loss: 3.9612	batch_accuracy: 29.96%	lr:0.000366
Ep: 2/48	It: 6551/8134	batch_loss: 3.8874	batch_accuracy: 30.76%	lr:0.000367
Ep: 2/48	It: 6601/8134	batch_loss: 3.9640	batch_accuracy: 30.32%	lr:0.000369
Ep: 2/48	It: 6651/8134	batch_loss: 3.9730	batch_accuracy: 29.22%	lr:0.000370
Ep: 2/48	It: 6701/8134	batch_loss: 3.8854	batch_accuracy: 32.52%	lr:0.000371
Ep: 2/48	It: 6751/8134	batch_loss: 4.0225	batch_accuracy: 30.98%	lr:0.000372
Ep: 2/48	It: 6801/8134	batch_loss: 3.8613	batch_accuracy: 32.25%	lr:0.000374
Ep: 2/48	It: 6851/8134	batch_loss: 3.9402	batch_accuracy: 30.27%	lr:0.000375
Ep: 2/48	It: 6901/8134	batch_loss: 4.0592	batch_accuracy: 29.59%	lr:0.000376
Ep: 2/48	It: 6951/8134	batch_loss: 3.9181	batch_accuracy: 30.79%	lr:0.000377
Ep: 2/48	It: 7001/8134	batch_loss: 4.0091	batch_accuracy: 29.71%	lr:0.000378
Ep: 2/48	It: 7051/8134	batch_loss: 4.0407	batch_accuracy: 29.17%	lr:0.000380
Ep: 2/48	It: 7101/8134	batch_loss: 3.8571	batch_accuracy: 31.54%	lr:0.000381
Ep: 2/48	It: 7151/8134	batch_loss: 3.8742	batch_accuracy: 31.86%	lr:0.000382
Ep: 2/48	It: 7201/8134	batch_loss: 3.8677	batch_accuracy: 31.52%	lr:0.000383
Ep: 2/48	It: 7251/8134	batch_loss: 3.8763	batch_accuracy: 32.03%	lr:0.000385
Ep: 2/48	It: 7301/8134	batch_loss: 4.0362	batch_accuracy: 30.49%	lr:0.000386
Ep: 2/48	It: 7351/8134	batch_loss: 3.9930	batch_accuracy: 30.81%	lr:0.000387
Ep: 2/48	It: 7401/8134	batch_loss: 4.1683	batch_accuracy: 26.59%	lr:0.000388
Ep: 2/48	It: 7451/8134	batch_loss: 4.0227	batch_accuracy: 29.91%	lr:0.000389
Ep: 2/48	It: 7501/8134	batch_loss: 3.7699	batch_accuracy: 32.79%	lr:0.000391
Ep: 2/48	It: 7551/8134	batch_loss: 3.9835	batch_accuracy: 30.22%	lr:0.000392
Ep: 2/48	It: 7601/8134	batch_loss: 4.0099	batch_accuracy: 30.44%	lr:0.000393
Ep: 2/48	It: 7651/8134	batch_loss: 3.9614	batch_accuracy: 30.00%	lr:0.000394
Ep: 2/48	It: 7701/8134	batch_loss: 3.9162	batch_accuracy: 31.40%	lr:0.000395
Ep: 2/48	It: 7751/8134	batch_loss: 3.8032	batch_accuracy: 31.76%	lr:0.000397
Ep: 2/48	It: 7801/8134	batch_loss: 3.8786	batch_accuracy: 31.25%	lr:0.000398
Ep: 2/48	It: 7851/8134	batch_loss: 3.9325	batch_accuracy: 30.05%	lr:0.000399
Ep: 2/48	It: 7901/8134	batch_loss: 3.9585	batch_accuracy: 30.47%	lr:0.000400
Ep: 2/48	It: 7951/8134	batch_loss: 4.0568	batch_accuracy: 28.71%	lr:0.000402
Ep: 2/48	It: 8001/8134	batch_loss: 3.9777	batch_accuracy: 29.81%	lr:0.000403
Ep: 2/48	It: 8051/8134	batch_loss: 3.9298	batch_accuracy: 30.35%	lr:0.000404
Ep: 2/48	It: 8101/8134	batch_loss: 3.9665	batch_accuracy: 29.83%	lr:0.000405
Ep: 2/48	It: 8134/8134	batch_loss: 3.9160	batch_accuracy: 31.08%	lr:0.000406


Generated text for input text "You" is:
You’s "theory" "d" town" in thesis is a major part of thesis."
In this article, this paper describes the analysis of theories of theories of ‘crçís’ (M) and thesis that thesis is, with respect to the “green”, “democracy,” “goldbul” or ‘data’, and the essence of the Suddad Seman (Cole, Buddhist, Memory, and Day. It has been argued that ‘discrimination and ‘doing’ is an impression of its ownership and ‘public’, the ‘‘doors’, ‘polated' (psycho-taking of 'doing', a "clicular") in terms of the “post-core” (p. 187) and ‘consumerative (p. 182). In the second step, the “toward” was the most important, for the most important in the past, and the “gold standard” and the “in the “no-


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 3/48	It: 1/8134	batch_loss: 3.9784	batch_accuracy: 30.27%	lr:0.000406
Ep: 3/48	It: 51/8134	batch_loss: 3.8751	batch_accuracy: 31.49%	lr:0.000407
Ep: 3/48	It: 101/8134	batch_loss: 3.9610	batch_accuracy: 30.03%	lr:0.000408
Ep: 3/48	It: 151/8134	batch_loss: 3.9147	batch_accuracy: 31.32%	lr:0.000410
Ep: 3/48	It: 201/8134	batch_loss: 3.9497	batch_accuracy: 30.93%	lr:0.000411
Ep: 3/48	It: 251/8134	batch_loss: 3.8571	batch_accuracy: 31.45%	lr:0.000412
Ep: 3/48	It: 301/8134	batch_loss: 3.8653	batch_accuracy: 30.69%	lr:0.000413
Ep: 3/48	It: 351/8134	batch_loss: 3.8680	batch_accuracy: 31.40%	lr:0.000415
Ep: 3/48	It: 401/8134	batch_loss: 3.8343	batch_accuracy: 32.28%	lr:0.000416
Ep: 3/48	It: 451/8134	batch_loss: 3.7900	batch_accuracy: 32.13%	lr:0.000417
Ep: 3/48	It: 501/8134	batch_loss: 3.9874	batch_accuracy: 28.76%	lr:0.000418
Ep: 3/48	It: 551/8134	batch_loss: 4.0726	batch_accuracy: 28.81%	lr:0.000419
Ep: 3/48	It: 601/8134	batch_loss: 4.0312	batch_accuracy: 29.13%	lr:0.000421
Ep: 3/48	It: 651/8134	batch_loss: 3.9875	batch_accuracy: 29.17%	lr:0.000422
Ep: 3/48	It: 701/8134	batch_loss: 3.9493	batch_accuracy: 30.13%	lr:0.000423
Ep: 3/48	It: 751/8134	batch_loss: 4.0217	batch_accuracy: 29.44%	lr:0.000424
Ep: 3/48	It: 801/8134	batch_loss: 3.9835	batch_accuracy: 30.54%	lr:0.000425
Ep: 3/48	It: 851/8134	batch_loss: 3.9086	batch_accuracy: 31.76%	lr:0.000427
Ep: 3/48	It: 901/8134	batch_loss: 3.8461	batch_accuracy: 31.30%	lr:0.000428
Ep: 3/48	It: 951/8134	batch_loss: 3.8581	batch_accuracy: 31.05%	lr:0.000429
Ep: 3/48	It: 1001/8134	batch_loss: 4.0514	batch_accuracy: 28.56%	lr:0.000430
Ep: 3/48	It: 1051/8134	batch_loss: 3.9069	batch_accuracy: 30.76%	lr:0.000432
Ep: 3/48	It: 1101/8134	batch_loss: 3.9504	batch_accuracy: 30.71%	lr:0.000433
Ep: 3/48	It: 1151/8134	batch_loss: 3.8480	batch_accuracy: 31.81%	lr:0.000434
Ep: 3/48	It: 1201/8134	batch_loss: 3.7813	batch_accuracy: 32.98%	lr:0.000435
Ep: 3/48	It: 1251/8134	batch_loss: 3.9468	batch_accuracy: 31.74%	lr:0.000436
Ep: 3/48	It: 1301/8134	batch_loss: 4.0130	batch_accuracy: 29.47%	lr:0.000438
Ep: 3/48	It: 1351/8134	batch_loss: 3.8741	batch_accuracy: 32.52%	lr:0.000439
Ep: 3/48	It: 1401/8134	batch_loss: 3.9922	batch_accuracy: 29.49%	lr:0.000440
Ep: 3/48	It: 1451/8134	batch_loss: 3.9304	batch_accuracy: 29.32%	lr:0.000441
Ep: 3/48	It: 1501/8134	batch_loss: 3.8587	batch_accuracy: 31.79%	lr:0.000443
Ep: 3/48	It: 1551/8134	batch_loss: 4.0215	batch_accuracy: 30.69%	lr:0.000444
Ep: 3/48	It: 1601/8134	batch_loss: 3.9541	batch_accuracy: 29.66%	lr:0.000445
Ep: 3/48	It: 1651/8134	batch_loss: 3.8599	batch_accuracy: 32.64%	lr:0.000446
Ep: 3/48	It: 1701/8134	batch_loss: 4.0296	batch_accuracy: 31.10%	lr:0.000447
Ep: 3/48	It: 1751/8134	batch_loss: 3.9249	batch_accuracy: 30.66%	lr:0.000449
Ep: 3/48	It: 1801/8134	batch_loss: 3.8662	batch_accuracy: 31.71%	lr:0.000450
Ep: 3/48	It: 1851/8134	batch_loss: 3.9558	batch_accuracy: 30.49%	lr:0.000451
Ep: 3/48	It: 1901/8134	batch_loss: 3.8635	batch_accuracy: 31.20%	lr:0.000452
Ep: 3/48	It: 1951/8134	batch_loss: 3.8495	batch_accuracy: 31.93%	lr:0.000453
Ep: 3/48	It: 2001/8134	batch_loss: 4.0319	batch_accuracy: 29.81%	lr:0.000455
Ep: 3/48	It: 2051/8134	batch_loss: 4.0362	batch_accuracy: 28.76%	lr:0.000456
Ep: 3/48	It: 2101/8134	batch_loss: 3.8705	batch_accuracy: 31.01%	lr:0.000457
Ep: 3/48	It: 2151/8134	batch_loss: 3.9437	batch_accuracy: 31.25%	lr:0.000458
Ep: 3/48	It: 2201/8134	batch_loss: 3.8899	batch_accuracy: 31.10%	lr:0.000460
Ep: 3/48	It: 2251/8134	batch_loss: 4.0152	batch_accuracy: 30.44%	lr:0.000461
Ep: 3/48	It: 2301/8134	batch_loss: 3.9517	batch_accuracy: 31.25%	lr:0.000462
Ep: 3/48	It: 2351/8134	batch_loss: 3.9102	batch_accuracy: 31.96%	lr:0.000463
Ep: 3/48	It: 2401/8134	batch_loss: 3.9716	batch_accuracy: 30.37%	lr:0.000464
Ep: 3/48	It: 2451/8134	batch_loss: 3.8494	batch_accuracy: 30.76%	lr:0.000466
Ep: 3/48	It: 2501/8134	batch_loss: 3.9083	batch_accuracy: 31.08%	lr:0.000467
Ep: 3/48	It: 2551/8134	batch_loss: 3.7925	batch_accuracy: 31.35%	lr:0.000468
Ep: 3/48	It: 2601/8134	batch_loss: 3.8992	batch_accuracy: 31.10%	lr:0.000469
Ep: 3/48	It: 2651/8134	batch_loss: 3.9186	batch_accuracy: 30.27%	lr:0.000471
Ep: 3/48	It: 2701/8134	batch_loss: 3.8316	batch_accuracy: 31.93%	lr:0.000472
Ep: 3/48	It: 2751/8134	batch_loss: 3.8673	batch_accuracy: 31.25%	lr:0.000473
Ep: 3/48	It: 2801/8134	batch_loss: 3.8022	batch_accuracy: 31.49%	lr:0.000474
Ep: 3/48	It: 2851/8134	batch_loss: 3.9774	batch_accuracy: 29.42%	lr:0.000475
Ep: 3/48	It: 2901/8134	batch_loss: 3.8885	batch_accuracy: 31.27%	lr:0.000477
Ep: 3/48	It: 2951/8134	batch_loss: 3.8222	batch_accuracy: 32.06%	lr:0.000478
Ep: 3/48	It: 3001/8134	batch_loss: 3.7700	batch_accuracy: 32.79%	lr:0.000479
Ep: 3/48	It: 3051/8134	batch_loss: 3.9275	batch_accuracy: 30.76%	lr:0.000480
Ep: 3/48	It: 3101/8134	batch_loss: 3.7323	batch_accuracy: 33.57%	lr:0.000481
Ep: 3/48	It: 3151/8134	batch_loss: 3.7949	batch_accuracy: 32.89%	lr:0.000483
Ep: 3/48	It: 3201/8134	batch_loss: 3.9420	batch_accuracy: 30.88%	lr:0.000484
Ep: 3/48	It: 3251/8134	batch_loss: 3.7401	batch_accuracy: 34.28%	lr:0.000485
Ep: 3/48	It: 3301/8134	batch_loss: 3.8099	batch_accuracy: 32.62%	lr:0.000486
Ep: 3/48	It: 3351/8134	batch_loss: 3.8857	batch_accuracy: 31.71%	lr:0.000488
Ep: 3/48	It: 3401/8134	batch_loss: 3.7962	batch_accuracy: 31.79%	lr:0.000489
Ep: 3/48	It: 3451/8134	batch_loss: 3.9043	batch_accuracy: 30.88%	lr:0.000490
Ep: 3/48	It: 3501/8134	batch_loss: 3.7811	batch_accuracy: 32.06%	lr:0.000491
Ep: 3/48	It: 3551/8134	batch_loss: 3.9145	batch_accuracy: 30.57%	lr:0.000492
Ep: 3/48	It: 3601/8134	batch_loss: 3.8247	batch_accuracy: 31.15%	lr:0.000494
Ep: 3/48	It: 3651/8134	batch_loss: 3.6864	batch_accuracy: 33.08%	lr:0.000495
Ep: 3/48	It: 3701/8134	batch_loss: 3.8548	batch_accuracy: 30.86%	lr:0.000496
Ep: 3/48	It: 3751/8134	batch_loss: 3.8228	batch_accuracy: 31.91%	lr:0.000497
Ep: 3/48	It: 3801/8134	batch_loss: 3.8144	batch_accuracy: 31.98%	lr:0.000499
Ep: 3/48	It: 3851/8134	batch_loss: 3.8350	batch_accuracy: 30.98%	lr:0.000500
Ep: 3/48	It: 3901/8134	batch_loss: 3.8194	batch_accuracy: 32.35%	lr:0.000501
Ep: 3/48	It: 3951/8134	batch_loss: 3.8115	batch_accuracy: 32.50%	lr:0.000502
Ep: 3/48	It: 4001/8134	batch_loss: 4.0255	batch_accuracy: 30.05%	lr:0.000503
Ep: 3/48	It: 4051/8134	batch_loss: 3.9053	batch_accuracy: 30.35%	lr:0.000505
Ep: 3/48	It: 4101/8134	batch_loss: 3.8331	batch_accuracy: 31.69%	lr:0.000506
Ep: 3/48	It: 4151/8134	batch_loss: 3.8071	batch_accuracy: 31.81%	lr:0.000507
Ep: 3/48	It: 4201/8134	batch_loss: 3.6753	batch_accuracy: 33.35%	lr:0.000508
Ep: 3/48	It: 4251/8134	batch_loss: 3.7906	batch_accuracy: 32.67%	lr:0.000509
Ep: 3/48	It: 4301/8134	batch_loss: 3.9020	batch_accuracy: 30.10%	lr:0.000511
Ep: 3/48	It: 4351/8134	batch_loss: 3.8973	batch_accuracy: 31.47%	lr:0.000512
Ep: 3/48	It: 4401/8134	batch_loss: 3.7592	batch_accuracy: 32.59%	lr:0.000513
Ep: 3/48	It: 4451/8134	batch_loss: 3.8783	batch_accuracy: 31.64%	lr:0.000514
Ep: 3/48	It: 4501/8134	batch_loss: 3.7663	batch_accuracy: 33.03%	lr:0.000516
Ep: 3/48	It: 4551/8134	batch_loss: 3.9924	batch_accuracy: 29.57%	lr:0.000517
Ep: 3/48	It: 4601/8134	batch_loss: 3.8760	batch_accuracy: 31.18%	lr:0.000518
Ep: 3/48	It: 4651/8134	batch_loss: 3.9169	batch_accuracy: 31.20%	lr:0.000519
Ep: 3/48	It: 4701/8134	batch_loss: 3.8561	batch_accuracy: 32.08%	lr:0.000520
Ep: 3/48	It: 4751/8134	batch_loss: 3.8982	batch_accuracy: 30.62%	lr:0.000522
Ep: 3/48	It: 4801/8134	batch_loss: 3.9021	batch_accuracy: 31.25%	lr:0.000523
Ep: 3/48	It: 4851/8134	batch_loss: 3.8039	batch_accuracy: 31.88%	lr:0.000524
Ep: 3/48	It: 4901/8134	batch_loss: 3.9486	batch_accuracy: 30.15%	lr:0.000525
Ep: 3/48	It: 4951/8134	batch_loss: 3.8246	batch_accuracy: 31.71%	lr:0.000527
Ep: 3/48	It: 5001/8134	batch_loss: 3.9158	batch_accuracy: 30.44%	lr:0.000528
Ep: 3/48	It: 5051/8134	batch_loss: 3.7988	batch_accuracy: 31.93%	lr:0.000529
Ep: 3/48	It: 5101/8134	batch_loss: 3.9331	batch_accuracy: 31.20%	lr:0.000530
Ep: 3/48	It: 5151/8134	batch_loss: 3.8422	batch_accuracy: 31.96%	lr:0.000531
Ep: 3/48	It: 5201/8134	batch_loss: 3.8622	batch_accuracy: 31.96%	lr:0.000533
Ep: 3/48	It: 5251/8134	batch_loss: 3.8154	batch_accuracy: 31.67%	lr:0.000534
Ep: 3/48	It: 5301/8134	batch_loss: 3.7715	batch_accuracy: 32.32%	lr:0.000535
Ep: 3/48	It: 5351/8134	batch_loss: 3.7288	batch_accuracy: 33.96%	lr:0.000536
Ep: 3/48	It: 5401/8134	batch_loss: 3.7840	batch_accuracy: 32.67%	lr:0.000537
Ep: 3/48	It: 5451/8134	batch_loss: 3.9219	batch_accuracy: 31.20%	lr:0.000539
Ep: 3/48	It: 5501/8134	batch_loss: 3.8217	batch_accuracy: 31.98%	lr:0.000540
Ep: 3/48	It: 5551/8134	batch_loss: 3.7609	batch_accuracy: 32.74%	lr:0.000541
Ep: 3/48	It: 5601/8134	batch_loss: 3.7320	batch_accuracy: 34.50%	lr:0.000542
Ep: 3/48	It: 5651/8134	batch_loss: 3.8118	batch_accuracy: 33.33%	lr:0.000544
Ep: 3/48	It: 5701/8134	batch_loss: 3.7507	batch_accuracy: 33.57%	lr:0.000545
Ep: 3/48	It: 5751/8134	batch_loss: 3.8310	batch_accuracy: 31.84%	lr:0.000546
Ep: 3/48	It: 5801/8134	batch_loss: 3.9257	batch_accuracy: 30.57%	lr:0.000547
Ep: 3/48	It: 5851/8134	batch_loss: 3.9108	batch_accuracy: 30.93%	lr:0.000548
Ep: 3/48	It: 5901/8134	batch_loss: 3.9479	batch_accuracy: 29.91%	lr:0.000550
Ep: 3/48	It: 5951/8134	batch_loss: 3.7223	batch_accuracy: 32.79%	lr:0.000551
Ep: 3/48	It: 6001/8134	batch_loss: 3.6642	batch_accuracy: 33.45%	lr:0.000552
Ep: 3/48	It: 6051/8134	batch_loss: 3.7798	batch_accuracy: 32.69%	lr:0.000553
Ep: 3/48	It: 6101/8134	batch_loss: 3.7902	batch_accuracy: 33.01%	lr:0.000555
Ep: 3/48	It: 6151/8134	batch_loss: 3.8655	batch_accuracy: 31.86%	lr:0.000556
Ep: 3/48	It: 6201/8134	batch_loss: 3.7837	batch_accuracy: 31.18%	lr:0.000557
Ep: 3/48	It: 6251/8134	batch_loss: 3.7682	batch_accuracy: 32.91%	lr:0.000558
Ep: 3/48	It: 6301/8134	batch_loss: 3.8874	batch_accuracy: 31.23%	lr:0.000559
Ep: 3/48	It: 6351/8134	batch_loss: 3.8312	batch_accuracy: 32.37%	lr:0.000561
Ep: 3/48	It: 6401/8134	batch_loss: 3.8023	batch_accuracy: 30.91%	lr:0.000562
Ep: 3/48	It: 6451/8134	batch_loss: 3.7148	batch_accuracy: 32.91%	lr:0.000563
Ep: 3/48	It: 6501/8134	batch_loss: 3.8458	batch_accuracy: 31.79%	lr:0.000564
Ep: 3/48	It: 6551/8134	batch_loss: 3.7282	batch_accuracy: 33.57%	lr:0.000565
Ep: 3/48	It: 6601/8134	batch_loss: 3.8457	batch_accuracy: 31.32%	lr:0.000567
Ep: 3/48	It: 6651/8134	batch_loss: 3.8723	batch_accuracy: 30.76%	lr:0.000568
Ep: 3/48	It: 6701/8134	batch_loss: 3.8364	batch_accuracy: 32.18%	lr:0.000569
Ep: 3/48	It: 6751/8134	batch_loss: 3.9453	batch_accuracy: 31.10%	lr:0.000570
Ep: 3/48	It: 6801/8134	batch_loss: 3.9341	batch_accuracy: 30.47%	lr:0.000572
Ep: 3/48	It: 6851/8134	batch_loss: 3.8351	batch_accuracy: 31.27%	lr:0.000573
Ep: 3/48	It: 6901/8134	batch_loss: 3.7578	batch_accuracy: 33.28%	lr:0.000574
Ep: 3/48	It: 6951/8134	batch_loss: 3.7691	batch_accuracy: 32.93%	lr:0.000575
Ep: 3/48	It: 7001/8134	batch_loss: 3.6110	batch_accuracy: 34.96%	lr:0.000576
Ep: 3/48	It: 7051/8134	batch_loss: 3.8418	batch_accuracy: 31.40%	lr:0.000578
Ep: 3/48	It: 7101/8134	batch_loss: 3.8802	batch_accuracy: 31.40%	lr:0.000579
Ep: 3/48	It: 7151/8134	batch_loss: 3.6943	batch_accuracy: 32.96%	lr:0.000580
Ep: 3/48	It: 7201/8134	batch_loss: 3.8150	batch_accuracy: 31.32%	lr:0.000581
Ep: 3/48	It: 7251/8134	batch_loss: 3.7455	batch_accuracy: 33.13%	lr:0.000583
Ep: 3/48	It: 7301/8134	batch_loss: 3.8721	batch_accuracy: 31.96%	lr:0.000584
Ep: 3/48	It: 7351/8134	batch_loss: 3.7803	batch_accuracy: 31.84%	lr:0.000585
Ep: 3/48	It: 7401/8134	batch_loss: 3.7290	batch_accuracy: 33.28%	lr:0.000586
Ep: 3/48	It: 7451/8134	batch_loss: 3.9346	batch_accuracy: 30.44%	lr:0.000587
Ep: 3/48	It: 7501/8134	batch_loss: 3.7951	batch_accuracy: 31.69%	lr:0.000589
Ep: 3/48	It: 7551/8134	batch_loss: 3.8841	batch_accuracy: 31.23%	lr:0.000590
Ep: 3/48	It: 7601/8134	batch_loss: 3.7917	batch_accuracy: 31.32%	lr:0.000591
Ep: 3/48	It: 7651/8134	batch_loss: 3.8381	batch_accuracy: 31.71%	lr:0.000592
Ep: 3/48	It: 7701/8134	batch_loss: 3.7532	batch_accuracy: 33.11%	lr:0.000593
Ep: 3/48	It: 7751/8134	batch_loss: 3.8209	batch_accuracy: 32.01%	lr:0.000595
Ep: 3/48	It: 7801/8134	batch_loss: 3.8017	batch_accuracy: 31.25%	lr:0.000596
Ep: 3/48	It: 7851/8134	batch_loss: 3.7644	batch_accuracy: 33.06%	lr:0.000597
Ep: 3/48	It: 7901/8134	batch_loss: 3.8481	batch_accuracy: 31.93%	lr:0.000598
Ep: 3/48	It: 7951/8134	batch_loss: 3.8571	batch_accuracy: 31.88%	lr:0.000600
Ep: 3/48	It: 8001/8134	batch_loss: 3.7871	batch_accuracy: 32.74%	lr:0.000601
Ep: 3/48	It: 8051/8134	batch_loss: 3.8281	batch_accuracy: 31.86%	lr:0.000602
Ep: 3/48	It: 8101/8134	batch_loss: 3.8588	batch_accuracy: 31.91%	lr:0.000603
Ep: 3/48	It: 8134/8134	batch_loss: 3.9078	batch_accuracy: 30.98%	lr:0.000604


Generated text for input text "You" is:
You,,, and the number of people in the United States (19), theorists are interested in order to understand the relationship between social and health services in this area. In the United States, many countries are interested in the United States, which have changed, in the United States, and are likely to be more likely to be inadequately. It is not always necessary that there are many factors that may be associated with health care providers. This article reports on the epidemiology of the prevalence of hypertension, the incidence of asthma, and management of chronic diseases of the illness, the risk of the morbidity and mortality in this population of pediatricians. This article reviews the epidemiology of asthma, including epidemiology, clinical manifestations, and prevention of these diseases. The study was conducted in all patients with acute asthma. Methods: In this study, we analyzed the incidence of hypertension, diabetes, heart failure, heart failure, and heart failure (HF) with age. In the study, patients with TSH, TSH, and CB were divided into three groups: those who received HF and HF or HF, and control groups (P = .04). The TSH was significantly more frequent in HF (P <


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 4/48	It: 1/8134	batch_loss: 3.8175	batch_accuracy: 31.25%	lr:0.000604
Ep: 4/48	It: 51/8134	batch_loss: 3.7239	batch_accuracy: 32.96%	lr:0.000605
Ep: 4/48	It: 101/8134	batch_loss: 3.8062	batch_accuracy: 32.76%	lr:0.000606
Ep: 4/48	It: 151/8134	batch_loss: 3.7059	batch_accuracy: 33.69%	lr:0.000608
Ep: 4/48	It: 201/8134	batch_loss: 3.8686	batch_accuracy: 30.86%	lr:0.000609
Ep: 4/48	It: 251/8134	batch_loss: 3.6878	batch_accuracy: 33.64%	lr:0.000610
Ep: 4/48	It: 301/8134	batch_loss: 3.8237	batch_accuracy: 32.32%	lr:0.000611
Ep: 4/48	It: 351/8134	batch_loss: 3.8282	batch_accuracy: 32.13%	lr:0.000613
Ep: 4/48	It: 401/8134	batch_loss: 3.7156	batch_accuracy: 32.15%	lr:0.000614
Ep: 4/48	It: 451/8134	batch_loss: 3.8759	batch_accuracy: 30.69%	lr:0.000615
Ep: 4/48	It: 501/8134	batch_loss: 3.7507	batch_accuracy: 32.06%	lr:0.000616
Ep: 4/48	It: 551/8134	batch_loss: 3.7605	batch_accuracy: 32.93%	lr:0.000617
Ep: 4/48	It: 601/8134	batch_loss: 3.7791	batch_accuracy: 32.25%	lr:0.000619
Ep: 4/48	It: 651/8134	batch_loss: 3.9599	batch_accuracy: 29.71%	lr:0.000620
Ep: 4/48	It: 701/8134	batch_loss: 4.0245	batch_accuracy: 29.81%	lr:0.000621
Ep: 4/48	It: 751/8134	batch_loss: 3.7174	batch_accuracy: 32.57%	lr:0.000622
Ep: 4/48	It: 801/8134	batch_loss: 3.7527	batch_accuracy: 33.13%	lr:0.000623
Ep: 4/48	It: 851/8134	batch_loss: 3.8668	batch_accuracy: 31.52%	lr:0.000625
Ep: 4/48	It: 901/8134	batch_loss: 3.8916	batch_accuracy: 30.88%	lr:0.000626
Ep: 4/48	It: 951/8134	batch_loss: 3.8518	batch_accuracy: 31.52%	lr:0.000627
Ep: 4/48	It: 1001/8134	batch_loss: 3.8241	batch_accuracy: 31.52%	lr:0.000628
Ep: 4/48	It: 1051/8134	batch_loss: 3.7610	batch_accuracy: 32.25%	lr:0.000630
Ep: 4/48	It: 1101/8134	batch_loss: 3.8114	batch_accuracy: 32.59%	lr:0.000631
Ep: 4/48	It: 1151/8134	batch_loss: 3.8400	batch_accuracy: 31.71%	lr:0.000632
Ep: 4/48	It: 1201/8134	batch_loss: 3.7922	batch_accuracy: 32.25%	lr:0.000633
Ep: 4/48	It: 1251/8134	batch_loss: 3.8235	batch_accuracy: 31.79%	lr:0.000634
Ep: 4/48	It: 1301/8134	batch_loss: 3.7134	batch_accuracy: 33.57%	lr:0.000636
Ep: 4/48	It: 1351/8134	batch_loss: 3.7518	batch_accuracy: 33.50%	lr:0.000637
Ep: 4/48	It: 1401/8134	batch_loss: 3.6756	batch_accuracy: 34.45%	lr:0.000638
Ep: 4/48	It: 1451/8134	batch_loss: 3.8934	batch_accuracy: 31.15%	lr:0.000639
Ep: 4/48	It: 1501/8134	batch_loss: 3.8044	batch_accuracy: 31.03%	lr:0.000641
Ep: 4/48	It: 1551/8134	batch_loss: 3.7079	batch_accuracy: 32.98%	lr:0.000642
Ep: 4/48	It: 1601/8134	batch_loss: 3.7194	batch_accuracy: 33.06%	lr:0.000643
Ep: 4/48	It: 1651/8134	batch_loss: 3.8498	batch_accuracy: 33.01%	lr:0.000644
Ep: 4/48	It: 1701/8134	batch_loss: 3.8530	batch_accuracy: 31.69%	lr:0.000645
Ep: 4/48	It: 1751/8134	batch_loss: 3.7195	batch_accuracy: 33.06%	lr:0.000647
Ep: 4/48	It: 1801/8134	batch_loss: 3.9843	batch_accuracy: 29.30%	lr:0.000648
Ep: 4/48	It: 1851/8134	batch_loss: 3.7132	batch_accuracy: 32.91%	lr:0.000649
Ep: 4/48	It: 1901/8134	batch_loss: 3.7582	batch_accuracy: 33.96%	lr:0.000650
Ep: 4/48	It: 1951/8134	batch_loss: 3.8028	batch_accuracy: 32.47%	lr:0.000651
Ep: 4/48	It: 2001/8134	batch_loss: 3.8360	batch_accuracy: 31.57%	lr:0.000653
Ep: 4/48	It: 2051/8134	batch_loss: 3.8119	batch_accuracy: 31.81%	lr:0.000654
Ep: 4/48	It: 2101/8134	batch_loss: 3.7732	batch_accuracy: 33.42%	lr:0.000655
Ep: 4/48	It: 2151/8134	batch_loss: 3.7738	batch_accuracy: 32.23%	lr:0.000656
Ep: 4/48	It: 2201/8134	batch_loss: 3.6943	batch_accuracy: 34.30%	lr:0.000658
Ep: 4/48	It: 2251/8134	batch_loss: 3.7810	batch_accuracy: 33.08%	lr:0.000659
Ep: 4/48	It: 2301/8134	batch_loss: 3.8115	batch_accuracy: 32.52%	lr:0.000660
Ep: 4/48	It: 2351/8134	batch_loss: 3.7590	batch_accuracy: 32.30%	lr:0.000661
Ep: 4/48	It: 2401/8134	batch_loss: 3.6982	batch_accuracy: 33.03%	lr:0.000662
Ep: 4/48	It: 2451/8134	batch_loss: 3.8399	batch_accuracy: 31.05%	lr:0.000664
Ep: 4/48	It: 2501/8134	batch_loss: 3.7488	batch_accuracy: 33.11%	lr:0.000665
Ep: 4/48	It: 2551/8134	batch_loss: 3.6753	batch_accuracy: 33.23%	lr:0.000666
Ep: 4/48	It: 2601/8134	batch_loss: 3.5639	batch_accuracy: 35.11%	lr:0.000667
Ep: 4/48	It: 2651/8134	batch_loss: 3.7196	batch_accuracy: 33.57%	lr:0.000669
Ep: 4/48	It: 2701/8134	batch_loss: 3.7722	batch_accuracy: 32.35%	lr:0.000670
Ep: 4/48	It: 2751/8134	batch_loss: 3.7479	batch_accuracy: 33.81%	lr:0.000671
Ep: 4/48	It: 2801/8134	batch_loss: 3.7428	batch_accuracy: 32.59%	lr:0.000672
Ep: 4/48	It: 2851/8134	batch_loss: 3.6144	batch_accuracy: 34.47%	lr:0.000673
Ep: 4/48	It: 2901/8134	batch_loss: 3.7305	batch_accuracy: 33.76%	lr:0.000675
Ep: 4/48	It: 2951/8134	batch_loss: 3.8682	batch_accuracy: 30.88%	lr:0.000676
Ep: 4/48	It: 3001/8134	batch_loss: 3.7279	batch_accuracy: 32.32%	lr:0.000677
Ep: 4/48	It: 3051/8134	batch_loss: 3.6955	batch_accuracy: 34.30%	lr:0.000678
Ep: 4/48	It: 3101/8134	batch_loss: 3.7235	batch_accuracy: 32.10%	lr:0.000679
Ep: 4/48	It: 3151/8134	batch_loss: 3.7427	batch_accuracy: 32.45%	lr:0.000681
Ep: 4/48	It: 3201/8134	batch_loss: 3.7391	batch_accuracy: 33.08%	lr:0.000682
Ep: 4/48	It: 3251/8134	batch_loss: 3.9009	batch_accuracy: 30.49%	lr:0.000683
Ep: 4/48	It: 3301/8134	batch_loss: 3.7261	batch_accuracy: 32.52%	lr:0.000684
Ep: 4/48	It: 3351/8134	batch_loss: 3.7453	batch_accuracy: 33.57%	lr:0.000686
Ep: 4/48	It: 3401/8134	batch_loss: 3.8642	batch_accuracy: 32.96%	lr:0.000687
Ep: 4/48	It: 3451/8134	batch_loss: 3.7080	batch_accuracy: 33.18%	lr:0.000688
Ep: 4/48	It: 3501/8134	batch_loss: 3.7992	batch_accuracy: 31.54%	lr:0.000689
Ep: 4/48	It: 3551/8134	batch_loss: 3.7584	batch_accuracy: 32.76%	lr:0.000690
Ep: 4/48	It: 3601/8134	batch_loss: 3.7457	batch_accuracy: 33.18%	lr:0.000692
Ep: 4/48	It: 3651/8134	batch_loss: 3.6792	batch_accuracy: 33.13%	lr:0.000693
Ep: 4/48	It: 3701/8134	batch_loss: 3.6669	batch_accuracy: 34.18%	lr:0.000694
Ep: 4/48	It: 3751/8134	batch_loss: 3.7116	batch_accuracy: 33.67%	lr:0.000695
Ep: 4/48	It: 3801/8134	batch_loss: 3.6533	batch_accuracy: 33.81%	lr:0.000697
Ep: 4/48	It: 3851/8134	batch_loss: 3.7842	batch_accuracy: 31.69%	lr:0.000698
Ep: 4/48	It: 3901/8134	batch_loss: 3.8390	batch_accuracy: 31.37%	lr:0.000699
Ep: 4/48	It: 3951/8134	batch_loss: 3.7314	batch_accuracy: 32.20%	lr:0.000700
Ep: 4/48	It: 4001/8134	batch_loss: 3.6613	batch_accuracy: 33.40%	lr:0.000701
Ep: 4/48	It: 4051/8134	batch_loss: 3.7068	batch_accuracy: 32.86%	lr:0.000703
Ep: 4/48	It: 4101/8134	batch_loss: 3.7395	batch_accuracy: 32.45%	lr:0.000704
Ep: 4/48	It: 4151/8134	batch_loss: 3.7603	batch_accuracy: 32.01%	lr:0.000705
Ep: 4/48	It: 4201/8134	batch_loss: 3.7600	batch_accuracy: 32.93%	lr:0.000706
Ep: 4/48	It: 4251/8134	batch_loss: 3.7728	batch_accuracy: 33.20%	lr:0.000707
Ep: 4/48	It: 4301/8134	batch_loss: 3.8196	batch_accuracy: 31.88%	lr:0.000709
Ep: 4/48	It: 4351/8134	batch_loss: 3.6666	batch_accuracy: 33.86%	lr:0.000710
Ep: 4/48	It: 4401/8134	batch_loss: 3.7804	batch_accuracy: 31.05%	lr:0.000711
Ep: 4/48	It: 4451/8134	batch_loss: 3.7699	batch_accuracy: 31.96%	lr:0.000712
Ep: 4/48	It: 4501/8134	batch_loss: 3.7321	batch_accuracy: 33.40%	lr:0.000714
Ep: 4/48	It: 4551/8134	batch_loss: 3.7965	batch_accuracy: 32.06%	lr:0.000715
Ep: 4/48	It: 4601/8134	batch_loss: 3.8146	batch_accuracy: 32.40%	lr:0.000716
Ep: 4/48	It: 4651/8134	batch_loss: 3.8782	batch_accuracy: 30.74%	lr:0.000717
Ep: 4/48	It: 4701/8134	batch_loss: 3.6458	batch_accuracy: 33.62%	lr:0.000718
Ep: 4/48	It: 4751/8134	batch_loss: 3.7641	batch_accuracy: 32.91%	lr:0.000720
Ep: 4/48	It: 4801/8134	batch_loss: 3.7676	batch_accuracy: 32.15%	lr:0.000721
Ep: 4/48	It: 4851/8134	batch_loss: 3.7110	batch_accuracy: 33.37%	lr:0.000722
Ep: 4/48	It: 4901/8134	batch_loss: 3.7591	batch_accuracy: 32.84%	lr:0.000723
Ep: 4/48	It: 4951/8134	batch_loss: 3.7202	batch_accuracy: 33.25%	lr:0.000725
Ep: 4/48	It: 5001/8134	batch_loss: 3.8179	batch_accuracy: 31.37%	lr:0.000726
Ep: 4/48	It: 5051/8134	batch_loss: 3.8080	batch_accuracy: 32.74%	lr:0.000727
Ep: 4/48	It: 5101/8134	batch_loss: 3.6187	batch_accuracy: 34.52%	lr:0.000728
Ep: 4/48	It: 5151/8134	batch_loss: 3.6874	batch_accuracy: 33.52%	lr:0.000729
Ep: 4/48	It: 5201/8134	batch_loss: 3.8135	batch_accuracy: 32.32%	lr:0.000731
Ep: 4/48	It: 5251/8134	batch_loss: 3.6669	batch_accuracy: 33.35%	lr:0.000732
Ep: 4/48	It: 5301/8134	batch_loss: 3.6736	batch_accuracy: 33.89%	lr:0.000733
Ep: 4/48	It: 5351/8134	batch_loss: 3.9000	batch_accuracy: 30.69%	lr:0.000734
Ep: 4/48	It: 5401/8134	batch_loss: 3.7366	batch_accuracy: 33.62%	lr:0.000735
Ep: 4/48	It: 5451/8134	batch_loss: 3.8090	batch_accuracy: 31.23%	lr:0.000737
Ep: 4/48	It: 5501/8134	batch_loss: 3.8898	batch_accuracy: 31.69%	lr:0.000738
Ep: 4/48	It: 5551/8134	batch_loss: 3.6923	batch_accuracy: 33.67%	lr:0.000739
Ep: 4/48	It: 5601/8134	batch_loss: 3.7718	batch_accuracy: 32.79%	lr:0.000740
Ep: 4/48	It: 5651/8134	batch_loss: 3.7940	batch_accuracy: 31.91%	lr:0.000742
Ep: 4/48	It: 5701/8134	batch_loss: 3.6917	batch_accuracy: 33.69%	lr:0.000743
Ep: 4/48	It: 5751/8134	batch_loss: 3.7499	batch_accuracy: 33.25%	lr:0.000744
Ep: 4/48	It: 5801/8134	batch_loss: 3.6566	batch_accuracy: 33.67%	lr:0.000745
Ep: 4/48	It: 5851/8134	batch_loss: 3.7745	batch_accuracy: 32.20%	lr:0.000746
Ep: 4/48	It: 5901/8134	batch_loss: 3.6414	batch_accuracy: 34.38%	lr:0.000748
Ep: 4/48	It: 5951/8134	batch_loss: 3.6710	batch_accuracy: 33.74%	lr:0.000749
Ep: 4/48	It: 6001/8134	batch_loss: 3.7071	batch_accuracy: 33.50%	lr:0.000750
Ep: 4/48	It: 6051/8134	batch_loss: 3.7755	batch_accuracy: 32.42%	lr:0.000751
Ep: 4/48	It: 6101/8134	batch_loss: 3.5202	batch_accuracy: 36.47%	lr:0.000753
Ep: 4/48	It: 6151/8134	batch_loss: 3.6497	batch_accuracy: 34.25%	lr:0.000754
Ep: 4/48	It: 6201/8134	batch_loss: 3.7840	batch_accuracy: 32.03%	lr:0.000755
Ep: 4/48	It: 6251/8134	batch_loss: 3.6819	batch_accuracy: 32.79%	lr:0.000756
Ep: 4/48	It: 6301/8134	batch_loss: 3.6634	batch_accuracy: 33.15%	lr:0.000757
Ep: 4/48	It: 6351/8134	batch_loss: 3.7403	batch_accuracy: 32.62%	lr:0.000759
Ep: 4/48	It: 6401/8134	batch_loss: 3.7652	batch_accuracy: 32.30%	lr:0.000760
Ep: 4/48	It: 6451/8134	batch_loss: 3.7673	batch_accuracy: 33.57%	lr:0.000761
Ep: 4/48	It: 6501/8134	batch_loss: 3.6853	batch_accuracy: 33.59%	lr:0.000762
Ep: 4/48	It: 6551/8134	batch_loss: 3.8228	batch_accuracy: 31.54%	lr:0.000763
Ep: 4/48	It: 6601/8134	batch_loss: 3.6600	batch_accuracy: 34.18%	lr:0.000765
Ep: 4/48	It: 6651/8134	batch_loss: 3.7439	batch_accuracy: 32.50%	lr:0.000766
Ep: 4/48	It: 6701/8134	batch_loss: 3.7301	batch_accuracy: 32.54%	lr:0.000767
Ep: 4/48	It: 6751/8134	batch_loss: 3.8185	batch_accuracy: 32.71%	lr:0.000768
Ep: 4/48	It: 6801/8134	batch_loss: 3.8032	batch_accuracy: 32.35%	lr:0.000770
Ep: 4/48	It: 6851/8134	batch_loss: 3.7960	batch_accuracy: 32.01%	lr:0.000771
Ep: 4/48	It: 6901/8134	batch_loss: 3.6666	batch_accuracy: 33.40%	lr:0.000772
Ep: 4/48	It: 6951/8134	batch_loss: 3.7886	batch_accuracy: 33.08%	lr:0.000773
Ep: 4/48	It: 7001/8134	batch_loss: 3.7713	batch_accuracy: 32.69%	lr:0.000774
Ep: 4/48	It: 7051/8134	batch_loss: 3.7466	batch_accuracy: 33.25%	lr:0.000776
Ep: 4/48	It: 7101/8134	batch_loss: 3.7222	batch_accuracy: 33.08%	lr:0.000777
Ep: 4/48	It: 7151/8134	batch_loss: 3.6790	batch_accuracy: 34.45%	lr:0.000778
Ep: 4/48	It: 7201/8134	batch_loss: 3.6533	batch_accuracy: 34.81%	lr:0.000779
Ep: 4/48	It: 7251/8134	batch_loss: 3.8013	batch_accuracy: 33.23%	lr:0.000781
Ep: 4/48	It: 7301/8134	batch_loss: 3.7927	batch_accuracy: 31.98%	lr:0.000782
Ep: 4/48	It: 7351/8134	batch_loss: 3.8006	batch_accuracy: 32.06%	lr:0.000783
Ep: 4/48	It: 7401/8134	batch_loss: 3.8958	batch_accuracy: 31.20%	lr:0.000784
Ep: 4/48	It: 7451/8134	batch_loss: 3.7773	batch_accuracy: 32.89%	lr:0.000785
Ep: 4/48	It: 7501/8134	batch_loss: 3.7717	batch_accuracy: 32.62%	lr:0.000787
Ep: 4/48	It: 7551/8134	batch_loss: 3.6349	batch_accuracy: 33.74%	lr:0.000788
Ep: 4/48	It: 7601/8134	batch_loss: 3.6620	batch_accuracy: 33.62%	lr:0.000789
Ep: 4/48	It: 7651/8134	batch_loss: 3.8560	batch_accuracy: 31.57%	lr:0.000790
Ep: 4/48	It: 7701/8134	batch_loss: 3.6124	batch_accuracy: 34.03%	lr:0.000791
Ep: 4/48	It: 7751/8134	batch_loss: 3.7201	batch_accuracy: 32.47%	lr:0.000793
Ep: 4/48	It: 7801/8134	batch_loss: 3.7418	batch_accuracy: 33.33%	lr:0.000794
Ep: 4/48	It: 7851/8134	batch_loss: 3.6562	batch_accuracy: 33.74%	lr:0.000795
Ep: 4/48	It: 7901/8134	batch_loss: 3.7390	batch_accuracy: 31.81%	lr:0.000796
Ep: 4/48	It: 7951/8134	batch_loss: 3.6580	batch_accuracy: 33.72%	lr:0.000798
Ep: 4/48	It: 8001/8134	batch_loss: 3.6387	batch_accuracy: 33.28%	lr:0.000799
Ep: 4/48	It: 8051/8134	batch_loss: 3.6525	batch_accuracy: 33.25%	lr:0.000800
Ep: 4/48	It: 8101/8134	batch_loss: 3.6603	batch_accuracy: 34.06%	lr:0.000801
Ep: 4/48	It: 8134/8134	batch_loss: 3.7190	batch_accuracy: 32.98%	lr:0.000802


Generated text for input text "You" is:
You and to provide a scientific framework to improve the use of these systems.

The research was undertaken to address the problem of theories and to describe the role of thesis in thesis.

METHODS
This review focuses on theories of research. Authorized review of theories of the literature and the literature was conducted.


RESULTS
This research is based on the analysis of literature on the authors' findings.


Findings
The results of this study were analysed using questionnaires.


RESULTS
The questionnaire was administered, with 350 respondents (mean age 12.4 years, range, mean age: 4.8 years, range, 7.9 years, 1.5 years). The questionnaire was administered to the questionnaire and questionnaires, the questionnaire, the questionnaire, the Questionnaire (QOLQ) and the QOLQ questionnaire. Results The median age was 43.3 years (range: 1-9) years).


RESULTS
Of the 129 participants, 138 (51.6%) were included in the analysis. A total of 125,78 (76.5%) children and 57 (52.


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 5/48	It: 1/8134	batch_loss: 3.5748	batch_accuracy: 34.30%	lr:0.000802
Ep: 5/48	It: 51/8134	batch_loss: 3.7185	batch_accuracy: 32.37%	lr:0.000803
Ep: 5/48	It: 101/8134	batch_loss: 3.7223	batch_accuracy: 32.71%	lr:0.000804
Ep: 5/48	It: 151/8134	batch_loss: 3.6328	batch_accuracy: 34.23%	lr:0.000806
Ep: 5/48	It: 201/8134	batch_loss: 3.7367	batch_accuracy: 33.94%	lr:0.000807
Ep: 5/48	It: 251/8134	batch_loss: 3.6789	batch_accuracy: 33.42%	lr:0.000808
Ep: 5/48	It: 301/8134	batch_loss: 3.7229	batch_accuracy: 33.01%	lr:0.000809
Ep: 5/48	It: 351/8134	batch_loss: 3.7900	batch_accuracy: 32.91%	lr:0.000811
Ep: 5/48	It: 401/8134	batch_loss: 3.6233	batch_accuracy: 34.25%	lr:0.000812
Ep: 5/48	It: 451/8134	batch_loss: 3.6842	batch_accuracy: 33.03%	lr:0.000813
Ep: 5/48	It: 501/8134	batch_loss: 3.6630	batch_accuracy: 33.96%	lr:0.000814
Ep: 5/48	It: 551/8134	batch_loss: 3.6686	batch_accuracy: 32.42%	lr:0.000815
Ep: 5/48	It: 601/8134	batch_loss: 3.6054	batch_accuracy: 35.67%	lr:0.000817
Ep: 5/48	It: 651/8134	batch_loss: 3.7888	batch_accuracy: 32.18%	lr:0.000818
Ep: 5/48	It: 701/8134	batch_loss: 3.7986	batch_accuracy: 31.42%	lr:0.000819
Ep: 5/48	It: 751/8134	batch_loss: 3.7330	batch_accuracy: 32.47%	lr:0.000820
Ep: 5/48	It: 801/8134	batch_loss: 3.7607	batch_accuracy: 31.96%	lr:0.000821
Ep: 5/48	It: 851/8134	batch_loss: 3.6333	batch_accuracy: 35.16%	lr:0.000823
Ep: 5/48	It: 901/8134	batch_loss: 3.8194	batch_accuracy: 31.59%	lr:0.000824
Ep: 5/48	It: 951/8134	batch_loss: 3.6500	batch_accuracy: 34.47%	lr:0.000825
Ep: 5/48	It: 1001/8134	batch_loss: 3.7737	batch_accuracy: 32.89%	lr:0.000826
Ep: 5/48	It: 1051/8134	batch_loss: 3.6446	batch_accuracy: 33.35%	lr:0.000828
Ep: 5/48	It: 1101/8134	batch_loss: 3.7224	batch_accuracy: 34.01%	lr:0.000829
Ep: 5/48	It: 1151/8134	batch_loss: 3.7976	batch_accuracy: 31.64%	lr:0.000830
Ep: 5/48	It: 1201/8134	batch_loss: 3.6341	batch_accuracy: 33.15%	lr:0.000831
Ep: 5/48	It: 1251/8134	batch_loss: 3.6508	batch_accuracy: 32.84%	lr:0.000832
Ep: 5/48	It: 1301/8134	batch_loss: 3.6927	batch_accuracy: 33.98%	lr:0.000834
Ep: 5/48	It: 1351/8134	batch_loss: 3.7366	batch_accuracy: 32.42%	lr:0.000835
Ep: 5/48	It: 1401/8134	batch_loss: 3.6928	batch_accuracy: 33.52%	lr:0.000836
Ep: 5/48	It: 1451/8134	batch_loss: 3.7303	batch_accuracy: 33.50%	lr:0.000837
Ep: 5/48	It: 1501/8134	batch_loss: 3.7484	batch_accuracy: 33.20%	lr:0.000839
Ep: 5/48	It: 1551/8134	batch_loss: 3.6865	batch_accuracy: 33.54%	lr:0.000840
Ep: 5/48	It: 1601/8134	batch_loss: 3.6509	batch_accuracy: 34.01%	lr:0.000841
Ep: 5/48	It: 1651/8134	batch_loss: 3.6036	batch_accuracy: 35.13%	lr:0.000842
Ep: 5/48	It: 1701/8134	batch_loss: 3.7149	batch_accuracy: 33.81%	lr:0.000843
Ep: 5/48	It: 1751/8134	batch_loss: 3.6366	batch_accuracy: 34.03%	lr:0.000845
Ep: 5/48	It: 1801/8134	batch_loss: 3.7067	batch_accuracy: 33.96%	lr:0.000846
Ep: 5/48	It: 1851/8134	batch_loss: 3.7558	batch_accuracy: 32.81%	lr:0.000847
Ep: 5/48	It: 1901/8134	batch_loss: 3.6343	batch_accuracy: 34.20%	lr:0.000848
Ep: 5/48	It: 1951/8134	batch_loss: 3.7221	batch_accuracy: 33.11%	lr:0.000849
Ep: 5/48	It: 2001/8134	batch_loss: 3.6682	batch_accuracy: 33.52%	lr:0.000851
Ep: 5/48	It: 2051/8134	batch_loss: 3.7446	batch_accuracy: 32.20%	lr:0.000852
Ep: 5/48	It: 2101/8134	batch_loss: 3.6164	batch_accuracy: 33.72%	lr:0.000853
Ep: 5/48	It: 2151/8134	batch_loss: 3.7654	batch_accuracy: 32.25%	lr:0.000854
Ep: 5/48	It: 2201/8134	batch_loss: 3.6591	batch_accuracy: 34.23%	lr:0.000856
Ep: 5/48	It: 2251/8134	batch_loss: 3.6285	batch_accuracy: 34.45%	lr:0.000857
Ep: 5/48	It: 2301/8134	batch_loss: 3.6668	batch_accuracy: 33.25%	lr:0.000858
Ep: 5/48	It: 2351/8134	batch_loss: 3.7167	batch_accuracy: 34.13%	lr:0.000859
Ep: 5/48	It: 2401/8134	batch_loss: 3.7155	batch_accuracy: 33.15%	lr:0.000860
Ep: 5/48	It: 2451/8134	batch_loss: 3.6682	batch_accuracy: 33.11%	lr:0.000862
Ep: 5/48	It: 2501/8134	batch_loss: 3.6880	batch_accuracy: 32.37%	lr:0.000863
Ep: 5/48	It: 2551/8134	batch_loss: 3.6743	batch_accuracy: 32.81%	lr:0.000864
Ep: 5/48	It: 2601/8134	batch_loss: 3.7225	batch_accuracy: 31.59%	lr:0.000865
Ep: 5/48	It: 2651/8134	batch_loss: 3.6342	batch_accuracy: 34.40%	lr:0.000867
Ep: 5/48	It: 2701/8134	batch_loss: 3.5095	batch_accuracy: 35.99%	lr:0.000868
Ep: 5/48	It: 2751/8134	batch_loss: 3.7930	batch_accuracy: 31.69%	lr:0.000869
Ep: 5/48	It: 2801/8134	batch_loss: 3.6052	batch_accuracy: 34.47%	lr:0.000870
Ep: 5/48	It: 2851/8134	batch_loss: 3.6115	batch_accuracy: 33.30%	lr:0.000871
Ep: 5/48	It: 2901/8134	batch_loss: 3.6340	batch_accuracy: 34.38%	lr:0.000873
Ep: 5/48	It: 2951/8134	batch_loss: 3.5503	batch_accuracy: 35.69%	lr:0.000874
Ep: 5/48	It: 3001/8134	batch_loss: 3.7321	batch_accuracy: 32.50%	lr:0.000875
Ep: 5/48	It: 3051/8134	batch_loss: 3.7263	batch_accuracy: 33.01%	lr:0.000876
Ep: 5/48	It: 3101/8134	batch_loss: 3.7195	batch_accuracy: 34.16%	lr:0.000877
Ep: 5/48	It: 3151/8134	batch_loss: 3.7626	batch_accuracy: 32.91%	lr:0.000879
Ep: 5/48	It: 3201/8134	batch_loss: 3.7737	batch_accuracy: 32.25%	lr:0.000880
Ep: 5/48	It: 3251/8134	batch_loss: 3.6279	batch_accuracy: 34.20%	lr:0.000881
Ep: 5/48	It: 3301/8134	batch_loss: 3.7185	batch_accuracy: 32.98%	lr:0.000882
Ep: 5/48	It: 3351/8134	batch_loss: 3.7237	batch_accuracy: 33.84%	lr:0.000884
Ep: 5/48	It: 3401/8134	batch_loss: 3.6466	batch_accuracy: 34.69%	lr:0.000885
Ep: 5/48	It: 3451/8134	batch_loss: 3.7528	batch_accuracy: 33.15%	lr:0.000886
Ep: 5/48	It: 3501/8134	batch_loss: 3.6063	batch_accuracy: 35.16%	lr:0.000887
Ep: 5/48	It: 3551/8134	batch_loss: 3.6658	batch_accuracy: 33.62%	lr:0.000888
Ep: 5/48	It: 3601/8134	batch_loss: 3.7963	batch_accuracy: 32.28%	lr:0.000890
Ep: 5/48	It: 3651/8134	batch_loss: 3.6823	batch_accuracy: 33.33%	lr:0.000891
Ep: 5/48	It: 3701/8134	batch_loss: 3.7178	batch_accuracy: 33.42%	lr:0.000892
Ep: 5/48	It: 3751/8134	batch_loss: 3.6687	batch_accuracy: 33.47%	lr:0.000893
Ep: 5/48	It: 3801/8134	batch_loss: 3.7223	batch_accuracy: 32.69%	lr:0.000895
Ep: 5/48	It: 3851/8134	batch_loss: 3.6703	batch_accuracy: 33.06%	lr:0.000896
Ep: 5/48	It: 3901/8134	batch_loss: 3.7774	batch_accuracy: 32.74%	lr:0.000897
Ep: 5/48	It: 3951/8134	batch_loss: 3.7370	batch_accuracy: 33.28%	lr:0.000898
Ep: 5/48	It: 4001/8134	batch_loss: 3.7325	batch_accuracy: 33.40%	lr:0.000899
Ep: 5/48	It: 4051/8134	batch_loss: 3.6050	batch_accuracy: 35.13%	lr:0.000901
Ep: 5/48	It: 4101/8134	batch_loss: 3.7223	batch_accuracy: 33.84%	lr:0.000902
Ep: 5/48	It: 4151/8134	batch_loss: 3.6536	batch_accuracy: 34.62%	lr:0.000903
Ep: 5/48	It: 4201/8134	batch_loss: 3.7954	batch_accuracy: 32.67%	lr:0.000904
Ep: 5/48	It: 4251/8134	batch_loss: 3.6522	batch_accuracy: 34.40%	lr:0.000905
Ep: 5/48	It: 4301/8134	batch_loss: 3.7211	batch_accuracy: 33.18%	lr:0.000907
Ep: 5/48	It: 4351/8134	batch_loss: 3.7399	batch_accuracy: 33.11%	lr:0.000908
Ep: 5/48	It: 4401/8134	batch_loss: 3.6106	batch_accuracy: 34.16%	lr:0.000909
Ep: 5/48	It: 4451/8134	batch_loss: 3.6035	batch_accuracy: 34.25%	lr:0.000910
Ep: 5/48	It: 4501/8134	batch_loss: 3.7482	batch_accuracy: 33.35%	lr:0.000912
Ep: 5/48	It: 4551/8134	batch_loss: 3.6487	batch_accuracy: 34.25%	lr:0.000913
Ep: 5/48	It: 4601/8134	batch_loss: 3.5911	batch_accuracy: 35.62%	lr:0.000914
Ep: 5/48	It: 4651/8134	batch_loss: 3.6436	batch_accuracy: 33.25%	lr:0.000915
Ep: 5/48	It: 4701/8134	batch_loss: 3.5801	batch_accuracy: 35.72%	lr:0.000916
Ep: 5/48	It: 4751/8134	batch_loss: 3.6338	batch_accuracy: 34.38%	lr:0.000918
Ep: 5/48	It: 4801/8134	batch_loss: 3.5832	batch_accuracy: 34.55%	lr:0.000919
Ep: 5/48	It: 4851/8134	batch_loss: 3.6796	batch_accuracy: 35.42%	lr:0.000920
Ep: 5/48	It: 4901/8134	batch_loss: 3.6284	batch_accuracy: 34.35%	lr:0.000921
Ep: 5/48	It: 4951/8134	batch_loss: 3.6154	batch_accuracy: 33.69%	lr:0.000923
Ep: 5/48	It: 5001/8134	batch_loss: 3.6870	batch_accuracy: 33.62%	lr:0.000924
Ep: 5/48	It: 5051/8134	batch_loss: 3.7069	batch_accuracy: 33.91%	lr:0.000925
Ep: 5/48	It: 5101/8134	batch_loss: 3.5943	batch_accuracy: 34.81%	lr:0.000926
Ep: 5/48	It: 5151/8134	batch_loss: 3.6671	batch_accuracy: 34.28%	lr:0.000927
Ep: 5/48	It: 5201/8134	batch_loss: 3.4924	batch_accuracy: 35.01%	lr:0.000929
Ep: 5/48	It: 5251/8134	batch_loss: 3.6160	batch_accuracy: 34.89%	lr:0.000930
Ep: 5/48	It: 5301/8134	batch_loss: 3.7324	batch_accuracy: 33.62%	lr:0.000931
Ep: 5/48	It: 5351/8134	batch_loss: 3.5169	batch_accuracy: 35.72%	lr:0.000932
Ep: 5/48	It: 5401/8134	batch_loss: 3.6966	batch_accuracy: 33.79%	lr:0.000933
Ep: 5/48	It: 5451/8134	batch_loss: 3.7505	batch_accuracy: 33.37%	lr:0.000935
Ep: 5/48	It: 5501/8134	batch_loss: 3.7590	batch_accuracy: 33.01%	lr:0.000936
Ep: 5/48	It: 5551/8134	batch_loss: 3.8487	batch_accuracy: 31.71%	lr:0.000937
Ep: 5/48	It: 5601/8134	batch_loss: 3.7524	batch_accuracy: 32.86%	lr:0.000938
Ep: 5/48	It: 5651/8134	batch_loss: 3.6888	batch_accuracy: 34.45%	lr:0.000940
Ep: 5/48	It: 5701/8134	batch_loss: 3.7469	batch_accuracy: 32.69%	lr:0.000941
Ep: 5/48	It: 5751/8134	batch_loss: 3.5953	batch_accuracy: 35.55%	lr:0.000942
Ep: 5/48	It: 5801/8134	batch_loss: 3.7004	batch_accuracy: 32.76%	lr:0.000943
Ep: 5/48	It: 5851/8134	batch_loss: 3.5772	batch_accuracy: 35.06%	lr:0.000944
Ep: 5/48	It: 5901/8134	batch_loss: 3.5774	batch_accuracy: 34.72%	lr:0.000946
Ep: 5/48	It: 5951/8134	batch_loss: 3.6280	batch_accuracy: 35.03%	lr:0.000947
Ep: 5/48	It: 6001/8134	batch_loss: 3.6958	batch_accuracy: 34.23%	lr:0.000948
Ep: 5/48	It: 6051/8134	batch_loss: 3.6257	batch_accuracy: 33.23%	lr:0.000949
Ep: 5/48	It: 6101/8134	batch_loss: 3.7049	batch_accuracy: 33.25%	lr:0.000951
Ep: 5/48	It: 6151/8134	batch_loss: 3.6342	batch_accuracy: 34.45%	lr:0.000952
Ep: 5/48	It: 6201/8134	batch_loss: 3.6577	batch_accuracy: 34.23%	lr:0.000953
Ep: 5/48	It: 6251/8134	batch_loss: 3.6689	batch_accuracy: 33.79%	lr:0.000954
Ep: 5/48	It: 6301/8134	batch_loss: 3.6202	batch_accuracy: 34.77%	lr:0.000955
Ep: 5/48	It: 6351/8134	batch_loss: 3.7290	batch_accuracy: 32.37%	lr:0.000957
Ep: 5/48	It: 6401/8134	batch_loss: 3.7558	batch_accuracy: 32.93%	lr:0.000958
Ep: 5/48	It: 6451/8134	batch_loss: 3.6418	batch_accuracy: 33.72%	lr:0.000959
Ep: 5/48	It: 6501/8134	batch_loss: 3.6621	batch_accuracy: 33.13%	lr:0.000960
Ep: 5/48	It: 6551/8134	batch_loss: 3.6305	batch_accuracy: 33.64%	lr:0.000961
Ep: 5/48	It: 6601/8134	batch_loss: 3.6048	batch_accuracy: 34.64%	lr:0.000963
Ep: 5/48	It: 6651/8134	batch_loss: 3.6520	batch_accuracy: 33.54%	lr:0.000964
Ep: 5/48	It: 6701/8134	batch_loss: 3.6177	batch_accuracy: 35.03%	lr:0.000965
Ep: 5/48	It: 6751/8134	batch_loss: 3.8286	batch_accuracy: 31.84%	lr:0.000966
Ep: 5/48	It: 6801/8134	batch_loss: 3.6557	batch_accuracy: 33.96%	lr:0.000968
Ep: 5/48	It: 6851/8134	batch_loss: 3.5664	batch_accuracy: 33.94%	lr:0.000969
Ep: 5/48	It: 6901/8134	batch_loss: 3.6643	batch_accuracy: 33.76%	lr:0.000970
Ep: 5/48	It: 6951/8134	batch_loss: 3.4799	batch_accuracy: 35.50%	lr:0.000971
Ep: 5/48	It: 7001/8134	batch_loss: 3.6420	batch_accuracy: 34.86%	lr:0.000972
Ep: 5/48	It: 7051/8134	batch_loss: 3.6272	batch_accuracy: 34.13%	lr:0.000974
Ep: 5/48	It: 7101/8134	batch_loss: 3.7557	batch_accuracy: 32.91%	lr:0.000975
Ep: 5/48	It: 7151/8134	batch_loss: 3.6416	batch_accuracy: 34.64%	lr:0.000976
Ep: 5/48	It: 7201/8134	batch_loss: 3.8300	batch_accuracy: 31.47%	lr:0.000977
Ep: 5/48	It: 7251/8134	batch_loss: 3.6767	batch_accuracy: 33.86%	lr:0.000979
Ep: 5/48	It: 7301/8134	batch_loss: 3.6098	batch_accuracy: 34.50%	lr:0.000980
Ep: 5/48	It: 7351/8134	batch_loss: 3.6344	batch_accuracy: 33.57%	lr:0.000981
Ep: 5/48	It: 7401/8134	batch_loss: 3.6400	batch_accuracy: 34.28%	lr:0.000982
Ep: 5/48	It: 7451/8134	batch_loss: 3.5318	batch_accuracy: 35.11%	lr:0.000983
Ep: 5/48	It: 7501/8134	batch_loss: 3.6864	batch_accuracy: 32.91%	lr:0.000985
Ep: 5/48	It: 7551/8134	batch_loss: 3.6050	batch_accuracy: 34.94%	lr:0.000986
Ep: 5/48	It: 7601/8134	batch_loss: 3.5872	batch_accuracy: 34.84%	lr:0.000987
Ep: 5/48	It: 7651/8134	batch_loss: 3.6511	batch_accuracy: 33.79%	lr:0.000988
Ep: 5/48	It: 7701/8134	batch_loss: 3.6470	batch_accuracy: 34.20%	lr:0.000989
Ep: 5/48	It: 7751/8134	batch_loss: 3.6839	batch_accuracy: 33.28%	lr:0.000991
Ep: 5/48	It: 7801/8134	batch_loss: 3.6487	batch_accuracy: 34.28%	lr:0.000992
Ep: 5/48	It: 7851/8134	batch_loss: 3.6714	batch_accuracy: 34.06%	lr:0.000993
Ep: 5/48	It: 7901/8134	batch_loss: 3.8717	batch_accuracy: 30.83%	lr:0.000994
Ep: 5/48	It: 7951/8134	batch_loss: 3.5878	batch_accuracy: 34.62%	lr:0.000996
Ep: 5/48	It: 8001/8134	batch_loss: 3.5955	batch_accuracy: 35.21%	lr:0.000997
Ep: 5/48	It: 8051/8134	batch_loss: 3.6167	batch_accuracy: 35.03%	lr:0.000998
Ep: 5/48	It: 8101/8134	batch_loss: 3.6089	batch_accuracy: 33.06%	lr:0.000999
Ep: 5/48	It: 8134/8134	batch_loss: 3.5403	batch_accuracy: 34.68%	lr:0.001000


Generated text for input text "You" is:
You-aden-fo-slaudi-fo--funds.
All of the Lago and its relatedness in relation to the Sanita-GG is the first of thesis that it has been in his study is that the Land of the Friendship Law (1993) and his/her (1954) view of the Bajaaūaçaçao’s Martian Law. This is the first, to be a first of the book.
<eot>
<sot>
[The influence of the degree of the action of the dentate gyrus in the tight junctions of the tight junctions].

The article presents a study on the effects of a series of the dentate gyrus and the tight junctions on the luminal gyrus, the cranial nerve in the tight junctions, and the lateral junctions. The tight junctions of the lumina were identified as the tight junctions, which were observed in the anterior cranial nerve and hippoc


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 6/48	It: 1/8134	batch_loss: 3.6564	batch_accuracy: 33.62%	lr:0.001000
Ep: 6/48	It: 51/8134	batch_loss: 3.7238	batch_accuracy: 33.33%	lr:0.001000
Ep: 6/48	It: 101/8134	batch_loss: 3.6763	batch_accuracy: 32.74%	lr:0.001000
Ep: 6/48	It: 151/8134	batch_loss: 3.6486	batch_accuracy: 33.79%	lr:0.001000
Ep: 6/48	It: 201/8134	batch_loss: 3.7697	batch_accuracy: 32.32%	lr:0.001000
Ep: 6/48	It: 251/8134	batch_loss: 3.7008	batch_accuracy: 33.54%	lr:0.001000
Ep: 6/48	It: 301/8134	batch_loss: 3.5539	batch_accuracy: 33.59%	lr:0.001000
Ep: 6/48	It: 351/8134	batch_loss: 3.4944	batch_accuracy: 37.33%	lr:0.001000
Ep: 6/48	It: 401/8134	batch_loss: 3.6607	batch_accuracy: 33.81%	lr:0.001000
Ep: 6/48	It: 451/8134	batch_loss: 3.6815	batch_accuracy: 33.64%	lr:0.001000
Ep: 6/48	It: 501/8134	batch_loss: 3.6831	batch_accuracy: 34.01%	lr:0.001000
Ep: 6/48	It: 551/8134	batch_loss: 3.6530	batch_accuracy: 33.94%	lr:0.001000
Ep: 6/48	It: 601/8134	batch_loss: 3.6409	batch_accuracy: 33.89%	lr:0.001000
Ep: 6/48	It: 651/8134	batch_loss: 3.6780	batch_accuracy: 34.91%	lr:0.001000
Ep: 6/48	It: 701/8134	batch_loss: 3.6999	batch_accuracy: 33.50%	lr:0.001000
Ep: 6/48	It: 751/8134	batch_loss: 3.6392	batch_accuracy: 33.37%	lr:0.001000
Ep: 6/48	It: 801/8134	batch_loss: 3.5895	batch_accuracy: 35.62%	lr:0.001000
Ep: 6/48	It: 851/8134	batch_loss: 3.6908	batch_accuracy: 32.54%	lr:0.001000
Ep: 6/48	It: 901/8134	batch_loss: 3.6478	batch_accuracy: 34.35%	lr:0.001000
Ep: 6/48	It: 951/8134	batch_loss: 3.6787	batch_accuracy: 33.06%	lr:0.001000
Ep: 6/48	It: 1001/8134	batch_loss: 3.6119	batch_accuracy: 35.52%	lr:0.001000
Ep: 6/48	It: 1051/8134	batch_loss: 3.6149	batch_accuracy: 34.01%	lr:0.001000
Ep: 6/48	It: 1101/8134	batch_loss: 3.5506	batch_accuracy: 35.96%	lr:0.001000
Ep: 6/48	It: 1151/8134	batch_loss: 3.6300	batch_accuracy: 33.37%	lr:0.001000
Ep: 6/48	It: 1201/8134	batch_loss: 3.6396	batch_accuracy: 34.77%	lr:0.001000
Ep: 6/48	It: 1251/8134	batch_loss: 3.6008	batch_accuracy: 34.42%	lr:0.001000
Ep: 6/48	It: 1301/8134	batch_loss: 3.8417	batch_accuracy: 32.08%	lr:0.001000
Ep: 6/48	It: 1351/8134	batch_loss: 3.7418	batch_accuracy: 32.10%	lr:0.001000
Ep: 6/48	It: 1401/8134	batch_loss: 3.6663	batch_accuracy: 34.89%	lr:0.001000
Ep: 6/48	It: 1451/8134	batch_loss: 3.6163	batch_accuracy: 35.13%	lr:0.001000
Ep: 6/48	It: 1501/8134	batch_loss: 3.5931	batch_accuracy: 34.59%	lr:0.001000
Ep: 6/48	It: 1551/8134	batch_loss: 3.5911	batch_accuracy: 35.35%	lr:0.001000
Ep: 6/48	It: 1601/8134	batch_loss: 3.5838	batch_accuracy: 35.38%	lr:0.001000
Ep: 6/48	It: 1651/8134	batch_loss: 3.6829	batch_accuracy: 33.37%	lr:0.001000
Ep: 6/48	It: 1701/8134	batch_loss: 3.6052	batch_accuracy: 35.21%	lr:0.001000
Ep: 6/48	It: 1751/8134	batch_loss: 3.7440	batch_accuracy: 33.67%	lr:0.001000
Ep: 6/48	It: 1801/8134	batch_loss: 3.5941	batch_accuracy: 34.81%	lr:0.001000
Ep: 6/48	It: 1851/8134	batch_loss: 3.5401	batch_accuracy: 34.96%	lr:0.001000
Ep: 6/48	It: 1901/8134	batch_loss: 3.6891	batch_accuracy: 34.18%	lr:0.001000
Ep: 6/48	It: 1951/8134	batch_loss: 3.6712	batch_accuracy: 34.69%	lr:0.001000
Ep: 6/48	It: 2001/8134	batch_loss: 3.7011	batch_accuracy: 33.57%	lr:0.001000
Ep: 6/48	It: 2051/8134	batch_loss: 3.5888	batch_accuracy: 34.96%	lr:0.001000
Ep: 6/48	It: 2101/8134	batch_loss: 3.6078	batch_accuracy: 34.94%	lr:0.001000
Ep: 6/48	It: 2151/8134	batch_loss: 3.6331	batch_accuracy: 34.18%	lr:0.001000
Ep: 6/48	It: 2201/8134	batch_loss: 3.7151	batch_accuracy: 33.45%	lr:0.001000
Ep: 6/48	It: 2251/8134	batch_loss: 3.7742	batch_accuracy: 32.54%	lr:0.001000
Ep: 6/48	It: 2301/8134	batch_loss: 3.5514	batch_accuracy: 35.72%	lr:0.001000
Ep: 6/48	It: 2351/8134	batch_loss: 3.5087	batch_accuracy: 37.11%	lr:0.001000
Ep: 6/48	It: 2401/8134	batch_loss: 3.6334	batch_accuracy: 34.30%	lr:0.001000
Ep: 6/48	It: 2451/8134	batch_loss: 3.6264	batch_accuracy: 34.28%	lr:0.001000
Ep: 6/48	It: 2501/8134	batch_loss: 3.5644	batch_accuracy: 35.08%	lr:0.001000
Ep: 6/48	It: 2551/8134	batch_loss: 3.7329	batch_accuracy: 33.13%	lr:0.001000
Ep: 6/48	It: 2601/8134	batch_loss: 3.6164	batch_accuracy: 34.18%	lr:0.001000
Ep: 6/48	It: 2651/8134	batch_loss: 3.6211	batch_accuracy: 33.37%	lr:0.001000
Ep: 6/48	It: 2701/8134	batch_loss: 3.5059	batch_accuracy: 35.40%	lr:0.001000
Ep: 6/48	It: 2751/8134	batch_loss: 3.6132	batch_accuracy: 32.57%	lr:0.001000
Ep: 6/48	It: 2801/8134	batch_loss: 3.4528	batch_accuracy: 36.69%	lr:0.001000
Ep: 6/48	It: 2851/8134	batch_loss: 3.4878	batch_accuracy: 35.13%	lr:0.001000
Ep: 6/48	It: 2901/8134	batch_loss: 3.5169	batch_accuracy: 36.25%	lr:0.001000
Ep: 6/48	It: 2951/8134	batch_loss: 3.5851	batch_accuracy: 35.06%	lr:0.001000
Ep: 6/48	It: 3001/8134	batch_loss: 3.6782	batch_accuracy: 34.06%	lr:0.001000
Ep: 6/48	It: 3051/8134	batch_loss: 3.6880	batch_accuracy: 33.96%	lr:0.001000
Ep: 6/48	It: 3101/8134	batch_loss: 3.5885	batch_accuracy: 34.38%	lr:0.001000
Ep: 6/48	It: 3151/8134	batch_loss: 3.6275	batch_accuracy: 35.03%	lr:0.001000
Ep: 6/48	It: 3201/8134	batch_loss: 3.6193	batch_accuracy: 34.13%	lr:0.001000
Ep: 6/48	It: 3251/8134	batch_loss: 3.5348	batch_accuracy: 35.21%	lr:0.001000
Ep: 6/48	It: 3301/8134	batch_loss: 3.5390	batch_accuracy: 35.03%	lr:0.001000
Ep: 6/48	It: 3351/8134	batch_loss: 3.5769	batch_accuracy: 34.03%	lr:0.001000
Ep: 6/48	It: 3401/8134	batch_loss: 3.5045	batch_accuracy: 35.35%	lr:0.001000
Ep: 6/48	It: 3451/8134	batch_loss: 3.5846	batch_accuracy: 34.74%	lr:0.001000
Ep: 6/48	It: 3501/8134	batch_loss: 3.5896	batch_accuracy: 34.35%	lr:0.001000
Ep: 6/48	It: 3551/8134	batch_loss: 3.6463	batch_accuracy: 34.23%	lr:0.001000
Ep: 6/48	It: 3601/8134	batch_loss: 3.6225	batch_accuracy: 34.20%	lr:0.001000
Ep: 6/48	It: 3651/8134	batch_loss: 3.5681	batch_accuracy: 34.28%	lr:0.001000
Ep: 6/48	It: 3701/8134	batch_loss: 3.7018	batch_accuracy: 33.33%	lr:0.001000
Ep: 6/48	It: 3751/8134	batch_loss: 3.6771	batch_accuracy: 33.52%	lr:0.001000
Ep: 6/48	It: 3801/8134	batch_loss: 3.6953	batch_accuracy: 33.45%	lr:0.001000
Ep: 6/48	It: 3851/8134	batch_loss: 3.5785	batch_accuracy: 34.99%	lr:0.001000
Ep: 6/48	It: 3901/8134	batch_loss: 3.6633	batch_accuracy: 34.08%	lr:0.001000
Ep: 6/48	It: 3951/8134	batch_loss: 3.7001	batch_accuracy: 32.93%	lr:0.001000
Ep: 6/48	It: 4001/8134	batch_loss: 3.6103	batch_accuracy: 34.03%	lr:0.001000
Ep: 6/48	It: 4051/8134	batch_loss: 3.5383	batch_accuracy: 35.72%	lr:0.001000
Ep: 6/48	It: 4101/8134	batch_loss: 3.6487	batch_accuracy: 33.30%	lr:0.001000
Ep: 6/48	It: 4151/8134	batch_loss: 3.6742	batch_accuracy: 34.03%	lr:0.001000
Ep: 6/48	It: 4201/8134	batch_loss: 3.4840	batch_accuracy: 36.77%	lr:0.001000
Ep: 6/48	It: 4251/8134	batch_loss: 3.5994	batch_accuracy: 34.55%	lr:0.001000
Ep: 6/48	It: 4301/8134	batch_loss: 3.5356	batch_accuracy: 34.62%	lr:0.001000
Ep: 6/48	It: 4351/8134	batch_loss: 3.7080	batch_accuracy: 34.30%	lr:0.001000
Ep: 6/48	It: 4401/8134	batch_loss: 3.6475	batch_accuracy: 33.33%	lr:0.001000
Ep: 6/48	It: 4451/8134	batch_loss: 3.5690	batch_accuracy: 36.04%	lr:0.001000
Ep: 6/48	It: 4501/8134	batch_loss: 3.6661	batch_accuracy: 34.74%	lr:0.001000
Ep: 6/48	It: 4551/8134	batch_loss: 3.5260	batch_accuracy: 35.21%	lr:0.001000
Ep: 6/48	It: 4601/8134	batch_loss: 3.3769	batch_accuracy: 36.21%	lr:0.001000
Ep: 6/48	It: 4651/8134	batch_loss: 3.5794	batch_accuracy: 34.23%	lr:0.001000
Ep: 6/48	It: 4701/8134	batch_loss: 3.6254	batch_accuracy: 35.99%	lr:0.001000
Ep: 6/48	It: 4751/8134	batch_loss: 3.6392	batch_accuracy: 33.91%	lr:0.001000
Ep: 6/48	It: 4801/8134	batch_loss: 3.5696	batch_accuracy: 35.30%	lr:0.001000
Ep: 6/48	It: 4851/8134	batch_loss: 3.4999	batch_accuracy: 35.84%	lr:0.001000
Ep: 6/48	It: 4901/8134	batch_loss: 3.5826	batch_accuracy: 35.89%	lr:0.001000
Ep: 6/48	It: 4951/8134	batch_loss: 3.5856	batch_accuracy: 36.16%	lr:0.001000
Ep: 6/48	It: 5001/8134	batch_loss: 3.5273	batch_accuracy: 35.08%	lr:0.001000
Ep: 6/48	It: 5051/8134	batch_loss: 3.6425	batch_accuracy: 34.74%	lr:0.000999
Ep: 6/48	It: 5101/8134	batch_loss: 3.5151	batch_accuracy: 34.23%	lr:0.000999
Ep: 6/48	It: 5151/8134	batch_loss: 3.6150	batch_accuracy: 34.50%	lr:0.000999
Ep: 6/48	It: 5201/8134	batch_loss: 3.5510	batch_accuracy: 34.99%	lr:0.000999
Ep: 6/48	It: 5251/8134	batch_loss: 3.6270	batch_accuracy: 34.94%	lr:0.000999
Ep: 6/48	It: 5301/8134	batch_loss: 3.4626	batch_accuracy: 36.52%	lr:0.000999
Ep: 6/48	It: 5351/8134	batch_loss: 3.5750	batch_accuracy: 35.52%	lr:0.000999
Ep: 6/48	It: 5401/8134	batch_loss: 3.4825	batch_accuracy: 36.06%	lr:0.000999
Ep: 6/48	It: 5451/8134	batch_loss: 3.5840	batch_accuracy: 35.72%	lr:0.000999
Ep: 6/48	It: 5501/8134	batch_loss: 3.5310	batch_accuracy: 35.99%	lr:0.000999
Ep: 6/48	It: 5551/8134	batch_loss: 3.7959	batch_accuracy: 32.45%	lr:0.000999
Ep: 6/48	It: 5601/8134	batch_loss: 3.6267	batch_accuracy: 34.50%	lr:0.000999
Ep: 6/48	It: 5651/8134	batch_loss: 3.6121	batch_accuracy: 35.16%	lr:0.000999
Ep: 6/48	It: 5701/8134	batch_loss: 3.5373	batch_accuracy: 35.86%	lr:0.000999
Ep: 6/48	It: 5751/8134	batch_loss: 3.5855	batch_accuracy: 34.77%	lr:0.000999
Ep: 6/48	It: 5801/8134	batch_loss: 3.4083	batch_accuracy: 36.69%	lr:0.000999
Ep: 6/48	It: 5851/8134	batch_loss: 3.4990	batch_accuracy: 37.23%	lr:0.000999
Ep: 6/48	It: 5901/8134	batch_loss: 3.6001	batch_accuracy: 34.25%	lr:0.000999
Ep: 6/48	It: 5951/8134	batch_loss: 3.6174	batch_accuracy: 33.86%	lr:0.000999
Ep: 6/48	It: 6001/8134	batch_loss: 3.6054	batch_accuracy: 34.74%	lr:0.000999
Ep: 6/48	It: 6051/8134	batch_loss: 3.5282	batch_accuracy: 36.01%	lr:0.000999
Ep: 6/48	It: 6101/8134	batch_loss: 3.5393	batch_accuracy: 36.35%	lr:0.000999
Ep: 6/48	It: 6151/8134	batch_loss: 3.5166	batch_accuracy: 36.74%	lr:0.000999
Ep: 6/48	It: 6201/8134	batch_loss: 3.4932	batch_accuracy: 36.21%	lr:0.000999
Ep: 6/48	It: 6251/8134	batch_loss: 3.5471	batch_accuracy: 35.42%	lr:0.000999
Ep: 6/48	It: 6301/8134	batch_loss: 3.6056	batch_accuracy: 34.18%	lr:0.000999
Ep: 6/48	It: 6351/8134	batch_loss: 3.6478	batch_accuracy: 33.62%	lr:0.000999
Ep: 6/48	It: 6401/8134	batch_loss: 3.7088	batch_accuracy: 32.57%	lr:0.000999
Ep: 6/48	It: 6451/8134	batch_loss: 3.5895	batch_accuracy: 34.91%	lr:0.000999
Ep: 6/48	It: 6501/8134	batch_loss: 3.5318	batch_accuracy: 34.94%	lr:0.000999
Ep: 6/48	It: 6551/8134	batch_loss: 3.6431	batch_accuracy: 33.67%	lr:0.000999
Ep: 6/48	It: 6601/8134	batch_loss: 3.4799	batch_accuracy: 35.25%	lr:0.000999
Ep: 6/48	It: 6651/8134	batch_loss: 3.5901	batch_accuracy: 35.84%	lr:0.000999
Ep: 6/48	It: 6701/8134	batch_loss: 3.5611	batch_accuracy: 34.52%	lr:0.000999
Ep: 6/48	It: 6751/8134	batch_loss: 3.5384	batch_accuracy: 35.33%	lr:0.000999
Ep: 6/48	It: 6801/8134	batch_loss: 3.5314	batch_accuracy: 37.13%	lr:0.000999
Ep: 6/48	It: 6851/8134	batch_loss: 3.7316	batch_accuracy: 32.40%	lr:0.000999
Ep: 6/48	It: 6901/8134	batch_loss: 3.6106	batch_accuracy: 34.11%	lr:0.000999
Ep: 6/48	It: 6951/8134	batch_loss: 3.5537	batch_accuracy: 34.84%	lr:0.000999
Ep: 6/48	It: 7001/8134	batch_loss: 3.5341	batch_accuracy: 35.60%	lr:0.000999
Ep: 6/48	It: 7051/8134	batch_loss: 3.5724	batch_accuracy: 34.06%	lr:0.000999
Ep: 6/48	It: 7101/8134	batch_loss: 3.5936	batch_accuracy: 35.42%	lr:0.000999
Ep: 6/48	It: 7151/8134	batch_loss: 3.6038	batch_accuracy: 35.03%	lr:0.000999
Ep: 6/48	It: 7201/8134	batch_loss: 3.6171	batch_accuracy: 34.45%	lr:0.000999
Ep: 6/48	It: 7251/8134	batch_loss: 3.5575	batch_accuracy: 34.28%	lr:0.000999
Ep: 6/48	It: 7301/8134	batch_loss: 3.5297	batch_accuracy: 35.18%	lr:0.000999
Ep: 6/48	It: 7351/8134	batch_loss: 3.5395	batch_accuracy: 36.30%	lr:0.000999
Ep: 6/48	It: 7401/8134	batch_loss: 3.4693	batch_accuracy: 37.13%	lr:0.000999
Ep: 6/48	It: 7451/8134	batch_loss: 3.7453	batch_accuracy: 32.37%	lr:0.000999
Ep: 6/48	It: 7501/8134	batch_loss: 3.5675	batch_accuracy: 34.50%	lr:0.000999
Ep: 6/48	It: 7551/8134	batch_loss: 3.6349	batch_accuracy: 34.81%	lr:0.000999
Ep: 6/48	It: 7601/8134	batch_loss: 3.5128	batch_accuracy: 36.23%	lr:0.000999
Ep: 6/48	It: 7651/8134	batch_loss: 3.6054	batch_accuracy: 33.94%	lr:0.000999
Ep: 6/48	It: 7701/8134	batch_loss: 3.5908	batch_accuracy: 34.33%	lr:0.000999
Ep: 6/48	It: 7751/8134	batch_loss: 3.6112	batch_accuracy: 33.69%	lr:0.000999
Ep: 6/48	It: 7801/8134	batch_loss: 3.6146	batch_accuracy: 33.74%	lr:0.000999
Ep: 6/48	It: 7851/8134	batch_loss: 3.6563	batch_accuracy: 34.28%	lr:0.000999
Ep: 6/48	It: 7901/8134	batch_loss: 3.6194	batch_accuracy: 33.67%	lr:0.000999
Ep: 6/48	It: 7951/8134	batch_loss: 3.5764	batch_accuracy: 34.64%	lr:0.000999
Ep: 6/48	It: 8001/8134	batch_loss: 3.5782	batch_accuracy: 36.08%	lr:0.000999
Ep: 6/48	It: 8051/8134	batch_loss: 3.6402	batch_accuracy: 34.03%	lr:0.000999
Ep: 6/48	It: 8101/8134	batch_loss: 3.5960	batch_accuracy: 34.45%	lr:0.000999
Ep: 6/48	It: 8134/8134	batch_loss: 3.6013	batch_accuracy: 34.51%	lr:0.000999


Generated text for input text "You" is:
You are able to identify and evaluate their performance. The study was carried out on the effect of the effects on the user’s performance. The study included the students in thesis, the teachers, and students, the students and students who are in this study. The study was conducted with a questionnaire that included the students’ opinions of students and students from the students of this research. The students are divided into two groups: the students and teachers in their classrooms. The students were in-depth with students, and the students were in a group of students and students with students, teachers, students, and students. They were asked to learn to participate in a classroom. The students also learned from their students, which had been tested for their ability to learn a language from a given classroom, with a high degree of students to use a classroom, in the classroom, and in the classroom. In addition, the students were able to use different learning models to learn to test the skills of students in classroom. The results of the study revealed that students' students are more satisfied with their learning in classrooms and learning models than students. The teachers have learned that teachers can learn


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 7/48	It: 1/8134	batch_loss: 3.5072	batch_accuracy: 35.89%	lr:0.000999
Ep: 7/48	It: 51/8134	batch_loss: 3.5866	batch_accuracy: 35.23%	lr:0.000999
Ep: 7/48	It: 101/8134	batch_loss: 3.6384	batch_accuracy: 34.47%	lr:0.000999
Ep: 7/48	It: 151/8134	batch_loss: 3.6527	batch_accuracy: 33.89%	lr:0.000999
Ep: 7/48	It: 201/8134	batch_loss: 3.4887	batch_accuracy: 36.43%	lr:0.000999
Ep: 7/48	It: 251/8134	batch_loss: 3.6494	batch_accuracy: 34.11%	lr:0.000999
Ep: 7/48	It: 301/8134	batch_loss: 3.4831	batch_accuracy: 36.50%	lr:0.000999
Ep: 7/48	It: 351/8134	batch_loss: 3.5321	batch_accuracy: 36.35%	lr:0.000999
Ep: 7/48	It: 401/8134	batch_loss: 3.5762	batch_accuracy: 34.84%	lr:0.000999
Ep: 7/48	It: 451/8134	batch_loss: 3.4918	batch_accuracy: 35.79%	lr:0.000999
Ep: 7/48	It: 501/8134	batch_loss: 3.5965	batch_accuracy: 34.99%	lr:0.000999
Ep: 7/48	It: 551/8134	batch_loss: 3.5017	batch_accuracy: 36.13%	lr:0.000998
Ep: 7/48	It: 601/8134	batch_loss: 3.5131	batch_accuracy: 34.81%	lr:0.000998
Ep: 7/48	It: 651/8134	batch_loss: 3.6373	batch_accuracy: 33.54%	lr:0.000998
Ep: 7/48	It: 701/8134	batch_loss: 3.6024	batch_accuracy: 34.59%	lr:0.000998
Ep: 7/48	It: 751/8134	batch_loss: 3.6616	batch_accuracy: 33.08%	lr:0.000998
Ep: 7/48	It: 801/8134	batch_loss: 3.6581	batch_accuracy: 33.18%	lr:0.000998
Ep: 7/48	It: 851/8134	batch_loss: 3.5582	batch_accuracy: 35.16%	lr:0.000998
Ep: 7/48	It: 901/8134	batch_loss: 3.5370	batch_accuracy: 34.67%	lr:0.000998
Ep: 7/48	It: 951/8134	batch_loss: 3.5704	batch_accuracy: 34.50%	lr:0.000998
Ep: 7/48	It: 1001/8134	batch_loss: 3.5510	batch_accuracy: 34.16%	lr:0.000998
Ep: 7/48	It: 1051/8134	batch_loss: 3.6084	batch_accuracy: 34.79%	lr:0.000998
Ep: 7/48	It: 1101/8134	batch_loss: 3.5983	batch_accuracy: 35.06%	lr:0.000998
Ep: 7/48	It: 1151/8134	batch_loss: 3.6193	batch_accuracy: 34.16%	lr:0.000998
Ep: 7/48	It: 1201/8134	batch_loss: 3.5181	batch_accuracy: 35.42%	lr:0.000998
Ep: 7/48	It: 1251/8134	batch_loss: 3.6271	batch_accuracy: 34.01%	lr:0.000998
Ep: 7/48	It: 1301/8134	batch_loss: 3.5839	batch_accuracy: 34.72%	lr:0.000998
Ep: 7/48	It: 1351/8134	batch_loss: 3.4752	batch_accuracy: 36.99%	lr:0.000998
Ep: 7/48	It: 1401/8134	batch_loss: 3.6382	batch_accuracy: 34.33%	lr:0.000998
Ep: 7/48	It: 1451/8134	batch_loss: 3.6457	batch_accuracy: 34.03%	lr:0.000998
Ep: 7/48	It: 1501/8134	batch_loss: 3.4941	batch_accuracy: 35.77%	lr:0.000998
Ep: 7/48	It: 1551/8134	batch_loss: 3.4811	batch_accuracy: 35.99%	lr:0.000998
Ep: 7/48	It: 1601/8134	batch_loss: 3.4640	batch_accuracy: 36.72%	lr:0.000998
Ep: 7/48	It: 1651/8134	batch_loss: 3.4955	batch_accuracy: 35.69%	lr:0.000998
Ep: 7/48	It: 1701/8134	batch_loss: 3.5453	batch_accuracy: 34.86%	lr:0.000998
Ep: 7/48	It: 1751/8134	batch_loss: 3.4993	batch_accuracy: 34.84%	lr:0.000998
Ep: 7/48	It: 1801/8134	batch_loss: 3.5070	batch_accuracy: 37.11%	lr:0.000998
Ep: 7/48	It: 1851/8134	batch_loss: 3.4518	batch_accuracy: 34.96%	lr:0.000998
Ep: 7/48	It: 1901/8134	batch_loss: 3.5639	batch_accuracy: 35.67%	lr:0.000998
Ep: 7/48	It: 1951/8134	batch_loss: 3.5712	batch_accuracy: 34.52%	lr:0.000998
Ep: 7/48	It: 2001/8134	batch_loss: 3.6475	batch_accuracy: 33.96%	lr:0.000998
Ep: 7/48	It: 2051/8134	batch_loss: 3.5426	batch_accuracy: 34.18%	lr:0.000998
Ep: 7/48	It: 2101/8134	batch_loss: 3.5116	batch_accuracy: 35.96%	lr:0.000998
Ep: 7/48	It: 2151/8134	batch_loss: 3.4611	batch_accuracy: 35.77%	lr:0.000998
Ep: 7/48	It: 2201/8134	batch_loss: 3.5652	batch_accuracy: 35.50%	lr:0.000998
Ep: 7/48	It: 2251/8134	batch_loss: 3.5196	batch_accuracy: 36.40%	lr:0.000998
Ep: 7/48	It: 2301/8134	batch_loss: 3.4213	batch_accuracy: 35.72%	lr:0.000998
Ep: 7/48	It: 2351/8134	batch_loss: 3.4765	batch_accuracy: 36.72%	lr:0.000998
Ep: 7/48	It: 2401/8134	batch_loss: 3.5408	batch_accuracy: 34.67%	lr:0.000998
Ep: 7/48	It: 2451/8134	batch_loss: 3.4373	batch_accuracy: 36.23%	lr:0.000998
Ep: 7/48	It: 2501/8134	batch_loss: 3.5674	batch_accuracy: 34.89%	lr:0.000998
Ep: 7/48	It: 2551/8134	batch_loss: 3.5003	batch_accuracy: 36.38%	lr:0.000998
Ep: 7/48	It: 2601/8134	batch_loss: 3.5253	batch_accuracy: 35.38%	lr:0.000998
Ep: 7/48	It: 2651/8134	batch_loss: 3.4888	batch_accuracy: 36.28%	lr:0.000998
Ep: 7/48	It: 2701/8134	batch_loss: 3.5094	batch_accuracy: 36.77%	lr:0.000998
Ep: 7/48	It: 2751/8134	batch_loss: 3.3519	batch_accuracy: 38.55%	lr:0.000998
Ep: 7/48	It: 2801/8134	batch_loss: 3.6354	batch_accuracy: 33.72%	lr:0.000998
Ep: 7/48	It: 2851/8134	batch_loss: 3.5913	batch_accuracy: 33.76%	lr:0.000998
Ep: 7/48	It: 2901/8134	batch_loss: 3.5394	batch_accuracy: 34.86%	lr:0.000998
Ep: 7/48	It: 2951/8134	batch_loss: 3.4281	batch_accuracy: 37.13%	lr:0.000998
Ep: 7/48	It: 3001/8134	batch_loss: 3.5958	batch_accuracy: 35.08%	lr:0.000998
Ep: 7/48	It: 3051/8134	batch_loss: 3.5414	batch_accuracy: 35.77%	lr:0.000998
Ep: 7/48	It: 3101/8134	batch_loss: 3.4932	batch_accuracy: 36.21%	lr:0.000997
Ep: 7/48	It: 3151/8134	batch_loss: 3.6111	batch_accuracy: 34.86%	lr:0.000997
Ep: 7/48	It: 3201/8134	batch_loss: 3.4279	batch_accuracy: 36.99%	lr:0.000997
Ep: 7/48	It: 3251/8134	batch_loss: 3.6700	batch_accuracy: 34.01%	lr:0.000997
Ep: 7/48	It: 3301/8134	batch_loss: 3.5357	batch_accuracy: 35.55%	lr:0.000997
Ep: 7/48	It: 3351/8134	batch_loss: 3.4354	batch_accuracy: 36.08%	lr:0.000997
Ep: 7/48	It: 3401/8134	batch_loss: 3.6134	batch_accuracy: 33.15%	lr:0.000997
Ep: 7/48	It: 3451/8134	batch_loss: 3.4236	batch_accuracy: 36.94%	lr:0.000997
Ep: 7/48	It: 3501/8134	batch_loss: 3.6182	batch_accuracy: 34.52%	lr:0.000997
Ep: 7/48	It: 3551/8134	batch_loss: 3.5608	batch_accuracy: 34.81%	lr:0.000997
Ep: 7/48	It: 3601/8134	batch_loss: 3.5609	batch_accuracy: 35.25%	lr:0.000997
Ep: 7/48	It: 3651/8134	batch_loss: 3.5988	batch_accuracy: 34.91%	lr:0.000997
Ep: 7/48	It: 3701/8134	batch_loss: 3.6316	batch_accuracy: 34.01%	lr:0.000997
Ep: 7/48	It: 3751/8134	batch_loss: 3.5165	batch_accuracy: 35.40%	lr:0.000997
Ep: 7/48	It: 3801/8134	batch_loss: 3.3656	batch_accuracy: 37.18%	lr:0.000997
Ep: 7/48	It: 3851/8134	batch_loss: 3.6111	batch_accuracy: 34.74%	lr:0.000997
Ep: 7/48	It: 3901/8134	batch_loss: 3.3816	batch_accuracy: 37.96%	lr:0.000997
Ep: 7/48	It: 3951/8134	batch_loss: 3.4420	batch_accuracy: 36.25%	lr:0.000997
Ep: 7/48	It: 4001/8134	batch_loss: 3.4609	batch_accuracy: 35.74%	lr:0.000997
Ep: 7/48	It: 4051/8134	batch_loss: 3.6568	batch_accuracy: 33.28%	lr:0.000997
Ep: 7/48	It: 4101/8134	batch_loss: 3.5352	batch_accuracy: 35.99%	lr:0.000997
Ep: 7/48	It: 4151/8134	batch_loss: 3.5157	batch_accuracy: 36.06%	lr:0.000997
Ep: 7/48	It: 4201/8134	batch_loss: 3.5763	batch_accuracy: 35.38%	lr:0.000997
Ep: 7/48	It: 4251/8134	batch_loss: 3.7000	batch_accuracy: 32.93%	lr:0.000997
Ep: 7/48	It: 4301/8134	batch_loss: 3.6280	batch_accuracy: 33.89%	lr:0.000997
Ep: 7/48	It: 4351/8134	batch_loss: 3.5264	batch_accuracy: 36.45%	lr:0.000997
Ep: 7/48	It: 4401/8134	batch_loss: 3.4384	batch_accuracy: 36.72%	lr:0.000997
Ep: 7/48	It: 4451/8134	batch_loss: 3.4814	batch_accuracy: 35.79%	lr:0.000997
Ep: 7/48	It: 4501/8134	batch_loss: 3.5602	batch_accuracy: 34.62%	lr:0.000997
Ep: 7/48	It: 4551/8134	batch_loss: 3.5463	batch_accuracy: 34.33%	lr:0.000997
Ep: 7/48	It: 4601/8134	batch_loss: 3.5702	batch_accuracy: 35.79%	lr:0.000997
Ep: 7/48	It: 4651/8134	batch_loss: 3.6589	batch_accuracy: 35.01%	lr:0.000997
Ep: 7/48	It: 4701/8134	batch_loss: 3.5255	batch_accuracy: 34.74%	lr:0.000997
Ep: 7/48	It: 4751/8134	batch_loss: 3.6116	batch_accuracy: 33.59%	lr:0.000997
Ep: 7/48	It: 4801/8134	batch_loss: 3.6054	batch_accuracy: 34.57%	lr:0.000997
Ep: 7/48	It: 4851/8134	batch_loss: 3.5142	batch_accuracy: 36.04%	lr:0.000997
Ep: 7/48	It: 4901/8134	batch_loss: 3.5072	batch_accuracy: 36.45%	lr:0.000997
Ep: 7/48	It: 4951/8134	batch_loss: 3.5768	batch_accuracy: 34.47%	lr:0.000997
Ep: 7/48	It: 5001/8134	batch_loss: 3.4249	batch_accuracy: 36.84%	lr:0.000997
Ep: 7/48	It: 5051/8134	batch_loss: 3.5762	batch_accuracy: 35.72%	lr:0.000997
Ep: 7/48	It: 5101/8134	batch_loss: 3.5076	batch_accuracy: 35.38%	lr:0.000997
Ep: 7/48	It: 5151/8134	batch_loss: 3.4832	batch_accuracy: 36.94%	lr:0.000996
Ep: 7/48	It: 5201/8134	batch_loss: 3.4208	batch_accuracy: 36.94%	lr:0.000996
Ep: 7/48	It: 5251/8134	batch_loss: 3.5728	batch_accuracy: 35.33%	lr:0.000996
Ep: 7/48	It: 5301/8134	batch_loss: 3.5217	batch_accuracy: 35.72%	lr:0.000996
Ep: 7/48	It: 5351/8134	batch_loss: 3.5522	batch_accuracy: 34.38%	lr:0.000996
Ep: 7/48	It: 5401/8134	batch_loss: 3.5293	batch_accuracy: 34.33%	lr:0.000996
Ep: 7/48	It: 5451/8134	batch_loss: 3.4539	batch_accuracy: 36.40%	lr:0.000996
Ep: 7/48	It: 5501/8134	batch_loss: 3.5724	batch_accuracy: 34.94%	lr:0.000996
Ep: 7/48	It: 5551/8134	batch_loss: 3.5838	batch_accuracy: 34.77%	lr:0.000996
Ep: 7/48	It: 5601/8134	batch_loss: 3.4915	batch_accuracy: 36.23%	lr:0.000996
Ep: 7/48	It: 5651/8134	batch_loss: 3.5724	batch_accuracy: 35.33%	lr:0.000996
Ep: 7/48	It: 5701/8134	batch_loss: 3.5683	batch_accuracy: 34.62%	lr:0.000996
Ep: 7/48	It: 5751/8134	batch_loss: 3.4874	batch_accuracy: 35.33%	lr:0.000996
Ep: 7/48	It: 5801/8134	batch_loss: 3.5229	batch_accuracy: 35.60%	lr:0.000996
Ep: 7/48	It: 5851/8134	batch_loss: 3.5437	batch_accuracy: 35.42%	lr:0.000996
Ep: 7/48	It: 5901/8134	batch_loss: 3.5175	batch_accuracy: 36.38%	lr:0.000996
Ep: 7/48	It: 5951/8134	batch_loss: 3.5365	batch_accuracy: 35.99%	lr:0.000996
Ep: 7/48	It: 6001/8134	batch_loss: 3.3745	batch_accuracy: 38.09%	lr:0.000996
Ep: 7/48	It: 6051/8134	batch_loss: 3.5298	batch_accuracy: 35.35%	lr:0.000996
Ep: 7/48	It: 6101/8134	batch_loss: 3.5627	batch_accuracy: 35.08%	lr:0.000996
Ep: 7/48	It: 6151/8134	batch_loss: 3.3957	batch_accuracy: 36.91%	lr:0.000996
Ep: 7/48	It: 6201/8134	batch_loss: 3.5212	batch_accuracy: 35.18%	lr:0.000996
Ep: 7/48	It: 6251/8134	batch_loss: 3.4490	batch_accuracy: 36.43%	lr:0.000996
Ep: 7/48	It: 6301/8134	batch_loss: 3.5044	batch_accuracy: 35.89%	lr:0.000996
Ep: 7/48	It: 6351/8134	batch_loss: 3.5308	batch_accuracy: 34.84%	lr:0.000996
Ep: 7/48	It: 6401/8134	batch_loss: 3.4305	batch_accuracy: 36.62%	lr:0.000996
Ep: 7/48	It: 6451/8134	batch_loss: 3.5856	batch_accuracy: 34.45%	lr:0.000996
Ep: 7/48	It: 6501/8134	batch_loss: 3.5174	batch_accuracy: 36.01%	lr:0.000996
Ep: 7/48	It: 6551/8134	batch_loss: 3.4676	batch_accuracy: 36.84%	lr:0.000996
Ep: 7/48	It: 6601/8134	batch_loss: 3.4942	batch_accuracy: 35.42%	lr:0.000996
Ep: 7/48	It: 6651/8134	batch_loss: 3.4811	batch_accuracy: 36.06%	lr:0.000996
Ep: 7/48	It: 6701/8134	batch_loss: 3.4886	batch_accuracy: 35.86%	lr:0.000996
Ep: 7/48	It: 6751/8134	batch_loss: 3.5481	batch_accuracy: 35.33%	lr:0.000996
Ep: 7/48	It: 6801/8134	batch_loss: 3.5004	batch_accuracy: 35.69%	lr:0.000996
Ep: 7/48	It: 6851/8134	batch_loss: 3.4185	batch_accuracy: 37.62%	lr:0.000996
Ep: 7/48	It: 6901/8134	batch_loss: 3.4859	batch_accuracy: 36.43%	lr:0.000995
Ep: 7/48	It: 6951/8134	batch_loss: 3.4456	batch_accuracy: 36.55%	lr:0.000995
Ep: 7/48	It: 7001/8134	batch_loss: 3.5441	batch_accuracy: 34.30%	lr:0.000995
Ep: 7/48	It: 7051/8134	batch_loss: 3.3958	batch_accuracy: 37.74%	lr:0.000995
Ep: 7/48	It: 7101/8134	batch_loss: 3.3492	batch_accuracy: 37.67%	lr:0.000995
Ep: 7/48	It: 7151/8134	batch_loss: 3.3900	batch_accuracy: 36.47%	lr:0.000995
Ep: 7/48	It: 7201/8134	batch_loss: 3.5214	batch_accuracy: 35.82%	lr:0.000995
Ep: 7/48	It: 7251/8134	batch_loss: 3.4786	batch_accuracy: 35.99%	lr:0.000995
Ep: 7/48	It: 7301/8134	batch_loss: 3.5753	batch_accuracy: 34.35%	lr:0.000995
Ep: 7/48	It: 7351/8134	batch_loss: 3.4909	batch_accuracy: 36.60%	lr:0.000995
Ep: 7/48	It: 7401/8134	batch_loss: 3.5774	batch_accuracy: 35.23%	lr:0.000995
Ep: 7/48	It: 7451/8134	batch_loss: 3.5496	batch_accuracy: 35.45%	lr:0.000995
Ep: 7/48	It: 7501/8134	batch_loss: 3.5838	batch_accuracy: 34.08%	lr:0.000995
Ep: 7/48	It: 7551/8134	batch_loss: 3.5476	batch_accuracy: 34.86%	lr:0.000995
Ep: 7/48	It: 7601/8134	batch_loss: 3.5351	batch_accuracy: 36.01%	lr:0.000995
Ep: 7/48	It: 7651/8134	batch_loss: 3.4007	batch_accuracy: 37.60%	lr:0.000995
Ep: 7/48	It: 7701/8134	batch_loss: 3.5470	batch_accuracy: 34.25%	lr:0.000995
Ep: 7/48	It: 7751/8134	batch_loss: 3.4311	batch_accuracy: 36.38%	lr:0.000995
Ep: 7/48	It: 7801/8134	batch_loss: 3.4355	batch_accuracy: 37.35%	lr:0.000995
Ep: 7/48	It: 7851/8134	batch_loss: 3.4333	batch_accuracy: 36.30%	lr:0.000995
Ep: 7/48	It: 7901/8134	batch_loss: 3.5528	batch_accuracy: 35.35%	lr:0.000995
Ep: 7/48	It: 7951/8134	batch_loss: 3.5426	batch_accuracy: 35.40%	lr:0.000995
Ep: 7/48	It: 8001/8134	batch_loss: 3.4871	batch_accuracy: 35.57%	lr:0.000995
Ep: 7/48	It: 8051/8134	batch_loss: 3.5029	batch_accuracy: 35.60%	lr:0.000995
Ep: 7/48	It: 8101/8134	batch_loss: 3.5245	batch_accuracy: 35.84%	lr:0.000995
Ep: 7/48	It: 8134/8134	batch_loss: 3.6157	batch_accuracy: 34.68%	lr:0.000995


Generated text for input text "You" is:
Youxual, and the same is award forth. The study is a case study that is the same as for the students of London.
The study used data from the London's first study of English in thesis. The study used the qualitative study, descriptive research, and qualitative research design. The research results indicated that the second research shows the most effective and effective method of teaching English language teachers' teacher learning as a teacher teacher and teacher. The findings indicate that teachers’ teacher teaching skills, teacher competence, and teacher competence are the main components of the teacher’s professional activity. Students also experienced significant influence on teacher competence. However, they are more likely to have more influence on teacher engagement. In addition, they also highlight the importance of teaching teachers as well as teacher education of teacher education, and the influence of teacher competence on teacher performance.
<eot>
<sot>
Accuracy and validity of the Supervised Learning Approach to Assess Language Development in Federal Economics

The Supervised learning (SAL) approach used in the Federal Economic Development Programme (FEP) is a method to improve the Language


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 8/48	It: 1/8134	batch_loss: 3.5769	batch_accuracy: 34.64%	lr:0.000995
Ep: 8/48	It: 51/8134	batch_loss: 3.4868	batch_accuracy: 36.18%	lr:0.000995
Ep: 8/48	It: 101/8134	batch_loss: 3.5120	batch_accuracy: 36.55%	lr:0.000995
Ep: 8/48	It: 151/8134	batch_loss: 3.5610	batch_accuracy: 34.84%	lr:0.000995
Ep: 8/48	It: 201/8134	batch_loss: 3.4685	batch_accuracy: 35.47%	lr:0.000995
Ep: 8/48	It: 251/8134	batch_loss: 3.5886	batch_accuracy: 35.16%	lr:0.000995
Ep: 8/48	It: 301/8134	batch_loss: 3.5454	batch_accuracy: 35.16%	lr:0.000995
Ep: 8/48	It: 351/8134	batch_loss: 3.5272	batch_accuracy: 35.77%	lr:0.000994
Ep: 8/48	It: 401/8134	batch_loss: 3.5743	batch_accuracy: 35.50%	lr:0.000994
Ep: 8/48	It: 451/8134	batch_loss: 3.3729	batch_accuracy: 37.48%	lr:0.000994
Ep: 8/48	It: 501/8134	batch_loss: 3.5861	batch_accuracy: 34.79%	lr:0.000994
Ep: 8/48	It: 551/8134	batch_loss: 3.5270	batch_accuracy: 36.55%	lr:0.000994
Ep: 8/48	It: 601/8134	batch_loss: 3.4404	batch_accuracy: 36.67%	lr:0.000994
Ep: 8/48	It: 651/8134	batch_loss: 3.5328	batch_accuracy: 35.74%	lr:0.000994
Ep: 8/48	It: 701/8134	batch_loss: 3.5331	batch_accuracy: 35.82%	lr:0.000994
Ep: 8/48	It: 751/8134	batch_loss: 3.4643	batch_accuracy: 36.23%	lr:0.000994
Ep: 8/48	It: 801/8134	batch_loss: 3.4354	batch_accuracy: 37.72%	lr:0.000994
Ep: 8/48	It: 851/8134	batch_loss: 3.4162	batch_accuracy: 36.57%	lr:0.000994
Ep: 8/48	It: 901/8134	batch_loss: 3.4769	batch_accuracy: 36.18%	lr:0.000994
Ep: 8/48	It: 951/8134	batch_loss: 3.5678	batch_accuracy: 35.11%	lr:0.000994
Ep: 8/48	It: 1001/8134	batch_loss: 3.3570	batch_accuracy: 36.35%	lr:0.000994
Ep: 8/48	It: 1051/8134	batch_loss: 3.4997	batch_accuracy: 35.50%	lr:0.000994
Ep: 8/48	It: 1101/8134	batch_loss: 3.5271	batch_accuracy: 36.25%	lr:0.000994
Ep: 8/48	It: 1151/8134	batch_loss: 3.5272	batch_accuracy: 35.50%	lr:0.000994
Ep: 8/48	It: 1201/8134	batch_loss: 3.5395	batch_accuracy: 35.08%	lr:0.000994
Ep: 8/48	It: 1251/8134	batch_loss: 3.4577	batch_accuracy: 37.43%	lr:0.000994
Ep: 8/48	It: 1301/8134	batch_loss: 3.4902	batch_accuracy: 36.11%	lr:0.000994
Ep: 8/48	It: 1351/8134	batch_loss: 3.4974	batch_accuracy: 35.60%	lr:0.000994
Ep: 8/48	It: 1401/8134	batch_loss: 3.4504	batch_accuracy: 35.35%	lr:0.000994
Ep: 8/48	It: 1451/8134	batch_loss: 3.6086	batch_accuracy: 34.23%	lr:0.000994
Ep: 8/48	It: 1501/8134	batch_loss: 3.4607	batch_accuracy: 36.28%	lr:0.000994
Ep: 8/48	It: 1551/8134	batch_loss: 3.4850	batch_accuracy: 35.42%	lr:0.000994
Ep: 8/48	It: 1601/8134	batch_loss: 3.4858	batch_accuracy: 36.04%	lr:0.000994
Ep: 8/48	It: 1651/8134	batch_loss: 3.3709	batch_accuracy: 36.89%	lr:0.000994
Ep: 8/48	It: 1701/8134	batch_loss: 3.5230	batch_accuracy: 35.69%	lr:0.000994
Ep: 8/48	It: 1751/8134	batch_loss: 3.6134	batch_accuracy: 34.50%	lr:0.000994
Ep: 8/48	It: 1801/8134	batch_loss: 3.5319	batch_accuracy: 35.25%	lr:0.000993
Ep: 8/48	It: 1851/8134	batch_loss: 3.5033	batch_accuracy: 35.52%	lr:0.000993
Ep: 8/48	It: 1901/8134	batch_loss: 3.5479	batch_accuracy: 36.28%	lr:0.000993
Ep: 8/48	It: 1951/8134	batch_loss: 3.5116	batch_accuracy: 35.69%	lr:0.000993
Ep: 8/48	It: 2001/8134	batch_loss: 3.4423	batch_accuracy: 37.18%	lr:0.000993
Ep: 8/48	It: 2051/8134	batch_loss: 3.4458	batch_accuracy: 37.38%	lr:0.000993
Ep: 8/48	It: 2101/8134	batch_loss: 3.6631	batch_accuracy: 34.01%	lr:0.000993
Ep: 8/48	It: 2151/8134	batch_loss: 3.4636	batch_accuracy: 35.94%	lr:0.000993
Ep: 8/48	It: 2201/8134	batch_loss: 3.4741	batch_accuracy: 37.77%	lr:0.000993
Ep: 8/48	It: 2251/8134	batch_loss: 3.5099	batch_accuracy: 35.60%	lr:0.000993
Ep: 8/48	It: 2301/8134	batch_loss: 3.5486	batch_accuracy: 34.33%	lr:0.000993
Ep: 8/48	It: 2351/8134	batch_loss: 3.4561	batch_accuracy: 36.55%	lr:0.000993
Ep: 8/48	It: 2401/8134	batch_loss: 3.5933	batch_accuracy: 34.20%	lr:0.000993
Ep: 8/48	It: 2451/8134	batch_loss: 3.4684	batch_accuracy: 35.06%	lr:0.000993
Ep: 8/48	It: 2501/8134	batch_loss: 3.4797	batch_accuracy: 36.23%	lr:0.000993
Ep: 8/48	It: 2551/8134	batch_loss: 3.4279	batch_accuracy: 36.04%	lr:0.000993
Ep: 8/48	It: 2601/8134	batch_loss: 3.2847	batch_accuracy: 38.99%	lr:0.000993
Ep: 8/48	It: 2651/8134	batch_loss: 3.4480	batch_accuracy: 36.38%	lr:0.000993
Ep: 8/48	It: 2701/8134	batch_loss: 3.2367	batch_accuracy: 38.65%	lr:0.000993
Ep: 8/48	It: 2751/8134	batch_loss: 3.4467	batch_accuracy: 36.52%	lr:0.000993
Ep: 8/48	It: 2801/8134	batch_loss: 3.4947	batch_accuracy: 35.18%	lr:0.000993
Ep: 8/48	It: 2851/8134	batch_loss: 3.5785	batch_accuracy: 35.18%	lr:0.000993
Ep: 8/48	It: 2901/8134	batch_loss: 3.4606	batch_accuracy: 36.79%	lr:0.000993
Ep: 8/48	It: 2951/8134	batch_loss: 3.5410	batch_accuracy: 33.67%	lr:0.000993
Ep: 8/48	It: 3001/8134	batch_loss: 3.3936	batch_accuracy: 37.87%	lr:0.000993
Ep: 8/48	It: 3051/8134	batch_loss: 3.5020	batch_accuracy: 35.06%	lr:0.000993
Ep: 8/48	It: 3101/8134	batch_loss: 3.5573	batch_accuracy: 35.21%	lr:0.000993
Ep: 8/48	It: 3151/8134	batch_loss: 3.4449	batch_accuracy: 36.28%	lr:0.000992
Ep: 8/48	It: 3201/8134	batch_loss: 3.5526	batch_accuracy: 34.40%	lr:0.000992
Ep: 8/48	It: 3251/8134	batch_loss: 3.5169	batch_accuracy: 36.08%	lr:0.000992
Ep: 8/48	It: 3301/8134	batch_loss: 3.5217	batch_accuracy: 34.42%	lr:0.000992
Ep: 8/48	It: 3351/8134	batch_loss: 3.4301	batch_accuracy: 36.62%	lr:0.000992
Ep: 8/48	It: 3401/8134	batch_loss: 3.4782	batch_accuracy: 37.16%	lr:0.000992
Ep: 8/48	It: 3451/8134	batch_loss: 3.4668	batch_accuracy: 36.28%	lr:0.000992
Ep: 8/48	It: 3501/8134	batch_loss: 3.5281	batch_accuracy: 35.03%	lr:0.000992
Ep: 8/48	It: 3551/8134	batch_loss: 3.4434	batch_accuracy: 36.84%	lr:0.000992
Ep: 8/48	It: 3601/8134	batch_loss: 3.4697	batch_accuracy: 36.82%	lr:0.000992
Ep: 8/48	It: 3651/8134	batch_loss: 3.4664	batch_accuracy: 36.47%	lr:0.000992
Ep: 8/48	It: 3701/8134	batch_loss: 3.4325	batch_accuracy: 36.99%	lr:0.000992
Ep: 8/48	It: 3751/8134	batch_loss: 3.3686	batch_accuracy: 37.60%	lr:0.000992
Ep: 8/48	It: 3801/8134	batch_loss: 3.4897	batch_accuracy: 35.25%	lr:0.000992
Ep: 8/48	It: 3851/8134	batch_loss: 3.4564	batch_accuracy: 36.18%	lr:0.000992
Ep: 8/48	It: 3901/8134	batch_loss: 3.4610	batch_accuracy: 36.84%	lr:0.000992
Ep: 8/48	It: 3951/8134	batch_loss: 3.4277	batch_accuracy: 35.64%	lr:0.000992
Ep: 8/48	It: 4001/8134	batch_loss: 3.4397	batch_accuracy: 36.84%	lr:0.000992
Ep: 8/48	It: 4051/8134	batch_loss: 3.5341	batch_accuracy: 35.89%	lr:0.000992
Ep: 8/48	It: 4101/8134	batch_loss: 3.5840	batch_accuracy: 34.40%	lr:0.000992
Ep: 8/48	It: 4151/8134	batch_loss: 3.4648	batch_accuracy: 35.64%	lr:0.000992
Ep: 8/48	It: 4201/8134	batch_loss: 3.5527	batch_accuracy: 34.81%	lr:0.000992
Ep: 8/48	It: 4251/8134	batch_loss: 3.4969	batch_accuracy: 36.11%	lr:0.000992
Ep: 8/48	It: 4301/8134	batch_loss: 3.6170	batch_accuracy: 35.16%	lr:0.000992
Ep: 8/48	It: 4351/8134	batch_loss: 3.4636	batch_accuracy: 36.33%	lr:0.000992
Ep: 8/48	It: 4401/8134	batch_loss: 3.4708	batch_accuracy: 36.40%	lr:0.000991
Ep: 8/48	It: 4451/8134	batch_loss: 3.5366	batch_accuracy: 35.86%	lr:0.000991
Ep: 8/48	It: 4501/8134	batch_loss: 3.5429	batch_accuracy: 34.25%	lr:0.000991
Ep: 8/48	It: 4551/8134	batch_loss: 3.4021	batch_accuracy: 36.60%	lr:0.000991
Ep: 8/48	It: 4601/8134	batch_loss: 3.4626	batch_accuracy: 36.06%	lr:0.000991
Ep: 8/48	It: 4651/8134	batch_loss: 3.6171	batch_accuracy: 34.47%	lr:0.000991
Ep: 8/48	It: 4701/8134	batch_loss: 3.4880	batch_accuracy: 35.74%	lr:0.000991
Ep: 8/48	It: 4751/8134	batch_loss: 3.5386	batch_accuracy: 35.23%	lr:0.000991
Ep: 8/48	It: 4801/8134	batch_loss: 3.4499	batch_accuracy: 35.45%	lr:0.000991
Ep: 8/48	It: 4851/8134	batch_loss: 3.4850	batch_accuracy: 35.69%	lr:0.000991
Ep: 8/48	It: 4901/8134	batch_loss: 3.5636	batch_accuracy: 34.89%	lr:0.000991
Ep: 8/48	It: 4951/8134	batch_loss: 3.4378	batch_accuracy: 35.82%	lr:0.000991
Ep: 8/48	It: 5001/8134	batch_loss: 3.3993	batch_accuracy: 37.06%	lr:0.000991
Ep: 8/48	It: 5051/8134	batch_loss: 3.4071	batch_accuracy: 35.64%	lr:0.000991
Ep: 8/48	It: 5101/8134	batch_loss: 3.5108	batch_accuracy: 35.69%	lr:0.000991
Ep: 8/48	It: 5151/8134	batch_loss: 3.5686	batch_accuracy: 34.89%	lr:0.000991
Ep: 8/48	It: 5201/8134	batch_loss: 3.5219	batch_accuracy: 35.38%	lr:0.000991
Ep: 8/48	It: 5251/8134	batch_loss: 3.5532	batch_accuracy: 34.89%	lr:0.000991
Ep: 8/48	It: 5301/8134	batch_loss: 3.4827	batch_accuracy: 36.33%	lr:0.000991
Ep: 8/48	It: 5351/8134	batch_loss: 3.4349	batch_accuracy: 36.62%	lr:0.000991
Ep: 8/48	It: 5401/8134	batch_loss: 3.4626	batch_accuracy: 36.74%	lr:0.000991
Ep: 8/48	It: 5451/8134	batch_loss: 3.5631	batch_accuracy: 35.74%	lr:0.000991
Ep: 8/48	It: 5501/8134	batch_loss: 3.5096	batch_accuracy: 36.62%	lr:0.000991
Ep: 8/48	It: 5551/8134	batch_loss: 3.3733	batch_accuracy: 37.28%	lr:0.000991
Ep: 8/48	It: 5601/8134	batch_loss: 3.4861	batch_accuracy: 36.55%	lr:0.000990
Ep: 8/48	It: 5651/8134	batch_loss: 3.5131	batch_accuracy: 36.43%	lr:0.000990
Ep: 8/48	It: 5701/8134	batch_loss: 3.4991	batch_accuracy: 34.62%	lr:0.000990
Ep: 8/48	It: 5751/8134	batch_loss: 3.3747	batch_accuracy: 36.94%	lr:0.000990
Ep: 8/48	It: 5801/8134	batch_loss: 3.3600	batch_accuracy: 38.09%	lr:0.000990
Ep: 8/48	It: 5851/8134	batch_loss: 3.5260	batch_accuracy: 35.16%	lr:0.000990
Ep: 8/48	It: 5901/8134	batch_loss: 3.5387	batch_accuracy: 35.40%	lr:0.000990
Ep: 8/48	It: 5951/8134	batch_loss: 3.4280	batch_accuracy: 37.26%	lr:0.000990
Ep: 8/48	It: 6001/8134	batch_loss: 3.4441	batch_accuracy: 36.47%	lr:0.000990
Ep: 8/48	It: 6051/8134	batch_loss: 3.5354	batch_accuracy: 35.67%	lr:0.000990
Ep: 8/48	It: 6101/8134	batch_loss: 3.4423	batch_accuracy: 36.87%	lr:0.000990
Ep: 8/48	It: 6151/8134	batch_loss: 3.5219	batch_accuracy: 35.74%	lr:0.000990
Ep: 8/48	It: 6201/8134	batch_loss: 3.4199	batch_accuracy: 37.52%	lr:0.000990
Ep: 8/48	It: 6251/8134	batch_loss: 3.4588	batch_accuracy: 37.35%	lr:0.000990
Ep: 8/48	It: 6301/8134	batch_loss: 3.3503	batch_accuracy: 37.65%	lr:0.000990
Ep: 8/48	It: 6351/8134	batch_loss: 3.5231	batch_accuracy: 35.52%	lr:0.000990
Ep: 8/48	It: 6401/8134	batch_loss: 3.5580	batch_accuracy: 34.79%	lr:0.000990
Ep: 8/48	It: 6451/8134	batch_loss: 3.4066	batch_accuracy: 37.35%	lr:0.000990
Ep: 8/48	It: 6501/8134	batch_loss: 3.4013	batch_accuracy: 38.16%	lr:0.000990
Ep: 8/48	It: 6551/8134	batch_loss: 3.4839	batch_accuracy: 35.94%	lr:0.000990
Ep: 8/48	It: 6601/8134	batch_loss: 3.5766	batch_accuracy: 35.03%	lr:0.000990
Ep: 8/48	It: 6651/8134	batch_loss: 3.5162	batch_accuracy: 35.55%	lr:0.000990
Ep: 8/48	It: 6701/8134	batch_loss: 3.4162	batch_accuracy: 36.89%	lr:0.000990
Ep: 8/48	It: 6751/8134	batch_loss: 3.5268	batch_accuracy: 35.30%	lr:0.000989
Ep: 8/48	It: 6801/8134	batch_loss: 3.3305	batch_accuracy: 38.28%	lr:0.000989
Ep: 8/48	It: 6851/8134	batch_loss: 3.4268	batch_accuracy: 36.45%	lr:0.000989
Ep: 8/48	It: 6901/8134	batch_loss: 3.5163	batch_accuracy: 35.11%	lr:0.000989
Ep: 8/48	It: 6951/8134	batch_loss: 3.5137	batch_accuracy: 35.77%	lr:0.000989
Ep: 8/48	It: 7001/8134	batch_loss: 3.4910	batch_accuracy: 36.43%	lr:0.000989
Ep: 8/48	It: 7051/8134	batch_loss: 3.4425	batch_accuracy: 36.79%	lr:0.000989
Ep: 8/48	It: 7101/8134	batch_loss: 3.5220	batch_accuracy: 35.77%	lr:0.000989
Ep: 8/48	It: 7151/8134	batch_loss: 3.4311	batch_accuracy: 37.99%	lr:0.000989
Ep: 8/48	It: 7201/8134	batch_loss: 3.4805	batch_accuracy: 36.84%	lr:0.000989
Ep: 8/48	It: 7251/8134	batch_loss: 3.3301	batch_accuracy: 38.28%	lr:0.000989
Ep: 8/48	It: 7301/8134	batch_loss: 3.3649	batch_accuracy: 37.43%	lr:0.000989
Ep: 8/48	It: 7351/8134	batch_loss: 3.3938	batch_accuracy: 36.74%	lr:0.000989
Ep: 8/48	It: 7401/8134	batch_loss: 3.4654	batch_accuracy: 35.74%	lr:0.000989
Ep: 8/48	It: 7451/8134	batch_loss: 3.5577	batch_accuracy: 34.96%	lr:0.000989
Ep: 8/48	It: 7501/8134	batch_loss: 3.3885	batch_accuracy: 36.06%	lr:0.000989
Ep: 8/48	It: 7551/8134	batch_loss: 3.6154	batch_accuracy: 35.08%	lr:0.000989
Ep: 8/48	It: 7601/8134	batch_loss: 3.3747	batch_accuracy: 37.11%	lr:0.000989
Ep: 8/48	It: 7651/8134	batch_loss: 3.4141	batch_accuracy: 37.18%	lr:0.000989
Ep: 8/48	It: 7701/8134	batch_loss: 3.4480	batch_accuracy: 36.74%	lr:0.000989
Ep: 8/48	It: 7751/8134	batch_loss: 3.4001	batch_accuracy: 37.30%	lr:0.000989
Ep: 8/48	It: 7801/8134	batch_loss: 3.4153	batch_accuracy: 37.79%	lr:0.000988
Ep: 8/48	It: 7851/8134	batch_loss: 3.5144	batch_accuracy: 35.74%	lr:0.000988
Ep: 8/48	It: 7901/8134	batch_loss: 3.5686	batch_accuracy: 34.86%	lr:0.000988
Ep: 8/48	It: 7951/8134	batch_loss: 3.5251	batch_accuracy: 35.06%	lr:0.000988
Ep: 8/48	It: 8001/8134	batch_loss: 3.4710	batch_accuracy: 36.30%	lr:0.000988
Ep: 8/48	It: 8051/8134	batch_loss: 3.4860	batch_accuracy: 35.84%	lr:0.000988
Ep: 8/48	It: 8101/8134	batch_loss: 3.5445	batch_accuracy: 36.67%	lr:0.000988
Ep: 8/48	It: 8134/8134	batch_loss: 3.5175	batch_accuracy: 35.87%	lr:0.000988


Generated text for input text "You" is:
You, to the authors who were able to achieve the best of theories. The authors have taken up award of this article.
<eot>
<sot>
Proteins and mechanisms of human leukocyte migration in vitro.
SUBJECTIVE
The role of the effect of cytokines and the role of these processes in bone remodeling. The role of this hormone in the development of inflammatory inflammatory disorders is now the primary cause of the disease. We have previously shown that the effect of thyroid hormones on the growth of the human uve is mediated by the accumulation of endogenous IL-4. To determine the effects of thyroid hormones on the development of inflammatory disorders, we investigated the role of thyroid hormone-releasing hormone (TH) and thyroid hormone-releasing hormone (TH-RH) in the development of the inflammatory state of patients with thyroid cancer. We found that thyroid hormone receptor (TH) plays a role in thyroid function and expression of thyroid hormone-releasing hormone (TH) in patients with thyroid cancer.


CONCLUSIONS
TH-RH-RH has been found to have an effect on thyroid hormone-releasing hormone-releasing hormone (


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 9/48	It: 1/8134	batch_loss: 3.3558	batch_accuracy: 37.11%	lr:0.000988
Ep: 9/48	It: 51/8134	batch_loss: 3.4846	batch_accuracy: 37.33%	lr:0.000988
Ep: 9/48	It: 101/8134	batch_loss: 3.5237	batch_accuracy: 35.62%	lr:0.000988
Ep: 9/48	It: 151/8134	batch_loss: 3.4136	batch_accuracy: 36.25%	lr:0.000988
Ep: 9/48	It: 201/8134	batch_loss: 3.4023	batch_accuracy: 37.79%	lr:0.000988
Ep: 9/48	It: 251/8134	batch_loss: 3.4635	batch_accuracy: 35.18%	lr:0.000988
Ep: 9/48	It: 301/8134	batch_loss: 3.3609	batch_accuracy: 37.92%	lr:0.000988
Ep: 9/48	It: 351/8134	batch_loss: 3.5246	batch_accuracy: 36.08%	lr:0.000988
Ep: 9/48	It: 401/8134	batch_loss: 3.3356	batch_accuracy: 39.16%	lr:0.000988
Ep: 9/48	It: 451/8134	batch_loss: 3.4496	batch_accuracy: 36.08%	lr:0.000988
Ep: 9/48	It: 501/8134	batch_loss: 3.3822	batch_accuracy: 36.84%	lr:0.000988
Ep: 9/48	It: 551/8134	batch_loss: 3.4793	batch_accuracy: 35.84%	lr:0.000988
Ep: 9/48	It: 601/8134	batch_loss: 3.4435	batch_accuracy: 35.55%	lr:0.000988
Ep: 9/48	It: 651/8134	batch_loss: 3.5660	batch_accuracy: 34.62%	lr:0.000988
Ep: 9/48	It: 701/8134	batch_loss: 3.3960	batch_accuracy: 36.96%	lr:0.000987
Ep: 9/48	It: 751/8134	batch_loss: 3.5102	batch_accuracy: 34.91%	lr:0.000987
Ep: 9/48	It: 801/8134	batch_loss: 3.3591	batch_accuracy: 37.84%	lr:0.000987
Ep: 9/48	It: 851/8134	batch_loss: 3.4604	batch_accuracy: 35.57%	lr:0.000987
Ep: 9/48	It: 901/8134	batch_loss: 3.4188	batch_accuracy: 37.57%	lr:0.000987
Ep: 9/48	It: 951/8134	batch_loss: 3.5435	batch_accuracy: 35.57%	lr:0.000987
Ep: 9/48	It: 1001/8134	batch_loss: 3.4641	batch_accuracy: 35.62%	lr:0.000987
Ep: 9/48	It: 1051/8134	batch_loss: 3.4381	batch_accuracy: 37.11%	lr:0.000987
Ep: 9/48	It: 1101/8134	batch_loss: 3.5285	batch_accuracy: 35.99%	lr:0.000987
Ep: 9/48	It: 1151/8134	batch_loss: 3.5176	batch_accuracy: 35.72%	lr:0.000987
Ep: 9/48	It: 1201/8134	batch_loss: 3.4949	batch_accuracy: 35.64%	lr:0.000987
Ep: 9/48	It: 1251/8134	batch_loss: 3.4254	batch_accuracy: 36.89%	lr:0.000987
Ep: 9/48	It: 1301/8134	batch_loss: 3.5170	batch_accuracy: 36.45%	lr:0.000987
Ep: 9/48	It: 1351/8134	batch_loss: 3.5211	batch_accuracy: 35.52%	lr:0.000987
Ep: 9/48	It: 1401/8134	batch_loss: 3.3785	batch_accuracy: 36.99%	lr:0.000987
Ep: 9/48	It: 1451/8134	batch_loss: 3.2778	batch_accuracy: 38.40%	lr:0.000987
Ep: 9/48	It: 1501/8134	batch_loss: 3.3938	batch_accuracy: 36.96%	lr:0.000987
Ep: 9/48	It: 1551/8134	batch_loss: 3.5149	batch_accuracy: 35.08%	lr:0.000987
Ep: 9/48	It: 1601/8134	batch_loss: 3.5087	batch_accuracy: 34.38%	lr:0.000987
Ep: 9/48	It: 1651/8134	batch_loss: 3.3213	batch_accuracy: 38.33%	lr:0.000987
Ep: 9/48	It: 1701/8134	batch_loss: 3.5431	batch_accuracy: 34.55%	lr:0.000986
Ep: 9/48	It: 1751/8134	batch_loss: 3.4584	batch_accuracy: 35.50%	lr:0.000986
Ep: 9/48	It: 1801/8134	batch_loss: 3.4567	batch_accuracy: 37.16%	lr:0.000986
Ep: 9/48	It: 1851/8134	batch_loss: 3.4838	batch_accuracy: 35.67%	lr:0.000986
Ep: 9/48	It: 1901/8134	batch_loss: 3.3816	batch_accuracy: 36.99%	lr:0.000986
Ep: 9/48	It: 1951/8134	batch_loss: 3.3885	batch_accuracy: 37.28%	lr:0.000986
Ep: 9/48	It: 2001/8134	batch_loss: 3.4564	batch_accuracy: 36.65%	lr:0.000986
Ep: 9/48	It: 2051/8134	batch_loss: 3.4900	batch_accuracy: 36.62%	lr:0.000986
Ep: 9/48	It: 2101/8134	batch_loss: 3.5515	batch_accuracy: 34.69%	lr:0.000986
Ep: 9/48	It: 2151/8134	batch_loss: 3.4017	batch_accuracy: 35.79%	lr:0.000986
Ep: 9/48	It: 2201/8134	batch_loss: 3.4916	batch_accuracy: 36.35%	lr:0.000986
Ep: 9/48	It: 2251/8134	batch_loss: 3.4174	batch_accuracy: 36.91%	lr:0.000986
Ep: 9/48	It: 2301/8134	batch_loss: 3.4475	batch_accuracy: 37.06%	lr:0.000986
Ep: 9/48	It: 2351/8134	batch_loss: 3.4639	batch_accuracy: 36.62%	lr:0.000986
Ep: 9/48	It: 2401/8134	batch_loss: 3.5145	batch_accuracy: 35.60%	lr:0.000986
Ep: 9/48	It: 2451/8134	batch_loss: 3.4490	batch_accuracy: 37.55%	lr:0.000986
Ep: 9/48	It: 2501/8134	batch_loss: 3.4291	batch_accuracy: 35.86%	lr:0.000986
Ep: 9/48	It: 2551/8134	batch_loss: 3.4733	batch_accuracy: 37.04%	lr:0.000986
Ep: 9/48	It: 2601/8134	batch_loss: 3.5340	batch_accuracy: 35.74%	lr:0.000986
Ep: 9/48	It: 2651/8134	batch_loss: 3.4160	batch_accuracy: 38.09%	lr:0.000985
Ep: 9/48	It: 2701/8134	batch_loss: 3.5146	batch_accuracy: 36.04%	lr:0.000985
Ep: 9/48	It: 2751/8134	batch_loss: 3.5204	batch_accuracy: 35.94%	lr:0.000985
Ep: 9/48	It: 2801/8134	batch_loss: 3.4990	batch_accuracy: 35.21%	lr:0.000985
Ep: 9/48	It: 2851/8134	batch_loss: 3.3524	batch_accuracy: 37.92%	lr:0.000985
Ep: 9/48	It: 2901/8134	batch_loss: 3.4778	batch_accuracy: 35.50%	lr:0.000985
Ep: 9/48	It: 2951/8134	batch_loss: 3.3877	batch_accuracy: 37.28%	lr:0.000985
Ep: 9/48	It: 3001/8134	batch_loss: 3.4770	batch_accuracy: 35.52%	lr:0.000985
Ep: 9/48	It: 3051/8134	batch_loss: 3.5169	batch_accuracy: 34.40%	lr:0.000985
Ep: 9/48	It: 3101/8134	batch_loss: 3.4927	batch_accuracy: 35.72%	lr:0.000985
Ep: 9/48	It: 3151/8134	batch_loss: 3.3813	batch_accuracy: 36.18%	lr:0.000985
Ep: 9/48	It: 3201/8134	batch_loss: 3.4324	batch_accuracy: 36.87%	lr:0.000985
Ep: 9/48	It: 3251/8134	batch_loss: 3.3585	batch_accuracy: 37.30%	lr:0.000985
Ep: 9/48	It: 3301/8134	batch_loss: 3.3262	batch_accuracy: 37.62%	lr:0.000985
Ep: 9/48	It: 3351/8134	batch_loss: 3.5068	batch_accuracy: 36.11%	lr:0.000985
Ep: 9/48	It: 3401/8134	batch_loss: 3.4837	batch_accuracy: 36.43%	lr:0.000985
Ep: 9/48	It: 3451/8134	batch_loss: 3.4625	batch_accuracy: 36.57%	lr:0.000985
Ep: 9/48	It: 3501/8134	batch_loss: 3.3634	batch_accuracy: 38.43%	lr:0.000985
Ep: 9/48	It: 3551/8134	batch_loss: 3.3349	batch_accuracy: 38.72%	lr:0.000984
Ep: 9/48	It: 3601/8134	batch_loss: 3.4462	batch_accuracy: 36.84%	lr:0.000984
Ep: 9/48	It: 3651/8134	batch_loss: 3.3862	batch_accuracy: 37.57%	lr:0.000984
Ep: 9/48	It: 3701/8134	batch_loss: 3.4888	batch_accuracy: 35.89%	lr:0.000984
Ep: 9/48	It: 3751/8134	batch_loss: 3.3624	batch_accuracy: 38.45%	lr:0.000984
Ep: 9/48	It: 3801/8134	batch_loss: 3.4778	batch_accuracy: 36.28%	lr:0.000984
Ep: 9/48	It: 3851/8134	batch_loss: 3.4421	batch_accuracy: 36.50%	lr:0.000984
Ep: 9/48	It: 3901/8134	batch_loss: 3.4612	batch_accuracy: 37.70%	lr:0.000984
Ep: 9/48	It: 3951/8134	batch_loss: 3.3973	batch_accuracy: 37.23%	lr:0.000984
Ep: 9/48	It: 4001/8134	batch_loss: 3.3465	batch_accuracy: 38.23%	lr:0.000984
Ep: 9/48	It: 4051/8134	batch_loss: 3.4614	batch_accuracy: 36.38%	lr:0.000984
Ep: 9/48	It: 4101/8134	batch_loss: 3.4020	batch_accuracy: 36.99%	lr:0.000984
Ep: 9/48	It: 4151/8134	batch_loss: 3.3442	batch_accuracy: 38.18%	lr:0.000984
Ep: 9/48	It: 4201/8134	batch_loss: 3.4474	batch_accuracy: 36.50%	lr:0.000984
Ep: 9/48	It: 4251/8134	batch_loss: 3.3921	batch_accuracy: 36.38%	lr:0.000984
Ep: 9/48	It: 4301/8134	batch_loss: 3.3940	batch_accuracy: 37.45%	lr:0.000984
Ep: 9/48	It: 4351/8134	batch_loss: 3.4658	batch_accuracy: 37.08%	lr:0.000984
Ep: 9/48	It: 4401/8134	batch_loss: 3.3882	batch_accuracy: 37.72%	lr:0.000984
Ep: 9/48	It: 4451/8134	batch_loss: 3.4443	batch_accuracy: 36.89%	lr:0.000983
Ep: 9/48	It: 4501/8134	batch_loss: 3.4184	batch_accuracy: 36.04%	lr:0.000983
Ep: 9/48	It: 4551/8134	batch_loss: 3.5008	batch_accuracy: 36.38%	lr:0.000983
Ep: 9/48	It: 4601/8134	batch_loss: 3.4094	batch_accuracy: 35.91%	lr:0.000983
Ep: 9/48	It: 4651/8134	batch_loss: 3.5214	batch_accuracy: 36.79%	lr:0.000983
Ep: 9/48	It: 4701/8134	batch_loss: 3.4817	batch_accuracy: 36.06%	lr:0.000983
Ep: 9/48	It: 4751/8134	batch_loss: 3.4351	batch_accuracy: 36.74%	lr:0.000983
Ep: 9/48	It: 4801/8134	batch_loss: 3.4245	batch_accuracy: 36.01%	lr:0.000983
Ep: 9/48	It: 4851/8134	batch_loss: 3.3313	batch_accuracy: 37.72%	lr:0.000983
Ep: 9/48	It: 4901/8134	batch_loss: 3.3988	batch_accuracy: 37.06%	lr:0.000983
Ep: 9/48	It: 4951/8134	batch_loss: 3.4341	batch_accuracy: 37.35%	lr:0.000983
Ep: 9/48	It: 5001/8134	batch_loss: 3.3676	batch_accuracy: 36.21%	lr:0.000983
Ep: 9/48	It: 5051/8134	batch_loss: 3.4362	batch_accuracy: 37.13%	lr:0.000983
Ep: 9/48	It: 5101/8134	batch_loss: 3.5403	batch_accuracy: 35.30%	lr:0.000983
Ep: 9/48	It: 5151/8134	batch_loss: 3.4613	batch_accuracy: 35.84%	lr:0.000983
Ep: 9/48	It: 5201/8134	batch_loss: 3.3650	batch_accuracy: 38.57%	lr:0.000983
Ep: 9/48	It: 5251/8134	batch_loss: 3.3378	batch_accuracy: 38.82%	lr:0.000983
Ep: 9/48	It: 5301/8134	batch_loss: 3.5798	batch_accuracy: 35.74%	lr:0.000982
Ep: 9/48	It: 5351/8134	batch_loss: 3.3286	batch_accuracy: 36.79%	lr:0.000982
Ep: 9/48	It: 5401/8134	batch_loss: 3.5007	batch_accuracy: 35.69%	lr:0.000982
Ep: 9/48	It: 5451/8134	batch_loss: 3.2757	batch_accuracy: 38.77%	lr:0.000982
Ep: 9/48	It: 5501/8134	batch_loss: 3.3605	batch_accuracy: 37.72%	lr:0.000982
Ep: 9/48	It: 5551/8134	batch_loss: 3.6260	batch_accuracy: 34.62%	lr:0.000982
Ep: 9/48	It: 5601/8134	batch_loss: 3.4108	batch_accuracy: 36.23%	lr:0.000982
Ep: 9/48	It: 5651/8134	batch_loss: 3.5310	batch_accuracy: 34.86%	lr:0.000982
Ep: 9/48	It: 5701/8134	batch_loss: 3.4601	batch_accuracy: 35.55%	lr:0.000982
Ep: 9/48	It: 5751/8134	batch_loss: 3.3912	batch_accuracy: 37.82%	lr:0.000982
Ep: 9/48	It: 5801/8134	batch_loss: 3.3757	batch_accuracy: 37.35%	lr:0.000982
Ep: 9/48	It: 5851/8134	batch_loss: 3.5144	batch_accuracy: 34.16%	lr:0.000982
Ep: 9/48	It: 5901/8134	batch_loss: 3.4230	batch_accuracy: 36.55%	lr:0.000982
Ep: 9/48	It: 5951/8134	batch_loss: 3.5781	batch_accuracy: 35.23%	lr:0.000982
Ep: 9/48	It: 6001/8134	batch_loss: 3.5523	batch_accuracy: 34.91%	lr:0.000982
Ep: 9/48	It: 6051/8134	batch_loss: 3.4386	batch_accuracy: 37.01%	lr:0.000982
Ep: 9/48	It: 6101/8134	batch_loss: 3.3725	batch_accuracy: 37.82%	lr:0.000982
Ep: 9/48	It: 6151/8134	batch_loss: 3.5421	batch_accuracy: 34.96%	lr:0.000981
Ep: 9/48	It: 6201/8134	batch_loss: 3.5131	batch_accuracy: 35.25%	lr:0.000981
Ep: 9/48	It: 6251/8134	batch_loss: 3.3777	batch_accuracy: 36.96%	lr:0.000981
Ep: 9/48	It: 6301/8134	batch_loss: 3.4177	batch_accuracy: 37.11%	lr:0.000981
Ep: 9/48	It: 6351/8134	batch_loss: 3.5256	batch_accuracy: 35.86%	lr:0.000981
Ep: 9/48	It: 6401/8134	batch_loss: 3.5070	batch_accuracy: 35.01%	lr:0.000981
Ep: 9/48	It: 6451/8134	batch_loss: 3.5484	batch_accuracy: 34.52%	lr:0.000981
Ep: 9/48	It: 6501/8134	batch_loss: 3.4306	batch_accuracy: 37.40%	lr:0.000981
Ep: 9/48	It: 6551/8134	batch_loss: 3.3576	batch_accuracy: 37.99%	lr:0.000981
Ep: 9/48	It: 6601/8134	batch_loss: 3.3632	batch_accuracy: 37.13%	lr:0.000981
Ep: 9/48	It: 6651/8134	batch_loss: 3.4417	batch_accuracy: 36.89%	lr:0.000981
Ep: 9/48	It: 6701/8134	batch_loss: 3.3720	batch_accuracy: 36.84%	lr:0.000981
Ep: 9/48	It: 6751/8134	batch_loss: 3.5700	batch_accuracy: 34.13%	lr:0.000981
Ep: 9/48	It: 6801/8134	batch_loss: 3.4346	batch_accuracy: 35.91%	lr:0.000981
Ep: 9/48	It: 6851/8134	batch_loss: 3.3766	batch_accuracy: 36.57%	lr:0.000981
Ep: 9/48	It: 6901/8134	batch_loss: 3.3755	batch_accuracy: 37.16%	lr:0.000981
Ep: 9/48	It: 6951/8134	batch_loss: 3.3937	batch_accuracy: 36.60%	lr:0.000981
Ep: 9/48	It: 7001/8134	batch_loss: 3.3869	batch_accuracy: 37.70%	lr:0.000980
Ep: 9/48	It: 7051/8134	batch_loss: 3.4042	batch_accuracy: 37.50%	lr:0.000980
Ep: 9/48	It: 7101/8134	batch_loss: 3.4829	batch_accuracy: 36.43%	lr:0.000980
Ep: 9/48	It: 7151/8134	batch_loss: 3.3710	batch_accuracy: 36.99%	lr:0.000980
Ep: 9/48	It: 7201/8134	batch_loss: 3.4132	batch_accuracy: 35.99%	lr:0.000980
Ep: 9/48	It: 7251/8134	batch_loss: 3.4065	batch_accuracy: 37.50%	lr:0.000980
Ep: 9/48	It: 7301/8134	batch_loss: 3.4258	batch_accuracy: 37.74%	lr:0.000980
Ep: 9/48	It: 7351/8134	batch_loss: 3.4209	batch_accuracy: 37.67%	lr:0.000980
Ep: 9/48	It: 7401/8134	batch_loss: 3.4242	batch_accuracy: 37.13%	lr:0.000980
Ep: 9/48	It: 7451/8134	batch_loss: 3.4371	batch_accuracy: 36.30%	lr:0.000980
Ep: 9/48	It: 7501/8134	batch_loss: 3.4613	batch_accuracy: 35.82%	lr:0.000980
Ep: 9/48	It: 7551/8134	batch_loss: 3.4276	batch_accuracy: 36.60%	lr:0.000980
Ep: 9/48	It: 7601/8134	batch_loss: 3.3432	batch_accuracy: 37.70%	lr:0.000980
Ep: 9/48	It: 7651/8134	batch_loss: 3.2779	batch_accuracy: 37.87%	lr:0.000980
Ep: 9/48	It: 7701/8134	batch_loss: 3.4035	batch_accuracy: 36.25%	lr:0.000980
Ep: 9/48	It: 7751/8134	batch_loss: 3.3622	batch_accuracy: 37.72%	lr:0.000980
Ep: 9/48	It: 7801/8134	batch_loss: 3.4140	batch_accuracy: 36.50%	lr:0.000979
Ep: 9/48	It: 7851/8134	batch_loss: 3.3969	batch_accuracy: 36.87%	lr:0.000979
Ep: 9/48	It: 7901/8134	batch_loss: 3.4227	batch_accuracy: 36.69%	lr:0.000979
Ep: 9/48	It: 7951/8134	batch_loss: 3.4825	batch_accuracy: 35.99%	lr:0.000979
Ep: 9/48	It: 8001/8134	batch_loss: 3.4532	batch_accuracy: 36.62%	lr:0.000979
Ep: 9/48	It: 8051/8134	batch_loss: 3.4484	batch_accuracy: 35.62%	lr:0.000979
Ep: 9/48	It: 8101/8134	batch_loss: 3.5238	batch_accuracy: 36.04%	lr:0.000979
Ep: 9/48	It: 8134/8134	batch_loss: 3.3447	batch_accuracy: 36.45%	lr:0.000979


Generated text for input text "You" is:
Youa in the United States, and the world, is a major cause of death in the United States. This study explores the extent to which it is possible to determine the frequency of aetitians to the public, the way they are to get the most effective and more reliable solutions. The article concludes that in the absence of a general consensus in the health of a large population of the world, the number of people living in a neighborhood is more than the world, the number of people living in the world is less than 3 years old, and a lack of knowledge about the causes of death in the world is not always known.
<eot>
<sot>
Presence of the Future of the Circulation and Future of Myocardial Infarction in Patients with Cerebellar Syndrome: The Impact of Aerobic Ischemia and Tissue on Vascular Syndrome

Aim: To compare the clinical efficacy of angioplastin in the treatment of patients with cerebral ischemia in stroke patients with cerebral ischemia and to investigate whether the efficacy of Vitamin E antagonists is modulated by angioplastin and the mechanism of action


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 10/48	It: 1/8134	batch_loss: 3.5094	batch_accuracy: 36.08%	lr:0.000979
Ep: 10/48	It: 51/8134	batch_loss: 3.3972	batch_accuracy: 37.43%	lr:0.000979
Ep: 10/48	It: 101/8134	batch_loss: 3.2838	batch_accuracy: 38.57%	lr:0.000979
Ep: 10/48	It: 151/8134	batch_loss: 3.4476	batch_accuracy: 35.79%	lr:0.000979
Ep: 10/48	It: 201/8134	batch_loss: 3.3068	batch_accuracy: 37.84%	lr:0.000979
Ep: 10/48	It: 251/8134	batch_loss: 3.5662	batch_accuracy: 35.30%	lr:0.000979
Ep: 10/48	It: 301/8134	batch_loss: 3.3170	batch_accuracy: 37.92%	lr:0.000979
Ep: 10/48	It: 351/8134	batch_loss: 3.4669	batch_accuracy: 36.35%	lr:0.000979
Ep: 10/48	It: 401/8134	batch_loss: 3.6264	batch_accuracy: 34.59%	lr:0.000978
Ep: 10/48	It: 451/8134	batch_loss: 3.4620	batch_accuracy: 36.62%	lr:0.000978
Ep: 10/48	It: 501/8134	batch_loss: 3.3611	batch_accuracy: 37.57%	lr:0.000978
Ep: 10/48	It: 551/8134	batch_loss: 3.4451	batch_accuracy: 35.94%	lr:0.000978
Ep: 10/48	It: 601/8134	batch_loss: 3.3850	batch_accuracy: 37.01%	lr:0.000978
Ep: 10/48	It: 651/8134	batch_loss: 3.4863	batch_accuracy: 36.11%	lr:0.000978
Ep: 10/48	It: 701/8134	batch_loss: 3.4463	batch_accuracy: 37.65%	lr:0.000978
Ep: 10/48	It: 751/8134	batch_loss: 3.4289	batch_accuracy: 36.79%	lr:0.000978
Ep: 10/48	It: 801/8134	batch_loss: 3.5775	batch_accuracy: 35.60%	lr:0.000978
Ep: 10/48	It: 851/8134	batch_loss: 3.4474	batch_accuracy: 37.04%	lr:0.000978
Ep: 10/48	It: 901/8134	batch_loss: 3.3827	batch_accuracy: 36.99%	lr:0.000978
Ep: 10/48	It: 951/8134	batch_loss: 3.3153	batch_accuracy: 37.65%	lr:0.000978
Ep: 10/48	It: 1001/8134	batch_loss: 3.4172	batch_accuracy: 36.91%	lr:0.000978
Ep: 10/48	It: 1051/8134	batch_loss: 3.4329	batch_accuracy: 37.74%	lr:0.000978
Ep: 10/48	It: 1101/8134	batch_loss: 3.2580	batch_accuracy: 39.40%	lr:0.000978
Ep: 10/48	It: 1151/8134	batch_loss: 3.4142	batch_accuracy: 38.06%	lr:0.000978
Ep: 10/48	It: 1201/8134	batch_loss: 3.5186	batch_accuracy: 34.08%	lr:0.000977
Ep: 10/48	It: 1251/8134	batch_loss: 3.3950	batch_accuracy: 37.30%	lr:0.000977
Ep: 10/48	It: 1301/8134	batch_loss: 3.3841	batch_accuracy: 37.50%	lr:0.000977
Ep: 10/48	It: 1351/8134	batch_loss: 3.3704	batch_accuracy: 37.16%	lr:0.000977
Ep: 10/48	It: 1401/8134	batch_loss: 3.4287	batch_accuracy: 36.91%	lr:0.000977
Ep: 10/48	It: 1451/8134	batch_loss: 3.3708	batch_accuracy: 37.06%	lr:0.000977
Ep: 10/48	It: 1501/8134	batch_loss: 3.4494	batch_accuracy: 36.35%	lr:0.000977
Ep: 10/48	It: 1551/8134	batch_loss: 3.4823	batch_accuracy: 34.89%	lr:0.000977
Ep: 10/48	It: 1601/8134	batch_loss: 3.4155	batch_accuracy: 37.62%	lr:0.000977
Ep: 10/48	It: 1651/8134	batch_loss: 3.4135	batch_accuracy: 36.45%	lr:0.000977
Ep: 10/48	It: 1701/8134	batch_loss: 3.3947	batch_accuracy: 37.43%	lr:0.000977
Ep: 10/48	It: 1751/8134	batch_loss: 3.4291	batch_accuracy: 36.06%	lr:0.000977
Ep: 10/48	It: 1801/8134	batch_loss: 3.4628	batch_accuracy: 36.16%	lr:0.000977
Ep: 10/48	It: 1851/8134	batch_loss: 3.4775	batch_accuracy: 36.11%	lr:0.000977
Ep: 10/48	It: 1901/8134	batch_loss: 3.4178	batch_accuracy: 36.89%	lr:0.000977
Ep: 10/48	It: 1951/8134	batch_loss: 3.4490	batch_accuracy: 36.23%	lr:0.000976
Ep: 10/48	It: 2001/8134	batch_loss: 3.2634	batch_accuracy: 38.38%	lr:0.000976
Ep: 10/48	It: 2051/8134	batch_loss: 3.3687	batch_accuracy: 37.40%	lr:0.000976
Ep: 10/48	It: 2101/8134	batch_loss: 3.4016	batch_accuracy: 37.06%	lr:0.000976
Ep: 10/48	It: 2151/8134	batch_loss: 3.4197	batch_accuracy: 37.16%	lr:0.000976
Ep: 10/48	It: 2201/8134	batch_loss: 3.4123	batch_accuracy: 36.60%	lr:0.000976
Ep: 10/48	It: 2251/8134	batch_loss: 3.3604	batch_accuracy: 36.79%	lr:0.000976
Ep: 10/48	It: 2301/8134	batch_loss: 3.3643	batch_accuracy: 37.18%	lr:0.000976
Ep: 10/48	It: 2351/8134	batch_loss: 3.5006	batch_accuracy: 35.45%	lr:0.000976
Ep: 10/48	It: 2401/8134	batch_loss: 3.4142	batch_accuracy: 37.04%	lr:0.000976
Ep: 10/48	It: 2451/8134	batch_loss: 3.4535	batch_accuracy: 36.30%	lr:0.000976
Ep: 10/48	It: 2501/8134	batch_loss: 3.5192	batch_accuracy: 35.40%	lr:0.000976
Ep: 10/48	It: 2551/8134	batch_loss: 3.3433	batch_accuracy: 37.57%	lr:0.000976
Ep: 10/48	It: 2601/8134	batch_loss: 3.4624	batch_accuracy: 36.18%	lr:0.000976
Ep: 10/48	It: 2651/8134	batch_loss: 3.3144	batch_accuracy: 38.62%	lr:0.000975
Ep: 10/48	It: 2701/8134	batch_loss: 3.5261	batch_accuracy: 34.86%	lr:0.000975
Ep: 10/48	It: 2751/8134	batch_loss: 3.4294	batch_accuracy: 36.21%	lr:0.000975
Ep: 10/48	It: 2801/8134	batch_loss: 3.3498	batch_accuracy: 37.52%	lr:0.000975
Ep: 10/48	It: 2851/8134	batch_loss: 3.4338	batch_accuracy: 36.45%	lr:0.000975
Ep: 10/48	It: 2901/8134	batch_loss: 3.4990	batch_accuracy: 36.21%	lr:0.000975
Ep: 10/48	It: 2951/8134	batch_loss: 3.5021	batch_accuracy: 36.28%	lr:0.000975
Ep: 10/48	It: 3001/8134	batch_loss: 3.4895	batch_accuracy: 35.28%	lr:0.000975
Ep: 10/48	It: 3051/8134	batch_loss: 3.4860	batch_accuracy: 35.94%	lr:0.000975
Ep: 10/48	It: 3101/8134	batch_loss: 3.4280	batch_accuracy: 36.72%	lr:0.000975
Ep: 10/48	It: 3151/8134	batch_loss: 3.4485	batch_accuracy: 36.11%	lr:0.000975
Ep: 10/48	It: 3201/8134	batch_loss: 3.4557	batch_accuracy: 34.52%	lr:0.000975
Ep: 10/48	It: 3251/8134	batch_loss: 3.4497	batch_accuracy: 36.94%	lr:0.000975
Ep: 10/48	It: 3301/8134	batch_loss: 3.4067	batch_accuracy: 37.13%	lr:0.000975
Ep: 10/48	It: 3351/8134	batch_loss: 3.4490	batch_accuracy: 35.77%	lr:0.000975
Ep: 10/48	It: 3401/8134	batch_loss: 3.3877	batch_accuracy: 36.67%	lr:0.000974
Ep: 10/48	It: 3451/8134	batch_loss: 3.3627	batch_accuracy: 37.52%	lr:0.000974
Ep: 10/48	It: 3501/8134	batch_loss: 3.4065	batch_accuracy: 37.23%	lr:0.000974
Ep: 10/48	It: 3551/8134	batch_loss: 3.3552	batch_accuracy: 37.87%	lr:0.000974
Ep: 10/48	It: 3601/8134	batch_loss: 3.3692	batch_accuracy: 38.94%	lr:0.000974
Ep: 10/48	It: 3651/8134	batch_loss: 3.4372	batch_accuracy: 36.77%	lr:0.000974
Ep: 10/48	It: 3701/8134	batch_loss: 3.5158	batch_accuracy: 35.86%	lr:0.000974
Ep: 10/48	It: 3751/8134	batch_loss: 3.3952	batch_accuracy: 36.67%	lr:0.000974
Ep: 10/48	It: 3801/8134	batch_loss: 3.5458	batch_accuracy: 35.64%	lr:0.000974
Ep: 10/48	It: 3851/8134	batch_loss: 3.2689	batch_accuracy: 38.94%	lr:0.000974
Ep: 10/48	It: 3901/8134	batch_loss: 3.4087	batch_accuracy: 36.67%	lr:0.000974
Ep: 10/48	It: 3951/8134	batch_loss: 3.4517	batch_accuracy: 35.60%	lr:0.000974
Ep: 10/48	It: 4001/8134	batch_loss: 3.3230	batch_accuracy: 38.70%	lr:0.000974
Ep: 10/48	It: 4051/8134	batch_loss: 3.4873	batch_accuracy: 36.21%	lr:0.000974
Ep: 10/48	It: 4101/8134	batch_loss: 3.4130	batch_accuracy: 37.60%	lr:0.000973
Ep: 10/48	It: 4151/8134	batch_loss: 3.3682	batch_accuracy: 37.79%	lr:0.000973
Ep: 10/48	It: 4201/8134	batch_loss: 3.4242	batch_accuracy: 36.69%	lr:0.000973
Ep: 10/48	It: 4251/8134	batch_loss: 3.3758	batch_accuracy: 37.01%	lr:0.000973
Ep: 10/48	It: 4301/8134	batch_loss: 3.3178	batch_accuracy: 37.82%	lr:0.000973
Ep: 10/48	It: 4351/8134	batch_loss: 3.4098	batch_accuracy: 37.35%	lr:0.000973
Ep: 10/48	It: 4401/8134	batch_loss: 3.4001	batch_accuracy: 37.55%	lr:0.000973
Ep: 10/48	It: 4451/8134	batch_loss: 3.4244	batch_accuracy: 37.33%	lr:0.000973
Ep: 10/48	It: 4501/8134	batch_loss: 3.4489	batch_accuracy: 36.82%	lr:0.000973
Ep: 10/48	It: 4551/8134	batch_loss: 3.3262	batch_accuracy: 38.31%	lr:0.000973
Ep: 10/48	It: 4601/8134	batch_loss: 3.4011	batch_accuracy: 36.84%	lr:0.000973
Ep: 10/48	It: 4651/8134	batch_loss: 3.4232	batch_accuracy: 37.01%	lr:0.000973
Ep: 10/48	It: 4701/8134	batch_loss: 3.3128	batch_accuracy: 37.13%	lr:0.000973
Ep: 10/48	It: 4751/8134	batch_loss: 3.5450	batch_accuracy: 35.01%	lr:0.000972
Ep: 10/48	It: 4801/8134	batch_loss: 3.2497	batch_accuracy: 38.89%	lr:0.000972
Ep: 10/48	It: 4851/8134	batch_loss: 3.4603	batch_accuracy: 36.11%	lr:0.000972
Ep: 10/48	It: 4901/8134	batch_loss: 3.3495	batch_accuracy: 38.50%	lr:0.000972
Ep: 10/48	It: 4951/8134	batch_loss: 3.3381	batch_accuracy: 37.87%	lr:0.000972
Ep: 10/48	It: 5001/8134	batch_loss: 3.3095	batch_accuracy: 37.94%	lr:0.000972
Ep: 10/48	It: 5051/8134	batch_loss: 3.3602	batch_accuracy: 37.72%	lr:0.000972
Ep: 10/48	It: 5101/8134	batch_loss: 3.4164	batch_accuracy: 36.82%	lr:0.000972
Ep: 10/48	It: 5151/8134	batch_loss: 3.4040	batch_accuracy: 36.45%	lr:0.000972
Ep: 10/48	It: 5201/8134	batch_loss: 3.4846	batch_accuracy: 36.57%	lr:0.000972
Ep: 10/48	It: 5251/8134	batch_loss: 3.4354	batch_accuracy: 36.18%	lr:0.000972
Ep: 10/48	It: 5301/8134	batch_loss: 3.4915	batch_accuracy: 35.67%	lr:0.000972
Ep: 10/48	It: 5351/8134	batch_loss: 3.3788	batch_accuracy: 36.87%	lr:0.000972
Ep: 10/48	It: 5401/8134	batch_loss: 3.4947	batch_accuracy: 35.77%	lr:0.000972
Ep: 10/48	It: 5451/8134	batch_loss: 3.4183	batch_accuracy: 37.89%	lr:0.000971
Ep: 10/48	It: 5501/8134	batch_loss: 3.4273	batch_accuracy: 35.57%	lr:0.000971
Ep: 10/48	It: 5551/8134	batch_loss: 3.3394	batch_accuracy: 38.21%	lr:0.000971
Ep: 10/48	It: 5601/8134	batch_loss: 3.5034	batch_accuracy: 36.25%	lr:0.000971
Ep: 10/48	It: 5651/8134	batch_loss: 3.3394	batch_accuracy: 37.16%	lr:0.000971
Ep: 10/48	It: 5701/8134	batch_loss: 3.4153	batch_accuracy: 36.18%	lr:0.000971
Ep: 10/48	It: 5751/8134	batch_loss: 3.0956	batch_accuracy: 40.77%	lr:0.000971
Ep: 10/48	It: 5801/8134	batch_loss: 3.4803	batch_accuracy: 35.40%	lr:0.000971
Ep: 10/48	It: 5851/8134	batch_loss: 3.4586	batch_accuracy: 36.45%	lr:0.000971
Ep: 10/48	It: 5901/8134	batch_loss: 3.4383	batch_accuracy: 37.43%	lr:0.000971
Ep: 10/48	It: 5951/8134	batch_loss: 3.5144	batch_accuracy: 36.43%	lr:0.000971
Ep: 10/48	It: 6001/8134	batch_loss: 3.3338	batch_accuracy: 38.33%	lr:0.000971
Ep: 10/48	It: 6051/8134	batch_loss: 3.3277	batch_accuracy: 37.60%	lr:0.000971
Ep: 10/48	It: 6101/8134	batch_loss: 3.3953	batch_accuracy: 36.91%	lr:0.000970
Ep: 10/48	It: 6151/8134	batch_loss: 3.3988	batch_accuracy: 36.99%	lr:0.000970
Ep: 10/48	It: 6201/8134	batch_loss: 3.4301	batch_accuracy: 37.28%	lr:0.000970
Ep: 10/48	It: 6251/8134	batch_loss: 3.3776	batch_accuracy: 37.04%	lr:0.000970
Ep: 10/48	It: 6301/8134	batch_loss: 3.5062	batch_accuracy: 36.47%	lr:0.000970
Ep: 10/48	It: 6351/8134	batch_loss: 3.4910	batch_accuracy: 35.11%	lr:0.000970
Ep: 10/48	It: 6401/8134	batch_loss: 3.3535	batch_accuracy: 37.21%	lr:0.000970
Ep: 10/48	It: 6451/8134	batch_loss: 3.3423	batch_accuracy: 37.01%	lr:0.000970
Ep: 10/48	It: 6501/8134	batch_loss: 3.3345	batch_accuracy: 38.04%	lr:0.000970
Ep: 10/48	It: 6551/8134	batch_loss: 3.3758	batch_accuracy: 37.62%	lr:0.000970
Ep: 10/48	It: 6601/8134	batch_loss: 3.4155	batch_accuracy: 36.50%	lr:0.000970
Ep: 10/48	It: 6651/8134	batch_loss: 3.2700	batch_accuracy: 38.23%	lr:0.000970
Ep: 10/48	It: 6701/8134	batch_loss: 3.4417	batch_accuracy: 36.62%	lr:0.000970
Ep: 10/48	It: 6751/8134	batch_loss: 3.4079	batch_accuracy: 36.43%	lr:0.000969
Ep: 10/48	It: 6801/8134	batch_loss: 3.4995	batch_accuracy: 35.99%	lr:0.000969
Ep: 10/48	It: 6851/8134	batch_loss: 3.4076	batch_accuracy: 37.45%	lr:0.000969
Ep: 10/48	It: 6901/8134	batch_loss: 3.3679	batch_accuracy: 36.79%	lr:0.000969
Ep: 10/48	It: 6951/8134	batch_loss: 3.5001	batch_accuracy: 36.06%	lr:0.000969
Ep: 10/48	It: 7001/8134	batch_loss: 3.3649	batch_accuracy: 38.11%	lr:0.000969
Ep: 10/48	It: 7051/8134	batch_loss: 3.4078	batch_accuracy: 37.18%	lr:0.000969
Ep: 10/48	It: 7101/8134	batch_loss: 3.2982	batch_accuracy: 38.21%	lr:0.000969
Ep: 10/48	It: 7151/8134	batch_loss: 3.4417	batch_accuracy: 37.72%	lr:0.000969
Ep: 10/48	It: 7201/8134	batch_loss: 3.4860	batch_accuracy: 36.43%	lr:0.000969
Ep: 10/48	It: 7251/8134	batch_loss: 3.3994	batch_accuracy: 35.99%	lr:0.000969
Ep: 10/48	It: 7301/8134	batch_loss: 3.4452	batch_accuracy: 37.26%	lr:0.000969
Ep: 10/48	It: 7351/8134	batch_loss: 3.3471	batch_accuracy: 38.60%	lr:0.000969
Ep: 10/48	It: 7401/8134	batch_loss: 3.5010	batch_accuracy: 35.86%	lr:0.000968
Ep: 10/48	It: 7451/8134	batch_loss: 3.3638	batch_accuracy: 36.74%	lr:0.000968
Ep: 10/48	It: 7501/8134	batch_loss: 3.5474	batch_accuracy: 35.86%	lr:0.000968
Ep: 10/48	It: 7551/8134	batch_loss: 3.3714	batch_accuracy: 37.16%	lr:0.000968
Ep: 10/48	It: 7601/8134	batch_loss: 3.3092	batch_accuracy: 37.60%	lr:0.000968
Ep: 10/48	It: 7651/8134	batch_loss: 3.3156	batch_accuracy: 37.96%	lr:0.000968
Ep: 10/48	It: 7701/8134	batch_loss: 3.4361	batch_accuracy: 37.35%	lr:0.000968
Ep: 10/48	It: 7751/8134	batch_loss: 3.4161	batch_accuracy: 36.60%	lr:0.000968
Ep: 10/48	It: 7801/8134	batch_loss: 3.3732	batch_accuracy: 37.70%	lr:0.000968
Ep: 10/48	It: 7851/8134	batch_loss: 3.3574	batch_accuracy: 37.65%	lr:0.000968
Ep: 10/48	It: 7901/8134	batch_loss: 3.4157	batch_accuracy: 36.06%	lr:0.000968
Ep: 10/48	It: 7951/8134	batch_loss: 3.5175	batch_accuracy: 35.40%	lr:0.000968
Ep: 10/48	It: 8001/8134	batch_loss: 3.2022	batch_accuracy: 39.21%	lr:0.000968
Ep: 10/48	It: 8051/8134	batch_loss: 3.5229	batch_accuracy: 35.06%	lr:0.000967
Ep: 10/48	It: 8101/8134	batch_loss: 3.3683	batch_accuracy: 36.62%	lr:0.000967
Ep: 10/48	It: 8134/8134	batch_loss: 3.3989	batch_accuracy: 37.09%	lr:0.000967


Generated text for input text "You" is:
You, and other studies were carried out. The results show that the method of the proposed method is feasible and the effectiveness of the proposed method is demonstrated.

<eot>
<sot>
MULATION OF LINCULARY PERFECTS OF RECON
A BEATING CONCENTRATION

The article analyzes the potential for the development of a new technology for high-performance liquid chromatography (HPLC) detection. The use of the method of extraction of high-performance liquid chromatography (HPLC) has been shown to have great potential in the analysis of the gas and liquid phases in industrial products.
<eot>
<sot>
Principles of Integration of Carbon-Carbon-Metal-Sulfur Mechanics

The article analyzes the role of carbon-carbon-carbon-sulfur batteries in the formation of carbon-carbon-sulfur clusters in the formation of a new energy reservoir. The analysis of the effect of hydrogen-sulfur-oxide (H2O) on carbon-sulfur and nitrogen (N) emissions is carried out to determine


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 11/48	It: 1/8134	batch_loss: 3.5151	batch_accuracy: 35.03%	lr:0.000967
Ep: 11/48	It: 51/8134	batch_loss: 3.2514	batch_accuracy: 38.99%	lr:0.000967
Ep: 11/48	It: 101/8134	batch_loss: 3.3967	batch_accuracy: 37.18%	lr:0.000967
Ep: 11/48	It: 151/8134	batch_loss: 3.4116	batch_accuracy: 37.18%	lr:0.000967
Ep: 11/48	It: 201/8134	batch_loss: 3.3143	batch_accuracy: 38.21%	lr:0.000967
Ep: 11/48	It: 251/8134	batch_loss: 3.2935	batch_accuracy: 37.16%	lr:0.000967
Ep: 11/48	It: 301/8134	batch_loss: 3.3376	batch_accuracy: 38.57%	lr:0.000967
Ep: 11/48	It: 351/8134	batch_loss: 3.3574	batch_accuracy: 37.43%	lr:0.000967
Ep: 11/48	It: 401/8134	batch_loss: 3.5424	batch_accuracy: 33.94%	lr:0.000967
Ep: 11/48	It: 451/8134	batch_loss: 3.3049	batch_accuracy: 37.04%	lr:0.000967
Ep: 11/48	It: 501/8134	batch_loss: 3.4689	batch_accuracy: 37.16%	lr:0.000967
Ep: 11/48	It: 551/8134	batch_loss: 3.3796	batch_accuracy: 37.96%	lr:0.000966
Ep: 11/48	It: 601/8134	batch_loss: 3.4991	batch_accuracy: 36.96%	lr:0.000966
Ep: 11/48	It: 651/8134	batch_loss: 3.4322	batch_accuracy: 35.99%	lr:0.000966
Ep: 11/48	It: 701/8134	batch_loss: 3.5407	batch_accuracy: 34.96%	lr:0.000966
Ep: 11/48	It: 751/8134	batch_loss: 3.4512	batch_accuracy: 36.77%	lr:0.000966
Ep: 11/48	It: 801/8134	batch_loss: 3.4708	batch_accuracy: 36.38%	lr:0.000966
Ep: 11/48	It: 851/8134	batch_loss: 3.4981	batch_accuracy: 36.52%	lr:0.000966
Ep: 11/48	It: 901/8134	batch_loss: 3.4125	batch_accuracy: 36.82%	lr:0.000966
Ep: 11/48	It: 951/8134	batch_loss: 3.3340	batch_accuracy: 37.52%	lr:0.000966
Ep: 11/48	It: 1001/8134	batch_loss: 3.5313	batch_accuracy: 35.62%	lr:0.000966
Ep: 11/48	It: 1051/8134	batch_loss: 3.4726	batch_accuracy: 36.33%	lr:0.000966
Ep: 11/48	It: 1101/8134	batch_loss: 3.4711	batch_accuracy: 36.87%	lr:0.000966
Ep: 11/48	It: 1151/8134	batch_loss: 3.2578	batch_accuracy: 38.75%	lr:0.000965
Ep: 11/48	It: 1201/8134	batch_loss: 3.6125	batch_accuracy: 33.81%	lr:0.000965
Ep: 11/48	It: 1251/8134	batch_loss: 3.3860	batch_accuracy: 36.96%	lr:0.000965
Ep: 11/48	It: 1301/8134	batch_loss: 3.3425	batch_accuracy: 37.16%	lr:0.000965
Ep: 11/48	It: 1351/8134	batch_loss: 3.4895	batch_accuracy: 36.25%	lr:0.000965
Ep: 11/48	It: 1401/8134	batch_loss: 3.3478	batch_accuracy: 37.74%	lr:0.000965
Ep: 11/48	It: 1451/8134	batch_loss: 3.4340	batch_accuracy: 36.82%	lr:0.000965
Ep: 11/48	It: 1501/8134	batch_loss: 3.4506	batch_accuracy: 36.50%	lr:0.000965
Ep: 11/48	It: 1551/8134	batch_loss: 3.4498	batch_accuracy: 36.91%	lr:0.000965
Ep: 11/48	It: 1601/8134	batch_loss: 3.3625	batch_accuracy: 37.60%	lr:0.000965
Ep: 11/48	It: 1651/8134	batch_loss: 3.3325	batch_accuracy: 37.60%	lr:0.000965
Ep: 11/48	It: 1701/8134	batch_loss: 3.4139	batch_accuracy: 37.84%	lr:0.000965
Ep: 11/48	It: 1751/8134	batch_loss: 3.4286	batch_accuracy: 36.40%	lr:0.000964
Ep: 11/48	It: 1801/8134	batch_loss: 3.4386	batch_accuracy: 37.21%	lr:0.000964
Ep: 11/48	It: 1851/8134	batch_loss: 3.4223	batch_accuracy: 36.43%	lr:0.000964
Ep: 11/48	It: 1901/8134	batch_loss: 3.4089	batch_accuracy: 36.45%	lr:0.000964
Ep: 11/48	It: 1951/8134	batch_loss: 3.4662	batch_accuracy: 36.52%	lr:0.000964
Ep: 11/48	It: 2001/8134	batch_loss: 3.5446	batch_accuracy: 36.18%	lr:0.000964
Ep: 11/48	It: 2051/8134	batch_loss: 3.3169	batch_accuracy: 39.04%	lr:0.000964
Ep: 11/48	It: 2101/8134	batch_loss: 3.3596	batch_accuracy: 37.57%	lr:0.000964
Ep: 11/48	It: 2151/8134	batch_loss: 3.4307	batch_accuracy: 36.21%	lr:0.000964
Ep: 11/48	It: 2201/8134	batch_loss: 3.2773	batch_accuracy: 38.26%	lr:0.000964
Ep: 11/48	It: 2251/8134	batch_loss: 3.4844	batch_accuracy: 36.16%	lr:0.000964
Ep: 11/48	It: 2301/8134	batch_loss: 3.4479	batch_accuracy: 36.13%	lr:0.000964
Ep: 11/48	It: 2351/8134	batch_loss: 3.5071	batch_accuracy: 36.21%	lr:0.000964
Ep: 11/48	It: 2401/8134	batch_loss: 3.4811	batch_accuracy: 35.33%	lr:0.000963
Ep: 11/48	It: 2451/8134	batch_loss: 3.4436	batch_accuracy: 36.47%	lr:0.000963
Ep: 11/48	It: 2501/8134	batch_loss: 3.4902	batch_accuracy: 36.35%	lr:0.000963
Ep: 11/48	It: 2551/8134	batch_loss: 3.3850	batch_accuracy: 36.89%	lr:0.000963
Ep: 11/48	It: 2601/8134	batch_loss: 3.5310	batch_accuracy: 35.45%	lr:0.000963
Ep: 11/48	It: 2651/8134	batch_loss: 3.3804	batch_accuracy: 37.28%	lr:0.000963
Ep: 11/48	It: 2701/8134	batch_loss: 3.3984	batch_accuracy: 37.08%	lr:0.000963
Ep: 11/48	It: 2751/8134	batch_loss: 3.2068	batch_accuracy: 39.82%	lr:0.000963
Ep: 11/48	It: 2801/8134	batch_loss: 3.5701	batch_accuracy: 34.77%	lr:0.000963
Ep: 11/48	It: 2851/8134	batch_loss: 3.4376	batch_accuracy: 35.96%	lr:0.000963
Ep: 11/48	It: 2901/8134	batch_loss: 3.3789	batch_accuracy: 37.35%	lr:0.000963
Ep: 11/48	It: 2951/8134	batch_loss: 3.2624	batch_accuracy: 38.75%	lr:0.000962
Ep: 11/48	It: 3001/8134	batch_loss: 3.3436	batch_accuracy: 38.26%	lr:0.000962
Ep: 11/48	It: 3051/8134	batch_loss: 3.3206	batch_accuracy: 37.87%	lr:0.000962
Ep: 11/48	It: 3101/8134	batch_loss: 3.3810	batch_accuracy: 37.40%	lr:0.000962
Ep: 11/48	It: 3151/8134	batch_loss: 3.3587	batch_accuracy: 38.57%	lr:0.000962
Ep: 11/48	It: 3201/8134	batch_loss: 3.3486	batch_accuracy: 38.13%	lr:0.000962
Ep: 11/48	It: 3251/8134	batch_loss: 3.3015	batch_accuracy: 38.55%	lr:0.000962
Ep: 11/48	It: 3301/8134	batch_loss: 3.4375	batch_accuracy: 35.35%	lr:0.000962
Ep: 11/48	It: 3351/8134	batch_loss: 3.3242	batch_accuracy: 38.26%	lr:0.000962
Ep: 11/48	It: 3401/8134	batch_loss: 3.3670	batch_accuracy: 36.67%	lr:0.000962
Ep: 11/48	It: 3451/8134	batch_loss: 3.4581	batch_accuracy: 37.08%	lr:0.000962
Ep: 11/48	It: 3501/8134	batch_loss: 3.3646	batch_accuracy: 37.06%	lr:0.000962
Ep: 11/48	It: 3551/8134	batch_loss: 3.4447	batch_accuracy: 36.52%	lr:0.000961
Ep: 11/48	It: 3601/8134	batch_loss: 3.2805	batch_accuracy: 38.65%	lr:0.000961
Ep: 11/48	It: 3651/8134	batch_loss: 3.3548	batch_accuracy: 37.87%	lr:0.000961
Ep: 11/48	It: 3701/8134	batch_loss: 3.3865	batch_accuracy: 36.69%	lr:0.000961
Ep: 11/48	It: 3751/8134	batch_loss: 3.3467	batch_accuracy: 37.99%	lr:0.000961
Ep: 11/48	It: 3801/8134	batch_loss: 3.4067	batch_accuracy: 37.84%	lr:0.000961
Ep: 11/48	It: 3851/8134	batch_loss: 3.3487	batch_accuracy: 38.01%	lr:0.000961
Ep: 11/48	It: 3901/8134	batch_loss: 3.4153	batch_accuracy: 37.16%	lr:0.000961
Ep: 11/48	It: 3951/8134	batch_loss: 3.4107	batch_accuracy: 37.77%	lr:0.000961
Ep: 11/48	It: 4001/8134	batch_loss: 3.4870	batch_accuracy: 36.79%	lr:0.000961
Ep: 11/48	It: 4051/8134	batch_loss: 3.3984	batch_accuracy: 38.06%	lr:0.000961
Ep: 11/48	It: 4101/8134	batch_loss: 3.4153	batch_accuracy: 36.16%	lr:0.000961
Ep: 11/48	It: 4151/8134	batch_loss: 3.4714	batch_accuracy: 36.45%	lr:0.000960
Ep: 11/48	It: 4201/8134	batch_loss: 3.4346	batch_accuracy: 37.45%	lr:0.000960
Ep: 11/48	It: 4251/8134	batch_loss: 3.4730	batch_accuracy: 36.65%	lr:0.000960
Ep: 11/48	It: 4301/8134	batch_loss: 3.3225	batch_accuracy: 38.38%	lr:0.000960
Ep: 11/48	It: 4351/8134	batch_loss: 3.4523	batch_accuracy: 35.72%	lr:0.000960
Ep: 11/48	It: 4401/8134	batch_loss: 3.3152	batch_accuracy: 39.26%	lr:0.000960
Ep: 11/48	It: 4451/8134	batch_loss: 3.3229	batch_accuracy: 38.26%	lr:0.000960
Ep: 11/48	It: 4501/8134	batch_loss: 3.3872	batch_accuracy: 36.38%	lr:0.000960
Ep: 11/48	It: 4551/8134	batch_loss: 3.4722	batch_accuracy: 36.79%	lr:0.000960
Ep: 11/48	It: 4601/8134	batch_loss: 3.4111	batch_accuracy: 36.62%	lr:0.000960
Ep: 11/48	It: 4651/8134	batch_loss: 3.3317	batch_accuracy: 37.92%	lr:0.000960
Ep: 11/48	It: 4701/8134	batch_loss: 3.4631	batch_accuracy: 36.84%	lr:0.000959
Ep: 11/48	It: 4751/8134	batch_loss: 3.3634	batch_accuracy: 37.13%	lr:0.000959
Ep: 11/48	It: 4801/8134	batch_loss: 3.3364	batch_accuracy: 37.77%	lr:0.000959
Ep: 11/48	It: 4851/8134	batch_loss: 3.4826	batch_accuracy: 35.55%	lr:0.000959
Ep: 11/48	It: 4901/8134	batch_loss: 3.4381	batch_accuracy: 37.23%	lr:0.000959
Ep: 11/48	It: 4951/8134	batch_loss: 3.4723	batch_accuracy: 36.45%	lr:0.000959
Ep: 11/48	It: 5001/8134	batch_loss: 3.4047	batch_accuracy: 36.60%	lr:0.000959
Ep: 11/48	It: 5051/8134	batch_loss: 3.2314	batch_accuracy: 39.36%	lr:0.000959
Ep: 11/48	It: 5101/8134	batch_loss: 3.2446	batch_accuracy: 38.40%	lr:0.000959
Ep: 11/48	It: 5151/8134	batch_loss: 3.4890	batch_accuracy: 36.62%	lr:0.000959
Ep: 11/48	It: 5201/8134	batch_loss: 3.3927	batch_accuracy: 37.72%	lr:0.000959
Ep: 11/48	It: 5251/8134	batch_loss: 3.4447	batch_accuracy: 35.77%	lr:0.000958
Ep: 11/48	It: 5301/8134	batch_loss: 3.3576	batch_accuracy: 37.72%	lr:0.000958
Ep: 11/48	It: 5351/8134	batch_loss: 3.4235	batch_accuracy: 36.96%	lr:0.000958
Ep: 11/48	It: 5401/8134	batch_loss: 3.4460	batch_accuracy: 36.94%	lr:0.000958
Ep: 11/48	It: 5451/8134	batch_loss: 3.3881	batch_accuracy: 37.52%	lr:0.000958
Ep: 11/48	It: 5501/8134	batch_loss: 3.3300	batch_accuracy: 37.70%	lr:0.000958
Ep: 11/48	It: 5551/8134	batch_loss: 3.3101	batch_accuracy: 36.91%	lr:0.000958
Ep: 11/48	It: 5601/8134	batch_loss: 3.2462	batch_accuracy: 38.01%	lr:0.000958
Ep: 11/48	It: 5651/8134	batch_loss: 3.3525	batch_accuracy: 37.40%	lr:0.000958
Ep: 11/48	It: 5701/8134	batch_loss: 3.3805	batch_accuracy: 36.43%	lr:0.000958
Ep: 11/48	It: 5751/8134	batch_loss: 3.4046	batch_accuracy: 36.50%	lr:0.000958
Ep: 11/48	It: 5801/8134	batch_loss: 3.3800	batch_accuracy: 36.65%	lr:0.000958
Ep: 11/48	It: 5851/8134	batch_loss: 3.4507	batch_accuracy: 35.62%	lr:0.000957
Ep: 11/48	It: 5901/8134	batch_loss: 3.3678	batch_accuracy: 36.72%	lr:0.000957
Ep: 11/48	It: 5951/8134	batch_loss: 3.3275	batch_accuracy: 38.01%	lr:0.000957
Ep: 11/48	It: 6001/8134	batch_loss: 3.3335	batch_accuracy: 38.45%	lr:0.000957
Ep: 11/48	It: 6051/8134	batch_loss: 3.3790	batch_accuracy: 37.65%	lr:0.000957
Ep: 11/48	It: 6101/8134	batch_loss: 3.3771	batch_accuracy: 37.28%	lr:0.000957
Ep: 11/48	It: 6151/8134	batch_loss: 3.3874	batch_accuracy: 38.09%	lr:0.000957
Ep: 11/48	It: 6201/8134	batch_loss: 3.3505	batch_accuracy: 38.11%	lr:0.000957
Ep: 11/48	It: 6251/8134	batch_loss: 3.2844	batch_accuracy: 37.92%	lr:0.000957
Ep: 11/48	It: 6301/8134	batch_loss: 3.3313	batch_accuracy: 37.23%	lr:0.000957
Ep: 11/48	It: 6351/8134	batch_loss: 3.4272	batch_accuracy: 36.47%	lr:0.000957
Ep: 11/48	It: 6401/8134	batch_loss: 3.2943	batch_accuracy: 39.04%	lr:0.000956
Ep: 11/48	It: 6451/8134	batch_loss: 3.1845	batch_accuracy: 40.14%	lr:0.000956
Ep: 11/48	It: 6501/8134	batch_loss: 3.2770	batch_accuracy: 39.04%	lr:0.000956
Ep: 11/48	It: 6551/8134	batch_loss: 3.3240	batch_accuracy: 38.18%	lr:0.000956
Ep: 11/48	It: 6601/8134	batch_loss: 3.3561	batch_accuracy: 37.67%	lr:0.000956
Ep: 11/48	It: 6651/8134	batch_loss: 3.2252	batch_accuracy: 39.38%	lr:0.000956
Ep: 11/48	It: 6701/8134	batch_loss: 3.4089	batch_accuracy: 37.89%	lr:0.000956
Ep: 11/48	It: 6751/8134	batch_loss: 3.4681	batch_accuracy: 35.94%	lr:0.000956
Ep: 11/48	It: 6801/8134	batch_loss: 3.4488	batch_accuracy: 35.38%	lr:0.000956
Ep: 11/48	It: 6851/8134	batch_loss: 3.3769	batch_accuracy: 38.23%	lr:0.000956
Ep: 11/48	It: 6901/8134	batch_loss: 3.4393	batch_accuracy: 36.82%	lr:0.000955
Ep: 11/48	It: 6951/8134	batch_loss: 3.4015	batch_accuracy: 37.28%	lr:0.000955
Ep: 11/48	It: 7001/8134	batch_loss: 3.3825	batch_accuracy: 37.26%	lr:0.000955
Ep: 11/48	It: 7051/8134	batch_loss: 3.2127	batch_accuracy: 39.11%	lr:0.000955
Ep: 11/48	It: 7101/8134	batch_loss: 3.4092	batch_accuracy: 36.67%	lr:0.000955
Ep: 11/48	It: 7151/8134	batch_loss: 3.3200	batch_accuracy: 38.18%	lr:0.000955
Ep: 11/48	It: 7201/8134	batch_loss: 3.1920	batch_accuracy: 39.89%	lr:0.000955
Ep: 11/48	It: 7251/8134	batch_loss: 3.2326	batch_accuracy: 39.04%	lr:0.000955
Ep: 11/48	It: 7301/8134	batch_loss: 3.3619	batch_accuracy: 37.79%	lr:0.000955
Ep: 11/48	It: 7351/8134	batch_loss: 3.4441	batch_accuracy: 35.38%	lr:0.000955
Ep: 11/48	It: 7401/8134	batch_loss: 3.5343	batch_accuracy: 34.96%	lr:0.000955
Ep: 11/48	It: 7451/8134	batch_loss: 3.2956	batch_accuracy: 37.99%	lr:0.000954
Ep: 11/48	It: 7501/8134	batch_loss: 3.2210	batch_accuracy: 39.92%	lr:0.000954
Ep: 11/48	It: 7551/8134	batch_loss: 3.3526	batch_accuracy: 37.62%	lr:0.000954
Ep: 11/48	It: 7601/8134	batch_loss: 3.3628	batch_accuracy: 36.96%	lr:0.000954
Ep: 11/48	It: 7651/8134	batch_loss: 3.4448	batch_accuracy: 35.67%	lr:0.000954
Ep: 11/48	It: 7701/8134	batch_loss: 3.3980	batch_accuracy: 37.50%	lr:0.000954
Ep: 11/48	It: 7751/8134	batch_loss: 3.3642	batch_accuracy: 37.38%	lr:0.000954
Ep: 11/48	It: 7801/8134	batch_loss: 3.2606	batch_accuracy: 39.60%	lr:0.000954
Ep: 11/48	It: 7851/8134	batch_loss: 3.4322	batch_accuracy: 36.21%	lr:0.000954
Ep: 11/48	It: 7901/8134	batch_loss: 3.3127	batch_accuracy: 37.65%	lr:0.000954
Ep: 11/48	It: 7951/8134	batch_loss: 3.3233	batch_accuracy: 37.43%	lr:0.000954
Ep: 11/48	It: 8001/8134	batch_loss: 3.3449	batch_accuracy: 37.13%	lr:0.000953
Ep: 11/48	It: 8051/8134	batch_loss: 3.5012	batch_accuracy: 35.01%	lr:0.000953
Ep: 11/48	It: 8101/8134	batch_loss: 3.3710	batch_accuracy: 36.82%	lr:0.000953
Ep: 11/48	It: 8134/8134	batch_loss: 3.3623	batch_accuracy: 36.58%	lr:0.000953


Generated text for input text "You" is:
Youer-B (1.3–2.08%) and inpatient departments (93.072) were the best-carriage-care practices in the first year, with the largest town of the lowest. In the highest prevalence of DRs was the highest (79.4%) in the high- and low-income countries. In the second year, the lowest prevalence of DRR was found in the high-income countries. In the first year, the lowest prevalence of DRR was the lowest in the high-income countries. The lowest in the lowest-income countries (0.1–0.9), the lowest in the high-income countries (0.8–0.8), and the lowest in the lowest-income countries (0.7–0.9), and the lowest in the lowest-income countries (0.6–0.6) and lowest in the highest-income countries (0.7–0.6). We find that the highest level of income inequality inequality is the high income region, and the largest inequality is from the lowest income class income region.
<eot>


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 12/48	It: 1/8134	batch_loss: 3.3327	batch_accuracy: 38.28%	lr:0.000953
Ep: 12/48	It: 51/8134	batch_loss: 3.3775	batch_accuracy: 37.55%	lr:0.000953
Ep: 12/48	It: 101/8134	batch_loss: 3.2218	batch_accuracy: 39.62%	lr:0.000953
Ep: 12/48	It: 151/8134	batch_loss: 3.3158	batch_accuracy: 38.79%	lr:0.000953
Ep: 12/48	It: 201/8134	batch_loss: 3.3754	batch_accuracy: 37.62%	lr:0.000953
Ep: 12/48	It: 251/8134	batch_loss: 3.5460	batch_accuracy: 35.16%	lr:0.000953
Ep: 12/48	It: 301/8134	batch_loss: 3.3354	batch_accuracy: 37.38%	lr:0.000953
Ep: 12/48	It: 351/8134	batch_loss: 3.2999	batch_accuracy: 38.01%	lr:0.000953
Ep: 12/48	It: 401/8134	batch_loss: 3.3092	batch_accuracy: 38.55%	lr:0.000952
Ep: 12/48	It: 451/8134	batch_loss: 3.2749	batch_accuracy: 38.75%	lr:0.000952
Ep: 12/48	It: 501/8134	batch_loss: 3.3614	batch_accuracy: 37.11%	lr:0.000952
Ep: 12/48	It: 551/8134	batch_loss: 3.3392	batch_accuracy: 37.40%	lr:0.000952
Ep: 12/48	It: 601/8134	batch_loss: 3.3809	batch_accuracy: 37.74%	lr:0.000952
Ep: 12/48	It: 651/8134	batch_loss: 3.4189	batch_accuracy: 36.67%	lr:0.000952
Ep: 12/48	It: 701/8134	batch_loss: 3.3775	batch_accuracy: 36.65%	lr:0.000952
Ep: 12/48	It: 751/8134	batch_loss: 3.3268	batch_accuracy: 37.84%	lr:0.000952
Ep: 12/48	It: 801/8134	batch_loss: 3.3495	batch_accuracy: 37.77%	lr:0.000952
Ep: 12/48	It: 851/8134	batch_loss: 3.4636	batch_accuracy: 36.16%	lr:0.000952
Ep: 12/48	It: 901/8134	batch_loss: 3.4330	batch_accuracy: 36.55%	lr:0.000951
Ep: 12/48	It: 951/8134	batch_loss: 3.3727	batch_accuracy: 37.77%	lr:0.000951
Ep: 12/48	It: 1001/8134	batch_loss: 3.3849	batch_accuracy: 36.99%	lr:0.000951
Ep: 12/48	It: 1051/8134	batch_loss: 3.4220	batch_accuracy: 36.08%	lr:0.000951
Ep: 12/48	It: 1101/8134	batch_loss: 3.3141	batch_accuracy: 37.84%	lr:0.000951
Ep: 12/48	It: 1151/8134	batch_loss: 3.3918	batch_accuracy: 36.45%	lr:0.000951
Ep: 12/48	It: 1201/8134	batch_loss: 3.4323	batch_accuracy: 36.18%	lr:0.000951
Ep: 12/48	It: 1251/8134	batch_loss: 3.3514	batch_accuracy: 37.52%	lr:0.000951
Ep: 12/48	It: 1301/8134	batch_loss: 3.4047	batch_accuracy: 36.21%	lr:0.000951
Ep: 12/48	It: 1351/8134	batch_loss: 3.3611	batch_accuracy: 37.38%	lr:0.000951
Ep: 12/48	It: 1401/8134	batch_loss: 3.3330	batch_accuracy: 37.33%	lr:0.000951
Ep: 12/48	It: 1451/8134	batch_loss: 3.2838	batch_accuracy: 39.14%	lr:0.000950
Ep: 12/48	It: 1501/8134	batch_loss: 3.4686	batch_accuracy: 36.30%	lr:0.000950
Ep: 12/48	It: 1551/8134	batch_loss: 3.4776	batch_accuracy: 36.55%	lr:0.000950
Ep: 12/48	It: 1601/8134	batch_loss: 3.4396	batch_accuracy: 36.67%	lr:0.000950
Ep: 12/48	It: 1651/8134	batch_loss: 3.3904	batch_accuracy: 37.35%	lr:0.000950
Ep: 12/48	It: 1701/8134	batch_loss: 3.4247	batch_accuracy: 36.65%	lr:0.000950
Ep: 12/48	It: 1751/8134	batch_loss: 3.3814	batch_accuracy: 37.23%	lr:0.000950
Ep: 12/48	It: 1801/8134	batch_loss: 3.4632	batch_accuracy: 36.99%	lr:0.000950
Ep: 12/48	It: 1851/8134	batch_loss: 3.3393	batch_accuracy: 38.31%	lr:0.000950
Ep: 12/48	It: 1901/8134	batch_loss: 3.3562	batch_accuracy: 37.57%	lr:0.000950
Ep: 12/48	It: 1951/8134	batch_loss: 3.4497	batch_accuracy: 36.55%	lr:0.000949
Ep: 12/48	It: 2001/8134	batch_loss: 3.3924	batch_accuracy: 36.67%	lr:0.000949
Ep: 12/48	It: 2051/8134	batch_loss: 3.3897	batch_accuracy: 36.57%	lr:0.000949
Ep: 12/48	It: 2101/8134	batch_loss: 3.3577	batch_accuracy: 37.30%	lr:0.000949
Ep: 12/48	It: 2151/8134	batch_loss: 3.3253	batch_accuracy: 37.77%	lr:0.000949
Ep: 12/48	It: 2201/8134	batch_loss: 3.4473	batch_accuracy: 36.69%	lr:0.000949
Ep: 12/48	It: 2251/8134	batch_loss: 3.4527	batch_accuracy: 36.04%	lr:0.000949
Ep: 12/48	It: 2301/8134	batch_loss: 3.3687	batch_accuracy: 37.99%	lr:0.000949
Ep: 12/48	It: 2351/8134	batch_loss: 3.1380	batch_accuracy: 41.97%	lr:0.000949
Ep: 12/48	It: 2401/8134	batch_loss: 3.4108	batch_accuracy: 37.06%	lr:0.000949
Ep: 12/48	It: 2451/8134	batch_loss: 3.4515	batch_accuracy: 36.23%	lr:0.000948
Ep: 12/48	It: 2501/8134	batch_loss: 3.3886	batch_accuracy: 37.70%	lr:0.000948
Ep: 12/48	It: 2551/8134	batch_loss: 3.4128	batch_accuracy: 36.62%	lr:0.000948
Ep: 12/48	It: 2601/8134	batch_loss: 3.3694	batch_accuracy: 37.01%	lr:0.000948
Ep: 12/48	It: 2651/8134	batch_loss: 3.4062	batch_accuracy: 37.60%	lr:0.000948
Ep: 12/48	It: 2701/8134	batch_loss: 3.3678	batch_accuracy: 37.28%	lr:0.000948
Ep: 12/48	It: 2751/8134	batch_loss: 3.3639	batch_accuracy: 37.87%	lr:0.000948
Ep: 12/48	It: 2801/8134	batch_loss: 3.2951	batch_accuracy: 37.94%	lr:0.000948
Ep: 12/48	It: 2851/8134	batch_loss: 3.4537	batch_accuracy: 36.43%	lr:0.000948
Ep: 12/48	It: 2901/8134	batch_loss: 3.4254	batch_accuracy: 35.60%	lr:0.000948
Ep: 12/48	It: 2951/8134	batch_loss: 3.3367	batch_accuracy: 37.38%	lr:0.000947
Ep: 12/48	It: 3001/8134	batch_loss: 3.2983	batch_accuracy: 38.28%	lr:0.000947
Ep: 12/48	It: 3051/8134	batch_loss: 3.3371	batch_accuracy: 38.48%	lr:0.000947
Ep: 12/48	It: 3101/8134	batch_loss: 3.3624	batch_accuracy: 38.84%	lr:0.000947
Ep: 12/48	It: 3151/8134	batch_loss: 3.3322	batch_accuracy: 37.23%	lr:0.000947
Ep: 12/48	It: 3201/8134	batch_loss: 3.4921	batch_accuracy: 35.79%	lr:0.000947
Ep: 12/48	It: 3251/8134	batch_loss: 3.3450	batch_accuracy: 37.99%	lr:0.000947
Ep: 12/48	It: 3301/8134	batch_loss: 3.4088	batch_accuracy: 37.57%	lr:0.000947
Ep: 12/48	It: 3351/8134	batch_loss: 3.3310	batch_accuracy: 38.21%	lr:0.000947
Ep: 12/48	It: 3401/8134	batch_loss: 3.3600	batch_accuracy: 38.23%	lr:0.000947
Ep: 12/48	It: 3451/8134	batch_loss: 3.3078	batch_accuracy: 38.16%	lr:0.000946
Ep: 12/48	It: 3501/8134	batch_loss: 3.2928	batch_accuracy: 38.26%	lr:0.000946
Ep: 12/48	It: 3551/8134	batch_loss: 3.3604	batch_accuracy: 37.11%	lr:0.000946
Ep: 12/48	It: 3601/8134	batch_loss: 3.3371	batch_accuracy: 38.04%	lr:0.000946
Ep: 12/48	It: 3651/8134	batch_loss: 3.4134	batch_accuracy: 37.72%	lr:0.000946
Ep: 12/48	It: 3701/8134	batch_loss: 3.3281	batch_accuracy: 37.48%	lr:0.000946
Ep: 12/48	It: 3751/8134	batch_loss: 3.2886	batch_accuracy: 38.70%	lr:0.000946
Ep: 12/48	It: 3801/8134	batch_loss: 3.3779	batch_accuracy: 36.82%	lr:0.000946
Ep: 12/48	It: 3851/8134	batch_loss: 3.2886	batch_accuracy: 38.31%	lr:0.000946
Ep: 12/48	It: 3901/8134	batch_loss: 3.3900	batch_accuracy: 36.55%	lr:0.000946
Ep: 12/48	It: 3951/8134	batch_loss: 3.3878	batch_accuracy: 37.92%	lr:0.000945
Ep: 12/48	It: 4001/8134	batch_loss: 3.2708	batch_accuracy: 37.72%	lr:0.000945
Ep: 12/48	It: 4051/8134	batch_loss: 3.3467	batch_accuracy: 38.43%	lr:0.000945
Ep: 12/48	It: 4101/8134	batch_loss: 3.3587	batch_accuracy: 36.99%	lr:0.000945
Ep: 12/48	It: 4151/8134	batch_loss: 3.3213	batch_accuracy: 38.38%	lr:0.000945
Ep: 12/48	It: 4201/8134	batch_loss: 3.4345	batch_accuracy: 37.30%	lr:0.000945
Ep: 12/48	It: 4251/8134	batch_loss: 3.5040	batch_accuracy: 36.94%	lr:0.000945
Ep: 12/48	It: 4301/8134	batch_loss: 3.3469	batch_accuracy: 37.40%	lr:0.000945
Ep: 12/48	It: 4351/8134	batch_loss: 3.4163	batch_accuracy: 37.16%	lr:0.000945
Ep: 12/48	It: 4401/8134	batch_loss: 3.3144	batch_accuracy: 38.21%	lr:0.000945
Ep: 12/48	It: 4451/8134	batch_loss: 3.3283	batch_accuracy: 37.82%	lr:0.000944
Ep: 12/48	It: 4501/8134	batch_loss: 3.3492	batch_accuracy: 37.11%	lr:0.000944
Ep: 12/48	It: 4551/8134	batch_loss: 3.3099	batch_accuracy: 37.82%	lr:0.000944
Ep: 12/48	It: 4601/8134	batch_loss: 3.3584	batch_accuracy: 37.65%	lr:0.000944
Ep: 12/48	It: 4651/8134	batch_loss: 3.3141	batch_accuracy: 38.62%	lr:0.000944
Ep: 12/48	It: 4701/8134	batch_loss: 3.3504	batch_accuracy: 37.40%	lr:0.000944
Ep: 12/48	It: 4751/8134	batch_loss: 3.3744	batch_accuracy: 37.38%	lr:0.000944
Ep: 12/48	It: 4801/8134	batch_loss: 3.4121	batch_accuracy: 37.11%	lr:0.000944
Ep: 12/48	It: 4851/8134	batch_loss: 3.2844	batch_accuracy: 36.87%	lr:0.000944
Ep: 12/48	It: 4901/8134	batch_loss: 3.2152	batch_accuracy: 40.28%	lr:0.000944
Ep: 12/48	It: 4951/8134	batch_loss: 3.2206	batch_accuracy: 39.60%	lr:0.000943
Ep: 12/48	It: 5001/8134	batch_loss: 3.2941	batch_accuracy: 39.06%	lr:0.000943
Ep: 12/48	It: 5051/8134	batch_loss: 3.3065	batch_accuracy: 38.33%	lr:0.000943
Ep: 12/48	It: 5101/8134	batch_loss: 3.2754	batch_accuracy: 38.65%	lr:0.000943
Ep: 12/48	It: 5151/8134	batch_loss: 3.4062	batch_accuracy: 37.06%	lr:0.000943
Ep: 12/48	It: 5201/8134	batch_loss: 3.3419	batch_accuracy: 38.23%	lr:0.000943
Ep: 12/48	It: 5251/8134	batch_loss: 3.3454	batch_accuracy: 38.26%	lr:0.000943
Ep: 12/48	It: 5301/8134	batch_loss: 3.2460	batch_accuracy: 39.55%	lr:0.000943
Ep: 12/48	It: 5351/8134	batch_loss: 3.3443	batch_accuracy: 38.04%	lr:0.000943
Ep: 12/48	It: 5401/8134	batch_loss: 3.4312	batch_accuracy: 35.74%	lr:0.000942
Ep: 12/48	It: 5451/8134	batch_loss: 3.4742	batch_accuracy: 36.11%	lr:0.000942
Ep: 12/48	It: 5501/8134	batch_loss: 3.3955	batch_accuracy: 37.57%	lr:0.000942
Ep: 12/48	It: 5551/8134	batch_loss: 3.3342	batch_accuracy: 37.04%	lr:0.000942
Ep: 12/48	It: 5601/8134	batch_loss: 3.3393	batch_accuracy: 37.62%	lr:0.000942
Ep: 12/48	It: 5651/8134	batch_loss: 3.3349	batch_accuracy: 38.43%	lr:0.000942
Ep: 12/48	It: 5701/8134	batch_loss: 3.2609	batch_accuracy: 38.43%	lr:0.000942
Ep: 12/48	It: 5751/8134	batch_loss: 3.3860	batch_accuracy: 37.40%	lr:0.000942
Ep: 12/48	It: 5801/8134	batch_loss: 3.3493	batch_accuracy: 36.96%	lr:0.000942
Ep: 12/48	It: 5851/8134	batch_loss: 3.3613	batch_accuracy: 38.48%	lr:0.000942
Ep: 12/48	It: 5901/8134	batch_loss: 3.2559	batch_accuracy: 39.67%	lr:0.000941
Ep: 12/48	It: 5951/8134	batch_loss: 3.4763	batch_accuracy: 36.72%	lr:0.000941
Ep: 12/48	It: 6001/8134	batch_loss: 3.3263	batch_accuracy: 38.31%	lr:0.000941
Ep: 12/48	It: 6051/8134	batch_loss: 3.3479	batch_accuracy: 36.45%	lr:0.000941
Ep: 12/48	It: 6101/8134	batch_loss: 3.2400	batch_accuracy: 38.77%	lr:0.000941
Ep: 12/48	It: 6151/8134	batch_loss: 3.3524	batch_accuracy: 37.94%	lr:0.000941
Ep: 12/48	It: 6201/8134	batch_loss: 3.5113	batch_accuracy: 34.94%	lr:0.000941
Ep: 12/48	It: 6251/8134	batch_loss: 3.4158	batch_accuracy: 37.01%	lr:0.000941
Ep: 12/48	It: 6301/8134	batch_loss: 3.3074	batch_accuracy: 37.40%	lr:0.000941
Ep: 12/48	It: 6351/8134	batch_loss: 3.2579	batch_accuracy: 39.01%	lr:0.000940
Ep: 12/48	It: 6401/8134	batch_loss: 3.3484	batch_accuracy: 38.04%	lr:0.000940
Ep: 12/48	It: 6451/8134	batch_loss: 3.3887	batch_accuracy: 36.47%	lr:0.000940
Ep: 12/48	It: 6501/8134	batch_loss: 3.4174	batch_accuracy: 36.57%	lr:0.000940
Ep: 12/48	It: 6551/8134	batch_loss: 3.3742	batch_accuracy: 37.62%	lr:0.000940
Ep: 12/48	It: 6601/8134	batch_loss: 3.3390	batch_accuracy: 37.48%	lr:0.000940
Ep: 12/48	It: 6651/8134	batch_loss: 3.3537	batch_accuracy: 37.45%	lr:0.000940
Ep: 12/48	It: 6701/8134	batch_loss: 3.3573	batch_accuracy: 38.35%	lr:0.000940
Ep: 12/48	It: 6751/8134	batch_loss: 3.2823	batch_accuracy: 38.57%	lr:0.000940
Ep: 12/48	It: 6801/8134	batch_loss: 3.3439	batch_accuracy: 37.45%	lr:0.000940
Ep: 12/48	It: 6851/8134	batch_loss: 3.4348	batch_accuracy: 36.79%	lr:0.000939
Ep: 12/48	It: 6901/8134	batch_loss: 3.2243	batch_accuracy: 38.72%	lr:0.000939
Ep: 12/48	It: 6951/8134	batch_loss: 3.3207	batch_accuracy: 37.62%	lr:0.000939
Ep: 12/48	It: 7001/8134	batch_loss: 3.3659	batch_accuracy: 36.89%	lr:0.000939
Ep: 12/48	It: 7051/8134	batch_loss: 3.3367	batch_accuracy: 38.18%	lr:0.000939
Ep: 12/48	It: 7101/8134	batch_loss: 3.3405	batch_accuracy: 37.65%	lr:0.000939
Ep: 12/48	It: 7151/8134	batch_loss: 3.1524	batch_accuracy: 40.82%	lr:0.000939
Ep: 12/48	It: 7201/8134	batch_loss: 3.4067	batch_accuracy: 36.50%	lr:0.000939
Ep: 12/48	It: 7251/8134	batch_loss: 3.5444	batch_accuracy: 35.33%	lr:0.000939
Ep: 12/48	It: 7301/8134	batch_loss: 3.3844	batch_accuracy: 37.23%	lr:0.000938
Ep: 12/48	It: 7351/8134	batch_loss: 3.3921	batch_accuracy: 38.57%	lr:0.000938
Ep: 12/48	It: 7401/8134	batch_loss: 3.3423	batch_accuracy: 37.43%	lr:0.000938
Ep: 12/48	It: 7451/8134	batch_loss: 3.3874	batch_accuracy: 37.65%	lr:0.000938
Ep: 12/48	It: 7501/8134	batch_loss: 3.2741	batch_accuracy: 38.23%	lr:0.000938
Ep: 12/48	It: 7551/8134	batch_loss: 3.2960	batch_accuracy: 38.92%	lr:0.000938
Ep: 12/48	It: 7601/8134	batch_loss: 3.3755	batch_accuracy: 37.21%	lr:0.000938
Ep: 12/48	It: 7651/8134	batch_loss: 3.2979	batch_accuracy: 37.40%	lr:0.000938
Ep: 12/48	It: 7701/8134	batch_loss: 3.2012	batch_accuracy: 39.28%	lr:0.000938
Ep: 12/48	It: 7751/8134	batch_loss: 3.3146	batch_accuracy: 37.38%	lr:0.000937
Ep: 12/48	It: 7801/8134	batch_loss: 3.1872	batch_accuracy: 40.36%	lr:0.000937
Ep: 12/48	It: 7851/8134	batch_loss: 3.3948	batch_accuracy: 37.70%	lr:0.000937
Ep: 12/48	It: 7901/8134	batch_loss: 3.3848	batch_accuracy: 37.55%	lr:0.000937
Ep: 12/48	It: 7951/8134	batch_loss: 3.4222	batch_accuracy: 37.16%	lr:0.000937
Ep: 12/48	It: 8001/8134	batch_loss: 3.2842	batch_accuracy: 38.26%	lr:0.000937
Ep: 12/48	It: 8051/8134	batch_loss: 3.3395	batch_accuracy: 38.21%	lr:0.000937
Ep: 12/48	It: 8101/8134	batch_loss: 3.3740	batch_accuracy: 37.89%	lr:0.000937
Ep: 12/48	It: 8134/8134	batch_loss: 3.3216	batch_accuracy: 37.43%	lr:0.000937


Generated text for input text "You" is:
Youera, and other parts of theat. In this study, we report on the molecular mechanisms underlying the development of theskawa-ka and the effect of MM on the evolution of human embryonic kidney. Our results show that both the expression of mt genes is enhanced by the addition of ATP to an aldolase‐like form.
<eot>
<sot>
Parallel Computational Model for the Analysis of Coding-Oriented Genetic Programming

In this paper, we present a new approach to the development of a novel Genetic Programming (GP) framework for solving the Coding-Oriented Genetic Programming (CGP) problem. First, we use the GPU-based GPU programming to develop GPU parallel algorithms for distributed graphs. Second, we consider GPU-based GPU architectures, and propose a generic graph programming framework for parallel programming in distributed GPUs. This approach provides both hardware and hardware support for GPUs. We first show that GPUs can run a high level of execution time and can be executed to execute on-demand routing tasks. We then show that our algorithm


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 13/48	It: 1/8134	batch_loss: 3.3363	batch_accuracy: 37.43%	lr:0.000937
Ep: 13/48	It: 51/8134	batch_loss: 3.4104	batch_accuracy: 36.99%	lr:0.000937
Ep: 13/48	It: 101/8134	batch_loss: 3.2444	batch_accuracy: 39.60%	lr:0.000936
Ep: 13/48	It: 151/8134	batch_loss: 3.2389	batch_accuracy: 38.92%	lr:0.000936
Ep: 13/48	It: 201/8134	batch_loss: 3.2909	batch_accuracy: 38.53%	lr:0.000936
Ep: 13/48	It: 251/8134	batch_loss: 3.2989	batch_accuracy: 38.94%	lr:0.000936
Ep: 13/48	It: 301/8134	batch_loss: 3.4376	batch_accuracy: 36.79%	lr:0.000936
Ep: 13/48	It: 351/8134	batch_loss: 3.2628	batch_accuracy: 39.01%	lr:0.000936
Ep: 13/48	It: 401/8134	batch_loss: 3.3584	batch_accuracy: 38.35%	lr:0.000936
Ep: 13/48	It: 451/8134	batch_loss: 3.3254	batch_accuracy: 38.35%	lr:0.000936
Ep: 13/48	It: 501/8134	batch_loss: 3.3931	batch_accuracy: 36.72%	lr:0.000936
Ep: 13/48	It: 551/8134	batch_loss: 3.3610	batch_accuracy: 37.52%	lr:0.000935
Ep: 13/48	It: 601/8134	batch_loss: 3.4111	batch_accuracy: 36.16%	lr:0.000935
Ep: 13/48	It: 651/8134	batch_loss: 3.4019	batch_accuracy: 37.77%	lr:0.000935
Ep: 13/48	It: 701/8134	batch_loss: 3.4298	batch_accuracy: 36.55%	lr:0.000935
Ep: 13/48	It: 751/8134	batch_loss: 3.3798	batch_accuracy: 36.55%	lr:0.000935
Ep: 13/48	It: 801/8134	batch_loss: 3.2125	batch_accuracy: 38.79%	lr:0.000935
Ep: 13/48	It: 851/8134	batch_loss: 3.3300	batch_accuracy: 37.84%	lr:0.000935
Ep: 13/48	It: 901/8134	batch_loss: 3.2968	batch_accuracy: 39.09%	lr:0.000935
Ep: 13/48	It: 951/8134	batch_loss: 3.2916	batch_accuracy: 38.94%	lr:0.000935
Ep: 13/48	It: 1001/8134	batch_loss: 3.3481	batch_accuracy: 37.87%	lr:0.000934
Ep: 13/48	It: 1051/8134	batch_loss: 3.3072	batch_accuracy: 37.89%	lr:0.000934
Ep: 13/48	It: 1101/8134	batch_loss: 3.3237	batch_accuracy: 38.26%	lr:0.000934
Ep: 13/48	It: 1151/8134	batch_loss: 3.3448	batch_accuracy: 38.28%	lr:0.000934
Ep: 13/48	It: 1201/8134	batch_loss: 3.4165	batch_accuracy: 37.06%	lr:0.000934
Ep: 13/48	It: 1251/8134	batch_loss: 3.2412	batch_accuracy: 38.04%	lr:0.000934
Ep: 13/48	It: 1301/8134	batch_loss: 3.4085	batch_accuracy: 37.01%	lr:0.000934
Ep: 13/48	It: 1351/8134	batch_loss: 3.2681	batch_accuracy: 39.18%	lr:0.000934
Ep: 13/48	It: 1401/8134	batch_loss: 3.2666	batch_accuracy: 38.55%	lr:0.000934
Ep: 13/48	It: 1451/8134	batch_loss: 3.4018	batch_accuracy: 38.28%	lr:0.000933
Ep: 13/48	It: 1501/8134	batch_loss: 3.2836	batch_accuracy: 38.26%	lr:0.000933
Ep: 13/48	It: 1551/8134	batch_loss: 3.3506	batch_accuracy: 36.84%	lr:0.000933
Ep: 13/48	It: 1601/8134	batch_loss: 3.2680	batch_accuracy: 38.67%	lr:0.000933
Ep: 13/48	It: 1651/8134	batch_loss: 3.2456	batch_accuracy: 39.55%	lr:0.000933
Ep: 13/48	It: 1701/8134	batch_loss: 3.4349	batch_accuracy: 36.62%	lr:0.000933
Ep: 13/48	It: 1751/8134	batch_loss: 3.3356	batch_accuracy: 37.11%	lr:0.000933
Ep: 13/48	It: 1801/8134	batch_loss: 3.3378	batch_accuracy: 37.26%	lr:0.000933
Ep: 13/48	It: 1851/8134	batch_loss: 3.3220	batch_accuracy: 39.16%	lr:0.000933
Ep: 13/48	It: 1901/8134	batch_loss: 3.5099	batch_accuracy: 36.28%	lr:0.000932
Ep: 13/48	It: 1951/8134	batch_loss: 3.3322	batch_accuracy: 37.82%	lr:0.000932
Ep: 13/48	It: 2001/8134	batch_loss: 3.3416	batch_accuracy: 37.38%	lr:0.000932
Ep: 13/48	It: 2051/8134	batch_loss: 3.4714	batch_accuracy: 36.79%	lr:0.000932
Ep: 13/48	It: 2101/8134	batch_loss: 3.2681	batch_accuracy: 38.82%	lr:0.000932
Ep: 13/48	It: 2151/8134	batch_loss: 3.2071	batch_accuracy: 39.53%	lr:0.000932
Ep: 13/48	It: 2201/8134	batch_loss: 3.4218	batch_accuracy: 37.74%	lr:0.000932
Ep: 13/48	It: 2251/8134	batch_loss: 3.4766	batch_accuracy: 35.55%	lr:0.000932
Ep: 13/48	It: 2301/8134	batch_loss: 3.2781	batch_accuracy: 38.82%	lr:0.000932
Ep: 13/48	It: 2351/8134	batch_loss: 3.2978	batch_accuracy: 39.55%	lr:0.000931
Ep: 13/48	It: 2401/8134	batch_loss: 3.3165	batch_accuracy: 37.16%	lr:0.000931
Ep: 13/48	It: 2451/8134	batch_loss: 3.3499	batch_accuracy: 36.30%	lr:0.000931
Ep: 13/48	It: 2501/8134	batch_loss: 3.3664	batch_accuracy: 37.30%	lr:0.000931
Ep: 13/48	It: 2551/8134	batch_loss: 3.2242	batch_accuracy: 39.60%	lr:0.000931
Ep: 13/48	It: 2601/8134	batch_loss: 3.3404	batch_accuracy: 37.48%	lr:0.000931
Ep: 13/48	It: 2651/8134	batch_loss: 3.2753	batch_accuracy: 38.18%	lr:0.000931
Ep: 13/48	It: 2701/8134	batch_loss: 3.3529	batch_accuracy: 37.43%	lr:0.000931
Ep: 13/48	It: 2751/8134	batch_loss: 3.3420	batch_accuracy: 38.23%	lr:0.000931
Ep: 13/48	It: 2801/8134	batch_loss: 3.2871	batch_accuracy: 38.43%	lr:0.000930
Ep: 13/48	It: 2851/8134	batch_loss: 3.3972	batch_accuracy: 37.18%	lr:0.000930
Ep: 13/48	It: 2901/8134	batch_loss: 3.3366	batch_accuracy: 39.26%	lr:0.000930
Ep: 13/48	It: 2951/8134	batch_loss: 3.3020	batch_accuracy: 37.48%	lr:0.000930
Ep: 13/48	It: 3001/8134	batch_loss: 3.2830	batch_accuracy: 37.30%	lr:0.000930
Ep: 13/48	It: 3051/8134	batch_loss: 3.4045	batch_accuracy: 36.52%	lr:0.000930
Ep: 13/48	It: 3101/8134	batch_loss: 3.4195	batch_accuracy: 37.16%	lr:0.000930
Ep: 13/48	It: 3151/8134	batch_loss: 3.2073	batch_accuracy: 39.97%	lr:0.000930
Ep: 13/48	It: 3201/8134	batch_loss: 3.3060	batch_accuracy: 37.89%	lr:0.000930
Ep: 13/48	It: 3251/8134	batch_loss: 3.3032	batch_accuracy: 38.48%	lr:0.000929
Ep: 13/48	It: 3301/8134	batch_loss: 3.2540	batch_accuracy: 38.84%	lr:0.000929
Ep: 13/48	It: 3351/8134	batch_loss: 3.2446	batch_accuracy: 39.79%	lr:0.000929
Ep: 13/48	It: 3401/8134	batch_loss: 3.2487	batch_accuracy: 38.72%	lr:0.000929
Ep: 13/48	It: 3451/8134	batch_loss: 3.3119	batch_accuracy: 37.11%	lr:0.000929
Ep: 13/48	It: 3501/8134	batch_loss: 3.3108	batch_accuracy: 38.70%	lr:0.000929
Ep: 13/48	It: 3551/8134	batch_loss: 3.3862	batch_accuracy: 37.48%	lr:0.000929
Ep: 13/48	It: 3601/8134	batch_loss: 3.2372	batch_accuracy: 39.16%	lr:0.000929
Ep: 13/48	It: 3651/8134	batch_loss: 3.3586	batch_accuracy: 38.38%	lr:0.000928
Ep: 13/48	It: 3701/8134	batch_loss: 3.3611	batch_accuracy: 37.16%	lr:0.000928
Ep: 13/48	It: 3751/8134	batch_loss: 3.3473	batch_accuracy: 38.04%	lr:0.000928
Ep: 13/48	It: 3801/8134	batch_loss: 3.3021	batch_accuracy: 38.33%	lr:0.000928
Ep: 13/48	It: 3851/8134	batch_loss: 3.3811	batch_accuracy: 36.52%	lr:0.000928
Ep: 13/48	It: 3901/8134	batch_loss: 3.4560	batch_accuracy: 36.13%	lr:0.000928
Ep: 13/48	It: 3951/8134	batch_loss: 3.3253	batch_accuracy: 37.60%	lr:0.000928
Ep: 13/48	It: 4001/8134	batch_loss: 3.2477	batch_accuracy: 38.35%	lr:0.000928
Ep: 13/48	It: 4051/8134	batch_loss: 3.4152	batch_accuracy: 36.25%	lr:0.000928
Ep: 13/48	It: 4101/8134	batch_loss: 3.3324	batch_accuracy: 37.40%	lr:0.000927
Ep: 13/48	It: 4151/8134	batch_loss: 3.2964	batch_accuracy: 37.50%	lr:0.000927
Ep: 13/48	It: 4201/8134	batch_loss: 3.3633	batch_accuracy: 38.62%	lr:0.000927
Ep: 13/48	It: 4251/8134	batch_loss: 3.4235	batch_accuracy: 35.74%	lr:0.000927
Ep: 13/48	It: 4301/8134	batch_loss: 3.3716	batch_accuracy: 36.89%	lr:0.000927
Ep: 13/48	It: 4351/8134	batch_loss: 3.3794	batch_accuracy: 37.84%	lr:0.000927
Ep: 13/48	It: 4401/8134	batch_loss: 3.2845	batch_accuracy: 38.04%	lr:0.000927
Ep: 13/48	It: 4451/8134	batch_loss: 3.3275	batch_accuracy: 37.45%	lr:0.000927
Ep: 13/48	It: 4501/8134	batch_loss: 3.3050	batch_accuracy: 37.77%	lr:0.000927
Ep: 13/48	It: 4551/8134	batch_loss: 3.2836	batch_accuracy: 38.48%	lr:0.000926
Ep: 13/48	It: 4601/8134	batch_loss: 3.3913	batch_accuracy: 36.89%	lr:0.000926
Ep: 13/48	It: 4651/8134	batch_loss: 3.3757	batch_accuracy: 37.57%	lr:0.000926
Ep: 13/48	It: 4701/8134	batch_loss: 3.4161	batch_accuracy: 35.84%	lr:0.000926
Ep: 13/48	It: 4751/8134	batch_loss: 3.4230	batch_accuracy: 37.01%	lr:0.000926
Ep: 13/48	It: 4801/8134	batch_loss: 3.3730	batch_accuracy: 37.74%	lr:0.000926
Ep: 13/48	It: 4851/8134	batch_loss: 3.3035	batch_accuracy: 37.82%	lr:0.000926
Ep: 13/48	It: 4901/8134	batch_loss: 3.2740	batch_accuracy: 38.57%	lr:0.000926
Ep: 13/48	It: 4951/8134	batch_loss: 3.4040	batch_accuracy: 37.06%	lr:0.000925
Ep: 13/48	It: 5001/8134	batch_loss: 3.3302	batch_accuracy: 37.84%	lr:0.000925
Ep: 13/48	It: 5051/8134	batch_loss: 3.2544	batch_accuracy: 38.87%	lr:0.000925
Ep: 13/48	It: 5101/8134	batch_loss: 3.2946	batch_accuracy: 38.89%	lr:0.000925
Ep: 13/48	It: 5151/8134	batch_loss: 3.3906	batch_accuracy: 36.33%	lr:0.000925
Ep: 13/48	It: 5201/8134	batch_loss: 3.3650	batch_accuracy: 37.89%	lr:0.000925
Ep: 13/48	It: 5251/8134	batch_loss: 3.4786	batch_accuracy: 36.16%	lr:0.000925
Ep: 13/48	It: 5301/8134	batch_loss: 3.3070	batch_accuracy: 37.87%	lr:0.000925
Ep: 13/48	It: 5351/8134	batch_loss: 3.2497	batch_accuracy: 38.33%	lr:0.000925
Ep: 13/48	It: 5401/8134	batch_loss: 3.2969	batch_accuracy: 38.33%	lr:0.000924
Ep: 13/48	It: 5451/8134	batch_loss: 3.3541	batch_accuracy: 37.48%	lr:0.000924
Ep: 13/48	It: 5501/8134	batch_loss: 3.2617	batch_accuracy: 38.94%	lr:0.000924
Ep: 13/48	It: 5551/8134	batch_loss: 3.4496	batch_accuracy: 36.08%	lr:0.000924
Ep: 13/48	It: 5601/8134	batch_loss: 3.4321	batch_accuracy: 36.94%	lr:0.000924
Ep: 13/48	It: 5651/8134	batch_loss: 3.3804	batch_accuracy: 37.99%	lr:0.000924
Ep: 13/48	It: 5701/8134	batch_loss: 3.3214	batch_accuracy: 38.33%	lr:0.000924
Ep: 13/48	It: 5751/8134	batch_loss: 3.4099	batch_accuracy: 36.57%	lr:0.000924
Ep: 13/48	It: 5801/8134	batch_loss: 3.3226	batch_accuracy: 38.62%	lr:0.000923
Ep: 13/48	It: 5851/8134	batch_loss: 3.2668	batch_accuracy: 39.40%	lr:0.000923
Ep: 13/48	It: 5901/8134	batch_loss: 3.2668	batch_accuracy: 38.48%	lr:0.000923
Ep: 13/48	It: 5951/8134	batch_loss: 3.3560	batch_accuracy: 37.67%	lr:0.000923
Ep: 13/48	It: 6001/8134	batch_loss: 3.2636	batch_accuracy: 39.43%	lr:0.000923
Ep: 13/48	It: 6051/8134	batch_loss: 3.3066	batch_accuracy: 38.48%	lr:0.000923
Ep: 13/48	It: 6101/8134	batch_loss: 3.2235	batch_accuracy: 40.38%	lr:0.000923
Ep: 13/48	It: 6151/8134	batch_loss: 3.3231	batch_accuracy: 37.77%	lr:0.000923
Ep: 13/48	It: 6201/8134	batch_loss: 3.4038	batch_accuracy: 36.91%	lr:0.000923
Ep: 13/48	It: 6251/8134	batch_loss: 3.5189	batch_accuracy: 35.16%	lr:0.000922
Ep: 13/48	It: 6301/8134	batch_loss: 3.2872	batch_accuracy: 38.87%	lr:0.000922
Ep: 13/48	It: 6351/8134	batch_loss: 3.3298	batch_accuracy: 38.09%	lr:0.000922
Ep: 13/48	It: 6401/8134	batch_loss: 3.4582	batch_accuracy: 36.52%	lr:0.000922
Ep: 13/48	It: 6451/8134	batch_loss: 3.3042	batch_accuracy: 38.45%	lr:0.000922
Ep: 13/48	It: 6501/8134	batch_loss: 3.3445	batch_accuracy: 37.79%	lr:0.000922
Ep: 13/48	It: 6551/8134	batch_loss: 3.3399	batch_accuracy: 37.45%	lr:0.000922
Ep: 13/48	It: 6601/8134	batch_loss: 3.3716	batch_accuracy: 36.82%	lr:0.000922
Ep: 13/48	It: 6651/8134	batch_loss: 3.3669	batch_accuracy: 38.40%	lr:0.000921
Ep: 13/48	It: 6701/8134	batch_loss: 3.2804	batch_accuracy: 38.70%	lr:0.000921
Ep: 13/48	It: 6751/8134	batch_loss: 3.3493	batch_accuracy: 37.13%	lr:0.000921
Ep: 13/48	It: 6801/8134	batch_loss: 3.4202	batch_accuracy: 36.72%	lr:0.000921
Ep: 13/48	It: 6851/8134	batch_loss: 3.2953	batch_accuracy: 38.53%	lr:0.000921
Ep: 13/48	It: 6901/8134	batch_loss: 3.2714	batch_accuracy: 38.57%	lr:0.000921
Ep: 13/48	It: 6951/8134	batch_loss: 3.2579	batch_accuracy: 40.19%	lr:0.000921
Ep: 13/48	It: 7001/8134	batch_loss: 3.3991	batch_accuracy: 37.60%	lr:0.000921
Ep: 13/48	It: 7051/8134	batch_loss: 3.3096	batch_accuracy: 38.45%	lr:0.000920
Ep: 13/48	It: 7101/8134	batch_loss: 3.3661	batch_accuracy: 37.52%	lr:0.000920
Ep: 13/48	It: 7151/8134	batch_loss: 3.4613	batch_accuracy: 36.62%	lr:0.000920
Ep: 13/48	It: 7201/8134	batch_loss: 3.3826	batch_accuracy: 37.13%	lr:0.000920
Ep: 13/48	It: 7251/8134	batch_loss: 3.3806	batch_accuracy: 36.21%	lr:0.000920
Ep: 13/48	It: 7301/8134	batch_loss: 3.3516	batch_accuracy: 37.74%	lr:0.000920
Ep: 13/48	It: 7351/8134	batch_loss: 3.4225	batch_accuracy: 36.79%	lr:0.000920
Ep: 13/48	It: 7401/8134	batch_loss: 3.2564	batch_accuracy: 39.43%	lr:0.000920
Ep: 13/48	It: 7451/8134	batch_loss: 3.4059	batch_accuracy: 37.11%	lr:0.000919
Ep: 13/48	It: 7501/8134	batch_loss: 3.3507	batch_accuracy: 36.67%	lr:0.000919
Ep: 13/48	It: 7551/8134	batch_loss: 3.4270	batch_accuracy: 36.21%	lr:0.000919
Ep: 13/48	It: 7601/8134	batch_loss: 3.4222	batch_accuracy: 36.77%	lr:0.000919
Ep: 13/48	It: 7651/8134	batch_loss: 3.2882	batch_accuracy: 37.94%	lr:0.000919
Ep: 13/48	It: 7701/8134	batch_loss: 3.3846	batch_accuracy: 36.55%	lr:0.000919
Ep: 13/48	It: 7751/8134	batch_loss: 3.2487	batch_accuracy: 38.96%	lr:0.000919
Ep: 13/48	It: 7801/8134	batch_loss: 3.4068	batch_accuracy: 36.18%	lr:0.000919
Ep: 13/48	It: 7851/8134	batch_loss: 3.2295	batch_accuracy: 39.26%	lr:0.000919
Ep: 13/48	It: 7901/8134	batch_loss: 3.3664	batch_accuracy: 37.57%	lr:0.000918
Ep: 13/48	It: 7951/8134	batch_loss: 3.3800	batch_accuracy: 36.89%	lr:0.000918
Ep: 13/48	It: 8001/8134	batch_loss: 3.3061	batch_accuracy: 38.40%	lr:0.000918
Ep: 13/48	It: 8051/8134	batch_loss: 3.3214	batch_accuracy: 38.01%	lr:0.000918
Ep: 13/48	It: 8101/8134	batch_loss: 3.1881	batch_accuracy: 40.23%	lr:0.000918
Ep: 13/48	It: 8134/8134	batch_loss: 3.3331	batch_accuracy: 37.23%	lr:0.000918


Generated text for input text "You" is:
You’, and in this work. The paper is focused on thesis. In this paper, the author discusses theory of theorative, orthodic, and on theological concepts of theology and its philosophy. The article is based on a brief, thesis of anthropology, the philosophical philosophy of the art of theology, as well as theories of the “news” of the “symbolic” and “there are theological”. The book, in turn, has been considered to be the most important factor in the process of the study of the art of the art. It is not surprising that the book is a good introduction to the reader's book. The present chapter offers a brief overview of the work of the book and some of its contents.
<eot>
<sot>
Influence of Total Synthesis of Polymeric Organic Carbon Nanoparticles on the Photocatalytic Performance of Phosphate Nanoparticles

A novel and efficient method for the synthesis of silica nanoparticles (RPs) with different physical properties has been developed. The silica nanoparticles (Sn) are composed of a


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 14/48	It: 1/8134	batch_loss: 3.3731	batch_accuracy: 37.38%	lr:0.000918
Ep: 14/48	It: 51/8134	batch_loss: 3.3213	batch_accuracy: 37.50%	lr:0.000918
Ep: 14/48	It: 101/8134	batch_loss: 3.3217	batch_accuracy: 37.77%	lr:0.000918
Ep: 14/48	It: 151/8134	batch_loss: 3.2921	batch_accuracy: 37.30%	lr:0.000917
Ep: 14/48	It: 201/8134	batch_loss: 3.3912	batch_accuracy: 36.99%	lr:0.000917
Ep: 14/48	It: 251/8134	batch_loss: 3.3873	batch_accuracy: 35.96%	lr:0.000917
Ep: 14/48	It: 301/8134	batch_loss: 3.4470	batch_accuracy: 37.28%	lr:0.000917
Ep: 14/48	It: 351/8134	batch_loss: 3.2931	batch_accuracy: 38.13%	lr:0.000917
Ep: 14/48	It: 401/8134	batch_loss: 3.2468	batch_accuracy: 38.94%	lr:0.000917
Ep: 14/48	It: 451/8134	batch_loss: 3.1204	batch_accuracy: 39.97%	lr:0.000917
Ep: 14/48	It: 501/8134	batch_loss: 3.2399	batch_accuracy: 39.70%	lr:0.000917
Ep: 14/48	It: 551/8134	batch_loss: 3.4097	batch_accuracy: 36.52%	lr:0.000916
Ep: 14/48	It: 601/8134	batch_loss: 3.3408	batch_accuracy: 37.72%	lr:0.000916
Ep: 14/48	It: 651/8134	batch_loss: 3.3644	batch_accuracy: 37.30%	lr:0.000916
Ep: 14/48	It: 701/8134	batch_loss: 3.4528	batch_accuracy: 36.08%	lr:0.000916
Ep: 14/48	It: 751/8134	batch_loss: 3.3704	batch_accuracy: 37.67%	lr:0.000916
Ep: 14/48	It: 801/8134	batch_loss: 3.4753	batch_accuracy: 37.13%	lr:0.000916
Ep: 14/48	It: 851/8134	batch_loss: 3.3098	batch_accuracy: 38.04%	lr:0.000916
Ep: 14/48	It: 901/8134	batch_loss: 3.3492	batch_accuracy: 36.74%	lr:0.000916
Ep: 14/48	It: 951/8134	batch_loss: 3.3803	batch_accuracy: 38.01%	lr:0.000915
Ep: 14/48	It: 1001/8134	batch_loss: 3.3657	batch_accuracy: 38.04%	lr:0.000915
Ep: 14/48	It: 1051/8134	batch_loss: 3.3298	batch_accuracy: 38.21%	lr:0.000915
Ep: 14/48	It: 1101/8134	batch_loss: 3.2643	batch_accuracy: 38.43%	lr:0.000915
Ep: 14/48	It: 1151/8134	batch_loss: 3.3436	batch_accuracy: 37.94%	lr:0.000915
Ep: 14/48	It: 1201/8134	batch_loss: 3.3970	batch_accuracy: 37.50%	lr:0.000915
Ep: 14/48	It: 1251/8134	batch_loss: 3.3492	batch_accuracy: 37.33%	lr:0.000915
Ep: 14/48	It: 1301/8134	batch_loss: 3.2481	batch_accuracy: 39.11%	lr:0.000915
Ep: 14/48	It: 1351/8134	batch_loss: 3.2832	batch_accuracy: 37.26%	lr:0.000914
Ep: 14/48	It: 1401/8134	batch_loss: 3.4235	batch_accuracy: 36.89%	lr:0.000914
Ep: 14/48	It: 1451/8134	batch_loss: 3.2332	batch_accuracy: 38.89%	lr:0.000914
Ep: 14/48	It: 1501/8134	batch_loss: 3.4445	batch_accuracy: 37.72%	lr:0.000914
Ep: 14/48	It: 1551/8134	batch_loss: 3.3163	batch_accuracy: 37.79%	lr:0.000914
Ep: 14/48	It: 1601/8134	batch_loss: 3.3632	batch_accuracy: 37.35%	lr:0.000914
Ep: 14/48	It: 1651/8134	batch_loss: 3.3910	batch_accuracy: 36.65%	lr:0.000914
Ep: 14/48	It: 1701/8134	batch_loss: 3.4029	batch_accuracy: 37.08%	lr:0.000914
Ep: 14/48	It: 1751/8134	batch_loss: 3.4136	batch_accuracy: 37.82%	lr:0.000913
Ep: 14/48	It: 1801/8134	batch_loss: 3.3940	batch_accuracy: 37.11%	lr:0.000913
Ep: 14/48	It: 1851/8134	batch_loss: 3.3403	batch_accuracy: 36.30%	lr:0.000913
Ep: 14/48	It: 1901/8134	batch_loss: 3.2726	batch_accuracy: 38.96%	lr:0.000913
Ep: 14/48	It: 1951/8134	batch_loss: 3.3576	batch_accuracy: 37.43%	lr:0.000913
Ep: 14/48	It: 2001/8134	batch_loss: 3.4288	batch_accuracy: 37.28%	lr:0.000913
Ep: 14/48	It: 2051/8134	batch_loss: 3.3626	batch_accuracy: 36.79%	lr:0.000913
Ep: 14/48	It: 2101/8134	batch_loss: 3.4044	batch_accuracy: 36.18%	lr:0.000913
Ep: 14/48	It: 2151/8134	batch_loss: 3.3598	batch_accuracy: 37.48%	lr:0.000912
Ep: 14/48	It: 2201/8134	batch_loss: 3.3122	batch_accuracy: 38.33%	lr:0.000912
Ep: 14/48	It: 2251/8134	batch_loss: 3.3553	batch_accuracy: 37.70%	lr:0.000912
Ep: 14/48	It: 2301/8134	batch_loss: 3.2633	batch_accuracy: 38.75%	lr:0.000912
Ep: 14/48	It: 2351/8134	batch_loss: 3.3588	batch_accuracy: 37.65%	lr:0.000912
Ep: 14/48	It: 2401/8134	batch_loss: 3.3953	batch_accuracy: 36.60%	lr:0.000912
Ep: 14/48	It: 2451/8134	batch_loss: 3.4792	batch_accuracy: 36.62%	lr:0.000912
Ep: 14/48	It: 2501/8134	batch_loss: 3.3704	batch_accuracy: 37.74%	lr:0.000912
Ep: 14/48	It: 2551/8134	batch_loss: 3.3898	batch_accuracy: 37.04%	lr:0.000911
Ep: 14/48	It: 2601/8134	batch_loss: 3.4051	batch_accuracy: 36.99%	lr:0.000911
Ep: 14/48	It: 2651/8134	batch_loss: 3.2925	batch_accuracy: 39.31%	lr:0.000911
Ep: 14/48	It: 2701/8134	batch_loss: 3.4818	batch_accuracy: 35.99%	lr:0.000911
Ep: 14/48	It: 2751/8134	batch_loss: 3.2479	batch_accuracy: 38.65%	lr:0.000911
Ep: 14/48	It: 2801/8134	batch_loss: 3.2990	batch_accuracy: 37.45%	lr:0.000911
Ep: 14/48	It: 2851/8134	batch_loss: 3.3228	batch_accuracy: 37.79%	lr:0.000911
Ep: 14/48	It: 2901/8134	batch_loss: 3.2889	batch_accuracy: 38.65%	lr:0.000911
Ep: 14/48	It: 2951/8134	batch_loss: 3.2870	batch_accuracy: 38.35%	lr:0.000910
Ep: 14/48	It: 3001/8134	batch_loss: 3.2965	batch_accuracy: 38.18%	lr:0.000910
Ep: 14/48	It: 3051/8134	batch_loss: 3.2406	batch_accuracy: 39.21%	lr:0.000910
Ep: 14/48	It: 3101/8134	batch_loss: 3.2903	batch_accuracy: 39.40%	lr:0.000910
Ep: 14/48	It: 3151/8134	batch_loss: 3.1951	batch_accuracy: 39.97%	lr:0.000910
Ep: 14/48	It: 3201/8134	batch_loss: 3.3494	batch_accuracy: 37.77%	lr:0.000910
Ep: 14/48	It: 3251/8134	batch_loss: 3.3777	batch_accuracy: 37.77%	lr:0.000910
Ep: 14/48	It: 3301/8134	batch_loss: 3.3004	batch_accuracy: 37.94%	lr:0.000910
Ep: 14/48	It: 3351/8134	batch_loss: 3.2138	batch_accuracy: 39.33%	lr:0.000909
Ep: 14/48	It: 3401/8134	batch_loss: 3.2966	batch_accuracy: 37.38%	lr:0.000909
Ep: 14/48	It: 3451/8134	batch_loss: 3.3568	batch_accuracy: 36.91%	lr:0.000909
Ep: 14/48	It: 3501/8134	batch_loss: 3.2103	batch_accuracy: 40.82%	lr:0.000909
Ep: 14/48	It: 3551/8134	batch_loss: 3.4025	batch_accuracy: 36.45%	lr:0.000909
Ep: 14/48	It: 3601/8134	batch_loss: 3.2750	batch_accuracy: 38.16%	lr:0.000909
Ep: 14/48	It: 3651/8134	batch_loss: 3.2502	batch_accuracy: 38.84%	lr:0.000909
Ep: 14/48	It: 3701/8134	batch_loss: 3.3174	batch_accuracy: 38.62%	lr:0.000909
Ep: 14/48	It: 3751/8134	batch_loss: 3.3730	batch_accuracy: 36.55%	lr:0.000908
Ep: 14/48	It: 3801/8134	batch_loss: 3.2797	batch_accuracy: 38.43%	lr:0.000908
Ep: 14/48	It: 3851/8134	batch_loss: 3.2593	batch_accuracy: 38.50%	lr:0.000908
Ep: 14/48	It: 3901/8134	batch_loss: 3.4705	batch_accuracy: 37.38%	lr:0.000908
Ep: 14/48	It: 3951/8134	batch_loss: 3.2739	batch_accuracy: 38.23%	lr:0.000908
Ep: 14/48	It: 4001/8134	batch_loss: 3.3872	batch_accuracy: 36.35%	lr:0.000908
Ep: 14/48	It: 4051/8134	batch_loss: 3.3099	batch_accuracy: 38.09%	lr:0.000908
Ep: 14/48	It: 4101/8134	batch_loss: 3.3335	batch_accuracy: 38.33%	lr:0.000907
Ep: 14/48	It: 4151/8134	batch_loss: 3.3152	batch_accuracy: 38.11%	lr:0.000907
Ep: 14/48	It: 4201/8134	batch_loss: 3.4044	batch_accuracy: 37.16%	lr:0.000907
Ep: 14/48	It: 4251/8134	batch_loss: 3.2252	batch_accuracy: 38.89%	lr:0.000907
Ep: 14/48	It: 4301/8134	batch_loss: 3.3308	batch_accuracy: 38.89%	lr:0.000907
Ep: 14/48	It: 4351/8134	batch_loss: 3.3078	batch_accuracy: 37.52%	lr:0.000907
Ep: 14/48	It: 4401/8134	batch_loss: 3.1857	batch_accuracy: 39.72%	lr:0.000907
Ep: 14/48	It: 4451/8134	batch_loss: 3.4368	batch_accuracy: 36.21%	lr:0.000907
Ep: 14/48	It: 4501/8134	batch_loss: 3.3367	batch_accuracy: 36.57%	lr:0.000906
Ep: 14/48	It: 4551/8134	batch_loss: 3.2395	batch_accuracy: 38.84%	lr:0.000906
Ep: 14/48	It: 4601/8134	batch_loss: 3.2525	batch_accuracy: 39.45%	lr:0.000906
Ep: 14/48	It: 4651/8134	batch_loss: 3.2952	batch_accuracy: 38.48%	lr:0.000906
Ep: 14/48	It: 4701/8134	batch_loss: 3.3268	batch_accuracy: 38.62%	lr:0.000906
Ep: 14/48	It: 4751/8134	batch_loss: 3.2926	batch_accuracy: 37.70%	lr:0.000906
Ep: 14/48	It: 4801/8134	batch_loss: 3.1972	batch_accuracy: 39.94%	lr:0.000906
Ep: 14/48	It: 4851/8134	batch_loss: 3.2065	batch_accuracy: 39.89%	lr:0.000906
Ep: 14/48	It: 4901/8134	batch_loss: 3.2635	batch_accuracy: 39.06%	lr:0.000905
Ep: 14/48	It: 4951/8134	batch_loss: 3.2594	batch_accuracy: 37.65%	lr:0.000905
Ep: 14/48	It: 5001/8134	batch_loss: 3.3106	batch_accuracy: 38.79%	lr:0.000905
Ep: 14/48	It: 5051/8134	batch_loss: 3.3257	batch_accuracy: 37.96%	lr:0.000905
Ep: 14/48	It: 5101/8134	batch_loss: 3.2288	batch_accuracy: 38.62%	lr:0.000905
Ep: 14/48	It: 5151/8134	batch_loss: 3.2026	batch_accuracy: 41.11%	lr:0.000905
Ep: 14/48	It: 5201/8134	batch_loss: 3.2532	batch_accuracy: 39.89%	lr:0.000905
Ep: 14/48	It: 5251/8134	batch_loss: 3.3263	batch_accuracy: 37.79%	lr:0.000904
Ep: 14/48	It: 5301/8134	batch_loss: 3.3770	batch_accuracy: 37.77%	lr:0.000904
Ep: 14/48	It: 5351/8134	batch_loss: 3.3134	batch_accuracy: 38.82%	lr:0.000904
Ep: 14/48	It: 5401/8134	batch_loss: 3.3841	batch_accuracy: 38.11%	lr:0.000904
Ep: 14/48	It: 5451/8134	batch_loss: 3.3205	batch_accuracy: 37.21%	lr:0.000904
Ep: 14/48	It: 5501/8134	batch_loss: 3.3927	batch_accuracy: 37.16%	lr:0.000904
Ep: 14/48	It: 5551/8134	batch_loss: 3.4262	batch_accuracy: 37.08%	lr:0.000904
Ep: 14/48	It: 5601/8134	batch_loss: 3.4038	batch_accuracy: 36.69%	lr:0.000904
Ep: 14/48	It: 5651/8134	batch_loss: 3.3897	batch_accuracy: 36.69%	lr:0.000903
Ep: 14/48	It: 5701/8134	batch_loss: 3.4762	batch_accuracy: 35.42%	lr:0.000903
Ep: 14/48	It: 5751/8134	batch_loss: 3.1904	batch_accuracy: 40.55%	lr:0.000903
Ep: 14/48	It: 5801/8134	batch_loss: 3.3227	batch_accuracy: 38.94%	lr:0.000903
Ep: 14/48	It: 5851/8134	batch_loss: 3.2381	batch_accuracy: 38.50%	lr:0.000903
Ep: 14/48	It: 5901/8134	batch_loss: 3.3301	batch_accuracy: 37.87%	lr:0.000903
Ep: 14/48	It: 5951/8134	batch_loss: 3.3503	batch_accuracy: 38.18%	lr:0.000903
Ep: 14/48	It: 6001/8134	batch_loss: 3.3063	batch_accuracy: 37.96%	lr:0.000903
Ep: 14/48	It: 6051/8134	batch_loss: 3.3634	batch_accuracy: 37.23%	lr:0.000902
Ep: 14/48	It: 6101/8134	batch_loss: 3.4494	batch_accuracy: 37.01%	lr:0.000902
Ep: 14/48	It: 6151/8134	batch_loss: 3.3275	batch_accuracy: 38.18%	lr:0.000902
Ep: 14/48	It: 6201/8134	batch_loss: 3.2721	batch_accuracy: 39.06%	lr:0.000902
Ep: 14/48	It: 6251/8134	batch_loss: 3.1509	batch_accuracy: 40.75%	lr:0.000902
Ep: 14/48	It: 6301/8134	batch_loss: 3.3143	batch_accuracy: 38.62%	lr:0.000902
Ep: 14/48	It: 6351/8134	batch_loss: 3.4173	batch_accuracy: 37.62%	lr:0.000902
Ep: 14/48	It: 6401/8134	batch_loss: 3.3397	batch_accuracy: 37.18%	lr:0.000901
Ep: 14/48	It: 6451/8134	batch_loss: 3.2785	batch_accuracy: 39.21%	lr:0.000901
Ep: 14/48	It: 6501/8134	batch_loss: 3.3802	batch_accuracy: 37.65%	lr:0.000901
Ep: 14/48	It: 6551/8134	batch_loss: 3.1888	batch_accuracy: 38.55%	lr:0.000901
Ep: 14/48	It: 6601/8134	batch_loss: 3.3657	batch_accuracy: 37.48%	lr:0.000901
Ep: 14/48	It: 6651/8134	batch_loss: 3.2642	batch_accuracy: 39.01%	lr:0.000901
Ep: 14/48	It: 6701/8134	batch_loss: 3.2708	batch_accuracy: 38.55%	lr:0.000901
Ep: 14/48	It: 6751/8134	batch_loss: 3.3860	batch_accuracy: 36.50%	lr:0.000901
Ep: 14/48	It: 6801/8134	batch_loss: 3.3922	batch_accuracy: 37.84%	lr:0.000900
Ep: 14/48	It: 6851/8134	batch_loss: 3.3122	batch_accuracy: 38.65%	lr:0.000900
Ep: 14/48	It: 6901/8134	batch_loss: 3.3863	batch_accuracy: 37.11%	lr:0.000900
Ep: 14/48	It: 6951/8134	batch_loss: 3.3179	batch_accuracy: 37.62%	lr:0.000900
Ep: 14/48	It: 7001/8134	batch_loss: 3.3799	batch_accuracy: 36.01%	lr:0.000900
Ep: 14/48	It: 7051/8134	batch_loss: 3.3402	batch_accuracy: 38.11%	lr:0.000900
Ep: 14/48	It: 7101/8134	batch_loss: 3.3403	batch_accuracy: 37.40%	lr:0.000900
Ep: 14/48	It: 7151/8134	batch_loss: 3.3918	batch_accuracy: 36.91%	lr:0.000899
Ep: 14/48	It: 7201/8134	batch_loss: 3.2555	batch_accuracy: 38.57%	lr:0.000899
Ep: 14/48	It: 7251/8134	batch_loss: 3.2448	batch_accuracy: 39.65%	lr:0.000899
Ep: 14/48	It: 7301/8134	batch_loss: 3.4282	batch_accuracy: 37.01%	lr:0.000899
Ep: 14/48	It: 7351/8134	batch_loss: 3.3850	batch_accuracy: 37.72%	lr:0.000899
Ep: 14/48	It: 7401/8134	batch_loss: 3.2657	batch_accuracy: 39.67%	lr:0.000899
Ep: 14/48	It: 7451/8134	batch_loss: 3.3079	batch_accuracy: 38.21%	lr:0.000899
Ep: 14/48	It: 7501/8134	batch_loss: 3.2929	batch_accuracy: 38.53%	lr:0.000899
Ep: 14/48	It: 7551/8134	batch_loss: 3.3414	batch_accuracy: 37.13%	lr:0.000898
Ep: 14/48	It: 7601/8134	batch_loss: 3.1875	batch_accuracy: 40.36%	lr:0.000898
Ep: 14/48	It: 7651/8134	batch_loss: 3.2215	batch_accuracy: 40.58%	lr:0.000898
Ep: 14/48	It: 7701/8134	batch_loss: 3.3343	batch_accuracy: 37.65%	lr:0.000898
Ep: 14/48	It: 7751/8134	batch_loss: 3.3436	batch_accuracy: 37.16%	lr:0.000898
Ep: 14/48	It: 7801/8134	batch_loss: 3.3770	batch_accuracy: 37.48%	lr:0.000898
Ep: 14/48	It: 7851/8134	batch_loss: 3.3261	batch_accuracy: 38.21%	lr:0.000898
Ep: 14/48	It: 7901/8134	batch_loss: 3.3561	batch_accuracy: 38.38%	lr:0.000897
Ep: 14/48	It: 7951/8134	batch_loss: 3.2499	batch_accuracy: 39.50%	lr:0.000897
Ep: 14/48	It: 8001/8134	batch_loss: 3.3170	batch_accuracy: 38.62%	lr:0.000897
Ep: 14/48	It: 8051/8134	batch_loss: 3.3051	batch_accuracy: 37.06%	lr:0.000897
Ep: 14/48	It: 8101/8134	batch_loss: 3.3674	batch_accuracy: 36.55%	lr:0.000897
Ep: 14/48	It: 8134/8134	batch_loss: 3.3419	batch_accuracy: 37.77%	lr:0.000897


Generated text for input text "You" is:
Youtizing.
The use of anthranilumab for the treatment of solid tumors ing of patients with metastatic breast cancer has been well described. Here we present a case of a young female patient with aphigenital pseudocaine that is associated with a poor prognosis. The diagnosis is based on a review of the literature, in the literature, with the aim of assessing the incidence of metastatic breast cancer. This is the first report of a female breast carcinoma with an aggressive breast cancer. A total of 202 breast cancer patients with a history of breast cancer were studied for mammography. The mammography was performed for the breast. The presence of breast cancer was detected in a breast cancer group with a sensitivity of 84% and specificity of 78%. The breast cancer incidence was 53%. The sensitivity of breast cancer diagnosis was 91% and 97% respectively. A significant difference between the two groups was found between the two groups. The incidence of breast cancer incidence was higher in the breast cancer group than in the other groups.


CONCLUSION
The results of the study suggest that the use of breast cancer screening in the breast cancer population may help in reducing breast cancer mortality.
<eot>
<sot


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 15/48	It: 1/8134	batch_loss: 3.4296	batch_accuracy: 35.86%	lr:0.000897
Ep: 15/48	It: 51/8134	batch_loss: 3.4034	batch_accuracy: 38.21%	lr:0.000897
Ep: 15/48	It: 101/8134	batch_loss: 3.2620	batch_accuracy: 38.50%	lr:0.000897
Ep: 15/48	It: 151/8134	batch_loss: 3.2032	batch_accuracy: 39.43%	lr:0.000896
Ep: 15/48	It: 201/8134	batch_loss: 3.3228	batch_accuracy: 37.57%	lr:0.000896
Ep: 15/48	It: 251/8134	batch_loss: 3.2445	batch_accuracy: 38.60%	lr:0.000896
Ep: 15/48	It: 301/8134	batch_loss: 3.3031	batch_accuracy: 38.35%	lr:0.000896
Ep: 15/48	It: 351/8134	batch_loss: 3.4612	batch_accuracy: 37.35%	lr:0.000896
Ep: 15/48	It: 401/8134	batch_loss: 3.2848	batch_accuracy: 38.33%	lr:0.000896
Ep: 15/48	It: 451/8134	batch_loss: 3.4337	batch_accuracy: 36.74%	lr:0.000896
Ep: 15/48	It: 501/8134	batch_loss: 3.1521	batch_accuracy: 40.23%	lr:0.000895
Ep: 15/48	It: 551/8134	batch_loss: 3.3693	batch_accuracy: 37.06%	lr:0.000895
Ep: 15/48	It: 601/8134	batch_loss: 3.2636	batch_accuracy: 38.04%	lr:0.000895
Ep: 15/48	It: 651/8134	batch_loss: 3.2468	batch_accuracy: 38.50%	lr:0.000895
Ep: 15/48	It: 701/8134	batch_loss: 3.2537	batch_accuracy: 39.53%	lr:0.000895
Ep: 15/48	It: 751/8134	batch_loss: 3.2921	batch_accuracy: 39.38%	lr:0.000895
Ep: 15/48	It: 801/8134	batch_loss: 3.2804	batch_accuracy: 38.70%	lr:0.000895
Ep: 15/48	It: 851/8134	batch_loss: 3.2321	batch_accuracy: 39.16%	lr:0.000894
Ep: 15/48	It: 901/8134	batch_loss: 3.2755	batch_accuracy: 38.23%	lr:0.000894
Ep: 15/48	It: 951/8134	batch_loss: 3.3443	batch_accuracy: 37.11%	lr:0.000894
Ep: 15/48	It: 1001/8134	batch_loss: 3.3757	batch_accuracy: 37.50%	lr:0.000894
Ep: 15/48	It: 1051/8134	batch_loss: 3.3835	batch_accuracy: 37.65%	lr:0.000894
Ep: 15/48	It: 1101/8134	batch_loss: 3.3556	batch_accuracy: 37.33%	lr:0.000894
Ep: 15/48	It: 1151/8134	batch_loss: 3.2704	batch_accuracy: 38.99%	lr:0.000894
Ep: 15/48	It: 1201/8134	batch_loss: 3.3206	batch_accuracy: 38.43%	lr:0.000894
Ep: 15/48	It: 1251/8134	batch_loss: 3.1882	batch_accuracy: 40.14%	lr:0.000893
Ep: 15/48	It: 1301/8134	batch_loss: 3.3287	batch_accuracy: 37.84%	lr:0.000893
Ep: 15/48	It: 1351/8134	batch_loss: 3.3240	batch_accuracy: 37.77%	lr:0.000893
Ep: 15/48	It: 1401/8134	batch_loss: 3.2153	batch_accuracy: 39.82%	lr:0.000893
Ep: 15/48	It: 1451/8134	batch_loss: 3.1370	batch_accuracy: 41.63%	lr:0.000893
Ep: 15/48	It: 1501/8134	batch_loss: 3.3987	batch_accuracy: 36.74%	lr:0.000893
Ep: 15/48	It: 1551/8134	batch_loss: 3.2750	batch_accuracy: 37.77%	lr:0.000893
Ep: 15/48	It: 1601/8134	batch_loss: 3.3909	batch_accuracy: 37.82%	lr:0.000892
Ep: 15/48	It: 1651/8134	batch_loss: 3.2787	batch_accuracy: 37.70%	lr:0.000892
Ep: 15/48	It: 1701/8134	batch_loss: 3.2909	batch_accuracy: 37.70%	lr:0.000892
Ep: 15/48	It: 1751/8134	batch_loss: 3.2576	batch_accuracy: 38.75%	lr:0.000892
Ep: 15/48	It: 1801/8134	batch_loss: 3.1747	batch_accuracy: 40.48%	lr:0.000892
Ep: 15/48	It: 1851/8134	batch_loss: 3.2299	batch_accuracy: 39.16%	lr:0.000892
Ep: 15/48	It: 1901/8134	batch_loss: 3.4034	batch_accuracy: 37.84%	lr:0.000892
Ep: 15/48	It: 1951/8134	batch_loss: 3.3645	batch_accuracy: 37.35%	lr:0.000891
Ep: 15/48	It: 2001/8134	batch_loss: 3.2809	batch_accuracy: 38.87%	lr:0.000891
Ep: 15/48	It: 2051/8134	batch_loss: 3.3382	batch_accuracy: 37.26%	lr:0.000891
Ep: 15/48	It: 2101/8134	batch_loss: 3.2945	batch_accuracy: 37.77%	lr:0.000891
Ep: 15/48	It: 2151/8134	batch_loss: 3.3202	batch_accuracy: 37.67%	lr:0.000891
Ep: 15/48	It: 2201/8134	batch_loss: 3.2266	batch_accuracy: 38.89%	lr:0.000891
Ep: 15/48	It: 2251/8134	batch_loss: 3.3101	batch_accuracy: 38.11%	lr:0.000891
Ep: 15/48	It: 2301/8134	batch_loss: 3.3030	batch_accuracy: 38.62%	lr:0.000890
Ep: 15/48	It: 2351/8134	batch_loss: 3.3589	batch_accuracy: 37.08%	lr:0.000890
Ep: 15/48	It: 2401/8134	batch_loss: 3.3122	batch_accuracy: 39.04%	lr:0.000890
Ep: 15/48	It: 2451/8134	batch_loss: 3.2334	batch_accuracy: 39.11%	lr:0.000890
Ep: 15/48	It: 2501/8134	batch_loss: 3.3056	batch_accuracy: 38.11%	lr:0.000890
Ep: 15/48	It: 2551/8134	batch_loss: 3.4265	batch_accuracy: 36.77%	lr:0.000890
Ep: 15/48	It: 2601/8134	batch_loss: 3.3797	batch_accuracy: 37.67%	lr:0.000890
Ep: 15/48	It: 2651/8134	batch_loss: 3.3976	batch_accuracy: 38.06%	lr:0.000889
Ep: 15/48	It: 2701/8134	batch_loss: 3.3849	batch_accuracy: 36.45%	lr:0.000889
Ep: 15/48	It: 2751/8134	batch_loss: 3.3291	batch_accuracy: 38.50%	lr:0.000889
Ep: 15/48	It: 2801/8134	batch_loss: 3.3714	batch_accuracy: 37.96%	lr:0.000889
Ep: 15/48	It: 2851/8134	batch_loss: 3.2451	batch_accuracy: 39.58%	lr:0.000889
Ep: 15/48	It: 2901/8134	batch_loss: 3.3323	batch_accuracy: 37.08%	lr:0.000889
Ep: 15/48	It: 2951/8134	batch_loss: 3.2199	batch_accuracy: 39.11%	lr:0.000889
Ep: 15/48	It: 3001/8134	batch_loss: 3.2870	batch_accuracy: 37.79%	lr:0.000888
Ep: 15/48	It: 3051/8134	batch_loss: 3.3021	batch_accuracy: 37.72%	lr:0.000888
Ep: 15/48	It: 3101/8134	batch_loss: 3.2676	batch_accuracy: 38.75%	lr:0.000888
Ep: 15/48	It: 3151/8134	batch_loss: 3.1600	batch_accuracy: 40.75%	lr:0.000888
Ep: 15/48	It: 3201/8134	batch_loss: 3.3623	batch_accuracy: 37.74%	lr:0.000888
Ep: 15/48	It: 3251/8134	batch_loss: 3.3495	batch_accuracy: 37.38%	lr:0.000888
Ep: 15/48	It: 3301/8134	batch_loss: 3.2381	batch_accuracy: 39.01%	lr:0.000888
Ep: 15/48	It: 3351/8134	batch_loss: 3.3483	batch_accuracy: 36.99%	lr:0.000888
Ep: 15/48	It: 3401/8134	batch_loss: 3.1374	batch_accuracy: 41.04%	lr:0.000887
Ep: 15/48	It: 3451/8134	batch_loss: 3.3418	batch_accuracy: 37.92%	lr:0.000887
Ep: 15/48	It: 3501/8134	batch_loss: 3.3608	batch_accuracy: 37.38%	lr:0.000887
Ep: 15/48	It: 3551/8134	batch_loss: 3.3207	batch_accuracy: 38.94%	lr:0.000887
Ep: 15/48	It: 3601/8134	batch_loss: 3.2828	batch_accuracy: 38.82%	lr:0.000887
Ep: 15/48	It: 3651/8134	batch_loss: 3.2115	batch_accuracy: 37.92%	lr:0.000887
Ep: 15/48	It: 3701/8134	batch_loss: 3.3682	batch_accuracy: 37.21%	lr:0.000887
Ep: 15/48	It: 3751/8134	batch_loss: 3.3844	batch_accuracy: 37.43%	lr:0.000886
Ep: 15/48	It: 3801/8134	batch_loss: 3.2790	batch_accuracy: 39.16%	lr:0.000886
Ep: 15/48	It: 3851/8134	batch_loss: 3.3581	batch_accuracy: 36.99%	lr:0.000886
Ep: 15/48	It: 3901/8134	batch_loss: 3.3864	batch_accuracy: 37.82%	lr:0.000886
Ep: 15/48	It: 3951/8134	batch_loss: 3.3463	batch_accuracy: 37.08%	lr:0.000886
Ep: 15/48	It: 4001/8134	batch_loss: 3.2246	batch_accuracy: 39.01%	lr:0.000886
Ep: 15/48	It: 4051/8134	batch_loss: 3.3397	batch_accuracy: 38.70%	lr:0.000886
Ep: 15/48	It: 4101/8134	batch_loss: 3.2459	batch_accuracy: 37.60%	lr:0.000885
Ep: 15/48	It: 4151/8134	batch_loss: 3.2186	batch_accuracy: 38.96%	lr:0.000885
Ep: 15/48	It: 4201/8134	batch_loss: 3.2418	batch_accuracy: 39.99%	lr:0.000885
Ep: 15/48	It: 4251/8134	batch_loss: 3.3072	batch_accuracy: 37.89%	lr:0.000885
Ep: 15/48	It: 4301/8134	batch_loss: 3.1907	batch_accuracy: 38.72%	lr:0.000885
Ep: 15/48	It: 4351/8134	batch_loss: 3.2696	batch_accuracy: 38.67%	lr:0.000885
Ep: 15/48	It: 4401/8134	batch_loss: 3.3198	batch_accuracy: 37.72%	lr:0.000885
Ep: 15/48	It: 4451/8134	batch_loss: 3.1013	batch_accuracy: 42.11%	lr:0.000884
Ep: 15/48	It: 4501/8134	batch_loss: 3.4598	batch_accuracy: 35.64%	lr:0.000884
Ep: 15/48	It: 4551/8134	batch_loss: 3.2447	batch_accuracy: 39.62%	lr:0.000884
Ep: 15/48	It: 4601/8134	batch_loss: 3.2669	batch_accuracy: 38.75%	lr:0.000884
Ep: 15/48	It: 4651/8134	batch_loss: 3.2715	batch_accuracy: 38.82%	lr:0.000884
Ep: 15/48	It: 4701/8134	batch_loss: 3.2253	batch_accuracy: 38.99%	lr:0.000884
Ep: 15/48	It: 4751/8134	batch_loss: 3.3728	batch_accuracy: 36.38%	lr:0.000884
Ep: 15/48	It: 4801/8134	batch_loss: 3.3700	batch_accuracy: 38.01%	lr:0.000883
Ep: 15/48	It: 4851/8134	batch_loss: 3.2813	batch_accuracy: 38.45%	lr:0.000883
Ep: 15/48	It: 4901/8134	batch_loss: 3.3874	batch_accuracy: 37.11%	lr:0.000883
Ep: 15/48	It: 4951/8134	batch_loss: 3.4128	batch_accuracy: 36.04%	lr:0.000883
Ep: 15/48	It: 5001/8134	batch_loss: 3.3757	batch_accuracy: 37.33%	lr:0.000883
Ep: 15/48	It: 5051/8134	batch_loss: 3.1413	batch_accuracy: 40.77%	lr:0.000883
Ep: 15/48	It: 5101/8134	batch_loss: 3.3126	batch_accuracy: 38.57%	lr:0.000883
Ep: 15/48	It: 5151/8134	batch_loss: 3.4063	batch_accuracy: 36.87%	lr:0.000882
Ep: 15/48	It: 5201/8134	batch_loss: 3.3586	batch_accuracy: 36.72%	lr:0.000882
Ep: 15/48	It: 5251/8134	batch_loss: 3.3999	batch_accuracy: 36.77%	lr:0.000882
Ep: 15/48	It: 5301/8134	batch_loss: 3.2527	batch_accuracy: 39.21%	lr:0.000882
Ep: 15/48	It: 5351/8134	batch_loss: 3.2931	batch_accuracy: 38.62%	lr:0.000882
Ep: 15/48	It: 5401/8134	batch_loss: 3.3687	batch_accuracy: 37.21%	lr:0.000882
Ep: 15/48	It: 5451/8134	batch_loss: 3.2770	batch_accuracy: 38.96%	lr:0.000882
Ep: 15/48	It: 5501/8134	batch_loss: 3.2742	batch_accuracy: 39.60%	lr:0.000881
Ep: 15/48	It: 5551/8134	batch_loss: 3.1827	batch_accuracy: 38.87%	lr:0.000881
Ep: 15/48	It: 5601/8134	batch_loss: 3.4040	batch_accuracy: 37.57%	lr:0.000881
Ep: 15/48	It: 5651/8134	batch_loss: 3.3006	batch_accuracy: 37.92%	lr:0.000881
Ep: 15/48	It: 5701/8134	batch_loss: 3.3146	batch_accuracy: 37.99%	lr:0.000881
Ep: 15/48	It: 5751/8134	batch_loss: 3.2988	batch_accuracy: 37.65%	lr:0.000881
Ep: 15/48	It: 5801/8134	batch_loss: 3.3677	batch_accuracy: 36.60%	lr:0.000881
Ep: 15/48	It: 5851/8134	batch_loss: 3.2048	batch_accuracy: 40.33%	lr:0.000880
Ep: 15/48	It: 5901/8134	batch_loss: 3.3234	batch_accuracy: 37.40%	lr:0.000880
Ep: 15/48	It: 5951/8134	batch_loss: 3.2936	batch_accuracy: 38.72%	lr:0.000880
Ep: 15/48	It: 6001/8134	batch_loss: 3.2147	batch_accuracy: 39.04%	lr:0.000880
Ep: 15/48	It: 6051/8134	batch_loss: 3.2127	batch_accuracy: 39.53%	lr:0.000880
Ep: 15/48	It: 6101/8134	batch_loss: 3.3138	batch_accuracy: 37.16%	lr:0.000880
Ep: 15/48	It: 6151/8134	batch_loss: 3.3421	batch_accuracy: 36.33%	lr:0.000879
Ep: 15/48	It: 6201/8134	batch_loss: 3.2735	batch_accuracy: 38.84%	lr:0.000879
Ep: 15/48	It: 6251/8134	batch_loss: 3.3467	batch_accuracy: 37.84%	lr:0.000879
Ep: 15/48	It: 6301/8134	batch_loss: 3.2371	batch_accuracy: 39.18%	lr:0.000879
Ep: 15/48	It: 6351/8134	batch_loss: 3.4321	batch_accuracy: 36.28%	lr:0.000879
Ep: 15/48	It: 6401/8134	batch_loss: 3.3503	batch_accuracy: 37.26%	lr:0.000879
Ep: 15/48	It: 6451/8134	batch_loss: 3.3175	batch_accuracy: 38.38%	lr:0.000879
Ep: 15/48	It: 6501/8134	batch_loss: 3.2676	batch_accuracy: 39.38%	lr:0.000878
Ep: 15/48	It: 6551/8134	batch_loss: 3.3321	batch_accuracy: 37.48%	lr:0.000878
Ep: 15/48	It: 6601/8134	batch_loss: 3.4862	batch_accuracy: 35.64%	lr:0.000878
Ep: 15/48	It: 6651/8134	batch_loss: 3.3597	batch_accuracy: 36.91%	lr:0.000878
Ep: 15/48	It: 6701/8134	batch_loss: 3.3921	batch_accuracy: 36.30%	lr:0.000878
Ep: 15/48	It: 6751/8134	batch_loss: 3.4068	batch_accuracy: 36.99%	lr:0.000878
Ep: 15/48	It: 6801/8134	batch_loss: 3.3068	batch_accuracy: 38.65%	lr:0.000878
Ep: 15/48	It: 6851/8134	batch_loss: 3.1904	batch_accuracy: 39.50%	lr:0.000877
Ep: 15/48	It: 6901/8134	batch_loss: 3.3328	batch_accuracy: 37.79%	lr:0.000877
Ep: 15/48	It: 6951/8134	batch_loss: 3.3704	batch_accuracy: 37.40%	lr:0.000877
Ep: 15/48	It: 7001/8134	batch_loss: 3.2065	batch_accuracy: 39.26%	lr:0.000877
Ep: 15/48	It: 7051/8134	batch_loss: 3.2772	batch_accuracy: 38.40%	lr:0.000877
Ep: 15/48	It: 7101/8134	batch_loss: 3.2976	batch_accuracy: 38.28%	lr:0.000877
Ep: 15/48	It: 7151/8134	batch_loss: 3.3784	batch_accuracy: 36.99%	lr:0.000877
Ep: 15/48	It: 7201/8134	batch_loss: 3.2938	batch_accuracy: 39.04%	lr:0.000876
Ep: 15/48	It: 7251/8134	batch_loss: 3.1781	batch_accuracy: 40.53%	lr:0.000876
Ep: 15/48	It: 7301/8134	batch_loss: 3.3037	batch_accuracy: 37.79%	lr:0.000876
Ep: 15/48	It: 7351/8134	batch_loss: 3.2908	batch_accuracy: 38.60%	lr:0.000876
Ep: 15/48	It: 7401/8134	batch_loss: 3.3214	batch_accuracy: 38.28%	lr:0.000876
Ep: 15/48	It: 7451/8134	batch_loss: 3.4345	batch_accuracy: 37.01%	lr:0.000876
Ep: 15/48	It: 7501/8134	batch_loss: 3.1868	batch_accuracy: 39.92%	lr:0.000876
Ep: 15/48	It: 7551/8134	batch_loss: 3.3559	batch_accuracy: 38.31%	lr:0.000875
Ep: 15/48	It: 7601/8134	batch_loss: 3.2358	batch_accuracy: 38.62%	lr:0.000875
Ep: 15/48	It: 7651/8134	batch_loss: 3.3620	batch_accuracy: 36.94%	lr:0.000875
Ep: 15/48	It: 7701/8134	batch_loss: 3.2394	batch_accuracy: 39.11%	lr:0.000875
Ep: 15/48	It: 7751/8134	batch_loss: 3.3011	batch_accuracy: 38.70%	lr:0.000875
Ep: 15/48	It: 7801/8134	batch_loss: 3.1992	batch_accuracy: 39.60%	lr:0.000875
Ep: 15/48	It: 7851/8134	batch_loss: 3.3582	batch_accuracy: 37.52%	lr:0.000875
Ep: 15/48	It: 7901/8134	batch_loss: 3.3494	batch_accuracy: 38.33%	lr:0.000874
Ep: 15/48	It: 7951/8134	batch_loss: 3.2632	batch_accuracy: 39.04%	lr:0.000874
Ep: 15/48	It: 8001/8134	batch_loss: 3.4237	batch_accuracy: 36.55%	lr:0.000874
Ep: 15/48	It: 8051/8134	batch_loss: 3.2508	batch_accuracy: 38.79%	lr:0.000874
Ep: 15/48	It: 8101/8134	batch_loss: 3.4076	batch_accuracy: 36.87%	lr:0.000874
Ep: 15/48	It: 8134/8134	batch_loss: 3.1930	batch_accuracy: 40.12%	lr:0.000874


Generated text for input text "You" is:
You, to be a good way to find a new kind of graphs, which are not the same.

Theoretical and experimental results for theories of graph graph graphs in thesis
This article presents a new graph graph graph graph graph graph graph graph graph graph graph graph graph graph graphs and some numerical algorithms. The graph graph graph graph graph graph graph graph graph graph graph is graph graph graph graph graph graphs for graph graph graph graph graph graph graphs. The graph graph graph graphs of graph graph graphs and graph graph graph graph graph graphs are presented. The graph graphs of graph graph graphs, graph graph graphs, graph graphs and graph graphs are found. The graph graph of graph graph graphs and graph graphs of graph graphs is presented. The graph graph is a graph of graph graphs and graphs. We give graph graphs to graphs and graphs for graphs with graphs. We have shown that graph graphs of graph graphs and graphs of graphs are the most interesting graphs. We have shown that graphs of graphs can be classified as graphs of graphs, and graphs are the graphs of graphs. Our graphs are used to


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 16/48	It: 1/8134	batch_loss: 3.4074	batch_accuracy: 36.91%	lr:0.000874
Ep: 16/48	It: 51/8134	batch_loss: 3.3404	batch_accuracy: 38.50%	lr:0.000874
Ep: 16/48	It: 101/8134	batch_loss: 3.2594	batch_accuracy: 38.82%	lr:0.000873
Ep: 16/48	It: 151/8134	batch_loss: 3.2418	batch_accuracy: 39.50%	lr:0.000873
Ep: 16/48	It: 201/8134	batch_loss: 3.2709	batch_accuracy: 39.09%	lr:0.000873
Ep: 16/48	It: 251/8134	batch_loss: 3.2789	batch_accuracy: 37.92%	lr:0.000873
Ep: 16/48	It: 301/8134	batch_loss: 3.1637	batch_accuracy: 40.31%	lr:0.000873
Ep: 16/48	It: 351/8134	batch_loss: 3.3390	batch_accuracy: 37.38%	lr:0.000873
Ep: 16/48	It: 401/8134	batch_loss: 3.2365	batch_accuracy: 38.72%	lr:0.000872
Ep: 16/48	It: 451/8134	batch_loss: 3.3049	batch_accuracy: 36.84%	lr:0.000872
Ep: 16/48	It: 501/8134	batch_loss: 3.2766	batch_accuracy: 37.92%	lr:0.000872
Ep: 16/48	It: 551/8134	batch_loss: 3.2441	batch_accuracy: 39.23%	lr:0.000872
Ep: 16/48	It: 601/8134	batch_loss: 3.3172	batch_accuracy: 37.62%	lr:0.000872
Ep: 16/48	It: 651/8134	batch_loss: 3.1506	batch_accuracy: 39.94%	lr:0.000872
Ep: 16/48	It: 701/8134	batch_loss: 3.2677	batch_accuracy: 39.72%	lr:0.000872
Ep: 16/48	It: 751/8134	batch_loss: 3.3648	batch_accuracy: 37.50%	lr:0.000871
Ep: 16/48	It: 801/8134	batch_loss: 3.3150	batch_accuracy: 37.84%	lr:0.000871
Ep: 16/48	It: 851/8134	batch_loss: 3.3292	batch_accuracy: 37.48%	lr:0.000871
Ep: 16/48	It: 901/8134	batch_loss: 3.1249	batch_accuracy: 40.60%	lr:0.000871
Ep: 16/48	It: 951/8134	batch_loss: 3.2809	batch_accuracy: 39.23%	lr:0.000871
Ep: 16/48	It: 1001/8134	batch_loss: 3.2011	batch_accuracy: 40.72%	lr:0.000871
Ep: 16/48	It: 1051/8134	batch_loss: 3.3726	batch_accuracy: 36.65%	lr:0.000871
Ep: 16/48	It: 1101/8134	batch_loss: 3.3033	batch_accuracy: 38.87%	lr:0.000870
Ep: 16/48	It: 1151/8134	batch_loss: 3.3156	batch_accuracy: 38.38%	lr:0.000870
Ep: 16/48	It: 1201/8134	batch_loss: 3.2060	batch_accuracy: 39.01%	lr:0.000870
Ep: 16/48	It: 1251/8134	batch_loss: 3.3478	batch_accuracy: 38.48%	lr:0.000870
Ep: 16/48	It: 1301/8134	batch_loss: 3.3817	batch_accuracy: 37.16%	lr:0.000870
Ep: 16/48	It: 1351/8134	batch_loss: 3.2983	batch_accuracy: 38.35%	lr:0.000870
Ep: 16/48	It: 1401/8134	batch_loss: 3.3729	batch_accuracy: 37.11%	lr:0.000869
Ep: 16/48	It: 1451/8134	batch_loss: 3.3149	batch_accuracy: 38.09%	lr:0.000869
Ep: 16/48	It: 1501/8134	batch_loss: 3.2055	batch_accuracy: 39.14%	lr:0.000869
Ep: 16/48	It: 1551/8134	batch_loss: 3.2245	batch_accuracy: 39.33%	lr:0.000869
Ep: 16/48	It: 1601/8134	batch_loss: 3.4205	batch_accuracy: 36.60%	lr:0.000869
Ep: 16/48	It: 1651/8134	batch_loss: 3.2680	batch_accuracy: 38.77%	lr:0.000869
Ep: 16/48	It: 1701/8134	batch_loss: 3.3682	batch_accuracy: 37.99%	lr:0.000869
Ep: 16/48	It: 1751/8134	batch_loss: 3.2505	batch_accuracy: 39.26%	lr:0.000868
Ep: 16/48	It: 1801/8134	batch_loss: 3.2027	batch_accuracy: 39.43%	lr:0.000868
Ep: 16/48	It: 1851/8134	batch_loss: 3.3654	batch_accuracy: 36.50%	lr:0.000868
Ep: 16/48	It: 1901/8134	batch_loss: 3.1614	batch_accuracy: 39.31%	lr:0.000868
Ep: 16/48	It: 1951/8134	batch_loss: 3.3652	batch_accuracy: 37.38%	lr:0.000868
Ep: 16/48	It: 2001/8134	batch_loss: 3.1557	batch_accuracy: 39.21%	lr:0.000868
Ep: 16/48	It: 2051/8134	batch_loss: 3.3397	batch_accuracy: 37.38%	lr:0.000868
Ep: 16/48	It: 2101/8134	batch_loss: 3.3097	batch_accuracy: 38.01%	lr:0.000867
Ep: 16/48	It: 2151/8134	batch_loss: 3.2651	batch_accuracy: 39.04%	lr:0.000867
Ep: 16/48	It: 2201/8134	batch_loss: 3.2406	batch_accuracy: 37.84%	lr:0.000867
Ep: 16/48	It: 2251/8134	batch_loss: 3.3136	batch_accuracy: 39.23%	lr:0.000867
Ep: 16/48	It: 2301/8134	batch_loss: 3.2793	batch_accuracy: 38.60%	lr:0.000867
Ep: 16/48	It: 2351/8134	batch_loss: 3.3434	batch_accuracy: 37.16%	lr:0.000867
Ep: 16/48	It: 2401/8134	batch_loss: 3.2674	batch_accuracy: 38.87%	lr:0.000866
Ep: 16/48	It: 2451/8134	batch_loss: 3.3144	batch_accuracy: 38.60%	lr:0.000866
Ep: 16/48	It: 2501/8134	batch_loss: 3.2155	batch_accuracy: 39.58%	lr:0.000866
Ep: 16/48	It: 2551/8134	batch_loss: 3.2087	batch_accuracy: 39.40%	lr:0.000866
Ep: 16/48	It: 2601/8134	batch_loss: 3.3771	batch_accuracy: 37.18%	lr:0.000866
Ep: 16/48	It: 2651/8134	batch_loss: 3.2601	batch_accuracy: 38.77%	lr:0.000866
Ep: 16/48	It: 2701/8134	batch_loss: 3.2731	batch_accuracy: 39.94%	lr:0.000866
Ep: 16/48	It: 2751/8134	batch_loss: 3.1011	batch_accuracy: 39.94%	lr:0.000865
Ep: 16/48	It: 2801/8134	batch_loss: 3.3098	batch_accuracy: 38.13%	lr:0.000865
Ep: 16/48	It: 2851/8134	batch_loss: 3.2453	batch_accuracy: 39.55%	lr:0.000865
Ep: 16/48	It: 2901/8134	batch_loss: 3.2818	batch_accuracy: 38.43%	lr:0.000865
Ep: 16/48	It: 2951/8134	batch_loss: 3.3715	batch_accuracy: 36.40%	lr:0.000865
Ep: 16/48	It: 3001/8134	batch_loss: 3.1303	batch_accuracy: 39.26%	lr:0.000865
Ep: 16/48	It: 3051/8134	batch_loss: 3.3043	batch_accuracy: 37.33%	lr:0.000864
Ep: 16/48	It: 3101/8134	batch_loss: 3.3604	batch_accuracy: 38.18%	lr:0.000864
Ep: 16/48	It: 3151/8134	batch_loss: 3.2223	batch_accuracy: 39.62%	lr:0.000864
Ep: 16/48	It: 3201/8134	batch_loss: 3.2478	batch_accuracy: 39.33%	lr:0.000864
Ep: 16/48	It: 3251/8134	batch_loss: 3.2900	batch_accuracy: 38.48%	lr:0.000864
Ep: 16/48	It: 3301/8134	batch_loss: 3.2870	batch_accuracy: 39.09%	lr:0.000864
Ep: 16/48	It: 3351/8134	batch_loss: 3.2726	batch_accuracy: 38.53%	lr:0.000864
Ep: 16/48	It: 3401/8134	batch_loss: 3.4160	batch_accuracy: 36.72%	lr:0.000863
Ep: 16/48	It: 3451/8134	batch_loss: 3.2123	batch_accuracy: 39.33%	lr:0.000863
Ep: 16/48	It: 3501/8134	batch_loss: 3.2398	batch_accuracy: 39.65%	lr:0.000863
Ep: 16/48	It: 3551/8134	batch_loss: 3.3523	batch_accuracy: 37.40%	lr:0.000863
Ep: 16/48	It: 3601/8134	batch_loss: 3.2366	batch_accuracy: 39.16%	lr:0.000863
Ep: 16/48	It: 3651/8134	batch_loss: 3.2145	batch_accuracy: 40.01%	lr:0.000863
Ep: 16/48	It: 3701/8134	batch_loss: 3.3444	batch_accuracy: 37.92%	lr:0.000862
Ep: 16/48	It: 3751/8134	batch_loss: 3.3437	batch_accuracy: 37.57%	lr:0.000862
Ep: 16/48	It: 3801/8134	batch_loss: 3.3417	batch_accuracy: 36.77%	lr:0.000862
Ep: 16/48	It: 3851/8134	batch_loss: 3.3079	batch_accuracy: 38.06%	lr:0.000862
Ep: 16/48	It: 3901/8134	batch_loss: 3.3164	batch_accuracy: 37.30%	lr:0.000862
Ep: 16/48	It: 3951/8134	batch_loss: 3.1568	batch_accuracy: 39.87%	lr:0.000862
Ep: 16/48	It: 4001/8134	batch_loss: 3.2681	batch_accuracy: 37.94%	lr:0.000862
Ep: 16/48	It: 4051/8134	batch_loss: 3.2587	batch_accuracy: 38.50%	lr:0.000861
Ep: 16/48	It: 4101/8134	batch_loss: 3.1678	batch_accuracy: 39.28%	lr:0.000861
Ep: 16/48	It: 4151/8134	batch_loss: 3.3347	batch_accuracy: 37.01%	lr:0.000861
Ep: 16/48	It: 4201/8134	batch_loss: 3.4334	batch_accuracy: 37.94%	lr:0.000861
Ep: 16/48	It: 4251/8134	batch_loss: 3.4179	batch_accuracy: 36.45%	lr:0.000861
Ep: 16/48	It: 4301/8134	batch_loss: 3.2131	batch_accuracy: 38.87%	lr:0.000861
Ep: 16/48	It: 4351/8134	batch_loss: 3.3069	batch_accuracy: 38.18%	lr:0.000860
Ep: 16/48	It: 4401/8134	batch_loss: 3.2603	batch_accuracy: 39.09%	lr:0.000860
Ep: 16/48	It: 4451/8134	batch_loss: 3.3530	batch_accuracy: 37.48%	lr:0.000860
Ep: 16/48	It: 4501/8134	batch_loss: 3.1386	batch_accuracy: 40.04%	lr:0.000860
Ep: 16/48	It: 4551/8134	batch_loss: 3.3281	batch_accuracy: 37.57%	lr:0.000860
Ep: 16/48	It: 4601/8134	batch_loss: 3.3472	batch_accuracy: 38.38%	lr:0.000860
Ep: 16/48	It: 4651/8134	batch_loss: 3.2794	batch_accuracy: 38.28%	lr:0.000860
Ep: 16/48	It: 4701/8134	batch_loss: 3.3269	batch_accuracy: 38.09%	lr:0.000859
Ep: 16/48	It: 4751/8134	batch_loss: 3.1916	batch_accuracy: 39.04%	lr:0.000859
Ep: 16/48	It: 4801/8134	batch_loss: 3.3194	batch_accuracy: 38.53%	lr:0.000859
Ep: 16/48	It: 4851/8134	batch_loss: 3.2160	batch_accuracy: 39.01%	lr:0.000859
Ep: 16/48	It: 4901/8134	batch_loss: 3.2619	batch_accuracy: 38.82%	lr:0.000859
Ep: 16/48	It: 4951/8134	batch_loss: 3.1879	batch_accuracy: 39.70%	lr:0.000859
Ep: 16/48	It: 5001/8134	batch_loss: 3.4069	batch_accuracy: 37.06%	lr:0.000858
Ep: 16/48	It: 5051/8134	batch_loss: 3.3361	batch_accuracy: 38.43%	lr:0.000858
Ep: 16/48	It: 5101/8134	batch_loss: 3.2767	batch_accuracy: 38.09%	lr:0.000858
Ep: 16/48	It: 5151/8134	batch_loss: 3.2579	batch_accuracy: 38.75%	lr:0.000858
Ep: 16/48	It: 5201/8134	batch_loss: 3.3041	batch_accuracy: 37.77%	lr:0.000858
Ep: 16/48	It: 5251/8134	batch_loss: 3.2539	batch_accuracy: 38.43%	lr:0.000858
Ep: 16/48	It: 5301/8134	batch_loss: 3.2097	batch_accuracy: 38.99%	lr:0.000858
Ep: 16/48	It: 5351/8134	batch_loss: 3.2979	batch_accuracy: 38.13%	lr:0.000857
Ep: 16/48	It: 5401/8134	batch_loss: 3.3319	batch_accuracy: 37.08%	lr:0.000857
Ep: 16/48	It: 5451/8134	batch_loss: 3.2140	batch_accuracy: 40.14%	lr:0.000857
Ep: 16/48	It: 5501/8134	batch_loss: 3.2503	batch_accuracy: 39.70%	lr:0.000857
Ep: 16/48	It: 5551/8134	batch_loss: 3.2936	batch_accuracy: 38.04%	lr:0.000857
Ep: 16/48	It: 5601/8134	batch_loss: 3.2266	batch_accuracy: 39.53%	lr:0.000857
Ep: 16/48	It: 5651/8134	batch_loss: 3.2923	batch_accuracy: 37.62%	lr:0.000856
Ep: 16/48	It: 5701/8134	batch_loss: 3.2820	batch_accuracy: 38.70%	lr:0.000856
Ep: 16/48	It: 5751/8134	batch_loss: 3.2754	batch_accuracy: 39.48%	lr:0.000856
Ep: 16/48	It: 5801/8134	batch_loss: 3.2973	batch_accuracy: 38.26%	lr:0.000856
Ep: 16/48	It: 5851/8134	batch_loss: 3.2852	batch_accuracy: 38.77%	lr:0.000856
Ep: 16/48	It: 5901/8134	batch_loss: 3.3437	batch_accuracy: 36.67%	lr:0.000856
Ep: 16/48	It: 5951/8134	batch_loss: 3.2832	batch_accuracy: 38.82%	lr:0.000855
Ep: 16/48	It: 6001/8134	batch_loss: 3.3032	batch_accuracy: 38.33%	lr:0.000855
Ep: 16/48	It: 6051/8134	batch_loss: 3.1999	batch_accuracy: 39.75%	lr:0.000855
Ep: 16/48	It: 6101/8134	batch_loss: 3.2547	batch_accuracy: 38.87%	lr:0.000855
Ep: 16/48	It: 6151/8134	batch_loss: 3.1662	batch_accuracy: 40.82%	lr:0.000855
Ep: 16/48	It: 6201/8134	batch_loss: 3.3933	batch_accuracy: 36.74%	lr:0.000855
Ep: 16/48	It: 6251/8134	batch_loss: 3.2705	batch_accuracy: 38.99%	lr:0.000855
Ep: 16/48	It: 6301/8134	batch_loss: 3.3497	batch_accuracy: 37.40%	lr:0.000854
Ep: 16/48	It: 6351/8134	batch_loss: 3.3064	batch_accuracy: 38.16%	lr:0.000854
Ep: 16/48	It: 6401/8134	batch_loss: 3.3148	batch_accuracy: 38.23%	lr:0.000854
Ep: 16/48	It: 6451/8134	batch_loss: 3.3268	batch_accuracy: 39.18%	lr:0.000854
Ep: 16/48	It: 6501/8134	batch_loss: 3.2030	batch_accuracy: 38.99%	lr:0.000854
Ep: 16/48	It: 6551/8134	batch_loss: 3.2727	batch_accuracy: 39.36%	lr:0.000854
Ep: 16/48	It: 6601/8134	batch_loss: 3.2846	batch_accuracy: 38.18%	lr:0.000853
Ep: 16/48	It: 6651/8134	batch_loss: 3.2440	batch_accuracy: 39.43%	lr:0.000853
Ep: 16/48	It: 6701/8134	batch_loss: 3.2688	batch_accuracy: 38.99%	lr:0.000853
Ep: 16/48	It: 6751/8134	batch_loss: 3.2048	batch_accuracy: 39.33%	lr:0.000853
Ep: 16/48	It: 6801/8134	batch_loss: 3.3259	batch_accuracy: 38.16%	lr:0.000853
Ep: 16/48	It: 6851/8134	batch_loss: 3.2680	batch_accuracy: 38.65%	lr:0.000853
Ep: 16/48	It: 6901/8134	batch_loss: 3.3002	batch_accuracy: 38.06%	lr:0.000852
Ep: 16/48	It: 6951/8134	batch_loss: 3.5018	batch_accuracy: 36.43%	lr:0.000852
Ep: 16/48	It: 7001/8134	batch_loss: 3.2532	batch_accuracy: 38.33%	lr:0.000852
Ep: 16/48	It: 7051/8134	batch_loss: 3.2819	batch_accuracy: 39.16%	lr:0.000852
Ep: 16/48	It: 7101/8134	batch_loss: 3.2264	batch_accuracy: 38.62%	lr:0.000852
Ep: 16/48	It: 7151/8134	batch_loss: 3.3209	batch_accuracy: 37.16%	lr:0.000852
Ep: 16/48	It: 7201/8134	batch_loss: 3.2964	batch_accuracy: 38.11%	lr:0.000852
Ep: 16/48	It: 7251/8134	batch_loss: 3.2445	batch_accuracy: 39.16%	lr:0.000851
Ep: 16/48	It: 7301/8134	batch_loss: 3.1988	batch_accuracy: 39.28%	lr:0.000851
Ep: 16/48	It: 7351/8134	batch_loss: 3.3469	batch_accuracy: 37.99%	lr:0.000851
Ep: 16/48	It: 7401/8134	batch_loss: 3.3026	batch_accuracy: 38.50%	lr:0.000851
Ep: 16/48	It: 7451/8134	batch_loss: 3.3001	batch_accuracy: 37.82%	lr:0.000851
Ep: 16/48	It: 7501/8134	batch_loss: 3.3089	batch_accuracy: 38.35%	lr:0.000851
Ep: 16/48	It: 7551/8134	batch_loss: 3.2865	batch_accuracy: 38.38%	lr:0.000850
Ep: 16/48	It: 7601/8134	batch_loss: 3.2859	batch_accuracy: 38.23%	lr:0.000850
Ep: 16/48	It: 7651/8134	batch_loss: 3.3514	batch_accuracy: 37.43%	lr:0.000850
Ep: 16/48	It: 7701/8134	batch_loss: 3.3431	batch_accuracy: 36.91%	lr:0.000850
Ep: 16/48	It: 7751/8134	batch_loss: 3.3695	batch_accuracy: 36.23%	lr:0.000850
Ep: 16/48	It: 7801/8134	batch_loss: 3.2251	batch_accuracy: 38.89%	lr:0.000850
Ep: 16/48	It: 7851/8134	batch_loss: 3.1956	batch_accuracy: 38.72%	lr:0.000849
Ep: 16/48	It: 7901/8134	batch_loss: 3.1820	batch_accuracy: 40.06%	lr:0.000849
Ep: 16/48	It: 7951/8134	batch_loss: 3.2652	batch_accuracy: 37.87%	lr:0.000849
Ep: 16/48	It: 8001/8134	batch_loss: 3.3244	batch_accuracy: 38.38%	lr:0.000849
Ep: 16/48	It: 8051/8134	batch_loss: 3.3444	batch_accuracy: 38.70%	lr:0.000849
Ep: 16/48	It: 8101/8134	batch_loss: 3.2432	batch_accuracy: 39.26%	lr:0.000849
Ep: 16/48	It: 8134/8134	batch_loss: 3.1954	batch_accuracy: 38.99%	lr:0.000849


Generated text for input text "You" is:
You, and their respective roles, as well as other groups. The paper concludes with a broader discussion on theories of humanity and on theory, to theological and historical aspects of theories.
The chapter focuses on theology, and culture of human rights, which is of aesthetic origin, which has been one of the most important topics in human history. It will be of interest to note that these aspects of humanity in the world are not only a prerequisite for the establishment of human rights, but also a broader context for the development of social rights.
<eot>
<sot>
Automated Patch-Based Approach to Forecasting the Efficiency of Circuit Energy Harvesting Algorithms

According to the results of the study, the influence of the power consumption of the power plant on the output power has been studied. The simulation results show that the maximum power consumption for the PV array is about 10-6%.
<eot>
<sot>
Treatment of acute liver failure with intravenous pentazocine.

The purpose of this study was to compare the efficacy of a single intra-ab


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
TOKENIZERS_PARALLELISM=(true | false)
Ep: 17/48	It: 1/8134	batch_loss: 3.2354	batch_accuracy: 38.18%	lr:0.000849
Ep: 17/48	It: 51/8134	batch_loss: 3.2097	batch_accuracy: 39.40%	lr:0.000848
Ep: 17/48	It: 101/8134	batch_loss: 3.3132	batch_accuracy: 38.55%	lr:0.000848
Ep: 17/48	It: 151/8134	batch_loss: 3.3363	batch_accuracy: 37.72%	lr:0.000848
Ep: 17/48	It: 201/8134	batch_loss: 3.2917	batch_accuracy: 38.62%	lr:0.000848
Ep: 17/48	It: 251/8134	batch_loss: 3.2738	batch_accuracy: 37.82%	lr:0.000848
Ep: 17/48	It: 301/8134	batch_loss: 3.3020	batch_accuracy: 37.79%	lr:0.000848
Ep: 17/48	It: 351/8134	batch_loss: 3.3465	batch_accuracy: 36.99%	lr:0.000847
Ep: 17/48	It: 401/8134	batch_loss: 3.2092	batch_accuracy: 37.62%	lr:0.000847
Ep: 17/48	It: 451/8134	batch_loss: 3.2329	batch_accuracy: 38.96%	lr:0.000847
Ep: 17/48	It: 501/8134	batch_loss: 3.3531	batch_accuracy: 37.11%	lr:0.000847
Ep: 17/48	It: 551/8134	batch_loss: 3.2801	batch_accuracy: 38.60%	lr:0.000847
Ep: 17/48	It: 601/8134	batch_loss: 3.2533	batch_accuracy: 39.45%	lr:0.000847
Ep: 17/48	It: 651/8134	batch_loss: 3.3694	batch_accuracy: 37.74%	lr:0.000846
Ep: 17/48	It: 701/8134	batch_loss: 3.1931	batch_accuracy: 39.26%	lr:0.000846
Ep: 17/48	It: 751/8134	batch_loss: 3.2996	batch_accuracy: 37.96%	lr:0.000846
Ep: 17/48	It: 801/8134	batch_loss: 3.3505	batch_accuracy: 37.11%	lr:0.000846
Ep: 17/48	It: 851/8134	batch_loss: 3.2882	batch_accuracy: 38.16%	lr:0.000846
Ep: 17/48	It: 901/8134	batch_loss: 3.3360	batch_accuracy: 38.09%	lr:0.000846
Ep: 17/48	It: 951/8134	batch_loss: 3.3352	batch_accuracy: 37.70%	lr:0.000846
Ep: 17/48	It: 1001/8134	batch_loss: 3.2571	batch_accuracy: 37.99%	lr:0.000845
Ep: 17/48	It: 1051/8134	batch_loss: 3.2653	batch_accuracy: 39.14%	lr:0.000845
Ep: 17/48	It: 1101/8134	batch_loss: 3.3187	batch_accuracy: 37.72%	lr:0.000845
Ep: 17/48	It: 1151/8134	batch_loss: 3.2009	batch_accuracy: 40.23%	lr:0.000845
Ep: 17/48	It: 1201/8134	batch_loss: 3.1893	batch_accuracy: 40.06%	lr:0.000845
Ep: 17/48	It: 1251/8134	batch_loss: 3.2559	batch_accuracy: 38.67%	lr:0.000845
Ep: 17/48	It: 1301/8134	batch_loss: 3.3253	batch_accuracy: 38.06%	lr:0.000844
Ep: 17/48	It: 1351/8134	batch_loss: 3.2199	batch_accuracy: 39.84%	lr:0.000844
Ep: 17/48	It: 1401/8134	batch_loss: 3.2168	batch_accuracy: 39.31%	lr:0.000844
Ep: 17/48	It: 1451/8134	batch_loss: 3.3379	batch_accuracy: 37.60%	lr:0.000844
Ep: 17/48	It: 1501/8134	batch_loss: 3.1807	batch_accuracy: 39.45%	lr:0.000844
Ep: 17/48	It: 1551/8134	batch_loss: 3.2667	batch_accuracy: 38.09%	lr:0.000844
Ep: 17/48	It: 1601/8134	batch_loss: 3.4880	batch_accuracy: 36.72%	lr:0.000843
Ep: 17/48	It: 1651/8134	batch_loss: 3.2936	batch_accuracy: 38.70%	lr:0.000843
Ep: 17/48	It: 1701/8134	batch_loss: 3.3033	batch_accuracy: 37.74%	lr:0.000843
Ep: 17/48	It: 1751/8134	batch_loss: 3.3887	batch_accuracy: 37.96%	lr:0.000843
Ep: 17/48	It: 1801/8134	batch_loss: 3.1353	batch_accuracy: 39.55%	lr:0.000843
Ep: 17/48	It: 1851/8134	batch_loss: 3.2911	batch_accuracy: 37.74%	lr:0.000843
Ep: 17/48	It: 1901/8134	batch_loss: 3.2897	batch_accuracy: 39.65%	lr:0.000842
Ep: 17/48	It: 1951/8134	batch_loss: 3.1919	batch_accuracy: 39.28%	lr:0.000842
Ep: 17/48	It: 2001/8134	batch_loss: 3.3626	batch_accuracy: 38.35%	lr:0.000842
Ep: 17/48	It: 2051/8134	batch_loss: 3.3360	batch_accuracy: 38.09%	lr:0.000842
Ep: 17/48	It: 2101/8134	batch_loss: 3.2763	batch_accuracy: 39.28%	lr:0.000842
Ep: 17/48	It: 2151/8134	batch_loss: 3.3301	batch_accuracy: 37.01%	lr:0.000842
Ep: 17/48	It: 2201/8134	batch_loss: 3.3719	batch_accuracy: 37.18%	lr:0.000841
Ep: 17/48	It: 2251/8134	batch_loss: 3.4076	batch_accuracy: 37.89%	lr:0.000841
Ep: 17/48	It: 2301/8134	batch_loss: 3.1916	batch_accuracy: 38.77%	lr:0.000841
Ep: 17/48	It: 2351/8134	batch_loss: 3.2509	batch_accuracy: 38.94%	lr:0.000841
Ep: 17/48	It: 2401/8134	batch_loss: 3.2464	batch_accuracy: 39.38%	lr:0.000841
Ep: 17/48	It: 2451/8134	batch_loss: 3.2536	batch_accuracy: 38.31%	lr:0.000841
Ep: 17/48	It: 2501/8134	batch_loss: 3.3950	batch_accuracy: 37.01%	lr:0.000840
Ep: 17/48	It: 2551/8134	batch_loss: 3.2787	batch_accuracy: 38.99%	lr:0.000840
Ep: 17/48	It: 2601/8134	batch_loss: 3.4127	batch_accuracy: 37.23%	lr:0.000840
Ep: 17/48	It: 2651/8134	batch_loss: 3.3207	batch_accuracy: 38.70%	lr:0.000840
Ep: 17/48	It: 2701/8134	batch_loss: 3.3075	batch_accuracy: 38.55%	lr:0.000840
Ep: 17/48	It: 2751/8134	batch_loss: 3.1400	batch_accuracy: 41.14%	lr:0.000840
Ep: 17/48	It: 2801/8134	batch_loss: 3.2499	batch_accuracy: 39.67%	lr:0.000839
Ep: 17/48	It: 2851/8134	batch_loss: 3.2259	batch_accuracy: 39.16%	lr:0.000839
Ep: 17/48	It: 2901/8134	batch_loss: 3.2202	batch_accuracy: 39.09%	lr:0.000839
Ep: 17/48	It: 2951/8134	batch_loss: 3.2764	batch_accuracy: 38.31%	lr:0.000839
Ep: 17/48	It: 3001/8134	batch_loss: 3.3429	batch_accuracy: 37.38%	lr:0.000839
Ep: 17/48	It: 3051/8134	batch_loss: 3.2514	batch_accuracy: 38.79%	lr:0.000839
Ep: 17/48	It: 3101/8134	batch_loss: 3.1506	batch_accuracy: 41.31%	lr:0.000839
Ep: 17/48	It: 3151/8134	batch_loss: 3.2457	batch_accuracy: 38.96%	lr:0.000838
Ep: 17/48	It: 3201/8134	batch_loss: 3.3275	batch_accuracy: 38.48%	lr:0.000838
Ep: 17/48	It: 3251/8134	batch_loss: 3.2938	batch_accuracy: 37.72%	lr:0.000838
Ep: 17/48	It: 3301/8134	batch_loss: 3.2354	batch_accuracy: 39.36%	lr:0.000838
Ep: 17/48	It: 3351/8134	batch_loss: 3.3898	batch_accuracy: 38.01%	lr:0.000838
Ep: 17/48	It: 3401/8134	batch_loss: 3.2272	batch_accuracy: 39.79%	lr:0.000838
Ep: 17/48	It: 3451/8134	batch_loss: 3.2864	batch_accuracy: 38.65%	lr:0.000837
Ep: 17/48	It: 3501/8134	batch_loss: 3.1359	batch_accuracy: 39.82%	lr:0.000837
Ep: 17/48	It: 3551/8134	batch_loss: 3.2162	batch_accuracy: 38.50%	lr:0.000837
Ep: 17/48	It: 3601/8134	batch_loss: 3.2436	batch_accuracy: 38.26%	lr:0.000837
Ep: 17/48	It: 3651/8134	batch_loss: 3.2529	batch_accuracy: 38.01%	lr:0.000837
Ep: 17/48	It: 3701/8134	batch_loss: 3.2406	batch_accuracy: 40.26%	lr:0.000837
Ep: 17/48	It: 3751/8134	batch_loss: 3.2019	batch_accuracy: 39.40%	lr:0.000836
Ep: 17/48	It: 3801/8134	batch_loss: 3.2946	batch_accuracy: 38.21%	lr:0.000836
Ep: 17/48	It: 3851/8134	batch_loss: 3.3686	batch_accuracy: 36.84%	lr:0.000836
Ep: 17/48	It: 3901/8134	batch_loss: 3.3955	batch_accuracy: 37.06%	lr:0.000836
Ep: 17/48	It: 3951/8134	batch_loss: 3.3195	batch_accuracy: 37.74%	lr:0.000836
Ep: 17/48	It: 4001/8134	batch_loss: 3.3377	batch_accuracy: 37.55%	lr:0.000836
Ep: 17/48	It: 4051/8134	batch_loss: 3.4011	batch_accuracy: 36.99%	lr:0.000835
Ep: 17/48	It: 4101/8134	batch_loss: 3.3041	batch_accuracy: 37.62%	lr:0.000835
Ep: 17/48	It: 4151/8134	batch_loss: 3.1993	batch_accuracy: 39.28%	lr:0.000835
Ep: 17/48	It: 4201/8134	batch_loss: 3.2652	batch_accuracy: 38.13%	lr:0.000835
Ep: 17/48	It: 4251/8134	batch_loss: 3.3648	batch_accuracy: 36.87%	lr:0.000835
Ep: 17/48	It: 4301/8134	batch_loss: 3.3174	batch_accuracy: 38.92%	lr:0.000835
Ep: 17/48	It: 4351/8134	batch_loss: 3.2019	batch_accuracy: 39.33%	lr:0.000834
Ep: 17/48	It: 4401/8134	batch_loss: 3.3856	batch_accuracy: 37.38%	lr:0.000834
Ep: 17/48	It: 4451/8134	batch_loss: 3.1910	batch_accuracy: 40.38%	lr:0.000834
Ep: 17/48	It: 4501/8134	batch_loss: 3.3628	batch_accuracy: 37.62%	lr:0.000834
Ep: 17/48	It: 4551/8134	batch_loss: 3.2844	batch_accuracy: 39.09%	lr:0.000834
Ep: 17/48	It: 4601/8134	batch_loss: 3.2067	batch_accuracy: 39.55%	lr:0.000834
Ep: 17/48	It: 4651/8134	batch_loss: 3.3448	batch_accuracy: 37.96%	lr:0.000833
Ep: 17/48	It: 4701/8134	batch_loss: 3.2354	batch_accuracy: 38.96%	lr:0.000833
Ep: 17/48	It: 4751/8134	batch_loss: 3.1743	batch_accuracy: 39.92%	lr:0.000833
Ep: 17/48	It: 4801/8134	batch_loss: 3.2668	batch_accuracy: 38.31%	lr:0.000833
Ep: 17/48	It: 4851/8134	batch_loss: 3.2897	batch_accuracy: 39.18%	lr:0.000833
Ep: 17/48	It: 4901/8134	batch_loss: 3.2285	batch_accuracy: 39.21%	lr:0.000833
Ep: 17/48	It: 4951/8134	batch_loss: 3.1798	batch_accuracy: 40.28%	lr:0.000832
Ep: 17/48	It: 5001/8134	batch_loss: 3.3883	batch_accuracy: 37.23%	lr:0.000832
Ep: 17/48	It: 5051/8134	batch_loss: 3.1787	batch_accuracy: 39.38%	lr:0.000832
Ep: 17/48	It: 5101/8134	batch_loss: 3.2273	batch_accuracy: 40.11%	lr:0.000832
Ep: 17/48	It: 5151/8134	batch_loss: 3.3411	batch_accuracy: 37.04%	lr:0.000832
Ep: 17/48	It: 5201/8134	batch_loss: 3.3011	batch_accuracy: 38.04%	lr:0.000832
Ep: 17/48	It: 5251/8134	batch_loss: 3.2381	batch_accuracy: 37.52%	lr:0.000831
Ep: 17/48	It: 5301/8134	batch_loss: 3.1739	batch_accuracy: 38.94%	lr:0.000831
Ep: 17/48	It: 5351/8134	batch_loss: 3.1886	batch_accuracy: 40.38%	lr:0.000831
Ep: 17/48	It: 5401/8134	batch_loss: 3.3281	batch_accuracy: 37.30%	lr:0.000831
Ep: 17/48	It: 5451/8134	batch_loss: 3.2201	batch_accuracy: 39.23%	lr:0.000831
Ep: 17/48	It: 5501/8134	batch_loss: 3.4311	batch_accuracy: 36.21%	lr:0.000831
Ep: 17/48	It: 5551/8134	batch_loss: 3.1879	batch_accuracy: 39.09%	lr:0.000830
Ep: 17/48	It: 5601/8134	batch_loss: 3.2191	batch_accuracy: 38.82%	lr:0.000830
Ep: 17/48	It: 5651/8134	batch_loss: 3.3024	batch_accuracy: 38.18%	lr:0.000830
Ep: 17/48	It: 5701/8134	batch_loss: 3.1866	batch_accuracy: 39.92%	lr:0.000830
Ep: 17/48	It: 5751/8134	batch_loss: 3.2747	batch_accuracy: 38.11%	lr:0.000830
Ep: 17/48	It: 5801/8134	batch_loss: 3.1688	batch_accuracy: 40.58%	lr:0.000830
Ep: 17/48	It: 5851/8134	batch_loss: 3.2875	batch_accuracy: 38.87%	lr:0.000829
Ep: 17/48	It: 5901/8134	batch_loss: 3.2498	batch_accuracy: 39.28%	lr:0.000829
Ep: 17/48	It: 5951/8134	batch_loss: 3.2610	batch_accuracy: 38.13%	lr:0.000829
Ep: 17/48	It: 6001/8134	batch_loss: 3.1966	batch_accuracy: 39.87%	lr:0.000829
Ep: 17/48	It: 6051/8134	batch_loss: 3.2456	batch_accuracy: 39.01%	lr:0.000829
Ep: 17/48	It: 6101/8134	batch_loss: 3.3144	batch_accuracy: 38.53%	lr:0.000829
Ep: 17/48	It: 6151/8134	batch_loss: 3.2255	batch_accuracy: 38.48%	lr:0.000828
Ep: 17/48	It: 6201/8134	batch_loss: 3.1680	batch_accuracy: 40.14%	lr:0.000828
Ep: 17/48	It: 6251/8134	batch_loss: 3.3789	batch_accuracy: 36.52%	lr:0.000828
Ep: 17/48	It: 6301/8134	batch_loss: 3.3419	batch_accuracy: 38.82%	lr:0.000828
Ep: 17/48	It: 6351/8134	batch_loss: 3.1993	batch_accuracy: 39.62%	lr:0.000828
Ep: 17/48	It: 6401/8134	batch_loss: 3.2841	batch_accuracy: 38.50%	lr:0.000828
Ep: 17/48	It: 6451/8134	batch_loss: 3.1774	batch_accuracy: 39.77%	lr:0.000827
Ep: 17/48	It: 6501/8134	batch_loss: 3.2295	batch_accuracy: 38.84%	lr:0.000827
Ep: 17/48	It: 6551/8134	batch_loss: 3.1507	batch_accuracy: 40.31%	lr:0.000827
Ep: 17/48	It: 6601/8134	batch_loss: 3.2544	batch_accuracy: 39.58%	lr:0.000827
Ep: 17/48	It: 6651/8134	batch_loss: 3.2107	batch_accuracy: 40.36%	lr:0.000827
Ep: 17/48	It: 6701/8134	batch_loss: 3.2086	batch_accuracy: 39.94%	lr:0.000827
Ep: 17/48	It: 6751/8134	batch_loss: 3.1948	batch_accuracy: 40.09%	lr:0.000826
Ep: 17/48	It: 6801/8134	batch_loss: 3.2723	batch_accuracy: 39.58%	lr:0.000826
Ep: 17/48	It: 6851/8134	batch_loss: 3.1876	batch_accuracy: 39.23%	lr:0.000826
Ep: 17/48	It: 6901/8134	batch_loss: 3.3629	batch_accuracy: 37.79%	lr:0.000826
Ep: 17/48	It: 6951/8134	batch_loss: 3.2315	batch_accuracy: 39.48%	lr:0.000826
Ep: 17/48	It: 7001/8134	batch_loss: 3.1697	batch_accuracy: 40.21%	lr:0.000825
Ep: 17/48	It: 7051/8134	batch_loss: 3.3038	batch_accuracy: 38.31%	lr:0.000825
Ep: 17/48	It: 7101/8134	batch_loss: 3.1953	batch_accuracy: 39.60%	lr:0.000825
Ep: 17/48	It: 7151/8134	batch_loss: 3.3122	batch_accuracy: 38.28%	lr:0.000825
Ep: 17/48	It: 7201/8134	batch_loss: 3.2187	batch_accuracy: 38.01%	lr:0.000825
Ep: 17/48	It: 7251/8134	batch_loss: 3.3245	batch_accuracy: 37.35%	lr:0.000825
Ep: 17/48	It: 7301/8134	batch_loss: 3.2357	batch_accuracy: 39.50%	lr:0.000824
Ep: 17/48	It: 7351/8134	batch_loss: 3.2614	batch_accuracy: 38.77%	lr:0.000824
Ep: 17/48	It: 7401/8134	batch_loss: 3.4261	batch_accuracy: 36.89%	lr:0.000824
Ep: 17/48	It: 7451/8134	batch_loss: 3.3130	batch_accuracy: 37.89%	lr:0.000824
Ep: 17/48	It: 7501/8134	batch_loss: 3.2300	batch_accuracy: 39.40%	lr:0.000824
Ep: 17/48	It: 7551/8134	batch_loss: 3.1594	batch_accuracy: 40.33%	lr:0.000824
Ep: 17/48	It: 7601/8134	batch_loss: 3.2592	batch_accuracy: 38.31%	lr:0.000823
Ep: 17/48	It: 7651/8134	batch_loss: 3.1289	batch_accuracy: 40.21%	lr:0.000823
Ep: 17/48	It: 7701/8134	batch_loss: 3.1491	batch_accuracy: 40.41%	lr:0.000823
Ep: 17/48	It: 7751/8134	batch_loss: 3.3877	batch_accuracy: 37.60%	lr:0.000823
Ep: 17/48	It: 7801/8134	batch_loss: 3.2787	batch_accuracy: 38.70%	lr:0.000823
Ep: 17/48	It: 7851/8134	batch_loss: 3.2601	batch_accuracy: 38.94%	lr:0.000823
Ep: 17/48	It: 7901/8134	batch_loss: 3.2466	batch_accuracy: 39.04%	lr:0.000822
Ep: 17/48	It: 7951/8134	batch_loss: 3.2891	batch_accuracy: 38.92%	lr:0.000822
Ep: 17/48	It: 8001/8134	batch_loss: 3.1969	batch_accuracy: 39.28%	lr:0.000822
Ep: 17/48	It: 8051/8134	batch_loss: 3.3013	batch_accuracy: 38.26%	lr:0.000822
Ep: 17/48	It: 8101/8134	batch_loss: 3.1285	batch_accuracy: 39.82%	lr:0.000822
Ep: 17/48	It: 8134/8134	batch_loss: 3.3138	batch_accuracy: 38.69%	lr:0.000822


Generated text for input text "You" is:
Youhar and P. (1907)
The article concludes that theories of theory in relation to theology and that have a positive effect on this practice is a matter of theological and historical research, not only in theology of theological philosophy.
<eot>
<sot>
Micro-scale models of the interaction of the MEMS and its mixtures with a large particle size.

Micro-scale models have been widely used in many fields, including computer simulation, and machine learning. However, it is still a challenging problem that many researchers have developed in the past to perform numerical simulations and simulations. In this paper, we present a new approach for modelling a large particle size particle, which is able to simulate the flow of the particle, to be applied on a large scale particle. In this approach, the flow is controlled by a set of equations. In order to achieve the required performance, a method is proposed to estimate the flow rate of the particle as a function of the particle velocity. The particle size can be estimated by using a least squares method. This paper proposes a new approach for solving the flow rate problem with the optimal Poisson distribution. The method can


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 18/48	It: 1/8134	batch_loss: 3.2487	batch_accuracy: 38.48%	lr:0.000822
Ep: 18/48	It: 51/8134	batch_loss: 3.1454	batch_accuracy: 40.43%	lr:0.000821
Ep: 18/48	It: 101/8134	batch_loss: 3.2463	batch_accuracy: 40.28%	lr:0.000821
Ep: 18/48	It: 151/8134	batch_loss: 3.2799	batch_accuracy: 37.70%	lr:0.000821
Ep: 18/48	It: 201/8134	batch_loss: 3.2349	batch_accuracy: 39.75%	lr:0.000821
Ep: 18/48	It: 251/8134	batch_loss: 3.2486	batch_accuracy: 38.84%	lr:0.000821
Ep: 18/48	It: 301/8134	batch_loss: 3.2723	batch_accuracy: 37.99%	lr:0.000821
Ep: 18/48	It: 351/8134	batch_loss: 3.1395	batch_accuracy: 39.62%	lr:0.000820
Ep: 18/48	It: 401/8134	batch_loss: 3.3431	batch_accuracy: 37.79%	lr:0.000820
Ep: 18/48	It: 451/8134	batch_loss: 3.2379	batch_accuracy: 39.04%	lr:0.000820
Ep: 18/48	It: 501/8134	batch_loss: 3.2321	batch_accuracy: 38.84%	lr:0.000820
Ep: 18/48	It: 551/8134	batch_loss: 3.3061	batch_accuracy: 37.94%	lr:0.000820
Ep: 18/48	It: 601/8134	batch_loss: 3.2876	batch_accuracy: 38.65%	lr:0.000820
Ep: 18/48	It: 651/8134	batch_loss: 3.2047	batch_accuracy: 39.18%	lr:0.000819
Ep: 18/48	It: 701/8134	batch_loss: 3.3344	batch_accuracy: 38.16%	lr:0.000819
Ep: 18/48	It: 751/8134	batch_loss: 3.2133	batch_accuracy: 39.09%	lr:0.000819
Ep: 18/48	It: 801/8134	batch_loss: 3.2828	batch_accuracy: 37.55%	lr:0.000819
Ep: 18/48	It: 851/8134	batch_loss: 3.2633	batch_accuracy: 38.65%	lr:0.000819
Ep: 18/48	It: 901/8134	batch_loss: 3.3577	batch_accuracy: 37.52%	lr:0.000819
Ep: 18/48	It: 951/8134	batch_loss: 3.2861	batch_accuracy: 38.26%	lr:0.000818
Ep: 18/48	It: 1001/8134	batch_loss: 3.1802	batch_accuracy: 39.65%	lr:0.000818
Ep: 18/48	It: 1051/8134	batch_loss: 3.2446	batch_accuracy: 39.60%	lr:0.000818
Ep: 18/48	It: 1101/8134	batch_loss: 3.2829	batch_accuracy: 38.55%	lr:0.000818
Ep: 18/48	It: 1151/8134	batch_loss: 3.3136	batch_accuracy: 39.09%	lr:0.000818
Ep: 18/48	It: 1201/8134	batch_loss: 3.3354	batch_accuracy: 38.13%	lr:0.000818
Ep: 18/48	It: 1251/8134	batch_loss: 3.2253	batch_accuracy: 39.84%	lr:0.000817
Ep: 18/48	It: 1301/8134	batch_loss: 3.3637	batch_accuracy: 37.26%	lr:0.000817
Ep: 18/48	It: 1351/8134	batch_loss: 3.2254	batch_accuracy: 38.92%	lr:0.000817
Ep: 18/48	It: 1401/8134	batch_loss: 3.2879	batch_accuracy: 38.26%	lr:0.000817
Ep: 18/48	It: 1451/8134	batch_loss: 3.2254	batch_accuracy: 38.55%	lr:0.000817
Ep: 18/48	It: 1501/8134	batch_loss: 3.2600	batch_accuracy: 38.06%	lr:0.000816
Ep: 18/48	It: 1551/8134	batch_loss: 3.1800	batch_accuracy: 39.48%	lr:0.000816
Ep: 18/48	It: 1601/8134	batch_loss: 3.1410	batch_accuracy: 40.62%	lr:0.000816
Ep: 18/48	It: 1651/8134	batch_loss: 3.2401	batch_accuracy: 39.18%	lr:0.000816
Ep: 18/48	It: 1701/8134	batch_loss: 3.1573	batch_accuracy: 40.06%	lr:0.000816
Ep: 18/48	It: 1751/8134	batch_loss: 3.1606	batch_accuracy: 39.82%	lr:0.000816
Ep: 18/48	It: 1801/8134	batch_loss: 3.2334	batch_accuracy: 38.89%	lr:0.000815
Ep: 18/48	It: 1851/8134	batch_loss: 3.2961	batch_accuracy: 37.65%	lr:0.000815
Ep: 18/48	It: 1901/8134	batch_loss: 3.1336	batch_accuracy: 40.21%	lr:0.000815
Ep: 18/48	It: 1951/8134	batch_loss: 3.1576	batch_accuracy: 40.43%	lr:0.000815
Ep: 18/48	It: 2001/8134	batch_loss: 3.3626	batch_accuracy: 37.84%	lr:0.000815
Ep: 18/48	It: 2051/8134	batch_loss: 3.2473	batch_accuracy: 38.31%	lr:0.000815
Ep: 18/48	It: 2101/8134	batch_loss: 3.3086	batch_accuracy: 38.72%	lr:0.000814
Ep: 18/48	It: 2151/8134	batch_loss: 3.1857	batch_accuracy: 39.97%	lr:0.000814
Ep: 18/48	It: 2201/8134	batch_loss: 3.1593	batch_accuracy: 39.45%	lr:0.000814
Ep: 18/48	It: 2251/8134	batch_loss: 3.3354	batch_accuracy: 37.11%	lr:0.000814
Ep: 18/48	It: 2301/8134	batch_loss: 3.2003	batch_accuracy: 39.89%	lr:0.000814
Ep: 18/48	It: 2351/8134	batch_loss: 3.1363	batch_accuracy: 41.67%	lr:0.000814
Ep: 18/48	It: 2401/8134	batch_loss: 3.3257	batch_accuracy: 37.65%	lr:0.000813
Ep: 18/48	It: 2451/8134	batch_loss: 3.2460	batch_accuracy: 39.45%	lr:0.000813
Ep: 18/48	It: 2501/8134	batch_loss: 3.2544	batch_accuracy: 38.99%	lr:0.000813
Ep: 18/48	It: 2551/8134	batch_loss: 3.0899	batch_accuracy: 40.36%	lr:0.000813
Ep: 18/48	It: 2601/8134	batch_loss: 3.2433	batch_accuracy: 39.40%	lr:0.000813
Ep: 18/48	It: 2651/8134	batch_loss: 3.2093	batch_accuracy: 39.38%	lr:0.000812
Ep: 18/48	It: 2701/8134	batch_loss: 3.2661	batch_accuracy: 37.96%	lr:0.000812
Ep: 18/48	It: 2751/8134	batch_loss: 3.2554	batch_accuracy: 39.89%	lr:0.000812
Ep: 18/48	It: 2801/8134	batch_loss: 3.3086	batch_accuracy: 37.45%	lr:0.000812
Ep: 18/48	It: 2851/8134	batch_loss: 3.1340	batch_accuracy: 40.60%	lr:0.000812
Ep: 18/48	It: 2901/8134	batch_loss: 3.2707	batch_accuracy: 39.21%	lr:0.000812
Ep: 18/48	It: 2951/8134	batch_loss: 3.2378	batch_accuracy: 39.26%	lr:0.000811
Ep: 18/48	It: 3001/8134	batch_loss: 3.2248	batch_accuracy: 39.87%	lr:0.000811
Ep: 18/48	It: 3051/8134	batch_loss: 3.3521	batch_accuracy: 38.33%	lr:0.000811
Ep: 18/48	It: 3101/8134	batch_loss: 3.2642	batch_accuracy: 38.75%	lr:0.000811
Ep: 18/48	It: 3151/8134	batch_loss: 3.2868	batch_accuracy: 37.84%	lr:0.000811
Ep: 18/48	It: 3201/8134	batch_loss: 3.2997	batch_accuracy: 39.75%	lr:0.000811
Ep: 18/48	It: 3251/8134	batch_loss: 3.3807	batch_accuracy: 38.62%	lr:0.000810
Ep: 18/48	It: 3301/8134	batch_loss: 3.1787	batch_accuracy: 39.38%	lr:0.000810
Ep: 18/48	It: 3351/8134	batch_loss: 3.3129	batch_accuracy: 37.84%	lr:0.000810
Ep: 18/48	It: 3401/8134	batch_loss: 3.2716	batch_accuracy: 39.16%	lr:0.000810
Ep: 18/48	It: 3451/8134	batch_loss: 3.2977	batch_accuracy: 37.96%	lr:0.000810
Ep: 18/48	It: 3501/8134	batch_loss: 3.1320	batch_accuracy: 40.09%	lr:0.000810
Ep: 18/48	It: 3551/8134	batch_loss: 3.2215	batch_accuracy: 39.09%	lr:0.000809
Ep: 18/48	It: 3601/8134	batch_loss: 3.3236	batch_accuracy: 38.26%	lr:0.000809
Ep: 18/48	It: 3651/8134	batch_loss: 3.2130	batch_accuracy: 39.53%	lr:0.000809
Ep: 18/48	It: 3701/8134	batch_loss: 3.2515	batch_accuracy: 39.28%	lr:0.000809
Ep: 18/48	It: 3751/8134	batch_loss: 3.2495	batch_accuracy: 39.89%	lr:0.000809
Ep: 18/48	It: 3801/8134	batch_loss: 3.2308	batch_accuracy: 39.04%	lr:0.000808
Ep: 18/48	It: 3851/8134	batch_loss: 3.3155	batch_accuracy: 38.16%	lr:0.000808
Ep: 18/48	It: 3901/8134	batch_loss: 3.0693	batch_accuracy: 41.87%	lr:0.000808
Ep: 18/48	It: 3951/8134	batch_loss: 3.4404	batch_accuracy: 36.79%	lr:0.000808
Ep: 18/48	It: 4001/8134	batch_loss: 3.1319	batch_accuracy: 40.72%	lr:0.000808
Ep: 18/48	It: 4051/8134	batch_loss: 3.2339	batch_accuracy: 38.45%	lr:0.000808
Ep: 18/48	It: 4101/8134	batch_loss: 3.3167	batch_accuracy: 37.52%	lr:0.000807
Ep: 18/48	It: 4151/8134	batch_loss: 3.2476	batch_accuracy: 38.55%	lr:0.000807
Ep: 18/48	It: 4201/8134	batch_loss: 3.1888	batch_accuracy: 39.55%	lr:0.000807
Ep: 18/48	It: 4251/8134	batch_loss: 3.0926	batch_accuracy: 41.50%	lr:0.000807
Ep: 18/48	It: 4301/8134	batch_loss: 3.1422	batch_accuracy: 40.09%	lr:0.000807
Ep: 18/48	It: 4351/8134	batch_loss: 3.2310	batch_accuracy: 38.77%	lr:0.000807
Ep: 18/48	It: 4401/8134	batch_loss: 3.2696	batch_accuracy: 39.45%	lr:0.000806
Ep: 18/48	It: 4451/8134	batch_loss: 3.1683	batch_accuracy: 39.89%	lr:0.000806
Ep: 18/48	It: 4501/8134	batch_loss: 3.2399	batch_accuracy: 38.96%	lr:0.000806
Ep: 18/48	It: 4551/8134	batch_loss: 3.2866	batch_accuracy: 37.84%	lr:0.000806
Ep: 18/48	It: 4601/8134	batch_loss: 3.3002	batch_accuracy: 39.40%	lr:0.000806
Ep: 18/48	It: 4651/8134	batch_loss: 3.2243	batch_accuracy: 40.23%	lr:0.000805
Ep: 18/48	It: 4701/8134	batch_loss: 3.4053	batch_accuracy: 36.96%	lr:0.000805
Ep: 18/48	It: 4751/8134	batch_loss: 3.1727	batch_accuracy: 40.65%	lr:0.000805
Ep: 18/48	It: 4801/8134	batch_loss: 3.1901	batch_accuracy: 39.60%	lr:0.000805
Ep: 18/48	It: 4851/8134	batch_loss: 3.2222	batch_accuracy: 39.62%	lr:0.000805
Ep: 18/48	It: 4901/8134	batch_loss: 3.3294	batch_accuracy: 37.87%	lr:0.000805
Ep: 18/48	It: 4951/8134	batch_loss: 3.2048	batch_accuracy: 40.36%	lr:0.000804
Ep: 18/48	It: 5001/8134	batch_loss: 3.2901	batch_accuracy: 38.43%	lr:0.000804
Ep: 18/48	It: 5051/8134	batch_loss: 3.1502	batch_accuracy: 41.16%	lr:0.000804
Ep: 18/48	It: 5101/8134	batch_loss: 3.2203	batch_accuracy: 38.96%	lr:0.000804
Ep: 18/48	It: 5151/8134	batch_loss: 3.1877	batch_accuracy: 40.84%	lr:0.000804
Ep: 18/48	It: 5201/8134	batch_loss: 3.3444	batch_accuracy: 37.11%	lr:0.000804
Ep: 18/48	It: 5251/8134	batch_loss: 3.2577	batch_accuracy: 38.04%	lr:0.000803
Ep: 18/48	It: 5301/8134	batch_loss: 3.1837	batch_accuracy: 38.99%	lr:0.000803
Ep: 18/48	It: 5351/8134	batch_loss: 3.2181	batch_accuracy: 39.28%	lr:0.000803
Ep: 18/48	It: 5401/8134	batch_loss: 3.2775	batch_accuracy: 37.99%	lr:0.000803
Ep: 18/48	It: 5451/8134	batch_loss: 3.1790	batch_accuracy: 39.06%	lr:0.000803
Ep: 18/48	It: 5501/8134	batch_loss: 3.2044	batch_accuracy: 39.23%	lr:0.000802
Ep: 18/48	It: 5551/8134	batch_loss: 3.3267	batch_accuracy: 38.38%	lr:0.000802
Ep: 18/48	It: 5601/8134	batch_loss: 3.2841	batch_accuracy: 38.87%	lr:0.000802
Ep: 18/48	It: 5651/8134	batch_loss: 3.2656	batch_accuracy: 39.38%	lr:0.000802
Ep: 18/48	It: 5701/8134	batch_loss: 3.3170	batch_accuracy: 38.70%	lr:0.000802
Ep: 18/48	It: 5751/8134	batch_loss: 3.1911	batch_accuracy: 39.60%	lr:0.000802
Ep: 18/48	It: 5801/8134	batch_loss: 3.1847	batch_accuracy: 40.09%	lr:0.000801
Ep: 18/48	It: 5851/8134	batch_loss: 3.3513	batch_accuracy: 37.40%	lr:0.000801
Ep: 18/48	It: 5901/8134	batch_loss: 3.3899	batch_accuracy: 37.06%	lr:0.000801
Ep: 18/48	It: 5951/8134	batch_loss: 3.1502	batch_accuracy: 40.89%	lr:0.000801
Ep: 18/48	It: 6001/8134	batch_loss: 3.2254	batch_accuracy: 39.31%	lr:0.000801
Ep: 18/48	It: 6051/8134	batch_loss: 3.3601	batch_accuracy: 37.50%	lr:0.000801
Ep: 18/48	It: 6101/8134	batch_loss: 3.2597	batch_accuracy: 38.60%	lr:0.000800
Ep: 18/48	It: 6151/8134	batch_loss: 3.3365	batch_accuracy: 38.33%	lr:0.000800
Ep: 18/48	It: 6201/8134	batch_loss: 3.2455	batch_accuracy: 39.92%	lr:0.000800
Ep: 18/48	It: 6251/8134	batch_loss: 3.1887	batch_accuracy: 40.55%	lr:0.000800
Ep: 18/48	It: 6301/8134	batch_loss: 3.3389	batch_accuracy: 38.50%	lr:0.000800
Ep: 18/48	It: 6351/8134	batch_loss: 3.3088	batch_accuracy: 38.40%	lr:0.000799
Ep: 18/48	It: 6401/8134	batch_loss: 3.2747	batch_accuracy: 40.06%	lr:0.000799
Ep: 18/48	It: 6451/8134	batch_loss: 3.1454	batch_accuracy: 40.33%	lr:0.000799
Ep: 18/48	It: 6501/8134	batch_loss: 3.3183	batch_accuracy: 37.79%	lr:0.000799
Ep: 18/48	It: 6551/8134	batch_loss: 3.3729	batch_accuracy: 38.04%	lr:0.000799
Ep: 18/48	It: 6601/8134	batch_loss: 3.2613	batch_accuracy: 38.99%	lr:0.000799
Ep: 18/48	It: 6651/8134	batch_loss: 3.2198	batch_accuracy: 39.62%	lr:0.000798
Ep: 18/48	It: 6701/8134	batch_loss: 3.1436	batch_accuracy: 39.99%	lr:0.000798
Ep: 18/48	It: 6751/8134	batch_loss: 3.3611	batch_accuracy: 37.65%	lr:0.000798
Ep: 18/48	It: 6801/8134	batch_loss: 3.1249	batch_accuracy: 40.19%	lr:0.000798
Ep: 18/48	It: 6851/8134	batch_loss: 3.2616	batch_accuracy: 39.21%	lr:0.000798
Ep: 18/48	It: 6901/8134	batch_loss: 3.3701	batch_accuracy: 37.99%	lr:0.000797
Ep: 18/48	It: 6951/8134	batch_loss: 3.1824	batch_accuracy: 40.48%	lr:0.000797
Ep: 18/48	It: 7001/8134	batch_loss: 3.3293	batch_accuracy: 38.04%	lr:0.000797
Ep: 18/48	It: 7051/8134	batch_loss: 3.1160	batch_accuracy: 40.75%	lr:0.000797
Ep: 18/48	It: 7101/8134	batch_loss: 3.1922	batch_accuracy: 39.70%	lr:0.000797
Ep: 18/48	It: 7151/8134	batch_loss: 3.2143	batch_accuracy: 39.84%	lr:0.000797
Ep: 18/48	It: 7201/8134	batch_loss: 3.3319	batch_accuracy: 37.52%	lr:0.000796
Ep: 18/48	It: 7251/8134	batch_loss: 3.3596	batch_accuracy: 37.70%	lr:0.000796
Ep: 18/48	It: 7301/8134	batch_loss: 3.2800	batch_accuracy: 37.94%	lr:0.000796
Ep: 18/48	It: 7351/8134	batch_loss: 3.3366	batch_accuracy: 38.62%	lr:0.000796
Ep: 18/48	It: 7401/8134	batch_loss: 3.2892	batch_accuracy: 38.82%	lr:0.000796
Ep: 18/48	It: 7451/8134	batch_loss: 3.3085	batch_accuracy: 37.84%	lr:0.000795
Ep: 18/48	It: 7501/8134	batch_loss: 3.1594	batch_accuracy: 40.11%	lr:0.000795
Ep: 18/48	It: 7551/8134	batch_loss: 3.2535	batch_accuracy: 38.92%	lr:0.000795
Ep: 18/48	It: 7601/8134	batch_loss: 3.2668	batch_accuracy: 39.40%	lr:0.000795
Ep: 18/48	It: 7651/8134	batch_loss: 3.1835	batch_accuracy: 39.84%	lr:0.000795
Ep: 18/48	It: 7701/8134	batch_loss: 3.2061	batch_accuracy: 39.94%	lr:0.000795
Ep: 18/48	It: 7751/8134	batch_loss: 3.2415	batch_accuracy: 39.82%	lr:0.000794
Ep: 18/48	It: 7801/8134	batch_loss: 3.2665	batch_accuracy: 38.26%	lr:0.000794
Ep: 18/48	It: 7851/8134	batch_loss: 3.3523	batch_accuracy: 38.28%	lr:0.000794
Ep: 18/48	It: 7901/8134	batch_loss: 3.3431	batch_accuracy: 37.94%	lr:0.000794
Ep: 18/48	It: 7951/8134	batch_loss: 3.3327	batch_accuracy: 37.89%	lr:0.000794
Ep: 18/48	It: 8001/8134	batch_loss: 3.2336	batch_accuracy: 39.65%	lr:0.000794
Ep: 18/48	It: 8051/8134	batch_loss: 3.1790	batch_accuracy: 39.94%	lr:0.000793
Ep: 18/48	It: 8101/8134	batch_loss: 3.3463	batch_accuracy: 37.08%	lr:0.000793
Ep: 18/48	It: 8134/8134	batch_loss: 3.3479	batch_accuracy: 38.11%	lr:0.000793


Generated text for input text "You" is:
You’s Renal Retrieval” and its associated features of theatre in theoristic.
The author describes a new “bie” in theology of theology, including theology, history and theological and political, and other aspects of art, theology and religion, and the history of the Makings of Museums in Christian Ethics. He emphasizes the significance of the Museums of Christian Ethics in the period 1959-1959, and is also the first of its kind in the early twentieth century. The book is an important book that has been published in the last two years. The book is well-documented, but is not a book in which it has been published. He is a member of a member of the American Society of Heart Association, who held in 1994 and held in April 2004. His work is a member of the American Society of Heart Association of Heart Association at the Heart Association of Heart Association (HAPE) guidelines. Heart failure has


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 19/48	It: 1/8134	batch_loss: 3.2697	batch_accuracy: 38.50%	lr:0.000793
Ep: 19/48	It: 51/8134	batch_loss: 3.1899	batch_accuracy: 39.11%	lr:0.000793
Ep: 19/48	It: 101/8134	batch_loss: 3.1763	batch_accuracy: 40.33%	lr:0.000793
Ep: 19/48	It: 151/8134	batch_loss: 3.2098	batch_accuracy: 38.55%	lr:0.000792
Ep: 19/48	It: 201/8134	batch_loss: 3.2521	batch_accuracy: 38.65%	lr:0.000792
Ep: 19/48	It: 251/8134	batch_loss: 3.1730	batch_accuracy: 40.33%	lr:0.000792
Ep: 19/48	It: 301/8134	batch_loss: 3.2009	batch_accuracy: 39.87%	lr:0.000792
Ep: 19/48	It: 351/8134	batch_loss: 3.1871	batch_accuracy: 39.77%	lr:0.000792
Ep: 19/48	It: 401/8134	batch_loss: 3.2096	batch_accuracy: 39.40%	lr:0.000792
Ep: 19/48	It: 451/8134	batch_loss: 3.2745	batch_accuracy: 38.75%	lr:0.000791
Ep: 19/48	It: 501/8134	batch_loss: 3.1939	batch_accuracy: 39.70%	lr:0.000791
Ep: 19/48	It: 551/8134	batch_loss: 3.2640	batch_accuracy: 37.45%	lr:0.000791
Ep: 19/48	It: 601/8134	batch_loss: 3.1320	batch_accuracy: 40.84%	lr:0.000791
Ep: 19/48	It: 651/8134	batch_loss: 3.2190	batch_accuracy: 40.21%	lr:0.000791
Ep: 19/48	It: 701/8134	batch_loss: 3.2766	batch_accuracy: 37.99%	lr:0.000790
Ep: 19/48	It: 751/8134	batch_loss: 3.1717	batch_accuracy: 40.72%	lr:0.000790
Ep: 19/48	It: 801/8134	batch_loss: 3.1537	batch_accuracy: 40.82%	lr:0.000790
Ep: 19/48	It: 851/8134	batch_loss: 3.1846	batch_accuracy: 39.31%	lr:0.000790
Ep: 19/48	It: 901/8134	batch_loss: 3.2200	batch_accuracy: 39.33%	lr:0.000790
Ep: 19/48	It: 951/8134	batch_loss: 3.2152	batch_accuracy: 38.99%	lr:0.000790
Ep: 19/48	It: 1001/8134	batch_loss: 3.3514	batch_accuracy: 36.35%	lr:0.000789
Ep: 19/48	It: 1051/8134	batch_loss: 3.2312	batch_accuracy: 39.50%	lr:0.000789
Ep: 19/48	It: 1101/8134	batch_loss: 3.3070	batch_accuracy: 38.33%	lr:0.000789
Ep: 19/48	It: 1151/8134	batch_loss: 3.3086	batch_accuracy: 38.28%	lr:0.000789
Ep: 19/48	It: 1201/8134	batch_loss: 3.3418	batch_accuracy: 38.06%	lr:0.000789
Ep: 19/48	It: 1251/8134	batch_loss: 3.1718	batch_accuracy: 39.45%	lr:0.000788
Ep: 19/48	It: 1301/8134	batch_loss: 3.2312	batch_accuracy: 38.55%	lr:0.000788
Ep: 19/48	It: 1351/8134	batch_loss: 3.2483	batch_accuracy: 39.75%	lr:0.000788
Ep: 19/48	It: 1401/8134	batch_loss: 3.2993	batch_accuracy: 36.79%	lr:0.000788
Ep: 19/48	It: 1451/8134	batch_loss: 3.2095	batch_accuracy: 39.01%	lr:0.000788
Ep: 19/48	It: 1501/8134	batch_loss: 3.2882	batch_accuracy: 38.89%	lr:0.000788
Ep: 19/48	It: 1551/8134	batch_loss: 3.2439	batch_accuracy: 39.26%	lr:0.000787
Ep: 19/48	It: 1601/8134	batch_loss: 3.1921	batch_accuracy: 39.33%	lr:0.000787
Ep: 19/48	It: 1651/8134	batch_loss: 3.2141	batch_accuracy: 39.70%	lr:0.000787
Ep: 19/48	It: 1701/8134	batch_loss: 3.2177	batch_accuracy: 39.50%	lr:0.000787
Ep: 19/48	It: 1751/8134	batch_loss: 3.2100	batch_accuracy: 40.31%	lr:0.000787
Ep: 19/48	It: 1801/8134	batch_loss: 3.1100	batch_accuracy: 40.99%	lr:0.000786
Ep: 19/48	It: 1851/8134	batch_loss: 3.3016	batch_accuracy: 37.99%	lr:0.000786
Ep: 19/48	It: 1901/8134	batch_loss: 3.1979	batch_accuracy: 39.94%	lr:0.000786
Ep: 19/48	It: 1951/8134	batch_loss: 3.2701	batch_accuracy: 38.67%	lr:0.000786
Ep: 19/48	It: 2001/8134	batch_loss: 3.3008	batch_accuracy: 37.87%	lr:0.000786
Ep: 19/48	It: 2051/8134	batch_loss: 3.2981	batch_accuracy: 37.62%	lr:0.000786
Ep: 19/48	It: 2101/8134	batch_loss: 3.2798	batch_accuracy: 38.96%	lr:0.000785
Ep: 19/48	It: 2151/8134	batch_loss: 3.3102	batch_accuracy: 38.04%	lr:0.000785
Ep: 19/48	It: 2201/8134	batch_loss: 3.2474	batch_accuracy: 39.36%	lr:0.000785
Ep: 19/48	It: 2251/8134	batch_loss: 3.1767	batch_accuracy: 38.67%	lr:0.000785
Ep: 19/48	It: 2301/8134	batch_loss: 3.3265	batch_accuracy: 38.13%	lr:0.000785
Ep: 19/48	It: 2351/8134	batch_loss: 3.2208	batch_accuracy: 39.50%	lr:0.000784
Ep: 19/48	It: 2401/8134	batch_loss: 3.3414	batch_accuracy: 38.72%	lr:0.000784
Ep: 19/48	It: 2451/8134	batch_loss: 3.2583	batch_accuracy: 39.28%	lr:0.000784
Ep: 19/48	It: 2501/8134	batch_loss: 3.0533	batch_accuracy: 41.99%	lr:0.000784
Ep: 19/48	It: 2551/8134	batch_loss: 3.3299	batch_accuracy: 37.70%	lr:0.000784
Ep: 19/48	It: 2601/8134	batch_loss: 3.3089	batch_accuracy: 37.87%	lr:0.000784
Ep: 19/48	It: 2651/8134	batch_loss: 3.0742	batch_accuracy: 41.67%	lr:0.000783
Ep: 19/48	It: 2701/8134	batch_loss: 3.3423	batch_accuracy: 36.84%	lr:0.000783
Ep: 19/48	It: 2751/8134	batch_loss: 3.2705	batch_accuracy: 38.92%	lr:0.000783
Ep: 19/48	It: 2801/8134	batch_loss: 3.3905	batch_accuracy: 36.45%	lr:0.000783
Ep: 19/48	It: 2851/8134	batch_loss: 3.2107	batch_accuracy: 39.55%	lr:0.000783
Ep: 19/48	It: 2901/8134	batch_loss: 3.0794	batch_accuracy: 41.04%	lr:0.000782
Ep: 19/48	It: 2951/8134	batch_loss: 3.2826	batch_accuracy: 37.50%	lr:0.000782
Ep: 19/48	It: 3001/8134	batch_loss: 3.1906	batch_accuracy: 40.04%	lr:0.000782
Ep: 19/48	It: 3051/8134	batch_loss: 3.2805	batch_accuracy: 38.60%	lr:0.000782
Ep: 19/48	It: 3101/8134	batch_loss: 3.2920	batch_accuracy: 38.70%	lr:0.000782
Ep: 19/48	It: 3151/8134	batch_loss: 3.2584	batch_accuracy: 38.38%	lr:0.000782
Ep: 19/48	It: 3201/8134	batch_loss: 3.2970	batch_accuracy: 38.21%	lr:0.000781
Ep: 19/48	It: 3251/8134	batch_loss: 3.2803	batch_accuracy: 39.28%	lr:0.000781
Ep: 19/48	It: 3301/8134	batch_loss: 3.1795	batch_accuracy: 40.75%	lr:0.000781
Ep: 19/48	It: 3351/8134	batch_loss: 3.1024	batch_accuracy: 41.70%	lr:0.000781
Ep: 19/48	It: 3401/8134	batch_loss: 3.3469	batch_accuracy: 38.48%	lr:0.000781
Ep: 19/48	It: 3451/8134	batch_loss: 3.2664	batch_accuracy: 39.06%	lr:0.000780
Ep: 19/48	It: 3501/8134	batch_loss: 3.2107	batch_accuracy: 38.26%	lr:0.000780
Ep: 19/48	It: 3551/8134	batch_loss: 3.2916	batch_accuracy: 38.33%	lr:0.000780
Ep: 19/48	It: 3601/8134	batch_loss: 3.2939	batch_accuracy: 37.94%	lr:0.000780
Ep: 19/48	It: 3651/8134	batch_loss: 3.2782	batch_accuracy: 37.94%	lr:0.000780
Ep: 19/48	It: 3701/8134	batch_loss: 3.1885	batch_accuracy: 40.58%	lr:0.000779
Ep: 19/48	It: 3751/8134	batch_loss: 3.2611	batch_accuracy: 39.53%	lr:0.000779
Ep: 19/48	It: 3801/8134	batch_loss: 3.2448	batch_accuracy: 38.94%	lr:0.000779
Ep: 19/48	It: 3851/8134	batch_loss: 3.3380	batch_accuracy: 37.89%	lr:0.000779
Ep: 19/48	It: 3901/8134	batch_loss: 3.2413	batch_accuracy: 38.38%	lr:0.000779
Ep: 19/48	It: 3951/8134	batch_loss: 3.2282	batch_accuracy: 39.58%	lr:0.000779
Ep: 19/48	It: 4001/8134	batch_loss: 3.2003	batch_accuracy: 38.99%	lr:0.000778
Ep: 19/48	It: 4051/8134	batch_loss: 3.3186	batch_accuracy: 38.04%	lr:0.000778
Ep: 19/48	It: 4101/8134	batch_loss: 3.3547	batch_accuracy: 36.79%	lr:0.000778
Ep: 19/48	It: 4151/8134	batch_loss: 3.2513	batch_accuracy: 39.04%	lr:0.000778
Ep: 19/48	It: 4201/8134	batch_loss: 3.2341	batch_accuracy: 39.55%	lr:0.000778
Ep: 19/48	It: 4251/8134	batch_loss: 3.3674	batch_accuracy: 37.33%	lr:0.000777
Ep: 19/48	It: 4301/8134	batch_loss: 3.2631	batch_accuracy: 38.06%	lr:0.000777
Ep: 19/48	It: 4351/8134	batch_loss: 3.3004	batch_accuracy: 38.89%	lr:0.000777
Ep: 19/48	It: 4401/8134	batch_loss: 3.2055	batch_accuracy: 39.79%	lr:0.000777
Ep: 19/48	It: 4451/8134	batch_loss: 3.2024	batch_accuracy: 40.53%	lr:0.000777
Ep: 19/48	It: 4501/8134	batch_loss: 3.2846	batch_accuracy: 38.62%	lr:0.000777
Ep: 19/48	It: 4551/8134	batch_loss: 3.1120	batch_accuracy: 40.23%	lr:0.000776
Ep: 19/48	It: 4601/8134	batch_loss: 3.2900	batch_accuracy: 37.50%	lr:0.000776
Ep: 19/48	It: 4651/8134	batch_loss: 3.2780	batch_accuracy: 37.99%	lr:0.000776
Ep: 19/48	It: 4701/8134	batch_loss: 3.3100	batch_accuracy: 38.21%	lr:0.000776
Ep: 19/48	It: 4751/8134	batch_loss: 3.1395	batch_accuracy: 39.92%	lr:0.000776
Ep: 19/48	It: 4801/8134	batch_loss: 3.1483	batch_accuracy: 40.23%	lr:0.000775
Ep: 19/48	It: 4851/8134	batch_loss: 3.1918	batch_accuracy: 39.04%	lr:0.000775
Ep: 19/48	It: 4901/8134	batch_loss: 3.1085	batch_accuracy: 40.80%	lr:0.000775
Ep: 19/48	It: 4951/8134	batch_loss: 3.2259	batch_accuracy: 39.09%	lr:0.000775
Ep: 19/48	It: 5001/8134	batch_loss: 3.1541	batch_accuracy: 40.82%	lr:0.000775
Ep: 19/48	It: 5051/8134	batch_loss: 3.2530	batch_accuracy: 38.89%	lr:0.000774
Ep: 19/48	It: 5101/8134	batch_loss: 3.2843	batch_accuracy: 38.13%	lr:0.000774
Ep: 19/48	It: 5151/8134	batch_loss: 3.2985	batch_accuracy: 38.77%	lr:0.000774
Ep: 19/48	It: 5201/8134	batch_loss: 3.2467	batch_accuracy: 38.55%	lr:0.000774
Ep: 19/48	It: 5251/8134	batch_loss: 3.2606	batch_accuracy: 38.77%	lr:0.000774
Ep: 19/48	It: 5301/8134	batch_loss: 3.2995	batch_accuracy: 38.23%	lr:0.000774
Ep: 19/48	It: 5351/8134	batch_loss: 3.1859	batch_accuracy: 39.70%	lr:0.000773
Ep: 19/48	It: 5401/8134	batch_loss: 3.3551	batch_accuracy: 38.21%	lr:0.000773
Ep: 19/48	It: 5451/8134	batch_loss: 3.3699	batch_accuracy: 37.13%	lr:0.000773
Ep: 19/48	It: 5501/8134	batch_loss: 3.1856	batch_accuracy: 39.84%	lr:0.000773
Ep: 19/48	It: 5551/8134	batch_loss: 3.1380	batch_accuracy: 40.94%	lr:0.000773
Ep: 19/48	It: 5601/8134	batch_loss: 3.2024	batch_accuracy: 39.31%	lr:0.000772
Ep: 19/48	It: 5651/8134	batch_loss: 3.2055	batch_accuracy: 40.23%	lr:0.000772
Ep: 19/48	It: 5701/8134	batch_loss: 3.3050	batch_accuracy: 38.21%	lr:0.000772
Ep: 19/48	It: 5751/8134	batch_loss: 3.3397	batch_accuracy: 38.79%	lr:0.000772
Ep: 19/48	It: 5801/8134	batch_loss: 3.2677	batch_accuracy: 39.33%	lr:0.000772
Ep: 19/48	It: 5851/8134	batch_loss: 3.1692	batch_accuracy: 40.55%	lr:0.000771
Ep: 19/48	It: 5901/8134	batch_loss: 3.2623	batch_accuracy: 39.04%	lr:0.000771
Ep: 19/48	It: 5951/8134	batch_loss: 3.1339	batch_accuracy: 40.06%	lr:0.000771
Ep: 19/48	It: 6001/8134	batch_loss: 3.1920	batch_accuracy: 40.33%	lr:0.000771
Ep: 19/48	It: 6051/8134	batch_loss: 3.2698	batch_accuracy: 37.67%	lr:0.000771
Ep: 19/48	It: 6101/8134	batch_loss: 3.2501	batch_accuracy: 38.60%	lr:0.000771
Ep: 19/48	It: 6151/8134	batch_loss: 3.1436	batch_accuracy: 40.43%	lr:0.000770
Ep: 19/48	It: 6201/8134	batch_loss: 3.2875	batch_accuracy: 39.09%	lr:0.000770
Ep: 19/48	It: 6251/8134	batch_loss: 3.3279	batch_accuracy: 37.96%	lr:0.000770
Ep: 19/48	It: 6301/8134	batch_loss: 3.2601	batch_accuracy: 38.79%	lr:0.000770
Ep: 19/48	It: 6351/8134	batch_loss: 3.2270	batch_accuracy: 40.14%	lr:0.000770
Ep: 19/48	It: 6401/8134	batch_loss: 3.2749	batch_accuracy: 37.67%	lr:0.000769
Ep: 19/48	It: 6451/8134	batch_loss: 3.1453	batch_accuracy: 40.60%	lr:0.000769
Ep: 19/48	It: 6501/8134	batch_loss: 3.1592	batch_accuracy: 39.45%	lr:0.000769
Ep: 19/48	It: 6551/8134	batch_loss: 3.2209	batch_accuracy: 39.60%	lr:0.000769
Ep: 19/48	It: 6601/8134	batch_loss: 3.2890	batch_accuracy: 37.65%	lr:0.000769
Ep: 19/48	It: 6651/8134	batch_loss: 3.2048	batch_accuracy: 39.72%	lr:0.000768
Ep: 19/48	It: 6701/8134	batch_loss: 3.1682	batch_accuracy: 40.43%	lr:0.000768
Ep: 19/48	It: 6751/8134	batch_loss: 3.1587	batch_accuracy: 40.55%	lr:0.000768
Ep: 19/48	It: 6801/8134	batch_loss: 3.2652	batch_accuracy: 39.16%	lr:0.000768
Ep: 19/48	It: 6851/8134	batch_loss: 3.1749	batch_accuracy: 39.16%	lr:0.000768
Ep: 19/48	It: 6901/8134	batch_loss: 3.3013	batch_accuracy: 35.82%	lr:0.000768
Ep: 19/48	It: 6951/8134	batch_loss: 3.2761	batch_accuracy: 39.01%	lr:0.000767
Ep: 19/48	It: 7001/8134	batch_loss: 3.1979	batch_accuracy: 39.04%	lr:0.000767
Ep: 19/48	It: 7051/8134	batch_loss: 3.2911	batch_accuracy: 38.57%	lr:0.000767
Ep: 19/48	It: 7101/8134	batch_loss: 3.0866	batch_accuracy: 41.26%	lr:0.000767
Ep: 19/48	It: 7151/8134	batch_loss: 3.2344	batch_accuracy: 39.11%	lr:0.000767
Ep: 19/48	It: 7201/8134	batch_loss: 3.2332	batch_accuracy: 39.31%	lr:0.000766
Ep: 19/48	It: 7251/8134	batch_loss: 3.1902	batch_accuracy: 39.77%	lr:0.000766
Ep: 19/48	It: 7301/8134	batch_loss: 3.2080	batch_accuracy: 39.89%	lr:0.000766
Ep: 19/48	It: 7351/8134	batch_loss: 3.2512	batch_accuracy: 39.38%	lr:0.000766
Ep: 19/48	It: 7401/8134	batch_loss: 3.2778	batch_accuracy: 38.01%	lr:0.000766
Ep: 19/48	It: 7451/8134	batch_loss: 3.3484	batch_accuracy: 37.89%	lr:0.000765
Ep: 19/48	It: 7501/8134	batch_loss: 3.3785	batch_accuracy: 36.43%	lr:0.000765
Ep: 19/48	It: 7551/8134	batch_loss: 3.2096	batch_accuracy: 39.40%	lr:0.000765
Ep: 19/48	It: 7601/8134	batch_loss: 3.2931	batch_accuracy: 37.99%	lr:0.000765
Ep: 19/48	It: 7651/8134	batch_loss: 3.1005	batch_accuracy: 40.82%	lr:0.000765
Ep: 19/48	It: 7701/8134	batch_loss: 3.1718	batch_accuracy: 40.65%	lr:0.000765
Ep: 19/48	It: 7751/8134	batch_loss: 3.3066	batch_accuracy: 37.26%	lr:0.000764
Ep: 19/48	It: 7801/8134	batch_loss: 3.3280	batch_accuracy: 37.26%	lr:0.000764
Ep: 19/48	It: 7851/8134	batch_loss: 3.1905	batch_accuracy: 39.26%	lr:0.000764
Ep: 19/48	It: 7901/8134	batch_loss: 3.2013	batch_accuracy: 39.18%	lr:0.000764
Ep: 19/48	It: 7951/8134	batch_loss: 3.2593	batch_accuracy: 38.50%	lr:0.000764
Ep: 19/48	It: 8001/8134	batch_loss: 3.2089	batch_accuracy: 40.14%	lr:0.000763
Ep: 19/48	It: 8051/8134	batch_loss: 3.1874	batch_accuracy: 39.53%	lr:0.000763
Ep: 19/48	It: 8101/8134	batch_loss: 3.2312	batch_accuracy: 39.53%	lr:0.000763
Ep: 19/48	It: 8134/8134	batch_loss: 3.1156	batch_accuracy: 41.13%	lr:0.000763


Generated text for input text "You" is:
Youf-l, ine, azle, orch, and bene�, are used as theories for their applications. The main contribution is to theories which are used to analyze and compare it with theories. The paper uses a new method to examine the problems of theorized by the authors. The study was conducted in the field of designing and designing a new class of controllers. The research is the design of the model of a hybrid intelligent control system of the system. The system is designed to be a flexible and robust system that can be easily used for control of a flexible system. This method of the control system is applied to the control system to improve the system stability. The paper presents a design of a system of control system and a control system of the system. The system is designed and built to realize the system and then a fuzzy controller is used to control the system with a fuzzy control system. The control system has a high power factor and its operation and it is the best way of the system. The system is based on the fuzzy controller and the control system. The control system is based on fuzzy control system and the control system is proposed. The system operates at a minimum level of the state


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 20/48	It: 1/8134	batch_loss: 3.2415	batch_accuracy: 38.96%	lr:0.000763
Ep: 20/48	It: 51/8134	batch_loss: 3.1873	batch_accuracy: 40.55%	lr:0.000763
Ep: 20/48	It: 101/8134	batch_loss: 3.1846	batch_accuracy: 39.77%	lr:0.000762
Ep: 20/48	It: 151/8134	batch_loss: 3.2654	batch_accuracy: 37.55%	lr:0.000762
Ep: 20/48	It: 201/8134	batch_loss: 3.2189	batch_accuracy: 39.04%	lr:0.000762
Ep: 20/48	It: 251/8134	batch_loss: 3.2377	batch_accuracy: 39.67%	lr:0.000762
Ep: 20/48	It: 301/8134	batch_loss: 3.2214	batch_accuracy: 39.40%	lr:0.000762
Ep: 20/48	It: 351/8134	batch_loss: 3.2190	batch_accuracy: 40.31%	lr:0.000762
Ep: 20/48	It: 401/8134	batch_loss: 3.3615	batch_accuracy: 37.79%	lr:0.000761
Ep: 20/48	It: 451/8134	batch_loss: 3.1996	batch_accuracy: 38.72%	lr:0.000761
Ep: 20/48	It: 501/8134	batch_loss: 3.3103	batch_accuracy: 38.50%	lr:0.000761
Ep: 20/48	It: 551/8134	batch_loss: 3.2499	batch_accuracy: 38.04%	lr:0.000761
Ep: 20/48	It: 601/8134	batch_loss: 3.3228	batch_accuracy: 38.43%	lr:0.000761
Ep: 20/48	It: 651/8134	batch_loss: 3.2589	batch_accuracy: 38.23%	lr:0.000760
Ep: 20/48	It: 701/8134	batch_loss: 3.2330	batch_accuracy: 39.26%	lr:0.000760
Ep: 20/48	It: 751/8134	batch_loss: 3.2398	batch_accuracy: 39.40%	lr:0.000760
Ep: 20/48	It: 801/8134	batch_loss: 3.3374	batch_accuracy: 38.23%	lr:0.000760
Ep: 20/48	It: 851/8134	batch_loss: 3.0872	batch_accuracy: 41.46%	lr:0.000760
Ep: 20/48	It: 901/8134	batch_loss: 3.1926	batch_accuracy: 38.79%	lr:0.000759
Ep: 20/48	It: 951/8134	batch_loss: 3.1541	batch_accuracy: 39.89%	lr:0.000759
Ep: 20/48	It: 1001/8134	batch_loss: 3.3022	batch_accuracy: 38.31%	lr:0.000759
Ep: 20/48	It: 1051/8134	batch_loss: 3.1599	batch_accuracy: 39.94%	lr:0.000759
Ep: 20/48	It: 1101/8134	batch_loss: 3.1813	batch_accuracy: 39.58%	lr:0.000759
Ep: 20/48	It: 1151/8134	batch_loss: 3.3352	batch_accuracy: 37.79%	lr:0.000758
Ep: 20/48	It: 1201/8134	batch_loss: 3.2364	batch_accuracy: 38.79%	lr:0.000758
Ep: 20/48	It: 1251/8134	batch_loss: 3.2617	batch_accuracy: 37.99%	lr:0.000758
Ep: 20/48	It: 1301/8134	batch_loss: 3.1879	batch_accuracy: 40.80%	lr:0.000758
Ep: 20/48	It: 1351/8134	batch_loss: 3.1307	batch_accuracy: 39.53%	lr:0.000758
Ep: 20/48	It: 1401/8134	batch_loss: 3.2419	batch_accuracy: 39.70%	lr:0.000758
Ep: 20/48	It: 1451/8134	batch_loss: 3.1329	batch_accuracy: 40.21%	lr:0.000757
Ep: 20/48	It: 1501/8134	batch_loss: 3.1456	batch_accuracy: 40.06%	lr:0.000757
Ep: 20/48	It: 1551/8134	batch_loss: 3.2540	batch_accuracy: 38.67%	lr:0.000757
Ep: 20/48	It: 1601/8134	batch_loss: 3.1767	batch_accuracy: 39.99%	lr:0.000757
Ep: 20/48	It: 1651/8134	batch_loss: 3.1890	batch_accuracy: 39.62%	lr:0.000757
Ep: 20/48	It: 1701/8134	batch_loss: 3.1490	batch_accuracy: 40.41%	lr:0.000756
Ep: 20/48	It: 1751/8134	batch_loss: 3.3197	batch_accuracy: 38.06%	lr:0.000756
Ep: 20/48	It: 1801/8134	batch_loss: 3.1364	batch_accuracy: 41.06%	lr:0.000756
Ep: 20/48	It: 1851/8134	batch_loss: 3.1478	batch_accuracy: 40.19%	lr:0.000756
Ep: 20/48	It: 1901/8134	batch_loss: 3.3497	batch_accuracy: 37.96%	lr:0.000756
Ep: 20/48	It: 1951/8134	batch_loss: 3.2339	batch_accuracy: 39.06%	lr:0.000755
Ep: 20/48	It: 2001/8134	batch_loss: 3.3144	batch_accuracy: 37.70%	lr:0.000755
Ep: 20/48	It: 2051/8134	batch_loss: 3.1338	batch_accuracy: 40.94%	lr:0.000755
Ep: 20/48	It: 2101/8134	batch_loss: 3.1024	batch_accuracy: 41.16%	lr:0.000755
Ep: 20/48	It: 2151/8134	batch_loss: 3.1362	batch_accuracy: 40.19%	lr:0.000755
Ep: 20/48	It: 2201/8134	batch_loss: 3.2454	batch_accuracy: 37.82%	lr:0.000754
Ep: 20/48	It: 2251/8134	batch_loss: 3.1339	batch_accuracy: 39.55%	lr:0.000754
Ep: 20/48	It: 2301/8134	batch_loss: 3.2097	batch_accuracy: 39.75%	lr:0.000754
Ep: 20/48	It: 2351/8134	batch_loss: 3.1566	batch_accuracy: 39.99%	lr:0.000754
Ep: 20/48	It: 2401/8134	batch_loss: 3.3063	batch_accuracy: 38.72%	lr:0.000754
Ep: 20/48	It: 2451/8134	batch_loss: 3.2259	batch_accuracy: 38.60%	lr:0.000754
Ep: 20/48	It: 2501/8134	batch_loss: 3.2388	batch_accuracy: 38.13%	lr:0.000753
Ep: 20/48	It: 2551/8134	batch_loss: 3.2291	batch_accuracy: 39.72%	lr:0.000753
Ep: 20/48	It: 2601/8134	batch_loss: 3.2373	batch_accuracy: 39.67%	lr:0.000753
Ep: 20/48	It: 2651/8134	batch_loss: 3.1684	batch_accuracy: 40.33%	lr:0.000753
Ep: 20/48	It: 2701/8134	batch_loss: 3.1967	batch_accuracy: 38.65%	lr:0.000753
Ep: 20/48	It: 2751/8134	batch_loss: 3.1561	batch_accuracy: 39.97%	lr:0.000752
Ep: 20/48	It: 2801/8134	batch_loss: 3.2245	batch_accuracy: 39.23%	lr:0.000752
Ep: 20/48	It: 2851/8134	batch_loss: 3.2805	batch_accuracy: 38.53%	lr:0.000752
Ep: 20/48	It: 2901/8134	batch_loss: 3.1523	batch_accuracy: 40.60%	lr:0.000752
Ep: 20/48	It: 2951/8134	batch_loss: 3.2156	batch_accuracy: 39.48%	lr:0.000752
Ep: 20/48	It: 3001/8134	batch_loss: 3.1496	batch_accuracy: 40.23%	lr:0.000751
Ep: 20/48	It: 3051/8134	batch_loss: 3.2174	batch_accuracy: 39.60%	lr:0.000751
Ep: 20/48	It: 3101/8134	batch_loss: 3.2458	batch_accuracy: 39.26%	lr:0.000751
Ep: 20/48	It: 3151/8134	batch_loss: 3.2701	batch_accuracy: 39.09%	lr:0.000751
Ep: 20/48	It: 3201/8134	batch_loss: 3.2396	batch_accuracy: 39.06%	lr:0.000751
Ep: 20/48	It: 3251/8134	batch_loss: 3.1351	batch_accuracy: 40.28%	lr:0.000750
Ep: 20/48	It: 3301/8134	batch_loss: 3.0853	batch_accuracy: 41.46%	lr:0.000750
Ep: 20/48	It: 3351/8134	batch_loss: 3.2849	batch_accuracy: 38.84%	lr:0.000750
Ep: 20/48	It: 3401/8134	batch_loss: 3.1879	batch_accuracy: 40.21%	lr:0.000750
Ep: 20/48	It: 3451/8134	batch_loss: 3.2278	batch_accuracy: 39.53%	lr:0.000750
Ep: 20/48	It: 3501/8134	batch_loss: 3.1551	batch_accuracy: 40.60%	lr:0.000749
Ep: 20/48	It: 3551/8134	batch_loss: 3.0913	batch_accuracy: 40.97%	lr:0.000749
Ep: 20/48	It: 3601/8134	batch_loss: 3.2871	batch_accuracy: 39.99%	lr:0.000749
Ep: 20/48	It: 3651/8134	batch_loss: 3.3523	batch_accuracy: 36.47%	lr:0.000749
Ep: 20/48	It: 3701/8134	batch_loss: 3.1180	batch_accuracy: 40.26%	lr:0.000749
Ep: 20/48	It: 3751/8134	batch_loss: 3.3085	batch_accuracy: 37.62%	lr:0.000748
Ep: 20/48	It: 3801/8134	batch_loss: 3.1541	batch_accuracy: 39.55%	lr:0.000748
Ep: 20/48	It: 3851/8134	batch_loss: 3.2046	batch_accuracy: 39.65%	lr:0.000748
Ep: 20/48	It: 3901/8134	batch_loss: 3.3170	batch_accuracy: 38.72%	lr:0.000748
Ep: 20/48	It: 3951/8134	batch_loss: 3.2115	batch_accuracy: 39.50%	lr:0.000748
Ep: 20/48	It: 4001/8134	batch_loss: 3.2203	batch_accuracy: 38.87%	lr:0.000748
Ep: 20/48	It: 4051/8134	batch_loss: 3.3145	batch_accuracy: 38.67%	lr:0.000747
Ep: 20/48	It: 4101/8134	batch_loss: 3.1858	batch_accuracy: 39.50%	lr:0.000747
Ep: 20/48	It: 4151/8134	batch_loss: 3.1940	batch_accuracy: 39.45%	lr:0.000747
Ep: 20/48	It: 4201/8134	batch_loss: 3.3076	batch_accuracy: 38.11%	lr:0.000747
Ep: 20/48	It: 4251/8134	batch_loss: 3.1885	batch_accuracy: 39.21%	lr:0.000747
Ep: 20/48	It: 4301/8134	batch_loss: 3.3187	batch_accuracy: 37.67%	lr:0.000746
Ep: 20/48	It: 4351/8134	batch_loss: 3.0082	batch_accuracy: 42.09%	lr:0.000746
Ep: 20/48	It: 4401/8134	batch_loss: 3.3409	batch_accuracy: 37.92%	lr:0.000746
Ep: 20/48	It: 4451/8134	batch_loss: 3.2683	batch_accuracy: 38.67%	lr:0.000746
Ep: 20/48	It: 4501/8134	batch_loss: 3.1984	batch_accuracy: 40.16%	lr:0.000746
Ep: 20/48	It: 4551/8134	batch_loss: 3.1459	batch_accuracy: 40.01%	lr:0.000745
Ep: 20/48	It: 4601/8134	batch_loss: 3.3301	batch_accuracy: 37.43%	lr:0.000745
Ep: 20/48	It: 4651/8134	batch_loss: 3.1350	batch_accuracy: 39.45%	lr:0.000745
Ep: 20/48	It: 4701/8134	batch_loss: 3.2604	batch_accuracy: 39.45%	lr:0.000745
Ep: 20/48	It: 4751/8134	batch_loss: 3.2211	batch_accuracy: 39.33%	lr:0.000745
Ep: 20/48	It: 4801/8134	batch_loss: 3.2782	batch_accuracy: 38.09%	lr:0.000744
Ep: 20/48	It: 4851/8134	batch_loss: 3.2542	batch_accuracy: 38.09%	lr:0.000744
Ep: 20/48	It: 4901/8134	batch_loss: 3.1761	batch_accuracy: 39.65%	lr:0.000744
Ep: 20/48	It: 4951/8134	batch_loss: 3.1131	batch_accuracy: 40.58%	lr:0.000744
Ep: 20/48	It: 5001/8134	batch_loss: 3.2601	batch_accuracy: 37.96%	lr:0.000744
Ep: 20/48	It: 5051/8134	batch_loss: 3.2345	batch_accuracy: 37.96%	lr:0.000743
Ep: 20/48	It: 5101/8134	batch_loss: 3.2447	batch_accuracy: 38.16%	lr:0.000743
Ep: 20/48	It: 5151/8134	batch_loss: 3.3101	batch_accuracy: 38.60%	lr:0.000743
Ep: 20/48	It: 5201/8134	batch_loss: 3.0568	batch_accuracy: 41.46%	lr:0.000743
Ep: 20/48	It: 5251/8134	batch_loss: 3.1846	batch_accuracy: 40.84%	lr:0.000743
Ep: 20/48	It: 5301/8134	batch_loss: 3.2489	batch_accuracy: 39.28%	lr:0.000742
Ep: 20/48	It: 5351/8134	batch_loss: 3.1253	batch_accuracy: 41.92%	lr:0.000742
Ep: 20/48	It: 5401/8134	batch_loss: 3.1500	batch_accuracy: 40.58%	lr:0.000742
Ep: 20/48	It: 5451/8134	batch_loss: 3.1009	batch_accuracy: 41.09%	lr:0.000742
Ep: 20/48	It: 5501/8134	batch_loss: 3.1065	batch_accuracy: 41.14%	lr:0.000742
Ep: 20/48	It: 5551/8134	batch_loss: 3.2504	batch_accuracy: 39.28%	lr:0.000741
Ep: 20/48	It: 5601/8134	batch_loss: 3.2721	batch_accuracy: 38.55%	lr:0.000741
Ep: 20/48	It: 5651/8134	batch_loss: 3.1945	batch_accuracy: 39.67%	lr:0.000741
Ep: 20/48	It: 5701/8134	batch_loss: 3.2757	batch_accuracy: 38.26%	lr:0.000741
Ep: 20/48	It: 5751/8134	batch_loss: 3.1756	batch_accuracy: 40.01%	lr:0.000741
Ep: 20/48	It: 5801/8134	batch_loss: 3.2597	batch_accuracy: 38.79%	lr:0.000741
Ep: 20/48	It: 5851/8134	batch_loss: 3.2562	batch_accuracy: 39.14%	lr:0.000740
Ep: 20/48	It: 5901/8134	batch_loss: 3.1809	batch_accuracy: 38.72%	lr:0.000740
Ep: 20/48	It: 5951/8134	batch_loss: 3.2277	batch_accuracy: 39.77%	lr:0.000740
Ep: 20/48	It: 6001/8134	batch_loss: 3.2804	batch_accuracy: 38.38%	lr:0.000740
Ep: 20/48	It: 6051/8134	batch_loss: 3.2155	batch_accuracy: 39.16%	lr:0.000740
Ep: 20/48	It: 6101/8134	batch_loss: 3.0682	batch_accuracy: 42.11%	lr:0.000739
Ep: 20/48	It: 6151/8134	batch_loss: 3.2000	batch_accuracy: 39.53%	lr:0.000739
Ep: 20/48	It: 6201/8134	batch_loss: 3.2379	batch_accuracy: 39.31%	lr:0.000739
Ep: 20/48	It: 6251/8134	batch_loss: 3.1001	batch_accuracy: 41.06%	lr:0.000739
Ep: 20/48	It: 6301/8134	batch_loss: 3.1242	batch_accuracy: 41.06%	lr:0.000739
Ep: 20/48	It: 6351/8134	batch_loss: 3.1722	batch_accuracy: 40.67%	lr:0.000738
Ep: 20/48	It: 6401/8134	batch_loss: 3.1860	batch_accuracy: 39.11%	lr:0.000738
Ep: 20/48	It: 6451/8134	batch_loss: 3.2308	batch_accuracy: 39.28%	lr:0.000738
Ep: 20/48	It: 6501/8134	batch_loss: 3.2196	batch_accuracy: 39.21%	lr:0.000738
Ep: 20/48	It: 6551/8134	batch_loss: 3.2268	batch_accuracy: 38.77%	lr:0.000738
Ep: 20/48	It: 6601/8134	batch_loss: 3.2390	batch_accuracy: 37.38%	lr:0.000737
Ep: 20/48	It: 6651/8134	batch_loss: 3.2452	batch_accuracy: 38.99%	lr:0.000737
Ep: 20/48	It: 6701/8134	batch_loss: 3.2449	batch_accuracy: 39.21%	lr:0.000737
Ep: 20/48	It: 6751/8134	batch_loss: 3.1453	batch_accuracy: 39.33%	lr:0.000737
Ep: 20/48	It: 6801/8134	batch_loss: 3.3024	batch_accuracy: 38.99%	lr:0.000737
Ep: 20/48	It: 6851/8134	batch_loss: 3.0980	batch_accuracy: 40.80%	lr:0.000736
Ep: 20/48	It: 6901/8134	batch_loss: 3.2105	batch_accuracy: 39.50%	lr:0.000736
Ep: 20/48	It: 6951/8134	batch_loss: 3.2037	batch_accuracy: 39.55%	lr:0.000736
Ep: 20/48	It: 7001/8134	batch_loss: 3.1475	batch_accuracy: 40.99%	lr:0.000736
Ep: 20/48	It: 7051/8134	batch_loss: 3.3516	batch_accuracy: 37.70%	lr:0.000736
Ep: 20/48	It: 7101/8134	batch_loss: 3.2489	batch_accuracy: 39.28%	lr:0.000735
Ep: 20/48	It: 7151/8134	batch_loss: 3.1509	batch_accuracy: 39.87%	lr:0.000735
Ep: 20/48	It: 7201/8134	batch_loss: 3.1322	batch_accuracy: 40.58%	lr:0.000735
Ep: 20/48	It: 7251/8134	batch_loss: 3.1585	batch_accuracy: 39.16%	lr:0.000735
Ep: 20/48	It: 7301/8134	batch_loss: 3.2627	batch_accuracy: 38.48%	lr:0.000735
Ep: 20/48	It: 7351/8134	batch_loss: 3.2683	batch_accuracy: 39.40%	lr:0.000734
Ep: 20/48	It: 7401/8134	batch_loss: 3.2169	batch_accuracy: 39.11%	lr:0.000734
Ep: 20/48	It: 7451/8134	batch_loss: 3.2405	batch_accuracy: 38.99%	lr:0.000734
Ep: 20/48	It: 7501/8134	batch_loss: 3.2550	batch_accuracy: 39.45%	lr:0.000734
Ep: 20/48	It: 7551/8134	batch_loss: 3.1859	batch_accuracy: 39.60%	lr:0.000734
Ep: 20/48	It: 7601/8134	batch_loss: 3.2870	batch_accuracy: 39.28%	lr:0.000733
Ep: 20/48	It: 7651/8134	batch_loss: 3.1024	batch_accuracy: 39.40%	lr:0.000733
Ep: 20/48	It: 7701/8134	batch_loss: 3.1095	batch_accuracy: 41.65%	lr:0.000733
Ep: 20/48	It: 7751/8134	batch_loss: 3.1358	batch_accuracy: 39.55%	lr:0.000733
Ep: 20/48	It: 7801/8134	batch_loss: 3.1229	batch_accuracy: 40.45%	lr:0.000733
Ep: 20/48	It: 7851/8134	batch_loss: 3.1728	batch_accuracy: 39.31%	lr:0.000732
Ep: 20/48	It: 7901/8134	batch_loss: 3.2316	batch_accuracy: 39.33%	lr:0.000732
Ep: 20/48	It: 7951/8134	batch_loss: 3.2674	batch_accuracy: 39.58%	lr:0.000732
Ep: 20/48	It: 8001/8134	batch_loss: 3.2027	batch_accuracy: 40.21%	lr:0.000732
Ep: 20/48	It: 8051/8134	batch_loss: 3.2669	batch_accuracy: 39.31%	lr:0.000732
Ep: 20/48	It: 8101/8134	batch_loss: 3.2207	batch_accuracy: 39.01%	lr:0.000731
Ep: 20/48	It: 8134/8134	batch_loss: 3.2287	batch_accuracy: 39.23%	lr:0.000731


Generated text for input text "You" is:
You.
BACKGROUND
To evaluate the effect of bolide on serum T4 concentration inhaled corticosterone (CP) and its pharmacodynamic effects on the lungs.




The objective was to determine the relative effects of budesonide on serum L L E.




The aim of this study was to investigate the effect of bombesin on serum lipid levels and serum lipid levels in lung cancer patients.


METHODS
Between May 2018 and June 2019, patients were randomly assigned to receive bombesin (BZ) and berberine (BZ) on oral contraceptives. The study was a single-center study, in which a total of 2,316 patients with BZD and 128 without BZD were included in the study. In the study, we evaluated the efficacy of BZD and BZD in improving the efficacy of BZD and its effects on BZD patients. In the present study, we found that BZD treatment with bZD alone or in combination with BZD alone was significantly more effective than that of BZD alone. This study confirms the efficacy of BZD


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 21/48	It: 1/8134	batch_loss: 3.1625	batch_accuracy: 40.65%	lr:0.000731
Ep: 21/48	It: 51/8134	batch_loss: 3.1708	batch_accuracy: 39.33%	lr:0.000731
Ep: 21/48	It: 101/8134	batch_loss: 3.1800	batch_accuracy: 38.92%	lr:0.000731
Ep: 21/48	It: 151/8134	batch_loss: 3.2649	batch_accuracy: 38.60%	lr:0.000731
Ep: 21/48	It: 201/8134	batch_loss: 3.1837	batch_accuracy: 40.45%	lr:0.000731
Ep: 21/48	It: 251/8134	batch_loss: 3.2621	batch_accuracy: 38.75%	lr:0.000730
Ep: 21/48	It: 301/8134	batch_loss: 3.3073	batch_accuracy: 38.06%	lr:0.000730
Ep: 21/48	It: 351/8134	batch_loss: 3.0746	batch_accuracy: 41.72%	lr:0.000730
Ep: 21/48	It: 401/8134	batch_loss: 3.3280	batch_accuracy: 38.43%	lr:0.000730
Ep: 21/48	It: 451/8134	batch_loss: 3.3815	batch_accuracy: 37.74%	lr:0.000730
Ep: 21/48	It: 501/8134	batch_loss: 3.3935	batch_accuracy: 38.48%	lr:0.000729
Ep: 21/48	It: 551/8134	batch_loss: 3.2703	batch_accuracy: 38.33%	lr:0.000729
Ep: 21/48	It: 601/8134	batch_loss: 3.2868	batch_accuracy: 37.30%	lr:0.000729
Ep: 21/48	It: 651/8134	batch_loss: 3.1457	batch_accuracy: 40.09%	lr:0.000729
Ep: 21/48	It: 701/8134	batch_loss: 3.3606	batch_accuracy: 37.43%	lr:0.000729
Ep: 21/48	It: 751/8134	batch_loss: 3.1200	batch_accuracy: 40.77%	lr:0.000728
Ep: 21/48	It: 801/8134	batch_loss: 3.3181	batch_accuracy: 37.48%	lr:0.000728
Ep: 21/48	It: 851/8134	batch_loss: 3.1357	batch_accuracy: 39.94%	lr:0.000728
Ep: 21/48	It: 901/8134	batch_loss: 3.3699	batch_accuracy: 37.45%	lr:0.000728
Ep: 21/48	It: 951/8134	batch_loss: 3.2310	batch_accuracy: 39.09%	lr:0.000728
Ep: 21/48	It: 1001/8134	batch_loss: 3.1838	batch_accuracy: 39.82%	lr:0.000727
Ep: 21/48	It: 1051/8134	batch_loss: 3.1089	batch_accuracy: 40.65%	lr:0.000727
Ep: 21/48	It: 1101/8134	batch_loss: 3.3326	batch_accuracy: 37.99%	lr:0.000727
Ep: 21/48	It: 1151/8134	batch_loss: 3.2996	batch_accuracy: 38.94%	lr:0.000727
Ep: 21/48	It: 1201/8134	batch_loss: 3.3548	batch_accuracy: 37.40%	lr:0.000727
Ep: 21/48	It: 1251/8134	batch_loss: 3.1826	batch_accuracy: 40.11%	lr:0.000726
Ep: 21/48	It: 1301/8134	batch_loss: 3.1224	batch_accuracy: 40.84%	lr:0.000726
Ep: 21/48	It: 1351/8134	batch_loss: 3.2754	batch_accuracy: 38.84%	lr:0.000726
Ep: 21/48	It: 1401/8134	batch_loss: 3.1993	batch_accuracy: 39.48%	lr:0.000726
Ep: 21/48	It: 1451/8134	batch_loss: 3.1574	batch_accuracy: 41.14%	lr:0.000726
Ep: 21/48	It: 1501/8134	batch_loss: 3.2183	batch_accuracy: 40.09%	lr:0.000725
Ep: 21/48	It: 1551/8134	batch_loss: 3.2452	batch_accuracy: 38.79%	lr:0.000725
Ep: 21/48	It: 1601/8134	batch_loss: 3.1993	batch_accuracy: 40.36%	lr:0.000725
Ep: 21/48	It: 1651/8134	batch_loss: 3.1584	batch_accuracy: 40.55%	lr:0.000725
Ep: 21/48	It: 1701/8134	batch_loss: 3.2764	batch_accuracy: 38.53%	lr:0.000725
Ep: 21/48	It: 1751/8134	batch_loss: 3.2098	batch_accuracy: 39.06%	lr:0.000724
Ep: 21/48	It: 1801/8134	batch_loss: 3.2074	batch_accuracy: 38.89%	lr:0.000724
Ep: 21/48	It: 1851/8134	batch_loss: 3.1307	batch_accuracy: 40.50%	lr:0.000724
Ep: 21/48	It: 1901/8134	batch_loss: 3.1788	batch_accuracy: 39.31%	lr:0.000724
Ep: 21/48	It: 1951/8134	batch_loss: 3.2316	batch_accuracy: 39.14%	lr:0.000724
Ep: 21/48	It: 2001/8134	batch_loss: 3.1125	batch_accuracy: 41.92%	lr:0.000723
Ep: 21/48	It: 2051/8134	batch_loss: 3.3088	batch_accuracy: 37.72%	lr:0.000723
Ep: 21/48	It: 2101/8134	batch_loss: 3.1739	batch_accuracy: 39.04%	lr:0.000723
Ep: 21/48	It: 2151/8134	batch_loss: 3.2091	batch_accuracy: 39.50%	lr:0.000723
Ep: 21/48	It: 2201/8134	batch_loss: 3.2502	batch_accuracy: 39.48%	lr:0.000723
Ep: 21/48	It: 2251/8134	batch_loss: 3.2442	batch_accuracy: 38.77%	lr:0.000722
Ep: 21/48	It: 2301/8134	batch_loss: 3.0535	batch_accuracy: 42.50%	lr:0.000722
Ep: 21/48	It: 2351/8134	batch_loss: 3.2633	batch_accuracy: 38.45%	lr:0.000722
Ep: 21/48	It: 2401/8134	batch_loss: 3.1967	batch_accuracy: 39.99%	lr:0.000722
Ep: 21/48	It: 2451/8134	batch_loss: 3.2641	batch_accuracy: 38.48%	lr:0.000722
Ep: 21/48	It: 2501/8134	batch_loss: 3.1982	batch_accuracy: 40.01%	lr:0.000721
Ep: 21/48	It: 2551/8134	batch_loss: 3.2062	batch_accuracy: 39.60%	lr:0.000721
Ep: 21/48	It: 2601/8134	batch_loss: 3.2770	batch_accuracy: 38.87%	lr:0.000721
Ep: 21/48	It: 2651/8134	batch_loss: 3.2032	batch_accuracy: 38.82%	lr:0.000721
Ep: 21/48	It: 2701/8134	batch_loss: 3.2272	batch_accuracy: 38.55%	lr:0.000721
Ep: 21/48	It: 2751/8134	batch_loss: 3.1829	batch_accuracy: 40.01%	lr:0.000720
Ep: 21/48	It: 2801/8134	batch_loss: 3.1981	batch_accuracy: 40.41%	lr:0.000720
Ep: 21/48	It: 2851/8134	batch_loss: 3.1713	batch_accuracy: 39.82%	lr:0.000720
Ep: 21/48	It: 2901/8134	batch_loss: 3.1712	batch_accuracy: 39.58%	lr:0.000720
Ep: 21/48	It: 2951/8134	batch_loss: 3.3608	batch_accuracy: 37.67%	lr:0.000720
Ep: 21/48	It: 3001/8134	batch_loss: 3.1890	batch_accuracy: 40.16%	lr:0.000719
Ep: 21/48	It: 3051/8134	batch_loss: 3.1638	batch_accuracy: 40.45%	lr:0.000719
Ep: 21/48	It: 3101/8134	batch_loss: 3.3183	batch_accuracy: 38.62%	lr:0.000719
Ep: 21/48	It: 3151/8134	batch_loss: 3.1617	batch_accuracy: 39.60%	lr:0.000719
Ep: 21/48	It: 3201/8134	batch_loss: 3.2622	batch_accuracy: 39.11%	lr:0.000719
Ep: 21/48	It: 3251/8134	batch_loss: 3.1581	batch_accuracy: 39.45%	lr:0.000718
Ep: 21/48	It: 3301/8134	batch_loss: 3.1467	batch_accuracy: 40.33%	lr:0.000718
Ep: 21/48	It: 3351/8134	batch_loss: 3.1665	batch_accuracy: 40.33%	lr:0.000718
Ep: 21/48	It: 3401/8134	batch_loss: 3.2005	batch_accuracy: 38.96%	lr:0.000718
Ep: 21/48	It: 3451/8134	batch_loss: 3.1683	batch_accuracy: 39.11%	lr:0.000718
Ep: 21/48	It: 3501/8134	batch_loss: 3.1314	batch_accuracy: 39.92%	lr:0.000717
Ep: 21/48	It: 3551/8134	batch_loss: 3.1970	batch_accuracy: 39.67%	lr:0.000717
Ep: 21/48	It: 3601/8134	batch_loss: 3.2321	batch_accuracy: 38.94%	lr:0.000717
Ep: 21/48	It: 3651/8134	batch_loss: 3.2787	batch_accuracy: 38.38%	lr:0.000717
Ep: 21/48	It: 3701/8134	batch_loss: 3.2432	batch_accuracy: 40.09%	lr:0.000717
Ep: 21/48	It: 3751/8134	batch_loss: 3.0862	batch_accuracy: 41.99%	lr:0.000716
Ep: 21/48	It: 3801/8134	batch_loss: 3.3518	batch_accuracy: 37.92%	lr:0.000716
Ep: 21/48	It: 3851/8134	batch_loss: 3.2470	batch_accuracy: 38.65%	lr:0.000716
Ep: 21/48	It: 3901/8134	batch_loss: 3.2591	batch_accuracy: 38.43%	lr:0.000716
Ep: 21/48	It: 3951/8134	batch_loss: 3.1748	batch_accuracy: 39.65%	lr:0.000716
Ep: 21/48	It: 4001/8134	batch_loss: 3.1881	batch_accuracy: 40.58%	lr:0.000715
Ep: 21/48	It: 4051/8134	batch_loss: 3.2084	batch_accuracy: 39.70%	lr:0.000715
Ep: 21/48	It: 4101/8134	batch_loss: 3.0694	batch_accuracy: 41.36%	lr:0.000715
Ep: 21/48	It: 4151/8134	batch_loss: 3.2678	batch_accuracy: 37.96%	lr:0.000715
Ep: 21/48	It: 4201/8134	batch_loss: 3.2026	batch_accuracy: 38.87%	lr:0.000715
Ep: 21/48	It: 4251/8134	batch_loss: 3.2396	batch_accuracy: 38.45%	lr:0.000714
Ep: 21/48	It: 4301/8134	batch_loss: 3.2613	batch_accuracy: 38.45%	lr:0.000714
Ep: 21/48	It: 4351/8134	batch_loss: 3.2565	batch_accuracy: 38.50%	lr:0.000714
Ep: 21/48	It: 4401/8134	batch_loss: 3.2479	batch_accuracy: 38.55%	lr:0.000714
Ep: 21/48	It: 4451/8134	batch_loss: 3.1941	batch_accuracy: 38.87%	lr:0.000714
Ep: 21/48	It: 4501/8134	batch_loss: 3.3198	batch_accuracy: 37.89%	lr:0.000713
Ep: 21/48	It: 4551/8134	batch_loss: 3.1427	batch_accuracy: 40.70%	lr:0.000713
Ep: 21/48	It: 4601/8134	batch_loss: 3.2508	batch_accuracy: 39.21%	lr:0.000713
Ep: 21/48	It: 4651/8134	batch_loss: 3.2190	batch_accuracy: 40.26%	lr:0.000713
Ep: 21/48	It: 4701/8134	batch_loss: 3.1061	batch_accuracy: 40.28%	lr:0.000713
Ep: 21/48	It: 4751/8134	batch_loss: 3.2646	batch_accuracy: 39.18%	lr:0.000712
Ep: 21/48	It: 4801/8134	batch_loss: 3.2266	batch_accuracy: 39.89%	lr:0.000712
Ep: 21/48	It: 4851/8134	batch_loss: 3.2574	batch_accuracy: 38.79%	lr:0.000712
Ep: 21/48	It: 4901/8134	batch_loss: 3.2555	batch_accuracy: 39.01%	lr:0.000712
Ep: 21/48	It: 4951/8134	batch_loss: 3.1670	batch_accuracy: 39.48%	lr:0.000712
Ep: 21/48	It: 5001/8134	batch_loss: 3.3590	batch_accuracy: 37.92%	lr:0.000711
Ep: 21/48	It: 5051/8134	batch_loss: 3.1996	batch_accuracy: 38.82%	lr:0.000711
Ep: 21/48	It: 5101/8134	batch_loss: 3.1574	batch_accuracy: 39.79%	lr:0.000711
Ep: 21/48	It: 5151/8134	batch_loss: 3.2131	batch_accuracy: 39.82%	lr:0.000711
Ep: 21/48	It: 5201/8134	batch_loss: 3.1387	batch_accuracy: 39.04%	lr:0.000711
Ep: 21/48	It: 5251/8134	batch_loss: 3.2594	batch_accuracy: 38.33%	lr:0.000710
Ep: 21/48	It: 5301/8134	batch_loss: 3.2063	batch_accuracy: 39.40%	lr:0.000710
Ep: 21/48	It: 5351/8134	batch_loss: 3.2975	batch_accuracy: 38.50%	lr:0.000710
Ep: 21/48	It: 5401/8134	batch_loss: 3.3185	batch_accuracy: 37.92%	lr:0.000710
Ep: 21/48	It: 5451/8134	batch_loss: 3.2025	batch_accuracy: 39.77%	lr:0.000710
Ep: 21/48	It: 5501/8134	batch_loss: 3.1405	batch_accuracy: 41.04%	lr:0.000709
Ep: 21/48	It: 5551/8134	batch_loss: 3.2536	batch_accuracy: 37.82%	lr:0.000709
Ep: 21/48	It: 5601/8134	batch_loss: 3.2886	batch_accuracy: 38.45%	lr:0.000709
Ep: 21/48	It: 5651/8134	batch_loss: 3.2529	batch_accuracy: 37.96%	lr:0.000709
Ep: 21/48	It: 5701/8134	batch_loss: 3.1075	batch_accuracy: 39.60%	lr:0.000709
Ep: 21/48	It: 5751/8134	batch_loss: 3.3004	batch_accuracy: 38.65%	lr:0.000708
Ep: 21/48	It: 5801/8134	batch_loss: 3.1248	batch_accuracy: 40.75%	lr:0.000708
Ep: 21/48	It: 5851/8134	batch_loss: 3.2561	batch_accuracy: 38.57%	lr:0.000708
Ep: 21/48	It: 5901/8134	batch_loss: 3.1223	batch_accuracy: 40.72%	lr:0.000708
Ep: 21/48	It: 5951/8134	batch_loss: 3.1351	batch_accuracy: 41.21%	lr:0.000707
Ep: 21/48	It: 6001/8134	batch_loss: 3.2162	batch_accuracy: 39.55%	lr:0.000707
Ep: 21/48	It: 6051/8134	batch_loss: 3.2535	batch_accuracy: 39.48%	lr:0.000707
Ep: 21/48	It: 6101/8134	batch_loss: 3.1860	batch_accuracy: 39.23%	lr:0.000707
Ep: 21/48	It: 6151/8134	batch_loss: 3.3657	batch_accuracy: 37.35%	lr:0.000707
Ep: 21/48	It: 6201/8134	batch_loss: 3.2336	batch_accuracy: 40.38%	lr:0.000706
Ep: 21/48	It: 6251/8134	batch_loss: 3.1691	batch_accuracy: 39.36%	lr:0.000706
Ep: 21/48	It: 6301/8134	batch_loss: 3.1864	batch_accuracy: 38.92%	lr:0.000706
Ep: 21/48	It: 6351/8134	batch_loss: 3.3226	batch_accuracy: 37.82%	lr:0.000706
Ep: 21/48	It: 6401/8134	batch_loss: 3.2245	batch_accuracy: 40.01%	lr:0.000706
Ep: 21/48	It: 6451/8134	batch_loss: 3.1816	batch_accuracy: 40.36%	lr:0.000705
Ep: 21/48	It: 6501/8134	batch_loss: 3.2015	batch_accuracy: 38.96%	lr:0.000705
Ep: 21/48	It: 6551/8134	batch_loss: 3.1894	batch_accuracy: 39.58%	lr:0.000705
Ep: 21/48	It: 6601/8134	batch_loss: 3.1520	batch_accuracy: 40.43%	lr:0.000705
Ep: 21/48	It: 6651/8134	batch_loss: 3.1441	batch_accuracy: 40.48%	lr:0.000705
Ep: 21/48	It: 6701/8134	batch_loss: 3.2253	batch_accuracy: 39.48%	lr:0.000704
Ep: 21/48	It: 6751/8134	batch_loss: 3.2178	batch_accuracy: 39.36%	lr:0.000704
Ep: 21/48	It: 6801/8134	batch_loss: 3.1634	batch_accuracy: 39.89%	lr:0.000704
Ep: 21/48	It: 6851/8134	batch_loss: 3.1372	batch_accuracy: 41.26%	lr:0.000704
Ep: 21/48	It: 6901/8134	batch_loss: 3.3024	batch_accuracy: 39.23%	lr:0.000704
Ep: 21/48	It: 6951/8134	batch_loss: 3.1315	batch_accuracy: 40.58%	lr:0.000703
Ep: 21/48	It: 7001/8134	batch_loss: 3.2216	batch_accuracy: 40.19%	lr:0.000703
Ep: 21/48	It: 7051/8134	batch_loss: 3.1108	batch_accuracy: 41.11%	lr:0.000703
Ep: 21/48	It: 7101/8134	batch_loss: 3.1437	batch_accuracy: 40.58%	lr:0.000703
Ep: 21/48	It: 7151/8134	batch_loss: 3.1563	batch_accuracy: 40.99%	lr:0.000703
Ep: 21/48	It: 7201/8134	batch_loss: 3.1778	batch_accuracy: 40.23%	lr:0.000702
Ep: 21/48	It: 7251/8134	batch_loss: 3.2458	batch_accuracy: 39.09%	lr:0.000702
Ep: 21/48	It: 7301/8134	batch_loss: 3.2469	batch_accuracy: 39.26%	lr:0.000702
Ep: 21/48	It: 7351/8134	batch_loss: 3.2089	batch_accuracy: 38.16%	lr:0.000702
Ep: 21/48	It: 7401/8134	batch_loss: 3.2256	batch_accuracy: 39.06%	lr:0.000702
Ep: 21/48	It: 7451/8134	batch_loss: 3.3237	batch_accuracy: 38.11%	lr:0.000701
Ep: 21/48	It: 7501/8134	batch_loss: 3.1824	batch_accuracy: 40.36%	lr:0.000701
Ep: 21/48	It: 7551/8134	batch_loss: 3.1997	batch_accuracy: 40.09%	lr:0.000701
Ep: 21/48	It: 7601/8134	batch_loss: 3.2141	batch_accuracy: 39.23%	lr:0.000701
Ep: 21/48	It: 7651/8134	batch_loss: 3.2135	batch_accuracy: 39.60%	lr:0.000701
Ep: 21/48	It: 7701/8134	batch_loss: 3.1599	batch_accuracy: 39.53%	lr:0.000700
Ep: 21/48	It: 7751/8134	batch_loss: 3.1994	batch_accuracy: 39.26%	lr:0.000700
Ep: 21/48	It: 7801/8134	batch_loss: 3.2417	batch_accuracy: 39.21%	lr:0.000700
Ep: 21/48	It: 7851/8134	batch_loss: 3.3417	batch_accuracy: 38.13%	lr:0.000700
Ep: 21/48	It: 7901/8134	batch_loss: 3.2595	batch_accuracy: 38.55%	lr:0.000700
Ep: 21/48	It: 7951/8134	batch_loss: 3.2069	batch_accuracy: 40.14%	lr:0.000699
Ep: 21/48	It: 8001/8134	batch_loss: 3.2224	batch_accuracy: 37.67%	lr:0.000699
Ep: 21/48	It: 8051/8134	batch_loss: 3.2431	batch_accuracy: 38.55%	lr:0.000699
Ep: 21/48	It: 8101/8134	batch_loss: 3.3116	batch_accuracy: 38.38%	lr:0.000699
Ep: 21/48	It: 8134/8134	batch_loss: 3.1025	batch_accuracy: 41.98%	lr:0.000699


Generated text for input text "You" is:
Youx’s book ‘Te ‘The Bigs of theology’ (p.), and (4)’ (p.) The Movement of theorists’ “Psychotherapy” (p. 8) and theories of psychology, and theories of theories of “aesthetic pain” (p. 59). His argument is that the most important question is that the theory of pain is not a fundamental concept, but a particular perspective that is not clear. In fact, the authors show that in some cases, it is difficult to distinguish between pain and pain. In fact, in many cases, pain may be an important component of the pain. Indeed, the pain of pain can be reduced by painful changes in pain, pain, and pain. In addition, it is very difficult to predict the pain, but the use of pain is not a matter of debate.
<eot>
<sot>
Analysis of a Single-Single-Phase Ceramic Material Using Single-Signal Cavity Raman Spectroscopy

A simple and accurate method for fabrication of superconducting metamaterials using a


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 22/48	It: 1/8134	batch_loss: 3.1924	batch_accuracy: 39.92%	lr:0.000699
Ep: 22/48	It: 51/8134	batch_loss: 3.1368	batch_accuracy: 40.19%	lr:0.000698
Ep: 22/48	It: 101/8134	batch_loss: 3.1905	batch_accuracy: 39.99%	lr:0.000698
Ep: 22/48	It: 151/8134	batch_loss: 3.0563	batch_accuracy: 41.53%	lr:0.000698
Ep: 22/48	It: 201/8134	batch_loss: 3.1958	batch_accuracy: 39.70%	lr:0.000698
Ep: 22/48	It: 251/8134	batch_loss: 3.2711	batch_accuracy: 37.72%	lr:0.000698
Ep: 22/48	It: 301/8134	batch_loss: 3.2526	batch_accuracy: 40.36%	lr:0.000697
Ep: 22/48	It: 351/8134	batch_loss: 3.2372	batch_accuracy: 39.99%	lr:0.000697
Ep: 22/48	It: 401/8134	batch_loss: 3.1111	batch_accuracy: 40.67%	lr:0.000697
Ep: 22/48	It: 451/8134	batch_loss: 2.9862	batch_accuracy: 41.85%	lr:0.000697
Ep: 22/48	It: 501/8134	batch_loss: 3.1877	batch_accuracy: 39.60%	lr:0.000697
Ep: 22/48	It: 551/8134	batch_loss: 3.0789	batch_accuracy: 41.60%	lr:0.000696
Ep: 22/48	It: 601/8134	batch_loss: 3.2060	batch_accuracy: 39.75%	lr:0.000696
Ep: 22/48	It: 651/8134	batch_loss: 3.2513	batch_accuracy: 38.38%	lr:0.000696
Ep: 22/48	It: 701/8134	batch_loss: 3.1317	batch_accuracy: 40.60%	lr:0.000696
Ep: 22/48	It: 751/8134	batch_loss: 3.0194	batch_accuracy: 41.67%	lr:0.000696
Ep: 22/48	It: 801/8134	batch_loss: 3.0493	batch_accuracy: 42.02%	lr:0.000695
Ep: 22/48	It: 851/8134	batch_loss: 3.1543	batch_accuracy: 40.58%	lr:0.000695
Ep: 22/48	It: 901/8134	batch_loss: 3.2062	batch_accuracy: 39.36%	lr:0.000695
Ep: 22/48	It: 951/8134	batch_loss: 3.3600	batch_accuracy: 38.89%	lr:0.000695
Ep: 22/48	It: 1001/8134	batch_loss: 3.2810	batch_accuracy: 38.60%	lr:0.000694
Ep: 22/48	It: 1051/8134	batch_loss: 3.1973	batch_accuracy: 39.65%	lr:0.000694
Ep: 22/48	It: 1101/8134	batch_loss: 3.1904	batch_accuracy: 39.53%	lr:0.000694
Ep: 22/48	It: 1151/8134	batch_loss: 3.1211	batch_accuracy: 40.75%	lr:0.000694
Ep: 22/48	It: 1201/8134	batch_loss: 3.1801	batch_accuracy: 38.16%	lr:0.000694
Ep: 22/48	It: 1251/8134	batch_loss: 3.1892	batch_accuracy: 38.62%	lr:0.000693
Ep: 22/48	It: 1301/8134	batch_loss: 3.3112	batch_accuracy: 38.35%	lr:0.000693
Ep: 22/48	It: 1351/8134	batch_loss: 3.2490	batch_accuracy: 38.21%	lr:0.000693
Ep: 22/48	It: 1401/8134	batch_loss: 3.1086	batch_accuracy: 40.84%	lr:0.000693
Ep: 22/48	It: 1451/8134	batch_loss: 3.2409	batch_accuracy: 38.26%	lr:0.000693
Ep: 22/48	It: 1501/8134	batch_loss: 3.2564	batch_accuracy: 39.77%	lr:0.000692
Ep: 22/48	It: 1551/8134	batch_loss: 3.0848	batch_accuracy: 40.89%	lr:0.000692
Ep: 22/48	It: 1601/8134	batch_loss: 3.1904	batch_accuracy: 38.67%	lr:0.000692
Ep: 22/48	It: 1651/8134	batch_loss: 3.2088	batch_accuracy: 39.01%	lr:0.000692
Ep: 22/48	It: 1701/8134	batch_loss: 3.3092	batch_accuracy: 38.23%	lr:0.000692
Ep: 22/48	It: 1751/8134	batch_loss: 3.2615	batch_accuracy: 38.06%	lr:0.000691
Ep: 22/48	It: 1801/8134	batch_loss: 3.2726	batch_accuracy: 38.60%	lr:0.000691
Ep: 22/48	It: 1851/8134	batch_loss: 3.1427	batch_accuracy: 40.82%	lr:0.000691
Ep: 22/48	It: 1901/8134	batch_loss: 3.2148	batch_accuracy: 39.60%	lr:0.000691
Ep: 22/48	It: 1951/8134	batch_loss: 3.2439	batch_accuracy: 39.87%	lr:0.000691
Ep: 22/48	It: 2001/8134	batch_loss: 3.1628	batch_accuracy: 40.09%	lr:0.000690
Ep: 22/48	It: 2051/8134	batch_loss: 3.2207	batch_accuracy: 39.70%	lr:0.000690
Ep: 22/48	It: 2101/8134	batch_loss: 3.2140	batch_accuracy: 38.82%	lr:0.000690
Ep: 22/48	It: 2151/8134	batch_loss: 3.2066	batch_accuracy: 39.16%	lr:0.000690
Ep: 22/48	It: 2201/8134	batch_loss: 3.3082	batch_accuracy: 37.70%	lr:0.000690
Ep: 22/48	It: 2251/8134	batch_loss: 3.2110	batch_accuracy: 39.21%	lr:0.000689
Ep: 22/48	It: 2301/8134	batch_loss: 3.1388	batch_accuracy: 40.53%	lr:0.000689
Ep: 22/48	It: 2351/8134	batch_loss: 3.2884	batch_accuracy: 38.18%	lr:0.000689
Ep: 22/48	It: 2401/8134	batch_loss: 3.2160	batch_accuracy: 39.62%	lr:0.000689
Ep: 22/48	It: 2451/8134	batch_loss: 3.1703	batch_accuracy: 40.04%	lr:0.000689
Ep: 22/48	It: 2501/8134	batch_loss: 3.2273	batch_accuracy: 37.55%	lr:0.000688
Ep: 22/48	It: 2551/8134	batch_loss: 3.1904	batch_accuracy: 39.82%	lr:0.000688
Ep: 22/48	It: 2601/8134	batch_loss: 3.1863	batch_accuracy: 39.60%	lr:0.000688
Ep: 22/48	It: 2651/8134	batch_loss: 3.2149	batch_accuracy: 38.96%	lr:0.000688
Ep: 22/48	It: 2701/8134	batch_loss: 3.1814	batch_accuracy: 40.01%	lr:0.000687
Ep: 22/48	It: 2751/8134	batch_loss: 3.1946	batch_accuracy: 39.62%	lr:0.000687
Ep: 22/48	It: 2801/8134	batch_loss: 3.1644	batch_accuracy: 39.60%	lr:0.000687
Ep: 22/48	It: 2851/8134	batch_loss: 3.1658	batch_accuracy: 39.28%	lr:0.000687
Ep: 22/48	It: 2901/8134	batch_loss: 3.0657	batch_accuracy: 40.38%	lr:0.000687
Ep: 22/48	It: 2951/8134	batch_loss: 3.1779	batch_accuracy: 39.79%	lr:0.000686
Ep: 22/48	It: 3001/8134	batch_loss: 3.2390	batch_accuracy: 39.16%	lr:0.000686
Ep: 22/48	It: 3051/8134	batch_loss: 3.2082	batch_accuracy: 39.18%	lr:0.000686
Ep: 22/48	It: 3101/8134	batch_loss: 3.1954	batch_accuracy: 39.45%	lr:0.000686
Ep: 22/48	It: 3151/8134	batch_loss: 3.2449	batch_accuracy: 38.70%	lr:0.000686
Ep: 22/48	It: 3201/8134	batch_loss: 3.3494	batch_accuracy: 37.77%	lr:0.000685
Ep: 22/48	It: 3251/8134	batch_loss: 3.0688	batch_accuracy: 40.82%	lr:0.000685
Ep: 22/48	It: 3301/8134	batch_loss: 3.2372	batch_accuracy: 39.01%	lr:0.000685
Ep: 22/48	It: 3351/8134	batch_loss: 3.3263	batch_accuracy: 38.45%	lr:0.000685
Ep: 22/48	It: 3401/8134	batch_loss: 3.2964	batch_accuracy: 38.48%	lr:0.000685
Ep: 22/48	It: 3451/8134	batch_loss: 3.2533	batch_accuracy: 38.89%	lr:0.000684
Ep: 22/48	It: 3501/8134	batch_loss: 3.1307	batch_accuracy: 40.65%	lr:0.000684
Ep: 22/48	It: 3551/8134	batch_loss: 3.2554	batch_accuracy: 38.75%	lr:0.000684
Ep: 22/48	It: 3601/8134	batch_loss: 3.2128	batch_accuracy: 39.01%	lr:0.000684
Ep: 22/48	It: 3651/8134	batch_loss: 3.1096	batch_accuracy: 41.55%	lr:0.000684
Ep: 22/48	It: 3701/8134	batch_loss: 3.1722	batch_accuracy: 39.55%	lr:0.000683
Ep: 22/48	It: 3751/8134	batch_loss: 3.1744	batch_accuracy: 40.55%	lr:0.000683
Ep: 22/48	It: 3801/8134	batch_loss: 3.1625	batch_accuracy: 40.09%	lr:0.000683
Ep: 22/48	It: 3851/8134	batch_loss: 3.2019	batch_accuracy: 39.23%	lr:0.000683
Ep: 22/48	It: 3901/8134	batch_loss: 3.1329	batch_accuracy: 40.06%	lr:0.000683
Ep: 22/48	It: 3951/8134	batch_loss: 3.1074	batch_accuracy: 41.26%	lr:0.000682
Ep: 22/48	It: 4001/8134	batch_loss: 3.1372	batch_accuracy: 39.75%	lr:0.000682
Ep: 22/48	It: 4051/8134	batch_loss: 3.1792	batch_accuracy: 39.70%	lr:0.000682
Ep: 22/48	It: 4101/8134	batch_loss: 3.1803	batch_accuracy: 39.31%	lr:0.000682
Ep: 22/48	It: 4151/8134	batch_loss: 3.1889	batch_accuracy: 40.21%	lr:0.000681
Ep: 22/48	It: 4201/8134	batch_loss: 3.2298	batch_accuracy: 38.45%	lr:0.000681
Ep: 22/48	It: 4251/8134	batch_loss: 3.2609	batch_accuracy: 38.87%	lr:0.000681
Ep: 22/48	It: 4301/8134	batch_loss: 3.2741	batch_accuracy: 39.11%	lr:0.000681
Ep: 22/48	It: 4351/8134	batch_loss: 3.1715	batch_accuracy: 39.97%	lr:0.000681
Ep: 22/48	It: 4401/8134	batch_loss: 3.2622	batch_accuracy: 39.23%	lr:0.000680
Ep: 22/48	It: 4451/8134	batch_loss: 3.2139	batch_accuracy: 39.33%	lr:0.000680
Ep: 22/48	It: 4501/8134	batch_loss: 3.0903	batch_accuracy: 41.46%	lr:0.000680
Ep: 22/48	It: 4551/8134	batch_loss: 3.2059	batch_accuracy: 38.87%	lr:0.000680
Ep: 22/48	It: 4601/8134	batch_loss: 3.2981	batch_accuracy: 37.87%	lr:0.000680
Ep: 22/48	It: 4651/8134	batch_loss: 3.2390	batch_accuracy: 39.82%	lr:0.000679
Ep: 22/48	It: 4701/8134	batch_loss: 3.2173	batch_accuracy: 39.36%	lr:0.000679
Ep: 22/48	It: 4751/8134	batch_loss: 3.1892	batch_accuracy: 40.11%	lr:0.000679
Ep: 22/48	It: 4801/8134	batch_loss: 3.1955	batch_accuracy: 39.21%	lr:0.000679
Ep: 22/48	It: 4851/8134	batch_loss: 3.1643	batch_accuracy: 40.16%	lr:0.000679
Ep: 22/48	It: 4901/8134	batch_loss: 3.1323	batch_accuracy: 40.60%	lr:0.000678
Ep: 22/48	It: 4951/8134	batch_loss: 3.2469	batch_accuracy: 38.33%	lr:0.000678
Ep: 22/48	It: 5001/8134	batch_loss: 3.1896	batch_accuracy: 40.87%	lr:0.000678
Ep: 22/48	It: 5051/8134	batch_loss: 3.2587	batch_accuracy: 39.28%	lr:0.000678
Ep: 22/48	It: 5101/8134	batch_loss: 3.1473	batch_accuracy: 40.06%	lr:0.000678
Ep: 22/48	It: 5151/8134	batch_loss: 3.1420	batch_accuracy: 40.58%	lr:0.000677
Ep: 22/48	It: 5201/8134	batch_loss: 3.1415	batch_accuracy: 39.43%	lr:0.000677
Ep: 22/48	It: 5251/8134	batch_loss: 3.2266	batch_accuracy: 39.14%	lr:0.000677
Ep: 22/48	It: 5301/8134	batch_loss: 3.0882	batch_accuracy: 41.02%	lr:0.000677
Ep: 22/48	It: 5351/8134	batch_loss: 3.1885	batch_accuracy: 40.01%	lr:0.000676
Ep: 22/48	It: 5401/8134	batch_loss: 3.2237	batch_accuracy: 39.75%	lr:0.000676
Ep: 22/48	It: 5451/8134	batch_loss: 3.2400	batch_accuracy: 38.53%	lr:0.000676
Ep: 22/48	It: 5501/8134	batch_loss: 3.2556	batch_accuracy: 39.28%	lr:0.000676
Ep: 22/48	It: 5551/8134	batch_loss: 3.2590	batch_accuracy: 38.28%	lr:0.000676
Ep: 22/48	It: 5601/8134	batch_loss: 3.1822	batch_accuracy: 39.97%	lr:0.000675
Ep: 22/48	It: 5651/8134	batch_loss: 3.1140	batch_accuracy: 39.65%	lr:0.000675
Ep: 22/48	It: 5701/8134	batch_loss: 3.2251	batch_accuracy: 38.92%	lr:0.000675
Ep: 22/48	It: 5751/8134	batch_loss: 3.1722	batch_accuracy: 40.14%	lr:0.000675
Ep: 22/48	It: 5801/8134	batch_loss: 3.2333	batch_accuracy: 38.96%	lr:0.000675
Ep: 22/48	It: 5851/8134	batch_loss: 3.2239	batch_accuracy: 39.65%	lr:0.000674
Ep: 22/48	It: 5901/8134	batch_loss: 3.1552	batch_accuracy: 40.48%	lr:0.000674
Ep: 22/48	It: 5951/8134	batch_loss: 3.1836	batch_accuracy: 38.65%	lr:0.000674
Ep: 22/48	It: 6001/8134	batch_loss: 3.2108	batch_accuracy: 38.77%	lr:0.000674
Ep: 22/48	It: 6051/8134	batch_loss: 3.2423	batch_accuracy: 38.55%	lr:0.000674
Ep: 22/48	It: 6101/8134	batch_loss: 3.2871	batch_accuracy: 38.70%	lr:0.000673
Ep: 22/48	It: 6151/8134	batch_loss: 3.2968	batch_accuracy: 38.23%	lr:0.000673
Ep: 22/48	It: 6201/8134	batch_loss: 3.2745	batch_accuracy: 38.82%	lr:0.000673
Ep: 22/48	It: 6251/8134	batch_loss: 3.0997	batch_accuracy: 40.82%	lr:0.000673
Ep: 22/48	It: 6301/8134	batch_loss: 3.2878	batch_accuracy: 38.48%	lr:0.000673
Ep: 22/48	It: 6351/8134	batch_loss: 3.1682	batch_accuracy: 39.75%	lr:0.000672
Ep: 22/48	It: 6401/8134	batch_loss: 3.1611	batch_accuracy: 40.48%	lr:0.000672
Ep: 22/48	It: 6451/8134	batch_loss: 3.2194	batch_accuracy: 39.18%	lr:0.000672
Ep: 22/48	It: 6501/8134	batch_loss: 3.0982	batch_accuracy: 40.58%	lr:0.000672
Ep: 22/48	It: 6551/8134	batch_loss: 3.1592	batch_accuracy: 40.58%	lr:0.000671
Ep: 22/48	It: 6601/8134	batch_loss: 3.3114	batch_accuracy: 38.55%	lr:0.000671
Ep: 22/48	It: 6651/8134	batch_loss: 3.1506	batch_accuracy: 40.16%	lr:0.000671
Ep: 22/48	It: 6701/8134	batch_loss: 3.1552	batch_accuracy: 39.77%	lr:0.000671
Ep: 22/48	It: 6751/8134	batch_loss: 3.2352	batch_accuracy: 39.70%	lr:0.000671
Ep: 22/48	It: 6801/8134	batch_loss: 3.2910	batch_accuracy: 37.72%	lr:0.000670
Ep: 22/48	It: 6851/8134	batch_loss: 3.2719	batch_accuracy: 38.79%	lr:0.000670
Ep: 22/48	It: 6901/8134	batch_loss: 3.1877	batch_accuracy: 39.53%	lr:0.000670
Ep: 22/48	It: 6951/8134	batch_loss: 3.1595	batch_accuracy: 41.09%	lr:0.000670
Ep: 22/48	It: 7001/8134	batch_loss: 3.1781	batch_accuracy: 39.79%	lr:0.000670
Ep: 22/48	It: 7051/8134	batch_loss: 3.2706	batch_accuracy: 38.89%	lr:0.000669
Ep: 22/48	It: 7101/8134	batch_loss: 3.0773	batch_accuracy: 40.28%	lr:0.000669
Ep: 22/48	It: 7151/8134	batch_loss: 3.1119	batch_accuracy: 40.26%	lr:0.000669
Ep: 22/48	It: 7201/8134	batch_loss: 3.1919	batch_accuracy: 39.94%	lr:0.000669
Ep: 22/48	It: 7251/8134	batch_loss: 3.1578	batch_accuracy: 39.40%	lr:0.000669
Ep: 22/48	It: 7301/8134	batch_loss: 3.3440	batch_accuracy: 38.60%	lr:0.000668
Ep: 22/48	It: 7351/8134	batch_loss: 3.1358	batch_accuracy: 40.09%	lr:0.000668
Ep: 22/48	It: 7401/8134	batch_loss: 3.3795	batch_accuracy: 36.23%	lr:0.000668
Ep: 22/48	It: 7451/8134	batch_loss: 3.2164	batch_accuracy: 39.38%	lr:0.000668
Ep: 22/48	It: 7501/8134	batch_loss: 3.2088	batch_accuracy: 39.40%	lr:0.000667
Ep: 22/48	It: 7551/8134	batch_loss: 3.2295	batch_accuracy: 40.11%	lr:0.000667
Ep: 22/48	It: 7601/8134	batch_loss: 3.1234	batch_accuracy: 40.62%	lr:0.000667
Ep: 22/48	It: 7651/8134	batch_loss: 3.2116	batch_accuracy: 39.50%	lr:0.000667
Ep: 22/48	It: 7701/8134	batch_loss: 3.3144	batch_accuracy: 37.82%	lr:0.000667
Ep: 22/48	It: 7751/8134	batch_loss: 3.1674	batch_accuracy: 40.60%	lr:0.000666
Ep: 22/48	It: 7801/8134	batch_loss: 3.3745	batch_accuracy: 36.50%	lr:0.000666
Ep: 22/48	It: 7851/8134	batch_loss: 3.1835	batch_accuracy: 39.79%	lr:0.000666
Ep: 22/48	It: 7901/8134	batch_loss: 3.2987	batch_accuracy: 38.18%	lr:0.000666
Ep: 22/48	It: 7951/8134	batch_loss: 3.1275	batch_accuracy: 39.11%	lr:0.000666
Ep: 22/48	It: 8001/8134	batch_loss: 3.2256	batch_accuracy: 38.87%	lr:0.000665
Ep: 22/48	It: 8051/8134	batch_loss: 3.1099	batch_accuracy: 40.67%	lr:0.000665
Ep: 22/48	It: 8101/8134	batch_loss: 3.1280	batch_accuracy: 40.09%	lr:0.000665
Ep: 22/48	It: 8134/8134	batch_loss: 3.3245	batch_accuracy: 36.85%	lr:0.000665


Generated text for input text "You" is:
You’s book, is a license book that will be read by annotatic review. In this article I have readers of thesis that I have done in this field as many readers as many as we do, or even love. I think, and like my father, and me.
<eot>
<sot>
Does Self-Exploiting Feedback Control for a Multi-User Wireless Power System

In this paper, we investigate the effects of a multi-User WiMAX environment on the performance of a multi-user multi-user wireless power system. The multi-user interference (MII) environment can be reduced by using the MIMO system. The interference interference can be enhanced by the interference interference between the two multiuser interference (MUI) channels. In this paper, a novel adaptive multiuser interference (MAC) scheme is proposed for the MIMO system. The MIMO system is designed and simulated using MATLAB/Simulink environment. The proposed scheme is implemented on a Digital CMOS CMOS technology and is validated using a simulated prototype. The results show that


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 23/48	It: 1/8134	batch_loss: 3.2388	batch_accuracy: 39.31%	lr:0.000665
Ep: 23/48	It: 51/8134	batch_loss: 3.2185	batch_accuracy: 38.45%	lr:0.000665
Ep: 23/48	It: 101/8134	batch_loss: 3.1524	batch_accuracy: 40.53%	lr:0.000664
Ep: 23/48	It: 151/8134	batch_loss: 3.2287	batch_accuracy: 38.96%	lr:0.000664
Ep: 23/48	It: 201/8134	batch_loss: 3.1392	batch_accuracy: 39.87%	lr:0.000664
Ep: 23/48	It: 251/8134	batch_loss: 3.1878	batch_accuracy: 39.87%	lr:0.000664
Ep: 23/48	It: 301/8134	batch_loss: 3.2118	batch_accuracy: 38.99%	lr:0.000664
Ep: 23/48	It: 351/8134	batch_loss: 3.1425	batch_accuracy: 40.48%	lr:0.000663
Ep: 23/48	It: 401/8134	batch_loss: 3.3860	batch_accuracy: 37.11%	lr:0.000663
Ep: 23/48	It: 451/8134	batch_loss: 3.0479	batch_accuracy: 41.14%	lr:0.000663
Ep: 23/48	It: 501/8134	batch_loss: 3.1623	batch_accuracy: 40.41%	lr:0.000663
Ep: 23/48	It: 551/8134	batch_loss: 3.0962	batch_accuracy: 41.48%	lr:0.000663
Ep: 23/48	It: 601/8134	batch_loss: 3.1222	batch_accuracy: 40.21%	lr:0.000662
Ep: 23/48	It: 651/8134	batch_loss: 3.2916	batch_accuracy: 39.31%	lr:0.000662
Ep: 23/48	It: 701/8134	batch_loss: 3.2045	batch_accuracy: 38.72%	lr:0.000662
Ep: 23/48	It: 751/8134	batch_loss: 3.2610	batch_accuracy: 39.40%	lr:0.000662
Ep: 23/48	It: 801/8134	batch_loss: 3.1662	batch_accuracy: 39.87%	lr:0.000661
Ep: 23/48	It: 851/8134	batch_loss: 3.1775	batch_accuracy: 40.01%	lr:0.000661
Ep: 23/48	It: 901/8134	batch_loss: 3.2255	batch_accuracy: 40.09%	lr:0.000661
Ep: 23/48	It: 951/8134	batch_loss: 3.1294	batch_accuracy: 39.55%	lr:0.000661
Ep: 23/48	It: 1001/8134	batch_loss: 3.1277	batch_accuracy: 40.28%	lr:0.000661
Ep: 23/48	It: 1051/8134	batch_loss: 3.2805	batch_accuracy: 38.01%	lr:0.000660
Ep: 23/48	It: 1101/8134	batch_loss: 3.1243	batch_accuracy: 40.31%	lr:0.000660
Ep: 23/48	It: 1151/8134	batch_loss: 3.1922	batch_accuracy: 39.31%	lr:0.000660
Ep: 23/48	It: 1201/8134	batch_loss: 3.1368	batch_accuracy: 40.01%	lr:0.000660
Ep: 23/48	It: 1251/8134	batch_loss: 3.2789	batch_accuracy: 39.21%	lr:0.000660
Ep: 23/48	It: 1301/8134	batch_loss: 3.2945	batch_accuracy: 38.53%	lr:0.000659
Ep: 23/48	It: 1351/8134	batch_loss: 3.0953	batch_accuracy: 40.04%	lr:0.000659
Ep: 23/48	It: 1401/8134	batch_loss: 3.2495	batch_accuracy: 38.48%	lr:0.000659
Ep: 23/48	It: 1451/8134	batch_loss: 3.1620	batch_accuracy: 39.99%	lr:0.000659
Ep: 23/48	It: 1501/8134	batch_loss: 3.2030	batch_accuracy: 39.40%	lr:0.000658
Ep: 23/48	It: 1551/8134	batch_loss: 3.3992	batch_accuracy: 36.55%	lr:0.000658
Ep: 23/48	It: 1601/8134	batch_loss: 3.1762	batch_accuracy: 39.40%	lr:0.000658
Ep: 23/48	It: 1651/8134	batch_loss: 3.0984	batch_accuracy: 40.09%	lr:0.000658
Ep: 23/48	It: 1701/8134	batch_loss: 3.2010	batch_accuracy: 40.65%	lr:0.000658
Ep: 23/48	It: 1751/8134	batch_loss: 3.1672	batch_accuracy: 40.33%	lr:0.000657
Ep: 23/48	It: 1801/8134	batch_loss: 3.2680	batch_accuracy: 38.45%	lr:0.000657
Ep: 23/48	It: 1851/8134	batch_loss: 3.1584	batch_accuracy: 40.33%	lr:0.000657
Ep: 23/48	It: 1901/8134	batch_loss: 3.1614	batch_accuracy: 40.33%	lr:0.000657
Ep: 23/48	It: 1951/8134	batch_loss: 3.2593	batch_accuracy: 37.96%	lr:0.000657
Ep: 23/48	It: 2001/8134	batch_loss: 3.3132	batch_accuracy: 38.31%	lr:0.000656
Ep: 23/48	It: 2051/8134	batch_loss: 3.2102	batch_accuracy: 38.87%	lr:0.000656
Ep: 23/48	It: 2101/8134	batch_loss: 3.1321	batch_accuracy: 40.01%	lr:0.000656
Ep: 23/48	It: 2151/8134	batch_loss: 3.2663	batch_accuracy: 38.67%	lr:0.000656
Ep: 23/48	It: 2201/8134	batch_loss: 3.2036	batch_accuracy: 39.45%	lr:0.000656
Ep: 23/48	It: 2251/8134	batch_loss: 3.2552	batch_accuracy: 38.77%	lr:0.000655
Ep: 23/48	It: 2301/8134	batch_loss: 3.2179	batch_accuracy: 38.77%	lr:0.000655
Ep: 23/48	It: 2351/8134	batch_loss: 3.2203	batch_accuracy: 38.92%	lr:0.000655
Ep: 23/48	It: 2401/8134	batch_loss: 3.1675	batch_accuracy: 39.62%	lr:0.000655
Ep: 23/48	It: 2451/8134	batch_loss: 3.1295	batch_accuracy: 40.48%	lr:0.000654
Ep: 23/48	It: 2501/8134	batch_loss: 3.2896	batch_accuracy: 38.65%	lr:0.000654
Ep: 23/48	It: 2551/8134	batch_loss: 3.2688	batch_accuracy: 37.72%	lr:0.000654
Ep: 23/48	It: 2601/8134	batch_loss: 3.1529	batch_accuracy: 40.23%	lr:0.000654
Ep: 23/48	It: 2651/8134	batch_loss: 3.2290	batch_accuracy: 38.89%	lr:0.000654
Ep: 23/48	It: 2701/8134	batch_loss: 3.1550	batch_accuracy: 40.60%	lr:0.000653
Ep: 23/48	It: 2751/8134	batch_loss: 3.2138	batch_accuracy: 39.82%	lr:0.000653
Ep: 23/48	It: 2801/8134	batch_loss: 3.1687	batch_accuracy: 40.11%	lr:0.000653
Ep: 23/48	It: 2851/8134	batch_loss: 3.1672	batch_accuracy: 39.84%	lr:0.000653
Ep: 23/48	It: 2901/8134	batch_loss: 3.2064	batch_accuracy: 39.38%	lr:0.000653
Ep: 23/48	It: 2951/8134	batch_loss: 3.2305	batch_accuracy: 39.45%	lr:0.000652
Ep: 23/48	It: 3001/8134	batch_loss: 3.0998	batch_accuracy: 40.38%	lr:0.000652
Ep: 23/48	It: 3051/8134	batch_loss: 3.1338	batch_accuracy: 41.14%	lr:0.000652
Ep: 23/48	It: 3101/8134	batch_loss: 3.2229	batch_accuracy: 39.01%	lr:0.000652
Ep: 23/48	It: 3151/8134	batch_loss: 3.2194	batch_accuracy: 39.75%	lr:0.000652
Ep: 23/48	It: 3201/8134	batch_loss: 3.3681	batch_accuracy: 37.04%	lr:0.000651
Ep: 23/48	It: 3251/8134	batch_loss: 3.1728	batch_accuracy: 39.99%	lr:0.000651
Ep: 23/48	It: 3301/8134	batch_loss: 3.2004	batch_accuracy: 39.18%	lr:0.000651
Ep: 23/48	It: 3351/8134	batch_loss: 3.1518	batch_accuracy: 40.38%	lr:0.000651
Ep: 23/48	It: 3401/8134	batch_loss: 3.1814	batch_accuracy: 39.11%	lr:0.000650
Ep: 23/48	It: 3451/8134	batch_loss: 3.1822	batch_accuracy: 38.45%	lr:0.000650
Ep: 23/48	It: 3501/8134	batch_loss: 3.2280	batch_accuracy: 38.57%	lr:0.000650
Ep: 23/48	It: 3551/8134	batch_loss: 3.2053	batch_accuracy: 39.09%	lr:0.000650
Ep: 23/48	It: 3601/8134	batch_loss: 3.1611	batch_accuracy: 39.99%	lr:0.000650
Ep: 23/48	It: 3651/8134	batch_loss: 3.2292	batch_accuracy: 39.18%	lr:0.000649
Ep: 23/48	It: 3701/8134	batch_loss: 3.2757	batch_accuracy: 38.50%	lr:0.000649
Ep: 23/48	It: 3751/8134	batch_loss: 3.0455	batch_accuracy: 41.26%	lr:0.000649
Ep: 23/48	It: 3801/8134	batch_loss: 3.2677	batch_accuracy: 39.23%	lr:0.000649
Ep: 23/48	It: 3851/8134	batch_loss: 3.1387	batch_accuracy: 41.28%	lr:0.000649
Ep: 23/48	It: 3901/8134	batch_loss: 3.2800	batch_accuracy: 38.26%	lr:0.000648
Ep: 23/48	It: 3951/8134	batch_loss: 3.1815	batch_accuracy: 39.26%	lr:0.000648
Ep: 23/48	It: 4001/8134	batch_loss: 3.1229	batch_accuracy: 40.53%	lr:0.000648
Ep: 23/48	It: 4051/8134	batch_loss: 3.2305	batch_accuracy: 38.82%	lr:0.000648
Ep: 23/48	It: 4101/8134	batch_loss: 3.2006	batch_accuracy: 40.16%	lr:0.000647
Ep: 23/48	It: 4151/8134	batch_loss: 3.1775	batch_accuracy: 40.94%	lr:0.000647
Ep: 23/48	It: 4201/8134	batch_loss: 3.2484	batch_accuracy: 39.33%	lr:0.000647
Ep: 23/48	It: 4251/8134	batch_loss: 3.2227	batch_accuracy: 38.35%	lr:0.000647
Ep: 23/48	It: 4301/8134	batch_loss: 3.2485	batch_accuracy: 38.94%	lr:0.000647
Ep: 23/48	It: 4351/8134	batch_loss: 3.1952	batch_accuracy: 39.65%	lr:0.000646
Ep: 23/48	It: 4401/8134	batch_loss: 3.1688	batch_accuracy: 39.84%	lr:0.000646
Ep: 23/48	It: 4451/8134	batch_loss: 3.1100	batch_accuracy: 40.04%	lr:0.000646
Ep: 23/48	It: 4501/8134	batch_loss: 3.0904	batch_accuracy: 41.94%	lr:0.000646
Ep: 23/48	It: 4551/8134	batch_loss: 3.2124	batch_accuracy: 39.11%	lr:0.000646
Ep: 23/48	It: 4601/8134	batch_loss: 3.2584	batch_accuracy: 38.31%	lr:0.000645
Ep: 23/48	It: 4651/8134	batch_loss: 3.1912	batch_accuracy: 39.53%	lr:0.000645
Ep: 23/48	It: 4701/8134	batch_loss: 3.1674	batch_accuracy: 40.45%	lr:0.000645
Ep: 23/48	It: 4751/8134	batch_loss: 3.3009	batch_accuracy: 38.26%	lr:0.000645
Ep: 23/48	It: 4801/8134	batch_loss: 3.2014	batch_accuracy: 39.89%	lr:0.000644
Ep: 23/48	It: 4851/8134	batch_loss: 3.3257	batch_accuracy: 36.87%	lr:0.000644
Ep: 23/48	It: 4901/8134	batch_loss: 3.1372	batch_accuracy: 40.50%	lr:0.000644
Ep: 23/48	It: 4951/8134	batch_loss: 3.2360	batch_accuracy: 39.53%	lr:0.000644
Ep: 23/48	It: 5001/8134	batch_loss: 3.2009	batch_accuracy: 38.94%	lr:0.000644
Ep: 23/48	It: 5051/8134	batch_loss: 3.2030	batch_accuracy: 38.45%	lr:0.000643
Ep: 23/48	It: 5101/8134	batch_loss: 3.2052	batch_accuracy: 39.53%	lr:0.000643
Ep: 23/48	It: 5151/8134	batch_loss: 3.2207	batch_accuracy: 39.38%	lr:0.000643
Ep: 23/48	It: 5201/8134	batch_loss: 3.2100	batch_accuracy: 39.45%	lr:0.000643
Ep: 23/48	It: 5251/8134	batch_loss: 3.2034	batch_accuracy: 40.65%	lr:0.000643
Ep: 23/48	It: 5301/8134	batch_loss: 3.1075	batch_accuracy: 40.87%	lr:0.000642
Ep: 23/48	It: 5351/8134	batch_loss: 3.2324	batch_accuracy: 39.11%	lr:0.000642
Ep: 23/48	It: 5401/8134	batch_loss: 3.0717	batch_accuracy: 41.02%	lr:0.000642
Ep: 23/48	It: 5451/8134	batch_loss: 3.1849	batch_accuracy: 39.48%	lr:0.000642
Ep: 23/48	It: 5501/8134	batch_loss: 3.0601	batch_accuracy: 41.36%	lr:0.000641
Ep: 23/48	It: 5551/8134	batch_loss: 3.3000	batch_accuracy: 38.55%	lr:0.000641
Ep: 23/48	It: 5601/8134	batch_loss: 3.0675	batch_accuracy: 41.21%	lr:0.000641
Ep: 23/48	It: 5651/8134	batch_loss: 3.2696	batch_accuracy: 40.28%	lr:0.000641
Ep: 23/48	It: 5701/8134	batch_loss: 3.2462	batch_accuracy: 39.55%	lr:0.000641
Ep: 23/48	It: 5751/8134	batch_loss: 3.2124	batch_accuracy: 39.16%	lr:0.000640
Ep: 23/48	It: 5801/8134	batch_loss: 3.2245	batch_accuracy: 38.87%	lr:0.000640
Ep: 23/48	It: 5851/8134	batch_loss: 3.0545	batch_accuracy: 41.21%	lr:0.000640
Ep: 23/48	It: 5901/8134	batch_loss: 3.1038	batch_accuracy: 40.55%	lr:0.000640
Ep: 23/48	It: 5951/8134	batch_loss: 3.2437	batch_accuracy: 38.57%	lr:0.000640
Ep: 23/48	It: 6001/8134	batch_loss: 3.1570	batch_accuracy: 39.84%	lr:0.000639
Ep: 23/48	It: 6051/8134	batch_loss: 3.1414	batch_accuracy: 40.11%	lr:0.000639
Ep: 23/48	It: 6101/8134	batch_loss: 3.1964	batch_accuracy: 39.33%	lr:0.000639
Ep: 23/48	It: 6151/8134	batch_loss: 3.2937	batch_accuracy: 38.16%	lr:0.000639
Ep: 23/48	It: 6201/8134	batch_loss: 3.1796	batch_accuracy: 39.55%	lr:0.000638
Ep: 23/48	It: 6251/8134	batch_loss: 3.2807	batch_accuracy: 38.06%	lr:0.000638
Ep: 23/48	It: 6301/8134	batch_loss: 3.2569	batch_accuracy: 38.99%	lr:0.000638
Ep: 23/48	It: 6351/8134	batch_loss: 3.2826	batch_accuracy: 38.16%	lr:0.000638
Ep: 23/48	It: 6401/8134	batch_loss: 3.1376	batch_accuracy: 41.92%	lr:0.000638
Ep: 23/48	It: 6451/8134	batch_loss: 3.1848	batch_accuracy: 39.53%	lr:0.000637
Ep: 23/48	It: 6501/8134	batch_loss: 3.1555	batch_accuracy: 39.40%	lr:0.000637
Ep: 23/48	It: 6551/8134	batch_loss: 3.2499	batch_accuracy: 39.60%	lr:0.000637
Ep: 23/48	It: 6601/8134	batch_loss: 3.1889	batch_accuracy: 40.80%	lr:0.000637
Ep: 23/48	It: 6651/8134	batch_loss: 3.1283	batch_accuracy: 41.97%	lr:0.000637
Ep: 23/48	It: 6701/8134	batch_loss: 3.0855	batch_accuracy: 40.48%	lr:0.000636
Ep: 23/48	It: 6751/8134	batch_loss: 3.1031	batch_accuracy: 41.06%	lr:0.000636
Ep: 23/48	It: 6801/8134	batch_loss: 3.2901	batch_accuracy: 38.11%	lr:0.000636
Ep: 23/48	It: 6851/8134	batch_loss: 3.1601	batch_accuracy: 38.94%	lr:0.000636
Ep: 23/48	It: 6901/8134	batch_loss: 3.2106	batch_accuracy: 40.14%	lr:0.000635
Ep: 23/48	It: 6951/8134	batch_loss: 3.2629	batch_accuracy: 38.62%	lr:0.000635
Ep: 23/48	It: 7001/8134	batch_loss: 3.2311	batch_accuracy: 39.04%	lr:0.000635
Ep: 23/48	It: 7051/8134	batch_loss: 3.1935	batch_accuracy: 39.09%	lr:0.000635
Ep: 23/48	It: 7101/8134	batch_loss: 3.3015	batch_accuracy: 38.13%	lr:0.000635
Ep: 23/48	It: 7151/8134	batch_loss: 3.1263	batch_accuracy: 41.11%	lr:0.000634
Ep: 23/48	It: 7201/8134	batch_loss: 3.2142	batch_accuracy: 38.92%	lr:0.000634
Ep: 23/48	It: 7251/8134	batch_loss: 3.2142	batch_accuracy: 39.84%	lr:0.000634
Ep: 23/48	It: 7301/8134	batch_loss: 3.1023	batch_accuracy: 41.60%	lr:0.000634
Ep: 23/48	It: 7351/8134	batch_loss: 3.2651	batch_accuracy: 38.72%	lr:0.000634
Ep: 23/48	It: 7401/8134	batch_loss: 3.2758	batch_accuracy: 38.53%	lr:0.000633
Ep: 23/48	It: 7451/8134	batch_loss: 3.2578	batch_accuracy: 39.18%	lr:0.000633
Ep: 23/48	It: 7501/8134	batch_loss: 3.2538	batch_accuracy: 37.16%	lr:0.000633
Ep: 23/48	It: 7551/8134	batch_loss: 3.2668	batch_accuracy: 38.40%	lr:0.000633
Ep: 23/48	It: 7601/8134	batch_loss: 3.1274	batch_accuracy: 41.70%	lr:0.000632
Ep: 23/48	It: 7651/8134	batch_loss: 3.2260	batch_accuracy: 39.94%	lr:0.000632
Ep: 23/48	It: 7701/8134	batch_loss: 3.2447	batch_accuracy: 39.72%	lr:0.000632
Ep: 23/48	It: 7751/8134	batch_loss: 3.1436	batch_accuracy: 41.06%	lr:0.000632
Ep: 23/48	It: 7801/8134	batch_loss: 3.1021	batch_accuracy: 41.21%	lr:0.000632
Ep: 23/48	It: 7851/8134	batch_loss: 3.1355	batch_accuracy: 40.82%	lr:0.000631
Ep: 23/48	It: 7901/8134	batch_loss: 3.0914	batch_accuracy: 41.28%	lr:0.000631
Ep: 23/48	It: 7951/8134	batch_loss: 3.2079	batch_accuracy: 39.16%	lr:0.000631
Ep: 23/48	It: 8001/8134	batch_loss: 3.1020	batch_accuracy: 40.48%	lr:0.000631
Ep: 23/48	It: 8051/8134	batch_loss: 3.0882	batch_accuracy: 41.06%	lr:0.000631
Ep: 23/48	It: 8101/8134	batch_loss: 3.1947	batch_accuracy: 39.62%	lr:0.000630
Ep: 23/48	It: 8134/8134	batch_loss: 3.1925	batch_accuracy: 40.79%	lr:0.000630


Generated text for input text "You" is:
Youviated by theorefe of theologist and to aest theologians who had not been theologians and who were told. In theologians, who are in theology, theologians have come to theorizing that he was not the case for theologian and had been the first to provide a detailed account of this work. It is the author of a study of the literary history of modern art, in which McCarthy's analysis of the history of art is based on a description of a new form of art in the early modern world. The essay argues that it is of the first form of art, with the aim of a comparative study of art, the materialist and theological approach, and theorizing that theology is a more intriguing and more intuitive. The study, the theoretical and methodological background of this article is an analytical study of the literary practices of the Russian culture in the period of the 19th century. The analysis of the data is based on the results of the study of the Chinese characters of the Russian language. The data of the study is the data of the study of the Russian language of Russian language.


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 24/48	It: 1/8134	batch_loss: 3.1520	batch_accuracy: 40.87%	lr:0.000630
Ep: 24/48	It: 51/8134	batch_loss: 3.2443	batch_accuracy: 39.70%	lr:0.000630
Ep: 24/48	It: 101/8134	batch_loss: 3.1802	batch_accuracy: 39.65%	lr:0.000630
Ep: 24/48	It: 151/8134	batch_loss: 3.1249	batch_accuracy: 41.16%	lr:0.000630
Ep: 24/48	It: 201/8134	batch_loss: 3.1479	batch_accuracy: 40.50%	lr:0.000629
Ep: 24/48	It: 251/8134	batch_loss: 3.2293	batch_accuracy: 39.82%	lr:0.000629
Ep: 24/48	It: 301/8134	batch_loss: 3.1327	batch_accuracy: 40.26%	lr:0.000629
Ep: 24/48	It: 351/8134	batch_loss: 3.1305	batch_accuracy: 39.79%	lr:0.000629
Ep: 24/48	It: 401/8134	batch_loss: 3.1331	batch_accuracy: 39.53%	lr:0.000628
Ep: 24/48	It: 451/8134	batch_loss: 3.1809	batch_accuracy: 40.09%	lr:0.000628
Ep: 24/48	It: 501/8134	batch_loss: 3.1570	batch_accuracy: 40.06%	lr:0.000628
Ep: 24/48	It: 551/8134	batch_loss: 3.2757	batch_accuracy: 38.04%	lr:0.000628
Ep: 24/48	It: 601/8134	batch_loss: 3.3082	batch_accuracy: 37.92%	lr:0.000628
Ep: 24/48	It: 651/8134	batch_loss: 3.2196	batch_accuracy: 39.38%	lr:0.000627
Ep: 24/48	It: 701/8134	batch_loss: 3.1135	batch_accuracy: 40.38%	lr:0.000627
Ep: 24/48	It: 751/8134	batch_loss: 3.1865	batch_accuracy: 39.94%	lr:0.000627
Ep: 24/48	It: 801/8134	batch_loss: 3.0893	batch_accuracy: 40.21%	lr:0.000627
Ep: 24/48	It: 851/8134	batch_loss: 3.1751	batch_accuracy: 39.79%	lr:0.000627
Ep: 24/48	It: 901/8134	batch_loss: 3.2037	batch_accuracy: 39.84%	lr:0.000626
Ep: 24/48	It: 951/8134	batch_loss: 3.1276	batch_accuracy: 40.23%	lr:0.000626
Ep: 24/48	It: 1001/8134	batch_loss: 3.1857	batch_accuracy: 39.72%	lr:0.000626
Ep: 24/48	It: 1051/8134	batch_loss: 3.3556	batch_accuracy: 37.45%	lr:0.000626
Ep: 24/48	It: 1101/8134	batch_loss: 3.2250	batch_accuracy: 39.82%	lr:0.000625
Ep: 24/48	It: 1151/8134	batch_loss: 3.1053	batch_accuracy: 39.11%	lr:0.000625
Ep: 24/48	It: 1201/8134	batch_loss: 3.0910	batch_accuracy: 41.65%	lr:0.000625
Ep: 24/48	It: 1251/8134	batch_loss: 3.2181	batch_accuracy: 38.40%	lr:0.000625
Ep: 24/48	It: 1301/8134	batch_loss: 3.1617	batch_accuracy: 39.60%	lr:0.000625
Ep: 24/48	It: 1351/8134	batch_loss: 3.2377	batch_accuracy: 39.26%	lr:0.000624
Ep: 24/48	It: 1401/8134	batch_loss: 3.0362	batch_accuracy: 41.89%	lr:0.000624
Ep: 24/48	It: 1451/8134	batch_loss: 3.1495	batch_accuracy: 40.55%	lr:0.000624
Ep: 24/48	It: 1501/8134	batch_loss: 3.2005	batch_accuracy: 40.01%	lr:0.000624
Ep: 24/48	It: 1551/8134	batch_loss: 3.2178	batch_accuracy: 39.60%	lr:0.000624
Ep: 24/48	It: 1601/8134	batch_loss: 3.1277	batch_accuracy: 40.77%	lr:0.000623
Ep: 24/48	It: 1651/8134	batch_loss: 3.1194	batch_accuracy: 41.09%	lr:0.000623
Ep: 24/48	It: 1701/8134	batch_loss: 3.3764	batch_accuracy: 37.89%	lr:0.000623
Ep: 24/48	It: 1751/8134	batch_loss: 3.3354	batch_accuracy: 38.04%	lr:0.000623
Ep: 24/48	It: 1801/8134	batch_loss: 3.1849	batch_accuracy: 40.09%	lr:0.000622
Ep: 24/48	It: 1851/8134	batch_loss: 3.3185	batch_accuracy: 37.96%	lr:0.000622
Ep: 24/48	It: 1901/8134	batch_loss: 3.1867	batch_accuracy: 39.60%	lr:0.000622
Ep: 24/48	It: 1951/8134	batch_loss: 3.1794	batch_accuracy: 39.72%	lr:0.000622
Ep: 24/48	It: 2001/8134	batch_loss: 3.1905	batch_accuracy: 39.36%	lr:0.000622
Ep: 24/48	It: 2051/8134	batch_loss: 3.1418	batch_accuracy: 39.84%	lr:0.000621
Ep: 24/48	It: 2101/8134	batch_loss: 3.1298	batch_accuracy: 40.31%	lr:0.000621
Ep: 24/48	It: 2151/8134	batch_loss: 3.1999	batch_accuracy: 39.84%	lr:0.000621
Ep: 24/48	It: 2201/8134	batch_loss: 3.1443	batch_accuracy: 40.94%	lr:0.000621
Ep: 24/48	It: 2251/8134	batch_loss: 3.2314	batch_accuracy: 39.58%	lr:0.000620
Ep: 24/48	It: 2301/8134	batch_loss: 3.2088	batch_accuracy: 38.94%	lr:0.000620
Ep: 24/48	It: 2351/8134	batch_loss: 3.1949	batch_accuracy: 39.72%	lr:0.000620
Ep: 24/48	It: 2401/8134	batch_loss: 3.1679	batch_accuracy: 39.94%	lr:0.000620
Ep: 24/48	It: 2451/8134	batch_loss: 3.2262	batch_accuracy: 39.82%	lr:0.000620
Ep: 24/48	It: 2501/8134	batch_loss: 3.1354	batch_accuracy: 41.33%	lr:0.000619
Ep: 24/48	It: 2551/8134	batch_loss: 3.0928	batch_accuracy: 40.19%	lr:0.000619
Ep: 24/48	It: 2601/8134	batch_loss: 3.1240	batch_accuracy: 41.14%	lr:0.000619
Ep: 24/48	It: 2651/8134	batch_loss: 3.1448	batch_accuracy: 39.94%	lr:0.000619
Ep: 24/48	It: 2701/8134	batch_loss: 3.0615	batch_accuracy: 40.53%	lr:0.000619
Ep: 24/48	It: 2751/8134	batch_loss: 3.1228	batch_accuracy: 40.21%	lr:0.000618
Ep: 24/48	It: 2801/8134	batch_loss: 3.1010	batch_accuracy: 41.60%	lr:0.000618
Ep: 24/48	It: 2851/8134	batch_loss: 3.1572	batch_accuracy: 39.75%	lr:0.000618
Ep: 24/48	It: 2901/8134	batch_loss: 3.2641	batch_accuracy: 39.06%	lr:0.000618
Ep: 24/48	It: 2951/8134	batch_loss: 3.2314	batch_accuracy: 38.79%	lr:0.000617
Ep: 24/48	It: 3001/8134	batch_loss: 3.0734	batch_accuracy: 40.94%	lr:0.000617
Ep: 24/48	It: 3051/8134	batch_loss: 3.2055	batch_accuracy: 39.79%	lr:0.000617
Ep: 24/48	It: 3101/8134	batch_loss: 3.1852	batch_accuracy: 39.58%	lr:0.000617
Ep: 24/48	It: 3151/8134	batch_loss: 3.1489	batch_accuracy: 40.48%	lr:0.000617
Ep: 24/48	It: 3201/8134	batch_loss: 3.2091	batch_accuracy: 39.89%	lr:0.000616
Ep: 24/48	It: 3251/8134	batch_loss: 3.2229	batch_accuracy: 39.14%	lr:0.000616
Ep: 24/48	It: 3301/8134	batch_loss: 3.1718	batch_accuracy: 40.36%	lr:0.000616
Ep: 24/48	It: 3351/8134	batch_loss: 3.1571	batch_accuracy: 40.94%	lr:0.000616
Ep: 24/48	It: 3401/8134	batch_loss: 3.0155	batch_accuracy: 42.02%	lr:0.000616
Ep: 24/48	It: 3451/8134	batch_loss: 3.1883	batch_accuracy: 38.84%	lr:0.000615
Ep: 24/48	It: 3501/8134	batch_loss: 3.2744	batch_accuracy: 38.33%	lr:0.000615
Ep: 24/48	It: 3551/8134	batch_loss: 3.1728	batch_accuracy: 40.31%	lr:0.000615
Ep: 24/48	It: 3601/8134	batch_loss: 3.1794	batch_accuracy: 39.94%	lr:0.000615
Ep: 24/48	It: 3651/8134	batch_loss: 3.2590	batch_accuracy: 38.28%	lr:0.000614
Ep: 24/48	It: 3701/8134	batch_loss: 3.1104	batch_accuracy: 39.65%	lr:0.000614
Ep: 24/48	It: 3751/8134	batch_loss: 3.1623	batch_accuracy: 40.38%	lr:0.000614
Ep: 24/48	It: 3801/8134	batch_loss: 3.2458	batch_accuracy: 39.70%	lr:0.000614
Ep: 24/48	It: 3851/8134	batch_loss: 3.1640	batch_accuracy: 40.92%	lr:0.000614
Ep: 24/48	It: 3901/8134	batch_loss: 3.1989	batch_accuracy: 38.75%	lr:0.000613
Ep: 24/48	It: 3951/8134	batch_loss: 3.1213	batch_accuracy: 39.72%	lr:0.000613
Ep: 24/48	It: 4001/8134	batch_loss: 3.0797	batch_accuracy: 41.21%	lr:0.000613
Ep: 24/48	It: 4051/8134	batch_loss: 3.1266	batch_accuracy: 41.28%	lr:0.000613
Ep: 24/48	It: 4101/8134	batch_loss: 3.1446	batch_accuracy: 40.53%	lr:0.000612
Ep: 24/48	It: 4151/8134	batch_loss: 3.1938	batch_accuracy: 39.40%	lr:0.000612
Ep: 24/48	It: 4201/8134	batch_loss: 3.1216	batch_accuracy: 40.09%	lr:0.000612
Ep: 24/48	It: 4251/8134	batch_loss: 3.2779	batch_accuracy: 37.87%	lr:0.000612
Ep: 24/48	It: 4301/8134	batch_loss: 3.2673	batch_accuracy: 38.89%	lr:0.000612
Ep: 24/48	It: 4351/8134	batch_loss: 3.2408	batch_accuracy: 38.45%	lr:0.000611
Ep: 24/48	It: 4401/8134	batch_loss: 3.1392	batch_accuracy: 40.94%	lr:0.000611
Ep: 24/48	It: 4451/8134	batch_loss: 3.1519	batch_accuracy: 39.09%	lr:0.000611
Ep: 24/48	It: 4501/8134	batch_loss: 3.2112	batch_accuracy: 38.89%	lr:0.000611
Ep: 24/48	It: 4551/8134	batch_loss: 3.1961	batch_accuracy: 39.89%	lr:0.000611
Ep: 24/48	It: 4601/8134	batch_loss: 3.1598	batch_accuracy: 39.58%	lr:0.000610
Ep: 24/48	It: 4651/8134	batch_loss: 3.2133	batch_accuracy: 40.01%	lr:0.000610
Ep: 24/48	It: 4701/8134	batch_loss: 3.1043	batch_accuracy: 39.94%	lr:0.000610
Ep: 24/48	It: 4751/8134	batch_loss: 3.3228	batch_accuracy: 37.55%	lr:0.000610
Ep: 24/48	It: 4801/8134	batch_loss: 3.1595	batch_accuracy: 40.19%	lr:0.000609
Ep: 24/48	It: 4851/8134	batch_loss: 3.1077	batch_accuracy: 41.41%	lr:0.000609
Ep: 24/48	It: 4901/8134	batch_loss: 3.1656	batch_accuracy: 38.96%	lr:0.000609
Ep: 24/48	It: 4951/8134	batch_loss: 3.1630	batch_accuracy: 39.45%	lr:0.000609
Ep: 24/48	It: 5001/8134	batch_loss: 3.1348	batch_accuracy: 40.84%	lr:0.000609
Ep: 24/48	It: 5051/8134	batch_loss: 3.2124	batch_accuracy: 38.96%	lr:0.000608
Ep: 24/48	It: 5101/8134	batch_loss: 3.0633	batch_accuracy: 41.58%	lr:0.000608
Ep: 24/48	It: 5151/8134	batch_loss: 3.0693	batch_accuracy: 41.60%	lr:0.000608
Ep: 24/48	It: 5201/8134	batch_loss: 3.1324	batch_accuracy: 40.92%	lr:0.000608
Ep: 24/48	It: 5251/8134	batch_loss: 3.1626	batch_accuracy: 40.60%	lr:0.000607
Ep: 24/48	It: 5301/8134	batch_loss: 3.2346	batch_accuracy: 39.11%	lr:0.000607
Ep: 24/48	It: 5351/8134	batch_loss: 3.2006	batch_accuracy: 39.79%	lr:0.000607
Ep: 24/48	It: 5401/8134	batch_loss: 3.1355	batch_accuracy: 40.09%	lr:0.000607
Ep: 24/48	It: 5451/8134	batch_loss: 3.2781	batch_accuracy: 38.35%	lr:0.000607
Ep: 24/48	It: 5501/8134	batch_loss: 3.1851	batch_accuracy: 39.92%	lr:0.000606
Ep: 24/48	It: 5551/8134	batch_loss: 3.1913	batch_accuracy: 40.82%	lr:0.000606
Ep: 24/48	It: 5601/8134	batch_loss: 3.1171	batch_accuracy: 40.84%	lr:0.000606
Ep: 24/48	It: 5651/8134	batch_loss: 3.1715	batch_accuracy: 40.26%	lr:0.000606
Ep: 24/48	It: 5701/8134	batch_loss: 3.1569	batch_accuracy: 40.82%	lr:0.000606
Ep: 24/48	It: 5751/8134	batch_loss: 3.1867	batch_accuracy: 39.94%	lr:0.000605
Ep: 24/48	It: 5801/8134	batch_loss: 3.2247	batch_accuracy: 38.70%	lr:0.000605
Ep: 24/48	It: 5851/8134	batch_loss: 3.1518	batch_accuracy: 39.70%	lr:0.000605
Ep: 24/48	It: 5901/8134	batch_loss: 3.1115	batch_accuracy: 40.16%	lr:0.000605
Ep: 24/48	It: 5951/8134	batch_loss: 3.0168	batch_accuracy: 41.99%	lr:0.000604
Ep: 24/48	It: 6001/8134	batch_loss: 3.2601	batch_accuracy: 38.13%	lr:0.000604
Ep: 24/48	It: 6051/8134	batch_loss: 3.1867	batch_accuracy: 39.48%	lr:0.000604
Ep: 24/48	It: 6101/8134	batch_loss: 3.1578	batch_accuracy: 40.82%	lr:0.000604
Ep: 24/48	It: 6151/8134	batch_loss: 3.2553	batch_accuracy: 38.79%	lr:0.000604
Ep: 24/48	It: 6201/8134	batch_loss: 3.0950	batch_accuracy: 39.92%	lr:0.000603
Ep: 24/48	It: 6251/8134	batch_loss: 3.1177	batch_accuracy: 40.58%	lr:0.000603
Ep: 24/48	It: 6301/8134	batch_loss: 3.1857	batch_accuracy: 40.41%	lr:0.000603
Ep: 24/48	It: 6351/8134	batch_loss: 3.3150	batch_accuracy: 38.11%	lr:0.000603
Ep: 24/48	It: 6401/8134	batch_loss: 3.1847	batch_accuracy: 40.50%	lr:0.000602
Ep: 24/48	It: 6451/8134	batch_loss: 3.2209	batch_accuracy: 39.38%	lr:0.000602
Ep: 24/48	It: 6501/8134	batch_loss: 3.1557	batch_accuracy: 39.77%	lr:0.000602
Ep: 24/48	It: 6551/8134	batch_loss: 3.2231	batch_accuracy: 38.84%	lr:0.000602
Ep: 24/48	It: 6601/8134	batch_loss: 3.2291	batch_accuracy: 39.11%	lr:0.000602
Ep: 24/48	It: 6651/8134	batch_loss: 3.1525	batch_accuracy: 39.11%	lr:0.000601
Ep: 24/48	It: 6701/8134	batch_loss: 3.2566	batch_accuracy: 37.94%	lr:0.000601
Ep: 24/48	It: 6751/8134	batch_loss: 3.2115	batch_accuracy: 39.33%	lr:0.000601
Ep: 24/48	It: 6801/8134	batch_loss: 3.2305	batch_accuracy: 38.87%	lr:0.000601
Ep: 24/48	It: 6851/8134	batch_loss: 3.2251	batch_accuracy: 39.60%	lr:0.000601
Ep: 24/48	It: 6901/8134	batch_loss: 3.2596	batch_accuracy: 37.89%	lr:0.000600
Ep: 24/48	It: 6951/8134	batch_loss: 3.0963	batch_accuracy: 41.72%	lr:0.000600
Ep: 24/48	It: 7001/8134	batch_loss: 3.2794	batch_accuracy: 38.89%	lr:0.000600
Ep: 24/48	It: 7051/8134	batch_loss: 3.1614	batch_accuracy: 39.94%	lr:0.000600
Ep: 24/48	It: 7101/8134	batch_loss: 3.2134	batch_accuracy: 39.16%	lr:0.000599
Ep: 24/48	It: 7151/8134	batch_loss: 3.1122	batch_accuracy: 41.09%	lr:0.000599
Ep: 24/48	It: 7201/8134	batch_loss: 3.2020	batch_accuracy: 39.06%	lr:0.000599
Ep: 24/48	It: 7251/8134	batch_loss: 3.1586	batch_accuracy: 40.06%	lr:0.000599
Ep: 24/48	It: 7301/8134	batch_loss: 3.2387	batch_accuracy: 39.09%	lr:0.000599
Ep: 24/48	It: 7351/8134	batch_loss: 3.1858	batch_accuracy: 39.16%	lr:0.000598
Ep: 24/48	It: 7401/8134	batch_loss: 3.0990	batch_accuracy: 41.11%	lr:0.000598
Ep: 24/48	It: 7451/8134	batch_loss: 3.1519	batch_accuracy: 40.50%	lr:0.000598
Ep: 24/48	It: 7501/8134	batch_loss: 3.1477	batch_accuracy: 40.84%	lr:0.000598
Ep: 24/48	It: 7551/8134	batch_loss: 3.2362	batch_accuracy: 38.77%	lr:0.000597
Ep: 24/48	It: 7601/8134	batch_loss: 3.2443	batch_accuracy: 37.79%	lr:0.000597
Ep: 24/48	It: 7651/8134	batch_loss: 3.1495	batch_accuracy: 40.16%	lr:0.000597
Ep: 24/48	It: 7701/8134	batch_loss: 3.2488	batch_accuracy: 39.38%	lr:0.000597
Ep: 24/48	It: 7751/8134	batch_loss: 3.1409	batch_accuracy: 40.97%	lr:0.000597
Ep: 24/48	It: 7801/8134	batch_loss: 3.2187	batch_accuracy: 39.18%	lr:0.000596
Ep: 24/48	It: 7851/8134	batch_loss: 3.1613	batch_accuracy: 39.82%	lr:0.000596
Ep: 24/48	It: 7901/8134	batch_loss: 3.0687	batch_accuracy: 41.53%	lr:0.000596
Ep: 24/48	It: 7951/8134	batch_loss: 3.0898	batch_accuracy: 40.53%	lr:0.000596
Ep: 24/48	It: 8001/8134	batch_loss: 3.2592	batch_accuracy: 39.23%	lr:0.000595
Ep: 24/48	It: 8051/8134	batch_loss: 3.2114	batch_accuracy: 40.14%	lr:0.000595
Ep: 24/48	It: 8101/8134	batch_loss: 3.3113	batch_accuracy: 37.55%	lr:0.000595
Ep: 24/48	It: 8134/8134	batch_loss: 3.1034	batch_accuracy: 40.62%	lr:0.000595


Generated text for input text "You" is:
You, etc. The main purpose of this study was to evaluate the effects of aircraft on the mechanical properties of theories and the results of the mechanical properties of concrete in terms of the elasticity of concrete under different loading conditions. The experimental results show that the strength of concrete is better than the strength of concrete composite concrete composite with concrete. The effect of stiffness and buckling load is investigated by the different types of concrete loads. The experimental results show that the concrete strength of concrete structures with concrete and concrete structure can be improved by increasing the amount of plastic strain and the amount of plastic deformation.
<eot>
<sot>
[Distinct patterns of the immune complexes of the lung].

Distinct patterns of the immunologically active strains of lung, lung, lung, and liver were examined in 19 cases. In one case the changes of the immunologically active strains of lung were noted. The results of a study of the effect of a new strain of lung on the lung tissue showed that the same results were obtained. The results of the present study indicate that the protective effect of the virus on lung tissue was not due to lung damage and that the lung tissue is not immunoreactive, which in


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 25/48	It: 1/8134	batch_loss: 3.0415	batch_accuracy: 42.70%	lr:0.000595
Ep: 25/48	It: 51/8134	batch_loss: 3.2029	batch_accuracy: 40.11%	lr:0.000595
Ep: 25/48	It: 101/8134	batch_loss: 3.2117	batch_accuracy: 39.38%	lr:0.000594
Ep: 25/48	It: 151/8134	batch_loss: 3.2039	batch_accuracy: 39.62%	lr:0.000594
Ep: 25/48	It: 201/8134	batch_loss: 3.3108	batch_accuracy: 38.62%	lr:0.000594
Ep: 25/48	It: 251/8134	batch_loss: 3.1323	batch_accuracy: 39.94%	lr:0.000594
Ep: 25/48	It: 301/8134	batch_loss: 3.1206	batch_accuracy: 41.46%	lr:0.000594
Ep: 25/48	It: 351/8134	batch_loss: 3.2661	batch_accuracy: 38.89%	lr:0.000593
Ep: 25/48	It: 401/8134	batch_loss: 3.1307	batch_accuracy: 40.84%	lr:0.000593
Ep: 25/48	It: 451/8134	batch_loss: 3.1587	batch_accuracy: 40.41%	lr:0.000593
Ep: 25/48	It: 501/8134	batch_loss: 3.2310	batch_accuracy: 38.79%	lr:0.000593
Ep: 25/48	It: 551/8134	batch_loss: 3.2570	batch_accuracy: 39.72%	lr:0.000593
Ep: 25/48	It: 601/8134	batch_loss: 3.1840	batch_accuracy: 40.04%	lr:0.000592
Ep: 25/48	It: 651/8134	batch_loss: 3.2469	batch_accuracy: 39.28%	lr:0.000592
Ep: 25/48	It: 701/8134	batch_loss: 3.1839	batch_accuracy: 39.23%	lr:0.000592
Ep: 25/48	It: 751/8134	batch_loss: 3.1354	batch_accuracy: 39.70%	lr:0.000592
Ep: 25/48	It: 801/8134	batch_loss: 3.2209	batch_accuracy: 39.36%	lr:0.000591
Ep: 25/48	It: 851/8134	batch_loss: 3.1053	batch_accuracy: 40.16%	lr:0.000591
Ep: 25/48	It: 901/8134	batch_loss: 3.1621	batch_accuracy: 39.87%	lr:0.000591
Ep: 25/48	It: 951/8134	batch_loss: 3.1695	batch_accuracy: 41.48%	lr:0.000591
Ep: 25/48	It: 1001/8134	batch_loss: 3.2406	batch_accuracy: 38.92%	lr:0.000591
Ep: 25/48	It: 1051/8134	batch_loss: 3.3499	batch_accuracy: 37.16%	lr:0.000590
Ep: 25/48	It: 1101/8134	batch_loss: 3.0547	batch_accuracy: 41.80%	lr:0.000590
Ep: 25/48	It: 1151/8134	batch_loss: 3.2958	batch_accuracy: 37.60%	lr:0.000590
Ep: 25/48	It: 1201/8134	batch_loss: 3.0601	batch_accuracy: 41.38%	lr:0.000590
Ep: 25/48	It: 1251/8134	batch_loss: 3.1398	batch_accuracy: 40.50%	lr:0.000589
Ep: 25/48	It: 1301/8134	batch_loss: 3.1756	batch_accuracy: 39.65%	lr:0.000589
Ep: 25/48	It: 1351/8134	batch_loss: 3.2363	batch_accuracy: 38.75%	lr:0.000589
Ep: 25/48	It: 1401/8134	batch_loss: 3.1548	batch_accuracy: 39.94%	lr:0.000589
Ep: 25/48	It: 1451/8134	batch_loss: 3.2059	batch_accuracy: 39.48%	lr:0.000589
Ep: 25/48	It: 1501/8134	batch_loss: 3.1622	batch_accuracy: 39.40%	lr:0.000588
Ep: 25/48	It: 1551/8134	batch_loss: 3.2386	batch_accuracy: 39.04%	lr:0.000588
Ep: 25/48	It: 1601/8134	batch_loss: 3.2246	batch_accuracy: 39.65%	lr:0.000588
Ep: 25/48	It: 1651/8134	batch_loss: 3.2226	batch_accuracy: 39.26%	lr:0.000588
Ep: 25/48	It: 1701/8134	batch_loss: 3.1161	batch_accuracy: 39.53%	lr:0.000587
Ep: 25/48	It: 1751/8134	batch_loss: 3.2875	batch_accuracy: 39.36%	lr:0.000587
Ep: 25/48	It: 1801/8134	batch_loss: 3.2083	batch_accuracy: 39.53%	lr:0.000587
Ep: 25/48	It: 1851/8134	batch_loss: 3.1319	batch_accuracy: 40.92%	lr:0.000587
Ep: 25/48	It: 1901/8134	batch_loss: 2.9960	batch_accuracy: 42.38%	lr:0.000587
Ep: 25/48	It: 1951/8134	batch_loss: 3.2523	batch_accuracy: 38.94%	lr:0.000586
Ep: 25/48	It: 2001/8134	batch_loss: 3.0126	batch_accuracy: 42.24%	lr:0.000586
Ep: 25/48	It: 2051/8134	batch_loss: 3.2916	batch_accuracy: 37.74%	lr:0.000586
Ep: 25/48	It: 2101/8134	batch_loss: 3.1508	batch_accuracy: 39.33%	lr:0.000586
Ep: 25/48	It: 2151/8134	batch_loss: 3.1833	batch_accuracy: 39.50%	lr:0.000585
Ep: 25/48	It: 2201/8134	batch_loss: 3.1099	batch_accuracy: 40.26%	lr:0.000585
Ep: 25/48	It: 2251/8134	batch_loss: 3.1042	batch_accuracy: 41.53%	lr:0.000585
Ep: 25/48	It: 2301/8134	batch_loss: 3.1222	batch_accuracy: 41.06%	lr:0.000585
Ep: 25/48	It: 2351/8134	batch_loss: 3.0640	batch_accuracy: 41.85%	lr:0.000585
Ep: 25/48	It: 2401/8134	batch_loss: 3.1403	batch_accuracy: 40.19%	lr:0.000584
Ep: 25/48	It: 2451/8134	batch_loss: 3.1488	batch_accuracy: 41.50%	lr:0.000584
Ep: 25/48	It: 2501/8134	batch_loss: 3.1089	batch_accuracy: 40.89%	lr:0.000584
Ep: 25/48	It: 2551/8134	batch_loss: 3.2216	batch_accuracy: 39.70%	lr:0.000584
Ep: 25/48	It: 2601/8134	batch_loss: 3.1821	batch_accuracy: 40.11%	lr:0.000584
Ep: 25/48	It: 2651/8134	batch_loss: 3.1886	batch_accuracy: 39.58%	lr:0.000583
Ep: 25/48	It: 2701/8134	batch_loss: 3.2425	batch_accuracy: 37.50%	lr:0.000583
Ep: 25/48	It: 2751/8134	batch_loss: 3.2482	batch_accuracy: 38.28%	lr:0.000583
Ep: 25/48	It: 2801/8134	batch_loss: 3.2276	batch_accuracy: 39.65%	lr:0.000583
Ep: 25/48	It: 2851/8134	batch_loss: 3.0856	batch_accuracy: 40.60%	lr:0.000582
Ep: 25/48	It: 2901/8134	batch_loss: 3.1772	batch_accuracy: 40.23%	lr:0.000582
Ep: 25/48	It: 2951/8134	batch_loss: 3.2264	batch_accuracy: 39.23%	lr:0.000582
Ep: 25/48	It: 3001/8134	batch_loss: 3.2288	batch_accuracy: 39.36%	lr:0.000582
Ep: 25/48	It: 3051/8134	batch_loss: 3.2250	batch_accuracy: 39.92%	lr:0.000582
Ep: 25/48	It: 3101/8134	batch_loss: 3.1391	batch_accuracy: 40.89%	lr:0.000581
Ep: 25/48	It: 3151/8134	batch_loss: 3.0414	batch_accuracy: 40.48%	lr:0.000581
Ep: 25/48	It: 3201/8134	batch_loss: 3.1410	batch_accuracy: 39.94%	lr:0.000581
Ep: 25/48	It: 3251/8134	batch_loss: 3.1510	batch_accuracy: 40.62%	lr:0.000581
Ep: 25/48	It: 3301/8134	batch_loss: 3.1732	batch_accuracy: 38.65%	lr:0.000580
Ep: 25/48	It: 3351/8134	batch_loss: 3.2890	batch_accuracy: 38.75%	lr:0.000580
Ep: 25/48	It: 3401/8134	batch_loss: 3.2266	batch_accuracy: 39.36%	lr:0.000580
Ep: 25/48	It: 3451/8134	batch_loss: 3.1398	batch_accuracy: 41.16%	lr:0.000580
Ep: 25/48	It: 3501/8134	batch_loss: 3.0803	batch_accuracy: 41.50%	lr:0.000580
Ep: 25/48	It: 3551/8134	batch_loss: 3.2240	batch_accuracy: 39.18%	lr:0.000579
Ep: 25/48	It: 3601/8134	batch_loss: 3.1542	batch_accuracy: 39.77%	lr:0.000579
Ep: 25/48	It: 3651/8134	batch_loss: 3.0905	batch_accuracy: 40.33%	lr:0.000579
Ep: 25/48	It: 3701/8134	batch_loss: 3.1423	batch_accuracy: 40.14%	lr:0.000579
Ep: 25/48	It: 3751/8134	batch_loss: 3.2119	batch_accuracy: 39.36%	lr:0.000578
Ep: 25/48	It: 3801/8134	batch_loss: 3.2182	batch_accuracy: 40.23%	lr:0.000578
Ep: 25/48	It: 3851/8134	batch_loss: 3.2998	batch_accuracy: 38.26%	lr:0.000578
Ep: 25/48	It: 3901/8134	batch_loss: 3.1388	batch_accuracy: 40.60%	lr:0.000578
Ep: 25/48	It: 3951/8134	batch_loss: 3.0473	batch_accuracy: 40.99%	lr:0.000578
Ep: 25/48	It: 4001/8134	batch_loss: 3.1277	batch_accuracy: 40.55%	lr:0.000577
Ep: 25/48	It: 4051/8134	batch_loss: 3.0684	batch_accuracy: 41.70%	lr:0.000577
Ep: 25/48	It: 4101/8134	batch_loss: 3.1779	batch_accuracy: 41.50%	lr:0.000577
Ep: 25/48	It: 4151/8134	batch_loss: 3.0958	batch_accuracy: 41.31%	lr:0.000577
Ep: 25/48	It: 4201/8134	batch_loss: 3.3157	batch_accuracy: 38.33%	lr:0.000576
Ep: 25/48	It: 4251/8134	batch_loss: 3.2958	batch_accuracy: 38.31%	lr:0.000576
Ep: 25/48	It: 4301/8134	batch_loss: 3.0771	batch_accuracy: 40.36%	lr:0.000576
Ep: 25/48	It: 4351/8134	batch_loss: 3.1602	batch_accuracy: 40.60%	lr:0.000576
Ep: 25/48	It: 4401/8134	batch_loss: 3.1277	batch_accuracy: 40.92%	lr:0.000576
Ep: 25/48	It: 4451/8134	batch_loss: 3.1589	batch_accuracy: 41.36%	lr:0.000575
Ep: 25/48	It: 4501/8134	batch_loss: 3.2082	batch_accuracy: 38.79%	lr:0.000575
Ep: 25/48	It: 4551/8134	batch_loss: 3.1045	batch_accuracy: 40.06%	lr:0.000575
Ep: 25/48	It: 4601/8134	batch_loss: 3.1779	batch_accuracy: 39.89%	lr:0.000575
Ep: 25/48	It: 4651/8134	batch_loss: 3.2511	batch_accuracy: 38.77%	lr:0.000575
Ep: 25/48	It: 4701/8134	batch_loss: 3.1336	batch_accuracy: 40.36%	lr:0.000574
Ep: 25/48	It: 4751/8134	batch_loss: 3.1206	batch_accuracy: 41.26%	lr:0.000574
Ep: 25/48	It: 4801/8134	batch_loss: 3.1201	batch_accuracy: 41.09%	lr:0.000574
Ep: 25/48	It: 4851/8134	batch_loss: 3.0976	batch_accuracy: 40.62%	lr:0.000574
Ep: 25/48	It: 4901/8134	batch_loss: 3.2019	batch_accuracy: 40.19%	lr:0.000573
Ep: 25/48	It: 4951/8134	batch_loss: 3.1270	batch_accuracy: 39.94%	lr:0.000573
Ep: 25/48	It: 5001/8134	batch_loss: 3.1434	batch_accuracy: 41.11%	lr:0.000573
Ep: 25/48	It: 5051/8134	batch_loss: 3.1451	batch_accuracy: 39.79%	lr:0.000573
Ep: 25/48	It: 5101/8134	batch_loss: 3.0904	batch_accuracy: 40.80%	lr:0.000573
Ep: 25/48	It: 5151/8134	batch_loss: 3.2726	batch_accuracy: 39.60%	lr:0.000572
Ep: 25/48	It: 5201/8134	batch_loss: 3.0990	batch_accuracy: 40.33%	lr:0.000572
Ep: 25/48	It: 5251/8134	batch_loss: 3.1362	batch_accuracy: 40.04%	lr:0.000572
Ep: 25/48	It: 5301/8134	batch_loss: 3.1112	batch_accuracy: 40.80%	lr:0.000572
Ep: 25/48	It: 5351/8134	batch_loss: 3.1841	batch_accuracy: 39.70%	lr:0.000571
Ep: 25/48	It: 5401/8134	batch_loss: 3.2327	batch_accuracy: 38.65%	lr:0.000571
Ep: 25/48	It: 5451/8134	batch_loss: 3.1219	batch_accuracy: 40.55%	lr:0.000571
Ep: 25/48	It: 5501/8134	batch_loss: 3.1777	batch_accuracy: 40.62%	lr:0.000571
Ep: 25/48	It: 5551/8134	batch_loss: 3.1691	batch_accuracy: 40.14%	lr:0.000571
Ep: 25/48	It: 5601/8134	batch_loss: 3.1337	batch_accuracy: 40.23%	lr:0.000570
Ep: 25/48	It: 5651/8134	batch_loss: 3.1859	batch_accuracy: 39.14%	lr:0.000570
Ep: 25/48	It: 5701/8134	batch_loss: 3.1399	batch_accuracy: 41.72%	lr:0.000570
Ep: 25/48	It: 5751/8134	batch_loss: 3.2965	batch_accuracy: 38.21%	lr:0.000570
Ep: 25/48	It: 5801/8134	batch_loss: 3.0632	batch_accuracy: 42.11%	lr:0.000569
Ep: 25/48	It: 5851/8134	batch_loss: 3.1032	batch_accuracy: 41.24%	lr:0.000569
Ep: 25/48	It: 5901/8134	batch_loss: 3.1286	batch_accuracy: 39.45%	lr:0.000569
Ep: 25/48	It: 5951/8134	batch_loss: 3.3317	batch_accuracy: 38.48%	lr:0.000569
Ep: 25/48	It: 6001/8134	batch_loss: 3.1508	batch_accuracy: 40.33%	lr:0.000569
Ep: 25/48	It: 6051/8134	batch_loss: 3.1256	batch_accuracy: 40.60%	lr:0.000568
Ep: 25/48	It: 6101/8134	batch_loss: 3.2113	batch_accuracy: 39.72%	lr:0.000568
Ep: 25/48	It: 6151/8134	batch_loss: 3.0227	batch_accuracy: 42.33%	lr:0.000568
Ep: 25/48	It: 6201/8134	batch_loss: 3.0504	batch_accuracy: 41.46%	lr:0.000568
Ep: 25/48	It: 6251/8134	batch_loss: 3.1942	batch_accuracy: 40.21%	lr:0.000567
Ep: 25/48	It: 6301/8134	batch_loss: 3.1396	batch_accuracy: 41.26%	lr:0.000567
Ep: 25/48	It: 6351/8134	batch_loss: 3.1164	batch_accuracy: 40.65%	lr:0.000567
Ep: 25/48	It: 6401/8134	batch_loss: 3.0831	batch_accuracy: 40.26%	lr:0.000567
Ep: 25/48	It: 6451/8134	batch_loss: 3.1530	batch_accuracy: 40.19%	lr:0.000567
Ep: 25/48	It: 6501/8134	batch_loss: 3.1671	batch_accuracy: 39.99%	lr:0.000566
Ep: 25/48	It: 6551/8134	batch_loss: 3.2051	batch_accuracy: 39.45%	lr:0.000566
Ep: 25/48	It: 6601/8134	batch_loss: 3.1446	batch_accuracy: 40.21%	lr:0.000566
Ep: 25/48	It: 6651/8134	batch_loss: 3.2859	batch_accuracy: 38.53%	lr:0.000566
Ep: 25/48	It: 6701/8134	batch_loss: 3.1466	batch_accuracy: 40.09%	lr:0.000565
Ep: 25/48	It: 6751/8134	batch_loss: 3.1459	batch_accuracy: 40.31%	lr:0.000565
Ep: 25/48	It: 6801/8134	batch_loss: 3.1401	batch_accuracy: 40.94%	lr:0.000565
Ep: 25/48	It: 6851/8134	batch_loss: 3.3437	batch_accuracy: 36.79%	lr:0.000565
Ep: 25/48	It: 6901/8134	batch_loss: 3.1268	batch_accuracy: 40.23%	lr:0.000565
Ep: 25/48	It: 6951/8134	batch_loss: 3.1245	batch_accuracy: 40.55%	lr:0.000564
Ep: 25/48	It: 7001/8134	batch_loss: 3.2374	batch_accuracy: 39.28%	lr:0.000564
Ep: 25/48	It: 7051/8134	batch_loss: 3.1664	batch_accuracy: 39.31%	lr:0.000564
Ep: 25/48	It: 7101/8134	batch_loss: 3.0760	batch_accuracy: 41.36%	lr:0.000564
Ep: 25/48	It: 7151/8134	batch_loss: 3.0890	batch_accuracy: 40.53%	lr:0.000563
Ep: 25/48	It: 7201/8134	batch_loss: 3.2254	batch_accuracy: 39.11%	lr:0.000563
Ep: 25/48	It: 7251/8134	batch_loss: 3.0700	batch_accuracy: 41.77%	lr:0.000563
Ep: 25/48	It: 7301/8134	batch_loss: 3.2324	batch_accuracy: 38.48%	lr:0.000563
Ep: 25/48	It: 7351/8134	batch_loss: 3.3618	batch_accuracy: 37.28%	lr:0.000563
Ep: 25/48	It: 7401/8134	batch_loss: 3.1714	batch_accuracy: 39.60%	lr:0.000562
Ep: 25/48	It: 7451/8134	batch_loss: 3.1793	batch_accuracy: 40.28%	lr:0.000562
Ep: 25/48	It: 7501/8134	batch_loss: 2.9829	batch_accuracy: 42.77%	lr:0.000562
Ep: 25/48	It: 7551/8134	batch_loss: 3.0841	batch_accuracy: 40.53%	lr:0.000562
Ep: 25/48	It: 7601/8134	batch_loss: 3.1027	batch_accuracy: 41.58%	lr:0.000561
Ep: 25/48	It: 7651/8134	batch_loss: 3.1939	batch_accuracy: 39.23%	lr:0.000561
Ep: 25/48	It: 7701/8134	batch_loss: 3.0941	batch_accuracy: 41.14%	lr:0.000561
Ep: 25/48	It: 7751/8134	batch_loss: 3.1714	batch_accuracy: 39.99%	lr:0.000561
Ep: 25/48	It: 7801/8134	batch_loss: 3.1403	batch_accuracy: 40.21%	lr:0.000561
Ep: 25/48	It: 7851/8134	batch_loss: 3.2294	batch_accuracy: 38.40%	lr:0.000560
Ep: 25/48	It: 7901/8134	batch_loss: 3.1585	batch_accuracy: 39.79%	lr:0.000560
Ep: 25/48	It: 7951/8134	batch_loss: 3.1508	batch_accuracy: 40.75%	lr:0.000560
Ep: 25/48	It: 8001/8134	batch_loss: 3.1574	batch_accuracy: 39.89%	lr:0.000560
Ep: 25/48	It: 8051/8134	batch_loss: 3.1204	batch_accuracy: 41.41%	lr:0.000560
Ep: 25/48	It: 8101/8134	batch_loss: 3.1317	batch_accuracy: 40.55%	lr:0.000559
Ep: 25/48	It: 8134/8134	batch_loss: 3.2117	batch_accuracy: 40.49%	lr:0.000559


Generated text for input text "You" is:
You, and, more, thesis, and theories of thesis, as well as theory, as well as theories of theories of theology, or theology, and theology.
<eot>
<sot>
The City of theology: Anthropology and theology of “Americanism”

This article examines the relationship between the religion of the world and the world. It explores the role of the religion in the process of social transformation. The religious significance of religion is studied by analysing the historiography of a particular religion and the rhetoric of the religious and political philosophy. It is found that the phenomenon of religion and religion, the form of religion, the concept of religion, and the principle of religion, as well as the concept of religion and religion. The article concludes that the principle of religion is very much more intellectual than the theory of religion. It is argued that religion is not a philosophy of religion, and that religion is not always the case.
<eot>
<sot>
The Impact of the Short-Term P


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 26/48	It: 1/8134	batch_loss: 3.2210	batch_accuracy: 38.92%	lr:0.000559
Ep: 26/48	It: 51/8134	batch_loss: 3.1286	batch_accuracy: 40.87%	lr:0.000559
Ep: 26/48	It: 101/8134	batch_loss: 3.2422	batch_accuracy: 38.65%	lr:0.000559
Ep: 26/48	It: 151/8134	batch_loss: 3.2794	batch_accuracy: 39.04%	lr:0.000558
Ep: 26/48	It: 201/8134	batch_loss: 3.1729	batch_accuracy: 40.04%	lr:0.000558
Ep: 26/48	It: 251/8134	batch_loss: 3.2579	batch_accuracy: 39.38%	lr:0.000558
Ep: 26/48	It: 301/8134	batch_loss: 3.3021	batch_accuracy: 38.13%	lr:0.000558
Ep: 26/48	It: 351/8134	batch_loss: 3.0830	batch_accuracy: 41.67%	lr:0.000558
Ep: 26/48	It: 401/8134	batch_loss: 3.2018	batch_accuracy: 38.89%	lr:0.000557
Ep: 26/48	It: 451/8134	batch_loss: 3.1437	batch_accuracy: 40.09%	lr:0.000557
Ep: 26/48	It: 501/8134	batch_loss: 3.1477	batch_accuracy: 39.45%	lr:0.000557
Ep: 26/48	It: 551/8134	batch_loss: 3.1322	batch_accuracy: 39.77%	lr:0.000557
Ep: 26/48	It: 601/8134	batch_loss: 3.1182	batch_accuracy: 39.72%	lr:0.000556
Ep: 26/48	It: 651/8134	batch_loss: 3.1726	batch_accuracy: 38.45%	lr:0.000556
Ep: 26/48	It: 701/8134	batch_loss: 3.0068	batch_accuracy: 41.87%	lr:0.000556
Ep: 26/48	It: 751/8134	batch_loss: 3.1997	batch_accuracy: 40.16%	lr:0.000556
Ep: 26/48	It: 801/8134	batch_loss: 3.1253	batch_accuracy: 40.21%	lr:0.000556
Ep: 26/48	It: 851/8134	batch_loss: 3.1310	batch_accuracy: 40.33%	lr:0.000555
Ep: 26/48	It: 901/8134	batch_loss: 3.1716	batch_accuracy: 41.04%	lr:0.000555
Ep: 26/48	It: 951/8134	batch_loss: 3.1801	batch_accuracy: 39.97%	lr:0.000555
Ep: 26/48	It: 1001/8134	batch_loss: 3.1645	batch_accuracy: 40.09%	lr:0.000555
Ep: 26/48	It: 1051/8134	batch_loss: 3.1281	batch_accuracy: 40.23%	lr:0.000554
Ep: 26/48	It: 1101/8134	batch_loss: 3.2290	batch_accuracy: 38.60%	lr:0.000554
Ep: 26/48	It: 1151/8134	batch_loss: 3.2083	batch_accuracy: 39.06%	lr:0.000554
Ep: 26/48	It: 1201/8134	batch_loss: 3.1849	batch_accuracy: 38.75%	lr:0.000554
Ep: 26/48	It: 1251/8134	batch_loss: 3.0359	batch_accuracy: 41.87%	lr:0.000554
Ep: 26/48	It: 1301/8134	batch_loss: 3.1312	batch_accuracy: 40.28%	lr:0.000553
Ep: 26/48	It: 1351/8134	batch_loss: 3.2046	batch_accuracy: 39.79%	lr:0.000553
Ep: 26/48	It: 1401/8134	batch_loss: 3.1598	batch_accuracy: 40.23%	lr:0.000553
Ep: 26/48	It: 1451/8134	batch_loss: 3.1370	batch_accuracy: 40.09%	lr:0.000553
Ep: 26/48	It: 1501/8134	batch_loss: 3.0982	batch_accuracy: 39.84%	lr:0.000553
Ep: 26/48	It: 1551/8134	batch_loss: 3.0587	batch_accuracy: 41.33%	lr:0.000552
Ep: 26/48	It: 1601/8134	batch_loss: 3.2286	batch_accuracy: 40.09%	lr:0.000552
Ep: 26/48	It: 1651/8134	batch_loss: 3.1351	batch_accuracy: 40.53%	lr:0.000552
Ep: 26/48	It: 1701/8134	batch_loss: 3.1843	batch_accuracy: 40.62%	lr:0.000552
Ep: 26/48	It: 1751/8134	batch_loss: 3.1672	batch_accuracy: 39.55%	lr:0.000551
Ep: 26/48	It: 1801/8134	batch_loss: 3.1831	batch_accuracy: 39.23%	lr:0.000551
Ep: 26/48	It: 1851/8134	batch_loss: 3.1481	batch_accuracy: 40.67%	lr:0.000551
Ep: 26/48	It: 1901/8134	batch_loss: 3.1626	batch_accuracy: 39.70%	lr:0.000551
Ep: 26/48	It: 1951/8134	batch_loss: 3.0507	batch_accuracy: 40.21%	lr:0.000551
Ep: 26/48	It: 2001/8134	batch_loss: 3.0786	batch_accuracy: 41.04%	lr:0.000550
Ep: 26/48	It: 2051/8134	batch_loss: 3.1072	batch_accuracy: 41.92%	lr:0.000550
Ep: 26/48	It: 2101/8134	batch_loss: 3.1882	batch_accuracy: 39.82%	lr:0.000550
Ep: 26/48	It: 2151/8134	batch_loss: 3.1911	batch_accuracy: 39.26%	lr:0.000550
Ep: 26/48	It: 2201/8134	batch_loss: 3.1695	batch_accuracy: 40.06%	lr:0.000549
Ep: 26/48	It: 2251/8134	batch_loss: 3.0591	batch_accuracy: 41.14%	lr:0.000549
Ep: 26/48	It: 2301/8134	batch_loss: 3.2736	batch_accuracy: 38.72%	lr:0.000549
Ep: 26/48	It: 2351/8134	batch_loss: 3.0861	batch_accuracy: 40.65%	lr:0.000549
Ep: 26/48	It: 2401/8134	batch_loss: 3.1953	batch_accuracy: 39.75%	lr:0.000549
Ep: 26/48	It: 2451/8134	batch_loss: 3.0969	batch_accuracy: 41.48%	lr:0.000548
Ep: 26/48	It: 2501/8134	batch_loss: 3.1239	batch_accuracy: 40.16%	lr:0.000548
Ep: 26/48	It: 2551/8134	batch_loss: 3.1163	batch_accuracy: 41.19%	lr:0.000548
Ep: 26/48	It: 2601/8134	batch_loss: 3.1260	batch_accuracy: 40.82%	lr:0.000548
Ep: 26/48	It: 2651/8134	batch_loss: 3.2191	batch_accuracy: 38.50%	lr:0.000547
Ep: 26/48	It: 2701/8134	batch_loss: 3.1830	batch_accuracy: 38.84%	lr:0.000547
Ep: 26/48	It: 2751/8134	batch_loss: 3.1781	batch_accuracy: 38.79%	lr:0.000547
Ep: 26/48	It: 2801/8134	batch_loss: 3.1236	batch_accuracy: 39.77%	lr:0.000547
Ep: 26/48	It: 2851/8134	batch_loss: 3.1592	batch_accuracy: 40.06%	lr:0.000547
Ep: 26/48	It: 2901/8134	batch_loss: 3.0685	batch_accuracy: 41.06%	lr:0.000546
Ep: 26/48	It: 2951/8134	batch_loss: 3.0834	batch_accuracy: 41.11%	lr:0.000546
Ep: 26/48	It: 3001/8134	batch_loss: 3.1611	batch_accuracy: 40.43%	lr:0.000546
Ep: 26/48	It: 3051/8134	batch_loss: 3.1973	batch_accuracy: 38.89%	lr:0.000546
Ep: 26/48	It: 3101/8134	batch_loss: 3.1227	batch_accuracy: 40.89%	lr:0.000545
Ep: 26/48	It: 3151/8134	batch_loss: 3.1255	batch_accuracy: 41.80%	lr:0.000545
Ep: 26/48	It: 3201/8134	batch_loss: 3.2644	batch_accuracy: 39.38%	lr:0.000545
Ep: 26/48	It: 3251/8134	batch_loss: 3.1317	batch_accuracy: 39.60%	lr:0.000545
Ep: 26/48	It: 3301/8134	batch_loss: 3.0543	batch_accuracy: 41.06%	lr:0.000545
Ep: 26/48	It: 3351/8134	batch_loss: 3.1793	batch_accuracy: 40.55%	lr:0.000544
Ep: 26/48	It: 3401/8134	batch_loss: 3.2056	batch_accuracy: 39.36%	lr:0.000544
Ep: 26/48	It: 3451/8134	batch_loss: 3.2547	batch_accuracy: 39.38%	lr:0.000544
Ep: 26/48	It: 3501/8134	batch_loss: 3.1758	batch_accuracy: 40.67%	lr:0.000544
Ep: 26/48	It: 3551/8134	batch_loss: 3.1499	batch_accuracy: 40.31%	lr:0.000543
Ep: 26/48	It: 3601/8134	batch_loss: 2.9914	batch_accuracy: 41.97%	lr:0.000543
Ep: 26/48	It: 3651/8134	batch_loss: 3.2167	batch_accuracy: 38.72%	lr:0.000543
Ep: 26/48	It: 3701/8134	batch_loss: 3.2113	batch_accuracy: 39.72%	lr:0.000543
Ep: 26/48	It: 3751/8134	batch_loss: 3.1687	batch_accuracy: 39.84%	lr:0.000543
Ep: 26/48	It: 3801/8134	batch_loss: 3.1513	batch_accuracy: 40.36%	lr:0.000542
Ep: 26/48	It: 3851/8134	batch_loss: 3.0829	batch_accuracy: 41.50%	lr:0.000542
Ep: 26/48	It: 3901/8134	batch_loss: 3.1314	batch_accuracy: 40.26%	lr:0.000542
Ep: 26/48	It: 3951/8134	batch_loss: 3.1992	batch_accuracy: 39.58%	lr:0.000542
Ep: 26/48	It: 4001/8134	batch_loss: 3.1879	batch_accuracy: 40.28%	lr:0.000541
Ep: 26/48	It: 4051/8134	batch_loss: 3.0671	batch_accuracy: 41.21%	lr:0.000541
Ep: 26/48	It: 4101/8134	batch_loss: 3.1742	batch_accuracy: 39.62%	lr:0.000541
Ep: 26/48	It: 4151/8134	batch_loss: 3.1034	batch_accuracy: 42.04%	lr:0.000541
Ep: 26/48	It: 4201/8134	batch_loss: 3.2263	batch_accuracy: 39.60%	lr:0.000541
Ep: 26/48	It: 4251/8134	batch_loss: 3.2091	batch_accuracy: 39.11%	lr:0.000540
Ep: 26/48	It: 4301/8134	batch_loss: 3.2915	batch_accuracy: 37.50%	lr:0.000540
Ep: 26/48	It: 4351/8134	batch_loss: 3.2334	batch_accuracy: 39.99%	lr:0.000540
Ep: 26/48	It: 4401/8134	batch_loss: 3.1376	batch_accuracy: 40.92%	lr:0.000540
Ep: 26/48	It: 4451/8134	batch_loss: 3.1443	batch_accuracy: 40.55%	lr:0.000539
Ep: 26/48	It: 4501/8134	batch_loss: 3.2173	batch_accuracy: 38.89%	lr:0.000539
Ep: 26/48	It: 4551/8134	batch_loss: 3.1427	batch_accuracy: 41.24%	lr:0.000539
Ep: 26/48	It: 4601/8134	batch_loss: 3.1289	batch_accuracy: 41.06%	lr:0.000539
Ep: 26/48	It: 4651/8134	batch_loss: 3.2332	batch_accuracy: 39.72%	lr:0.000539
Ep: 26/48	It: 4701/8134	batch_loss: 3.2374	batch_accuracy: 39.79%	lr:0.000538
Ep: 26/48	It: 4751/8134	batch_loss: 3.1667	batch_accuracy: 40.58%	lr:0.000538
Ep: 26/48	It: 4801/8134	batch_loss: 3.1444	batch_accuracy: 40.72%	lr:0.000538
Ep: 26/48	It: 4851/8134	batch_loss: 3.1471	batch_accuracy: 39.82%	lr:0.000538
Ep: 26/48	It: 4901/8134	batch_loss: 3.1677	batch_accuracy: 40.23%	lr:0.000537
Ep: 26/48	It: 4951/8134	batch_loss: 3.2434	batch_accuracy: 38.89%	lr:0.000537
Ep: 26/48	It: 5001/8134	batch_loss: 3.1651	batch_accuracy: 40.04%	lr:0.000537
Ep: 26/48	It: 5051/8134	batch_loss: 3.1109	batch_accuracy: 40.87%	lr:0.000537
Ep: 26/48	It: 5101/8134	batch_loss: 3.0439	batch_accuracy: 41.43%	lr:0.000537
Ep: 26/48	It: 5151/8134	batch_loss: 3.1443	batch_accuracy: 40.16%	lr:0.000536
Ep: 26/48	It: 5201/8134	batch_loss: 3.1916	batch_accuracy: 39.65%	lr:0.000536
Ep: 26/48	It: 5251/8134	batch_loss: 3.0302	batch_accuracy: 42.14%	lr:0.000536
Ep: 26/48	It: 5301/8134	batch_loss: 3.1843	batch_accuracy: 39.60%	lr:0.000536
Ep: 26/48	It: 5351/8134	batch_loss: 3.3382	batch_accuracy: 37.62%	lr:0.000535
Ep: 26/48	It: 5401/8134	batch_loss: 3.0519	batch_accuracy: 41.77%	lr:0.000535
Ep: 26/48	It: 5451/8134	batch_loss: 3.1029	batch_accuracy: 40.77%	lr:0.000535
Ep: 26/48	It: 5501/8134	batch_loss: 3.1974	batch_accuracy: 38.65%	lr:0.000535
Ep: 26/48	It: 5551/8134	batch_loss: 3.1346	batch_accuracy: 41.38%	lr:0.000535
Ep: 26/48	It: 5601/8134	batch_loss: 3.1115	batch_accuracy: 40.41%	lr:0.000534
Ep: 26/48	It: 5651/8134	batch_loss: 3.0532	batch_accuracy: 40.31%	lr:0.000534
Ep: 26/48	It: 5701/8134	batch_loss: 3.1182	batch_accuracy: 39.38%	lr:0.000534
Ep: 26/48	It: 5751/8134	batch_loss: 3.2417	batch_accuracy: 38.89%	lr:0.000534
Ep: 26/48	It: 5801/8134	batch_loss: 3.0449	batch_accuracy: 40.75%	lr:0.000533
Ep: 26/48	It: 5851/8134	batch_loss: 3.1615	batch_accuracy: 39.92%	lr:0.000533
Ep: 26/48	It: 5901/8134	batch_loss: 3.1831	batch_accuracy: 40.01%	lr:0.000533
Ep: 26/48	It: 5951/8134	batch_loss: 3.2412	batch_accuracy: 38.38%	lr:0.000533
Ep: 26/48	It: 6001/8134	batch_loss: 3.1551	batch_accuracy: 40.26%	lr:0.000533
Ep: 26/48	It: 6051/8134	batch_loss: 3.1444	batch_accuracy: 39.75%	lr:0.000532
Ep: 26/48	It: 6101/8134	batch_loss: 3.1330	batch_accuracy: 40.70%	lr:0.000532
Ep: 26/48	It: 6151/8134	batch_loss: 3.1793	batch_accuracy: 39.04%	lr:0.000532
Ep: 26/48	It: 6201/8134	batch_loss: 3.1523	batch_accuracy: 40.53%	lr:0.000532
Ep: 26/48	It: 6251/8134	batch_loss: 3.0386	batch_accuracy: 40.89%	lr:0.000531
Ep: 26/48	It: 6301/8134	batch_loss: 3.1285	batch_accuracy: 40.80%	lr:0.000531
Ep: 26/48	It: 6351/8134	batch_loss: 3.0362	batch_accuracy: 41.94%	lr:0.000531
Ep: 26/48	It: 6401/8134	batch_loss: 3.1565	batch_accuracy: 40.31%	lr:0.000531
Ep: 26/48	It: 6451/8134	batch_loss: 3.2121	batch_accuracy: 38.65%	lr:0.000531
Ep: 26/48	It: 6501/8134	batch_loss: 3.1894	batch_accuracy: 39.60%	lr:0.000530
Ep: 26/48	It: 6551/8134	batch_loss: 3.2557	batch_accuracy: 40.04%	lr:0.000530
Ep: 26/48	It: 6601/8134	batch_loss: 3.1993	batch_accuracy: 38.26%	lr:0.000530
Ep: 26/48	It: 6651/8134	batch_loss: 3.1048	batch_accuracy: 41.48%	lr:0.000530
Ep: 26/48	It: 6701/8134	batch_loss: 3.1230	batch_accuracy: 39.92%	lr:0.000529
Ep: 26/48	It: 6751/8134	batch_loss: 3.1589	batch_accuracy: 40.65%	lr:0.000529
Ep: 26/48	It: 6801/8134	batch_loss: 3.1383	batch_accuracy: 39.65%	lr:0.000529
Ep: 26/48	It: 6851/8134	batch_loss: 3.2154	batch_accuracy: 38.18%	lr:0.000529
Ep: 26/48	It: 6901/8134	batch_loss: 3.0605	batch_accuracy: 41.60%	lr:0.000529
Ep: 26/48	It: 6951/8134	batch_loss: 3.1316	batch_accuracy: 40.58%	lr:0.000528
Ep: 26/48	It: 7001/8134	batch_loss: 3.1726	batch_accuracy: 39.53%	lr:0.000528
Ep: 26/48	It: 7051/8134	batch_loss: 3.0686	batch_accuracy: 40.94%	lr:0.000528
Ep: 26/48	It: 7101/8134	batch_loss: 3.1127	batch_accuracy: 41.14%	lr:0.000528
Ep: 26/48	It: 7151/8134	batch_loss: 3.1502	batch_accuracy: 40.80%	lr:0.000527
Ep: 26/48	It: 7201/8134	batch_loss: 3.2045	batch_accuracy: 39.75%	lr:0.000527
Ep: 26/48	It: 7251/8134	batch_loss: 3.1911	batch_accuracy: 39.75%	lr:0.000527
Ep: 26/48	It: 7301/8134	batch_loss: 3.2176	batch_accuracy: 39.67%	lr:0.000527
Ep: 26/48	It: 7351/8134	batch_loss: 3.0479	batch_accuracy: 41.50%	lr:0.000527
Ep: 26/48	It: 7401/8134	batch_loss: 3.1923	batch_accuracy: 39.84%	lr:0.000526
Ep: 26/48	It: 7451/8134	batch_loss: 3.2487	batch_accuracy: 39.18%	lr:0.000526
Ep: 26/48	It: 7501/8134	batch_loss: 3.1385	batch_accuracy: 40.26%	lr:0.000526
Ep: 26/48	It: 7551/8134	batch_loss: 3.1885	batch_accuracy: 39.62%	lr:0.000526
Ep: 26/48	It: 7601/8134	batch_loss: 3.1430	batch_accuracy: 39.89%	lr:0.000525
Ep: 26/48	It: 7651/8134	batch_loss: 3.1627	batch_accuracy: 40.01%	lr:0.000525
Ep: 26/48	It: 7701/8134	batch_loss: 3.1750	batch_accuracy: 40.55%	lr:0.000525
Ep: 26/48	It: 7751/8134	batch_loss: 3.1505	batch_accuracy: 40.06%	lr:0.000525
Ep: 26/48	It: 7801/8134	batch_loss: 3.2037	batch_accuracy: 40.01%	lr:0.000525
Ep: 26/48	It: 7851/8134	batch_loss: 3.1667	batch_accuracy: 39.55%	lr:0.000524
Ep: 26/48	It: 7901/8134	batch_loss: 3.1530	batch_accuracy: 40.23%	lr:0.000524
Ep: 26/48	It: 7951/8134	batch_loss: 3.1335	batch_accuracy: 40.28%	lr:0.000524
Ep: 26/48	It: 8001/8134	batch_loss: 3.1963	batch_accuracy: 39.26%	lr:0.000524
Ep: 26/48	It: 8051/8134	batch_loss: 3.2102	batch_accuracy: 38.67%	lr:0.000523
Ep: 26/48	It: 8101/8134	batch_loss: 3.1412	batch_accuracy: 40.36%	lr:0.000523
Ep: 26/48	It: 8134/8134	batch_loss: 3.2278	batch_accuracy: 38.93%	lr:0.000523


Generated text for input text "You" is:
You’s work is theories of theorizing and theories of theology. Theological imaginative, and aesthetic, and theological, philosophical, aesthetic, and also theological and philosophical studies of theological theory. In theological and geographical analysis, Martin D. D. Lawrence is also in the book of the first chapters, but the book is not a comprehensive review of the history of his own, but a more detailed and well-studied book. The book is based on a short history of his books, which is a good example of how the book’s original form and theorized by the articles published in his edited collection. The book also provides a short summary of the works of this volume, with a special section on the topic of the books.
<eot>
<sot>
Treatment of Pseudomonas aeruginosa with Bacillus subtilis strain of Streptococcus pneumoniae.

Bacillus subtilis strain PCC 693T was isolated from a Streptococcus pneumoniae strain PCC 591T, which enc


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 27/48	It: 1/8134	batch_loss: 3.1454	batch_accuracy: 40.41%	lr:0.000523
Ep: 27/48	It: 51/8134	batch_loss: 3.0621	batch_accuracy: 40.87%	lr:0.000523
Ep: 27/48	It: 101/8134	batch_loss: 3.2199	batch_accuracy: 40.04%	lr:0.000523
Ep: 27/48	It: 151/8134	batch_loss: 3.1480	batch_accuracy: 40.19%	lr:0.000522
Ep: 27/48	It: 201/8134	batch_loss: 3.1158	batch_accuracy: 40.04%	lr:0.000522
Ep: 27/48	It: 251/8134	batch_loss: 3.2387	batch_accuracy: 38.11%	lr:0.000522
Ep: 27/48	It: 301/8134	batch_loss: 3.0616	batch_accuracy: 41.80%	lr:0.000522
Ep: 27/48	It: 351/8134	batch_loss: 3.0085	batch_accuracy: 42.04%	lr:0.000522
Ep: 27/48	It: 401/8134	batch_loss: 3.1345	batch_accuracy: 41.04%	lr:0.000521
Ep: 27/48	It: 451/8134	batch_loss: 3.1252	batch_accuracy: 39.62%	lr:0.000521
Ep: 27/48	It: 501/8134	batch_loss: 3.0736	batch_accuracy: 41.43%	lr:0.000521
Ep: 27/48	It: 551/8134	batch_loss: 3.0675	batch_accuracy: 41.33%	lr:0.000521
Ep: 27/48	It: 601/8134	batch_loss: 3.1646	batch_accuracy: 40.14%	lr:0.000520
Ep: 27/48	It: 651/8134	batch_loss: 3.0644	batch_accuracy: 40.99%	lr:0.000520
Ep: 27/48	It: 701/8134	batch_loss: 3.1007	batch_accuracy: 40.19%	lr:0.000520
Ep: 27/48	It: 751/8134	batch_loss: 3.0659	batch_accuracy: 40.87%	lr:0.000520
Ep: 27/48	It: 801/8134	batch_loss: 2.9889	batch_accuracy: 43.33%	lr:0.000520
Ep: 27/48	It: 851/8134	batch_loss: 3.1322	batch_accuracy: 40.04%	lr:0.000519
Ep: 27/48	It: 901/8134	batch_loss: 3.1350	batch_accuracy: 39.58%	lr:0.000519
Ep: 27/48	It: 951/8134	batch_loss: 3.0439	batch_accuracy: 41.92%	lr:0.000519
Ep: 27/48	It: 1001/8134	batch_loss: 3.0423	batch_accuracy: 42.19%	lr:0.000519
Ep: 27/48	It: 1051/8134	batch_loss: 3.1673	batch_accuracy: 39.48%	lr:0.000518
Ep: 27/48	It: 1101/8134	batch_loss: 3.1445	batch_accuracy: 40.16%	lr:0.000518
Ep: 27/48	It: 1151/8134	batch_loss: 3.1250	batch_accuracy: 40.60%	lr:0.000518
Ep: 27/48	It: 1201/8134	batch_loss: 3.2111	batch_accuracy: 39.06%	lr:0.000518
Ep: 27/48	It: 1251/8134	batch_loss: 3.0778	batch_accuracy: 40.70%	lr:0.000518
Ep: 27/48	It: 1301/8134	batch_loss: 3.3081	batch_accuracy: 37.87%	lr:0.000517
Ep: 27/48	It: 1351/8134	batch_loss: 3.0898	batch_accuracy: 40.06%	lr:0.000517
Ep: 27/48	It: 1401/8134	batch_loss: 3.1392	batch_accuracy: 39.75%	lr:0.000517
Ep: 27/48	It: 1451/8134	batch_loss: 3.0590	batch_accuracy: 41.19%	lr:0.000517
Ep: 27/48	It: 1501/8134	batch_loss: 3.2035	batch_accuracy: 38.35%	lr:0.000516
Ep: 27/48	It: 1551/8134	batch_loss: 3.1634	batch_accuracy: 40.87%	lr:0.000516
Ep: 27/48	It: 1601/8134	batch_loss: 3.1548	batch_accuracy: 39.38%	lr:0.000516
Ep: 27/48	It: 1651/8134	batch_loss: 3.1762	batch_accuracy: 39.92%	lr:0.000516
Ep: 27/48	It: 1701/8134	batch_loss: 3.0241	batch_accuracy: 42.58%	lr:0.000516
Ep: 27/48	It: 1751/8134	batch_loss: 3.0924	batch_accuracy: 41.28%	lr:0.000515
Ep: 27/48	It: 1801/8134	batch_loss: 3.0104	batch_accuracy: 41.99%	lr:0.000515
Ep: 27/48	It: 1851/8134	batch_loss: 3.0838	batch_accuracy: 41.50%	lr:0.000515
Ep: 27/48	It: 1901/8134	batch_loss: 3.0729	batch_accuracy: 41.41%	lr:0.000515
Ep: 27/48	It: 1951/8134	batch_loss: 3.1140	batch_accuracy: 40.65%	lr:0.000514
Ep: 27/48	It: 2001/8134	batch_loss: 3.1618	batch_accuracy: 40.31%	lr:0.000514
Ep: 27/48	It: 2051/8134	batch_loss: 3.1177	batch_accuracy: 40.67%	lr:0.000514
Ep: 27/48	It: 2101/8134	batch_loss: 3.0423	batch_accuracy: 42.02%	lr:0.000514
Ep: 27/48	It: 2151/8134	batch_loss: 3.0947	batch_accuracy: 40.97%	lr:0.000514
Ep: 27/48	It: 2201/8134	batch_loss: 3.1811	batch_accuracy: 40.36%	lr:0.000513
Ep: 27/48	It: 2251/8134	batch_loss: 3.0705	batch_accuracy: 39.94%	lr:0.000513
Ep: 27/48	It: 2301/8134	batch_loss: 3.1877	batch_accuracy: 39.84%	lr:0.000513
Ep: 27/48	It: 2351/8134	batch_loss: 3.1851	batch_accuracy: 38.65%	lr:0.000513
Ep: 27/48	It: 2401/8134	batch_loss: 3.0664	batch_accuracy: 41.06%	lr:0.000512
Ep: 27/48	It: 2451/8134	batch_loss: 3.2479	batch_accuracy: 37.96%	lr:0.000512
Ep: 27/48	It: 2501/8134	batch_loss: 3.1866	batch_accuracy: 40.48%	lr:0.000512
Ep: 27/48	It: 2551/8134	batch_loss: 3.1922	batch_accuracy: 39.48%	lr:0.000512
Ep: 27/48	It: 2601/8134	batch_loss: 3.0974	batch_accuracy: 40.06%	lr:0.000512
Ep: 27/48	It: 2651/8134	batch_loss: 3.0312	batch_accuracy: 41.04%	lr:0.000511
Ep: 27/48	It: 2701/8134	batch_loss: 3.1829	batch_accuracy: 39.82%	lr:0.000511
Ep: 27/48	It: 2751/8134	batch_loss: 3.1521	batch_accuracy: 39.84%	lr:0.000511
Ep: 27/48	It: 2801/8134	batch_loss: 3.1054	batch_accuracy: 40.45%	lr:0.000511
Ep: 27/48	It: 2851/8134	batch_loss: 3.0555	batch_accuracy: 42.11%	lr:0.000510
Ep: 27/48	It: 2901/8134	batch_loss: 3.1482	batch_accuracy: 39.67%	lr:0.000510
Ep: 27/48	It: 2951/8134	batch_loss: 3.0321	batch_accuracy: 41.09%	lr:0.000510
Ep: 27/48	It: 3001/8134	batch_loss: 3.2455	batch_accuracy: 39.01%	lr:0.000510
Ep: 27/48	It: 3051/8134	batch_loss: 3.1126	batch_accuracy: 39.99%	lr:0.000510
Ep: 27/48	It: 3101/8134	batch_loss: 3.1470	batch_accuracy: 40.06%	lr:0.000509
Ep: 27/48	It: 3151/8134	batch_loss: 3.0863	batch_accuracy: 41.89%	lr:0.000509
Ep: 27/48	It: 3201/8134	batch_loss: 3.2062	batch_accuracy: 39.75%	lr:0.000509
Ep: 27/48	It: 3251/8134	batch_loss: 3.1203	batch_accuracy: 40.87%	lr:0.000509
Ep: 27/48	It: 3301/8134	batch_loss: 3.1138	batch_accuracy: 40.58%	lr:0.000508
Ep: 27/48	It: 3351/8134	batch_loss: 3.1310	batch_accuracy: 41.09%	lr:0.000508
Ep: 27/48	It: 3401/8134	batch_loss: 3.0937	batch_accuracy: 40.94%	lr:0.000508
Ep: 27/48	It: 3451/8134	batch_loss: 3.2838	batch_accuracy: 39.38%	lr:0.000508
Ep: 27/48	It: 3501/8134	batch_loss: 3.1706	batch_accuracy: 40.16%	lr:0.000508
Ep: 27/48	It: 3551/8134	batch_loss: 3.2282	batch_accuracy: 38.70%	lr:0.000507
Ep: 27/48	It: 3601/8134	batch_loss: 3.2204	batch_accuracy: 39.82%	lr:0.000507
Ep: 27/48	It: 3651/8134	batch_loss: 3.1520	batch_accuracy: 40.55%	lr:0.000507
Ep: 27/48	It: 3701/8134	batch_loss: 3.1788	batch_accuracy: 40.16%	lr:0.000507
Ep: 27/48	It: 3751/8134	batch_loss: 3.1340	batch_accuracy: 39.99%	lr:0.000506
Ep: 27/48	It: 3801/8134	batch_loss: 3.1481	batch_accuracy: 40.87%	lr:0.000506
Ep: 27/48	It: 3851/8134	batch_loss: 3.1688	batch_accuracy: 41.04%	lr:0.000506
Ep: 27/48	It: 3901/8134	batch_loss: 3.2575	batch_accuracy: 37.92%	lr:0.000506
Ep: 27/48	It: 3951/8134	batch_loss: 3.1650	batch_accuracy: 39.70%	lr:0.000506
Ep: 27/48	It: 4001/8134	batch_loss: 3.1711	batch_accuracy: 40.04%	lr:0.000505
Ep: 27/48	It: 4051/8134	batch_loss: 3.0319	batch_accuracy: 42.07%	lr:0.000505
Ep: 27/48	It: 4101/8134	batch_loss: 3.1450	batch_accuracy: 40.41%	lr:0.000505
Ep: 27/48	It: 4151/8134	batch_loss: 3.1408	batch_accuracy: 40.26%	lr:0.000505
Ep: 27/48	It: 4201/8134	batch_loss: 3.1208	batch_accuracy: 41.04%	lr:0.000504
Ep: 27/48	It: 4251/8134	batch_loss: 3.0938	batch_accuracy: 40.28%	lr:0.000504
Ep: 27/48	It: 4301/8134	batch_loss: 3.0603	batch_accuracy: 41.67%	lr:0.000504
Ep: 27/48	It: 4351/8134	batch_loss: 3.1454	batch_accuracy: 40.01%	lr:0.000504
Ep: 27/48	It: 4401/8134	batch_loss: 3.1920	batch_accuracy: 39.84%	lr:0.000504
Ep: 27/48	It: 4451/8134	batch_loss: 3.1124	batch_accuracy: 41.11%	lr:0.000503
Ep: 27/48	It: 4501/8134	batch_loss: 3.1092	batch_accuracy: 41.11%	lr:0.000503
Ep: 27/48	It: 4551/8134	batch_loss: 3.2426	batch_accuracy: 39.55%	lr:0.000503
Ep: 27/48	It: 4601/8134	batch_loss: 3.2046	batch_accuracy: 40.11%	lr:0.000503
Ep: 27/48	It: 4651/8134	batch_loss: 3.1934	batch_accuracy: 39.75%	lr:0.000502
Ep: 27/48	It: 4701/8134	batch_loss: 3.1350	batch_accuracy: 40.01%	lr:0.000502
Ep: 27/48	It: 4751/8134	batch_loss: 3.0818	batch_accuracy: 42.16%	lr:0.000502
Ep: 27/48	It: 4801/8134	batch_loss: 3.2490	batch_accuracy: 39.48%	lr:0.000502
Ep: 27/48	It: 4851/8134	batch_loss: 3.1723	batch_accuracy: 39.77%	lr:0.000502
Ep: 27/48	It: 4901/8134	batch_loss: 3.0839	batch_accuracy: 41.77%	lr:0.000501
Ep: 27/48	It: 4951/8134	batch_loss: 3.0851	batch_accuracy: 40.70%	lr:0.000501
Ep: 27/48	It: 5001/8134	batch_loss: 3.2933	batch_accuracy: 37.72%	lr:0.000501
Ep: 27/48	It: 5051/8134	batch_loss: 3.1613	batch_accuracy: 40.16%	lr:0.000501
Ep: 27/48	It: 5101/8134	batch_loss: 3.0557	batch_accuracy: 40.97%	lr:0.000500
Ep: 27/48	It: 5151/8134	batch_loss: 3.2718	batch_accuracy: 39.77%	lr:0.000500
Ep: 27/48	It: 5201/8134	batch_loss: 3.1977	batch_accuracy: 38.77%	lr:0.000500
Ep: 27/48	It: 5251/8134	batch_loss: 3.1030	batch_accuracy: 40.45%	lr:0.000500
Ep: 27/48	It: 5301/8134	batch_loss: 3.0741	batch_accuracy: 41.04%	lr:0.000500
Ep: 27/48	It: 5351/8134	batch_loss: 3.2213	batch_accuracy: 38.57%	lr:0.000499
Ep: 27/48	It: 5401/8134	batch_loss: 3.1250	batch_accuracy: 41.16%	lr:0.000499
Ep: 27/48	It: 5451/8134	batch_loss: 3.1221	batch_accuracy: 41.46%	lr:0.000499
Ep: 27/48	It: 5501/8134	batch_loss: 3.1141	batch_accuracy: 40.48%	lr:0.000499
Ep: 27/48	It: 5551/8134	batch_loss: 3.2060	batch_accuracy: 40.45%	lr:0.000498
Ep: 27/48	It: 5601/8134	batch_loss: 3.3234	batch_accuracy: 38.13%	lr:0.000498
Ep: 27/48	It: 5651/8134	batch_loss: 3.1262	batch_accuracy: 40.21%	lr:0.000498
Ep: 27/48	It: 5701/8134	batch_loss: 3.1526	batch_accuracy: 40.45%	lr:0.000498
Ep: 27/48	It: 5751/8134	batch_loss: 3.1792	batch_accuracy: 40.43%	lr:0.000498
Ep: 27/48	It: 5801/8134	batch_loss: 3.0287	batch_accuracy: 42.29%	lr:0.000497
Ep: 27/48	It: 5851/8134	batch_loss: 3.2862	batch_accuracy: 39.75%	lr:0.000497
Ep: 27/48	It: 5901/8134	batch_loss: 3.2067	batch_accuracy: 38.55%	lr:0.000497
Ep: 27/48	It: 5951/8134	batch_loss: 3.2154	batch_accuracy: 39.55%	lr:0.000497
Ep: 27/48	It: 6001/8134	batch_loss: 3.1543	batch_accuracy: 40.58%	lr:0.000496
Ep: 27/48	It: 6051/8134	batch_loss: 3.0696	batch_accuracy: 41.14%	lr:0.000496
Ep: 27/48	It: 6101/8134	batch_loss: 3.1340	batch_accuracy: 40.45%	lr:0.000496
Ep: 27/48	It: 6151/8134	batch_loss: 3.1741	batch_accuracy: 40.04%	lr:0.000496
Ep: 27/48	It: 6201/8134	batch_loss: 3.0607	batch_accuracy: 41.38%	lr:0.000496
Ep: 27/48	It: 6251/8134	batch_loss: 3.1408	batch_accuracy: 40.48%	lr:0.000495
Ep: 27/48	It: 6301/8134	batch_loss: 3.1274	batch_accuracy: 39.70%	lr:0.000495
Ep: 27/48	It: 6351/8134	batch_loss: 3.1049	batch_accuracy: 40.62%	lr:0.000495
Ep: 27/48	It: 6401/8134	batch_loss: 3.0822	batch_accuracy: 41.43%	lr:0.000495
Ep: 27/48	It: 6451/8134	batch_loss: 3.1871	batch_accuracy: 39.65%	lr:0.000494
Ep: 27/48	It: 6501/8134	batch_loss: 3.2386	batch_accuracy: 38.77%	lr:0.000494
Ep: 27/48	It: 6551/8134	batch_loss: 3.2145	batch_accuracy: 40.11%	lr:0.000494
Ep: 27/48	It: 6601/8134	batch_loss: 3.0585	batch_accuracy: 42.21%	lr:0.000494
Ep: 27/48	It: 6651/8134	batch_loss: 3.0683	batch_accuracy: 41.82%	lr:0.000494
Ep: 27/48	It: 6701/8134	batch_loss: 3.0596	batch_accuracy: 41.82%	lr:0.000493
Ep: 27/48	It: 6751/8134	batch_loss: 3.2286	batch_accuracy: 39.26%	lr:0.000493
Ep: 27/48	It: 6801/8134	batch_loss: 3.1386	batch_accuracy: 41.02%	lr:0.000493
Ep: 27/48	It: 6851/8134	batch_loss: 3.1974	batch_accuracy: 39.77%	lr:0.000493
Ep: 27/48	It: 6901/8134	batch_loss: 3.1472	batch_accuracy: 41.58%	lr:0.000492
Ep: 27/48	It: 6951/8134	batch_loss: 3.1210	batch_accuracy: 40.89%	lr:0.000492
Ep: 27/48	It: 7001/8134	batch_loss: 3.1013	batch_accuracy: 41.26%	lr:0.000492
Ep: 27/48	It: 7051/8134	batch_loss: 3.1401	batch_accuracy: 39.97%	lr:0.000492
Ep: 27/48	It: 7101/8134	batch_loss: 3.0353	batch_accuracy: 41.72%	lr:0.000492
Ep: 27/48	It: 7151/8134	batch_loss: 3.0620	batch_accuracy: 40.94%	lr:0.000491
Ep: 27/48	It: 7201/8134	batch_loss: 3.0654	batch_accuracy: 40.94%	lr:0.000491
Ep: 27/48	It: 7251/8134	batch_loss: 3.1869	batch_accuracy: 39.18%	lr:0.000491
Ep: 27/48	It: 7301/8134	batch_loss: 3.2821	batch_accuracy: 37.67%	lr:0.000491
Ep: 27/48	It: 7351/8134	batch_loss: 3.1153	batch_accuracy: 40.14%	lr:0.000490
Ep: 27/48	It: 7401/8134	batch_loss: 3.1214	batch_accuracy: 41.21%	lr:0.000490
Ep: 27/48	It: 7451/8134	batch_loss: 3.0534	batch_accuracy: 41.50%	lr:0.000490
Ep: 27/48	It: 7501/8134	batch_loss: 3.1725	batch_accuracy: 40.92%	lr:0.000490
Ep: 27/48	It: 7551/8134	batch_loss: 3.1213	batch_accuracy: 40.04%	lr:0.000490
Ep: 27/48	It: 7601/8134	batch_loss: 3.1006	batch_accuracy: 40.23%	lr:0.000489
Ep: 27/48	It: 7651/8134	batch_loss: 3.1939	batch_accuracy: 39.55%	lr:0.000489
Ep: 27/48	It: 7701/8134	batch_loss: 3.1184	batch_accuracy: 40.33%	lr:0.000489
Ep: 27/48	It: 7751/8134	batch_loss: 3.0970	batch_accuracy: 40.11%	lr:0.000489
Ep: 27/48	It: 7801/8134	batch_loss: 3.0977	batch_accuracy: 41.21%	lr:0.000488
Ep: 27/48	It: 7851/8134	batch_loss: 3.2499	batch_accuracy: 39.31%	lr:0.000488
Ep: 27/48	It: 7901/8134	batch_loss: 3.1512	batch_accuracy: 39.14%	lr:0.000488
Ep: 27/48	It: 7951/8134	batch_loss: 3.0438	batch_accuracy: 41.31%	lr:0.000488
Ep: 27/48	It: 8001/8134	batch_loss: 3.1465	batch_accuracy: 40.58%	lr:0.000488
Ep: 27/48	It: 8051/8134	batch_loss: 3.2334	batch_accuracy: 38.60%	lr:0.000487
Ep: 27/48	It: 8101/8134	batch_loss: 3.0639	batch_accuracy: 41.33%	lr:0.000487
Ep: 27/48	It: 8134/8134	batch_loss: 3.2622	batch_accuracy: 38.55%	lr:0.000487


Generated text for input text "You" is:
You. We have also provided a comprehensive overview of thesis and some recent studies of theory, in detail, and their possible applications. The most important aspects of thesis in thesis are: the development of theories, concepts, methods, and theories, methods, and theories, methods, and methods. In the second part, we introduce a new methodology to the study of the process of building theories and to provide a theoretical framework for understanding the evolution of the concept of sustainable development. The research methodology used in this research is descriptive and inferential analysis. The methodological basis of the study is a comparative study of the main methods of the research and the method of the research of industrial production, industrial and technological processes, methods of analysis and synthesis of the process of production of oil products, methods of oil production, the method of analysis of the process of oil production and construction of the enterprise oil production, method of oil production and production of oil production, its process of industrial production and production process of oil production and industrial production of oil production and its industrial production. The article also provides a detailed information on the process of oil production process. The analysis and method of the method of research on oil production process of oil production process of oil production


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 28/48	It: 1/8134	batch_loss: 3.2523	batch_accuracy: 37.18%	lr:0.000487
Ep: 28/48	It: 51/8134	batch_loss: 3.1442	batch_accuracy: 40.75%	lr:0.000487
Ep: 28/48	It: 101/8134	batch_loss: 3.1668	batch_accuracy: 40.21%	lr:0.000486
Ep: 28/48	It: 151/8134	batch_loss: 3.1347	batch_accuracy: 39.75%	lr:0.000486
Ep: 28/48	It: 201/8134	batch_loss: 3.1253	batch_accuracy: 41.33%	lr:0.000486
Ep: 28/48	It: 251/8134	batch_loss: 3.0954	batch_accuracy: 41.33%	lr:0.000486
Ep: 28/48	It: 301/8134	batch_loss: 3.0955	batch_accuracy: 40.84%	lr:0.000486
Ep: 28/48	It: 351/8134	batch_loss: 3.1791	batch_accuracy: 39.45%	lr:0.000485
Ep: 28/48	It: 401/8134	batch_loss: 3.2364	batch_accuracy: 38.87%	lr:0.000485
Ep: 28/48	It: 451/8134	batch_loss: 3.0975	batch_accuracy: 40.14%	lr:0.000485
Ep: 28/48	It: 501/8134	batch_loss: 3.1944	batch_accuracy: 39.77%	lr:0.000485
Ep: 28/48	It: 551/8134	batch_loss: 3.2328	batch_accuracy: 39.14%	lr:0.000484
Ep: 28/48	It: 601/8134	batch_loss: 3.0976	batch_accuracy: 41.02%	lr:0.000484
Ep: 28/48	It: 651/8134	batch_loss: 3.1853	batch_accuracy: 39.31%	lr:0.000484
Ep: 28/48	It: 701/8134	batch_loss: 3.0995	batch_accuracy: 41.41%	lr:0.000484
Ep: 28/48	It: 751/8134	batch_loss: 2.9941	batch_accuracy: 41.75%	lr:0.000484
Ep: 28/48	It: 801/8134	batch_loss: 3.0891	batch_accuracy: 41.31%	lr:0.000483
Ep: 28/48	It: 851/8134	batch_loss: 3.1930	batch_accuracy: 39.60%	lr:0.000483
Ep: 28/48	It: 901/8134	batch_loss: 3.1859	batch_accuracy: 39.58%	lr:0.000483
Ep: 28/48	It: 951/8134	batch_loss: 3.1088	batch_accuracy: 40.04%	lr:0.000483
Ep: 28/48	It: 1001/8134	batch_loss: 3.0844	batch_accuracy: 40.84%	lr:0.000482
Ep: 28/48	It: 1051/8134	batch_loss: 3.1754	batch_accuracy: 39.99%	lr:0.000482
Ep: 28/48	It: 1101/8134	batch_loss: 3.2622	batch_accuracy: 39.36%	lr:0.000482
Ep: 28/48	It: 1151/8134	batch_loss: 3.1267	batch_accuracy: 39.70%	lr:0.000482
Ep: 28/48	It: 1201/8134	batch_loss: 3.0646	batch_accuracy: 41.46%	lr:0.000482
Ep: 28/48	It: 1251/8134	batch_loss: 3.1475	batch_accuracy: 40.16%	lr:0.000481
Ep: 28/48	It: 1301/8134	batch_loss: 3.1010	batch_accuracy: 40.62%	lr:0.000481
Ep: 28/48	It: 1351/8134	batch_loss: 3.1814	batch_accuracy: 38.72%	lr:0.000481
Ep: 28/48	It: 1401/8134	batch_loss: 3.2356	batch_accuracy: 38.84%	lr:0.000481
Ep: 28/48	It: 1451/8134	batch_loss: 2.9734	batch_accuracy: 42.94%	lr:0.000480
Ep: 28/48	It: 1501/8134	batch_loss: 3.2442	batch_accuracy: 39.01%	lr:0.000480
Ep: 28/48	It: 1551/8134	batch_loss: 3.1218	batch_accuracy: 40.65%	lr:0.000480
Ep: 28/48	It: 1601/8134	batch_loss: 2.9640	batch_accuracy: 43.99%	lr:0.000480
Ep: 28/48	It: 1651/8134	batch_loss: 3.1595	batch_accuracy: 40.62%	lr:0.000480
Ep: 28/48	It: 1701/8134	batch_loss: 3.1139	batch_accuracy: 39.53%	lr:0.000479
Ep: 28/48	It: 1751/8134	batch_loss: 3.1559	batch_accuracy: 40.36%	lr:0.000479
Ep: 28/48	It: 1801/8134	batch_loss: 3.1106	batch_accuracy: 41.06%	lr:0.000479
Ep: 28/48	It: 1851/8134	batch_loss: 3.0750	batch_accuracy: 41.04%	lr:0.000479
Ep: 28/48	It: 1901/8134	batch_loss: 3.2040	batch_accuracy: 39.26%	lr:0.000478
Ep: 28/48	It: 1951/8134	batch_loss: 3.0880	batch_accuracy: 40.84%	lr:0.000478
Ep: 28/48	It: 2001/8134	batch_loss: 3.1642	batch_accuracy: 40.04%	lr:0.000478
Ep: 28/48	It: 2051/8134	batch_loss: 3.1183	batch_accuracy: 41.02%	lr:0.000478
Ep: 28/48	It: 2101/8134	batch_loss: 3.1840	batch_accuracy: 39.26%	lr:0.000478
Ep: 28/48	It: 2151/8134	batch_loss: 3.0535	batch_accuracy: 40.80%	lr:0.000477
Ep: 28/48	It: 2201/8134	batch_loss: 3.2259	batch_accuracy: 39.11%	lr:0.000477
Ep: 28/48	It: 2251/8134	batch_loss: 3.1127	batch_accuracy: 40.62%	lr:0.000477
Ep: 28/48	It: 2301/8134	batch_loss: 3.1598	batch_accuracy: 40.70%	lr:0.000477
Ep: 28/48	It: 2351/8134	batch_loss: 3.1467	batch_accuracy: 40.26%	lr:0.000476
Ep: 28/48	It: 2401/8134	batch_loss: 3.0866	batch_accuracy: 41.11%	lr:0.000476
Ep: 28/48	It: 2451/8134	batch_loss: 3.1538	batch_accuracy: 40.50%	lr:0.000476
Ep: 28/48	It: 2501/8134	batch_loss: 3.0825	batch_accuracy: 41.31%	lr:0.000476
Ep: 28/48	It: 2551/8134	batch_loss: 3.1779	batch_accuracy: 39.36%	lr:0.000476
Ep: 28/48	It: 2601/8134	batch_loss: 3.1818	batch_accuracy: 39.72%	lr:0.000475
Ep: 28/48	It: 2651/8134	batch_loss: 3.0027	batch_accuracy: 42.36%	lr:0.000475
Ep: 28/48	It: 2701/8134	batch_loss: 3.1221	batch_accuracy: 40.99%	lr:0.000475
Ep: 28/48	It: 2751/8134	batch_loss: 3.1872	batch_accuracy: 39.26%	lr:0.000475
Ep: 28/48	It: 2801/8134	batch_loss: 3.1195	batch_accuracy: 41.16%	lr:0.000474
Ep: 28/48	It: 2851/8134	batch_loss: 3.1086	batch_accuracy: 41.46%	lr:0.000474
Ep: 28/48	It: 2901/8134	batch_loss: 3.1717	batch_accuracy: 39.70%	lr:0.000474
Ep: 28/48	It: 2951/8134	batch_loss: 3.0414	batch_accuracy: 41.87%	lr:0.000474
Ep: 28/48	It: 3001/8134	batch_loss: 3.1247	batch_accuracy: 40.84%	lr:0.000474
Ep: 28/48	It: 3051/8134	batch_loss: 3.1824	batch_accuracy: 39.75%	lr:0.000473
Ep: 28/48	It: 3101/8134	batch_loss: 3.1548	batch_accuracy: 39.26%	lr:0.000473
Ep: 28/48	It: 3151/8134	batch_loss: 3.0567	batch_accuracy: 41.70%	lr:0.000473
Ep: 28/48	It: 3201/8134	batch_loss: 3.0813	batch_accuracy: 40.50%	lr:0.000473
Ep: 28/48	It: 3251/8134	batch_loss: 3.1792	batch_accuracy: 38.70%	lr:0.000472
Ep: 28/48	It: 3301/8134	batch_loss: 3.1419	batch_accuracy: 40.65%	lr:0.000472
Ep: 28/48	It: 3351/8134	batch_loss: 3.2473	batch_accuracy: 38.13%	lr:0.000472
Ep: 28/48	It: 3401/8134	batch_loss: 3.2222	batch_accuracy: 38.77%	lr:0.000472
Ep: 28/48	It: 3451/8134	batch_loss: 3.2659	batch_accuracy: 38.89%	lr:0.000472
Ep: 28/48	It: 3501/8134	batch_loss: 3.0318	batch_accuracy: 41.72%	lr:0.000471
Ep: 28/48	It: 3551/8134	batch_loss: 3.2662	batch_accuracy: 39.53%	lr:0.000471
Ep: 28/48	It: 3601/8134	batch_loss: 3.1592	batch_accuracy: 39.75%	lr:0.000471
Ep: 28/48	It: 3651/8134	batch_loss: 3.0734	batch_accuracy: 42.38%	lr:0.000471
Ep: 28/48	It: 3701/8134	batch_loss: 3.1285	batch_accuracy: 39.92%	lr:0.000470
Ep: 28/48	It: 3751/8134	batch_loss: 3.1675	batch_accuracy: 39.94%	lr:0.000470
Ep: 28/48	It: 3801/8134	batch_loss: 3.2863	batch_accuracy: 38.43%	lr:0.000470
Ep: 28/48	It: 3851/8134	batch_loss: 3.2052	batch_accuracy: 38.82%	lr:0.000470
Ep: 28/48	It: 3901/8134	batch_loss: 3.1036	batch_accuracy: 40.55%	lr:0.000470
Ep: 28/48	It: 3951/8134	batch_loss: 3.1467	batch_accuracy: 39.65%	lr:0.000469
Ep: 28/48	It: 4001/8134	batch_loss: 3.1610	batch_accuracy: 40.50%	lr:0.000469
Ep: 28/48	It: 4051/8134	batch_loss: 3.1306	batch_accuracy: 39.75%	lr:0.000469
Ep: 28/48	It: 4101/8134	batch_loss: 3.2028	batch_accuracy: 39.53%	lr:0.000469
Ep: 28/48	It: 4151/8134	batch_loss: 3.1404	batch_accuracy: 40.28%	lr:0.000468
Ep: 28/48	It: 4201/8134	batch_loss: 3.0327	batch_accuracy: 41.43%	lr:0.000468
Ep: 28/48	It: 4251/8134	batch_loss: 3.1541	batch_accuracy: 41.36%	lr:0.000468
Ep: 28/48	It: 4301/8134	batch_loss: 3.1346	batch_accuracy: 41.28%	lr:0.000468
Ep: 28/48	It: 4351/8134	batch_loss: 2.9508	batch_accuracy: 42.46%	lr:0.000468
Ep: 28/48	It: 4401/8134	batch_loss: 3.2310	batch_accuracy: 38.18%	lr:0.000467
Ep: 28/48	It: 4451/8134	batch_loss: 3.2205	batch_accuracy: 38.60%	lr:0.000467
Ep: 28/48	It: 4501/8134	batch_loss: 3.0898	batch_accuracy: 40.14%	lr:0.000467
Ep: 28/48	It: 4551/8134	batch_loss: 3.1055	batch_accuracy: 40.53%	lr:0.000467
Ep: 28/48	It: 4601/8134	batch_loss: 3.2410	batch_accuracy: 37.87%	lr:0.000466
Ep: 28/48	It: 4651/8134	batch_loss: 3.1364	batch_accuracy: 40.92%	lr:0.000466
Ep: 28/48	It: 4701/8134	batch_loss: 3.1517	batch_accuracy: 39.72%	lr:0.000466
Ep: 28/48	It: 4751/8134	batch_loss: 3.2331	batch_accuracy: 38.79%	lr:0.000466
Ep: 28/48	It: 4801/8134	batch_loss: 3.1356	batch_accuracy: 40.70%	lr:0.000466
Ep: 28/48	It: 4851/8134	batch_loss: 3.1692	batch_accuracy: 40.38%	lr:0.000465
Ep: 28/48	It: 4901/8134	batch_loss: 3.3740	batch_accuracy: 37.40%	lr:0.000465
Ep: 28/48	It: 4951/8134	batch_loss: 3.1783	batch_accuracy: 40.19%	lr:0.000465
Ep: 28/48	It: 5001/8134	batch_loss: 3.1358	batch_accuracy: 39.92%	lr:0.000465
Ep: 28/48	It: 5051/8134	batch_loss: 3.0210	batch_accuracy: 41.02%	lr:0.000465
Ep: 28/48	It: 5101/8134	batch_loss: 3.2620	batch_accuracy: 38.67%	lr:0.000464
Ep: 28/48	It: 5151/8134	batch_loss: 3.0819	batch_accuracy: 41.41%	lr:0.000464
Ep: 28/48	It: 5201/8134	batch_loss: 2.9952	batch_accuracy: 42.72%	lr:0.000464
Ep: 28/48	It: 5251/8134	batch_loss: 3.0960	batch_accuracy: 41.28%	lr:0.000464
Ep: 28/48	It: 5301/8134	batch_loss: 3.1260	batch_accuracy: 40.31%	lr:0.000463
Ep: 28/48	It: 5351/8134	batch_loss: 3.1511	batch_accuracy: 40.11%	lr:0.000463
Ep: 28/48	It: 5401/8134	batch_loss: 3.1323	batch_accuracy: 39.87%	lr:0.000463
Ep: 28/48	It: 5451/8134	batch_loss: 3.2593	batch_accuracy: 39.21%	lr:0.000463
Ep: 28/48	It: 5501/8134	batch_loss: 3.1371	batch_accuracy: 40.06%	lr:0.000463
Ep: 28/48	It: 5551/8134	batch_loss: 3.0478	batch_accuracy: 41.14%	lr:0.000462
Ep: 28/48	It: 5601/8134	batch_loss: 3.1785	batch_accuracy: 39.67%	lr:0.000462
Ep: 28/48	It: 5651/8134	batch_loss: 3.1835	batch_accuracy: 40.36%	lr:0.000462
Ep: 28/48	It: 5701/8134	batch_loss: 3.2041	batch_accuracy: 39.45%	lr:0.000462
Ep: 28/48	It: 5751/8134	batch_loss: 3.2223	batch_accuracy: 39.18%	lr:0.000461
Ep: 28/48	It: 5801/8134	batch_loss: 2.9580	batch_accuracy: 42.55%	lr:0.000461
Ep: 28/48	It: 5851/8134	batch_loss: 3.1570	batch_accuracy: 39.79%	lr:0.000461
Ep: 28/48	It: 5901/8134	batch_loss: 3.1527	batch_accuracy: 39.70%	lr:0.000461
Ep: 28/48	It: 5951/8134	batch_loss: 3.0667	batch_accuracy: 41.24%	lr:0.000461
Ep: 28/48	It: 6001/8134	batch_loss: 3.1714	batch_accuracy: 39.97%	lr:0.000460
Ep: 28/48	It: 6051/8134	batch_loss: 3.1082	batch_accuracy: 41.24%	lr:0.000460
Ep: 28/48	It: 6101/8134	batch_loss: 3.1990	batch_accuracy: 39.23%	lr:0.000460
Ep: 28/48	It: 6151/8134	batch_loss: 3.0590	batch_accuracy: 40.70%	lr:0.000460
Ep: 28/48	It: 6201/8134	batch_loss: 3.2529	batch_accuracy: 38.82%	lr:0.000459
Ep: 28/48	It: 6251/8134	batch_loss: 3.1607	batch_accuracy: 40.65%	lr:0.000459
Ep: 28/48	It: 6301/8134	batch_loss: 3.1407	batch_accuracy: 41.19%	lr:0.000459
Ep: 28/48	It: 6351/8134	batch_loss: 3.0640	batch_accuracy: 42.26%	lr:0.000459
Ep: 28/48	It: 6401/8134	batch_loss: 3.1133	batch_accuracy: 40.94%	lr:0.000459
Ep: 28/48	It: 6451/8134	batch_loss: 3.2346	batch_accuracy: 39.53%	lr:0.000458
Ep: 28/48	It: 6501/8134	batch_loss: 3.0089	batch_accuracy: 41.72%	lr:0.000458
Ep: 28/48	It: 6551/8134	batch_loss: 3.0756	batch_accuracy: 40.33%	lr:0.000458
Ep: 28/48	It: 6601/8134	batch_loss: 3.0907	batch_accuracy: 41.33%	lr:0.000458
Ep: 28/48	It: 6651/8134	batch_loss: 3.2861	batch_accuracy: 38.35%	lr:0.000457
Ep: 28/48	It: 6701/8134	batch_loss: 3.0927	batch_accuracy: 40.80%	lr:0.000457
Ep: 28/48	It: 6751/8134	batch_loss: 3.0534	batch_accuracy: 42.33%	lr:0.000457
Ep: 28/48	It: 6801/8134	batch_loss: 3.1441	batch_accuracy: 40.36%	lr:0.000457
Ep: 28/48	It: 6851/8134	batch_loss: 3.1179	batch_accuracy: 41.02%	lr:0.000457
Ep: 28/48	It: 6901/8134	batch_loss: 3.0555	batch_accuracy: 41.36%	lr:0.000456
Ep: 28/48	It: 6951/8134	batch_loss: 3.0848	batch_accuracy: 40.84%	lr:0.000456
Ep: 28/48	It: 7001/8134	batch_loss: 3.2384	batch_accuracy: 38.92%	lr:0.000456
Ep: 28/48	It: 7051/8134	batch_loss: 3.1624	batch_accuracy: 39.45%	lr:0.000456
Ep: 28/48	It: 7101/8134	batch_loss: 3.1533	batch_accuracy: 40.72%	lr:0.000455
Ep: 28/48	It: 7151/8134	batch_loss: 3.1942	batch_accuracy: 40.67%	lr:0.000455
Ep: 28/48	It: 7201/8134	batch_loss: 3.1284	batch_accuracy: 40.97%	lr:0.000455
Ep: 28/48	It: 7251/8134	batch_loss: 3.1087	batch_accuracy: 41.53%	lr:0.000455
Ep: 28/48	It: 7301/8134	batch_loss: 3.2353	batch_accuracy: 38.79%	lr:0.000455
Ep: 28/48	It: 7351/8134	batch_loss: 3.1066	batch_accuracy: 40.58%	lr:0.000454
Ep: 28/48	It: 7401/8134	batch_loss: 3.1269	batch_accuracy: 39.75%	lr:0.000454
Ep: 28/48	It: 7451/8134	batch_loss: 3.1970	batch_accuracy: 39.60%	lr:0.000454
Ep: 28/48	It: 7501/8134	batch_loss: 3.0104	batch_accuracy: 42.16%	lr:0.000454
Ep: 28/48	It: 7551/8134	batch_loss: 3.2098	batch_accuracy: 39.01%	lr:0.000453
Ep: 28/48	It: 7601/8134	batch_loss: 3.1719	batch_accuracy: 38.89%	lr:0.000453
Ep: 28/48	It: 7651/8134	batch_loss: 3.1152	batch_accuracy: 40.38%	lr:0.000453
Ep: 28/48	It: 7701/8134	batch_loss: 3.1553	batch_accuracy: 39.97%	lr:0.000453
Ep: 28/48	It: 7751/8134	batch_loss: 3.2811	batch_accuracy: 38.40%	lr:0.000453
Ep: 28/48	It: 7801/8134	batch_loss: 3.2131	batch_accuracy: 38.96%	lr:0.000452
Ep: 28/48	It: 7851/8134	batch_loss: 3.2033	batch_accuracy: 39.58%	lr:0.000452
Ep: 28/48	It: 7901/8134	batch_loss: 3.1132	batch_accuracy: 40.28%	lr:0.000452
Ep: 28/48	It: 7951/8134	batch_loss: 3.1995	batch_accuracy: 39.62%	lr:0.000452
Ep: 28/48	It: 8001/8134	batch_loss: 3.0369	batch_accuracy: 41.58%	lr:0.000451
Ep: 28/48	It: 8051/8134	batch_loss: 3.0388	batch_accuracy: 41.28%	lr:0.000451
Ep: 28/48	It: 8101/8134	batch_loss: 3.0974	batch_accuracy: 40.84%	lr:0.000451
Ep: 28/48	It: 8134/8134	batch_loss: 3.0348	batch_accuracy: 41.98%	lr:0.000451


Generated text for input text "You" is:
You-P. The results showed that the mean difference between groups was 1. The prevalence of HG and SGGG among groups was 4. There was a trend of 0.5, and the most frequent HCV was HCC. The mean difference between the prevalence of HGGGG and the age of the patients was 0.71.


CONCLUSION
The prevalence of HCV genotype was higher in patients with HCV and HCV genotype, but it is more likely to be due to the higher rate of HCV infection.
<eot>
<sot>
Extending the Millennium Development Code: An Integrated Design and Development Course

In the last two decades, the use of technology has been an increasing trend in the number of industries and the number of manufacturing sectors. The present paper aims to analyze the effect of technology development on the performance of technology adoption by employees of a technology enterprise. Based on the analysis of technology application of technology and the application of technology, the research is carried out in order to improve the process of technology innovation.
<eot>
<sot>
Protective effects of pectin and its antioxid


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 29/48	It: 1/8134	batch_loss: 3.0906	batch_accuracy: 40.26%	lr:0.000451
Ep: 29/48	It: 51/8134	batch_loss: 3.0948	batch_accuracy: 40.23%	lr:0.000451
Ep: 29/48	It: 101/8134	batch_loss: 3.1114	batch_accuracy: 39.48%	lr:0.000450
Ep: 29/48	It: 151/8134	batch_loss: 3.0858	batch_accuracy: 41.24%	lr:0.000450
Ep: 29/48	It: 201/8134	batch_loss: 3.0116	batch_accuracy: 42.46%	lr:0.000450
Ep: 29/48	It: 251/8134	batch_loss: 3.0409	batch_accuracy: 43.02%	lr:0.000450
Ep: 29/48	It: 301/8134	batch_loss: 3.1705	batch_accuracy: 39.18%	lr:0.000450
Ep: 29/48	It: 351/8134	batch_loss: 3.1776	batch_accuracy: 39.04%	lr:0.000449
Ep: 29/48	It: 401/8134	batch_loss: 3.0699	batch_accuracy: 40.84%	lr:0.000449
Ep: 29/48	It: 451/8134	batch_loss: 3.0641	batch_accuracy: 41.58%	lr:0.000449
Ep: 29/48	It: 501/8134	batch_loss: 3.1528	batch_accuracy: 39.94%	lr:0.000449
Ep: 29/48	It: 551/8134	batch_loss: 3.1606	batch_accuracy: 40.53%	lr:0.000448
Ep: 29/48	It: 601/8134	batch_loss: 3.1144	batch_accuracy: 41.14%	lr:0.000448
Ep: 29/48	It: 651/8134	batch_loss: 3.1217	batch_accuracy: 41.33%	lr:0.000448
Ep: 29/48	It: 701/8134	batch_loss: 3.0079	batch_accuracy: 41.46%	lr:0.000448
Ep: 29/48	It: 751/8134	batch_loss: 3.0800	batch_accuracy: 40.99%	lr:0.000448
Ep: 29/48	It: 801/8134	batch_loss: 3.3009	batch_accuracy: 37.01%	lr:0.000447
Ep: 29/48	It: 851/8134	batch_loss: 3.1250	batch_accuracy: 39.43%	lr:0.000447
Ep: 29/48	It: 901/8134	batch_loss: 3.0133	batch_accuracy: 41.65%	lr:0.000447
Ep: 29/48	It: 951/8134	batch_loss: 3.2136	batch_accuracy: 39.50%	lr:0.000447
Ep: 29/48	It: 1001/8134	batch_loss: 3.2059	batch_accuracy: 38.94%	lr:0.000446
Ep: 29/48	It: 1051/8134	batch_loss: 3.2627	batch_accuracy: 40.11%	lr:0.000446
Ep: 29/48	It: 1101/8134	batch_loss: 3.0848	batch_accuracy: 41.06%	lr:0.000446
Ep: 29/48	It: 1151/8134	batch_loss: 3.0252	batch_accuracy: 42.14%	lr:0.000446
Ep: 29/48	It: 1201/8134	batch_loss: 3.1109	batch_accuracy: 40.26%	lr:0.000446
Ep: 29/48	It: 1251/8134	batch_loss: 3.0370	batch_accuracy: 41.50%	lr:0.000445
Ep: 29/48	It: 1301/8134	batch_loss: 3.0608	batch_accuracy: 40.94%	lr:0.000445
Ep: 29/48	It: 1351/8134	batch_loss: 3.0429	batch_accuracy: 40.58%	lr:0.000445
Ep: 29/48	It: 1401/8134	batch_loss: 3.1792	batch_accuracy: 38.92%	lr:0.000445
Ep: 29/48	It: 1451/8134	batch_loss: 3.0941	batch_accuracy: 40.16%	lr:0.000444
Ep: 29/48	It: 1501/8134	batch_loss: 3.2297	batch_accuracy: 39.40%	lr:0.000444
Ep: 29/48	It: 1551/8134	batch_loss: 3.1739	batch_accuracy: 40.01%	lr:0.000444
Ep: 29/48	It: 1601/8134	batch_loss: 3.1484	batch_accuracy: 39.97%	lr:0.000444
Ep: 29/48	It: 1651/8134	batch_loss: 3.1420	batch_accuracy: 38.70%	lr:0.000444
Ep: 29/48	It: 1701/8134	batch_loss: 3.1139	batch_accuracy: 40.77%	lr:0.000443
Ep: 29/48	It: 1751/8134	batch_loss: 3.1986	batch_accuracy: 40.23%	lr:0.000443
Ep: 29/48	It: 1801/8134	batch_loss: 3.2018	batch_accuracy: 39.79%	lr:0.000443
Ep: 29/48	It: 1851/8134	batch_loss: 3.2531	batch_accuracy: 38.13%	lr:0.000443
Ep: 29/48	It: 1901/8134	batch_loss: 3.0461	batch_accuracy: 41.87%	lr:0.000442
Ep: 29/48	It: 1951/8134	batch_loss: 3.0608	batch_accuracy: 41.16%	lr:0.000442
Ep: 29/48	It: 2001/8134	batch_loss: 3.0113	batch_accuracy: 41.60%	lr:0.000442
Ep: 29/48	It: 2051/8134	batch_loss: 3.2518	batch_accuracy: 38.13%	lr:0.000442
Ep: 29/48	It: 2101/8134	batch_loss: 3.0771	batch_accuracy: 40.89%	lr:0.000442
Ep: 29/48	It: 2151/8134	batch_loss: 3.0560	batch_accuracy: 40.97%	lr:0.000441
Ep: 29/48	It: 2201/8134	batch_loss: 3.1813	batch_accuracy: 39.18%	lr:0.000441
Ep: 29/48	It: 2251/8134	batch_loss: 3.0870	batch_accuracy: 42.02%	lr:0.000441
Ep: 29/48	It: 2301/8134	batch_loss: 3.1437	batch_accuracy: 40.11%	lr:0.000441
Ep: 29/48	It: 2351/8134	batch_loss: 3.2165	batch_accuracy: 39.09%	lr:0.000440
Ep: 29/48	It: 2401/8134	batch_loss: 3.1918	batch_accuracy: 39.09%	lr:0.000440
Ep: 29/48	It: 2451/8134	batch_loss: 3.2266	batch_accuracy: 39.38%	lr:0.000440
Ep: 29/48	It: 2501/8134	batch_loss: 3.1412	batch_accuracy: 40.33%	lr:0.000440
Ep: 29/48	It: 2551/8134	batch_loss: 3.1747	batch_accuracy: 39.60%	lr:0.000440
Ep: 29/48	It: 2601/8134	batch_loss: 3.0278	batch_accuracy: 41.60%	lr:0.000439
Ep: 29/48	It: 2651/8134	batch_loss: 3.1653	batch_accuracy: 40.48%	lr:0.000439
Ep: 29/48	It: 2701/8134	batch_loss: 3.2664	batch_accuracy: 38.33%	lr:0.000439
Ep: 29/48	It: 2751/8134	batch_loss: 3.0468	batch_accuracy: 42.24%	lr:0.000439
Ep: 29/48	It: 2801/8134	batch_loss: 3.1372	batch_accuracy: 39.92%	lr:0.000439
Ep: 29/48	It: 2851/8134	batch_loss: 3.1148	batch_accuracy: 40.58%	lr:0.000438
Ep: 29/48	It: 2901/8134	batch_loss: 3.1779	batch_accuracy: 40.16%	lr:0.000438
Ep: 29/48	It: 2951/8134	batch_loss: 3.2011	batch_accuracy: 39.50%	lr:0.000438
Ep: 29/48	It: 3001/8134	batch_loss: 3.0513	batch_accuracy: 42.38%	lr:0.000438
Ep: 29/48	It: 3051/8134	batch_loss: 3.0985	batch_accuracy: 41.28%	lr:0.000437
Ep: 29/48	It: 3101/8134	batch_loss: 3.1379	batch_accuracy: 40.99%	lr:0.000437
Ep: 29/48	It: 3151/8134	batch_loss: 3.0134	batch_accuracy: 42.33%	lr:0.000437
Ep: 29/48	It: 3201/8134	batch_loss: 3.0581	batch_accuracy: 40.97%	lr:0.000437
Ep: 29/48	It: 3251/8134	batch_loss: 3.1736	batch_accuracy: 39.48%	lr:0.000437
Ep: 29/48	It: 3301/8134	batch_loss: 3.1069	batch_accuracy: 41.46%	lr:0.000436
Ep: 29/48	It: 3351/8134	batch_loss: 3.0094	batch_accuracy: 42.87%	lr:0.000436
Ep: 29/48	It: 3401/8134	batch_loss: 3.1384	batch_accuracy: 41.50%	lr:0.000436
Ep: 29/48	It: 3451/8134	batch_loss: 3.0489	batch_accuracy: 42.24%	lr:0.000436
Ep: 29/48	It: 3501/8134	batch_loss: 3.1795	batch_accuracy: 39.21%	lr:0.000435
Ep: 29/48	It: 3551/8134	batch_loss: 3.1559	batch_accuracy: 40.72%	lr:0.000435
Ep: 29/48	It: 3601/8134	batch_loss: 3.1316	batch_accuracy: 40.70%	lr:0.000435
Ep: 29/48	It: 3651/8134	batch_loss: 3.1203	batch_accuracy: 40.62%	lr:0.000435
Ep: 29/48	It: 3701/8134	batch_loss: 3.1358	batch_accuracy: 40.45%	lr:0.000435
Ep: 29/48	It: 3751/8134	batch_loss: 3.1813	batch_accuracy: 39.01%	lr:0.000434
Ep: 29/48	It: 3801/8134	batch_loss: 3.0728	batch_accuracy: 40.67%	lr:0.000434
Ep: 29/48	It: 3851/8134	batch_loss: 3.1687	batch_accuracy: 39.38%	lr:0.000434
Ep: 29/48	It: 3901/8134	batch_loss: 3.1685	batch_accuracy: 39.97%	lr:0.000434
Ep: 29/48	It: 3951/8134	batch_loss: 3.2480	batch_accuracy: 38.77%	lr:0.000433
Ep: 29/48	It: 4001/8134	batch_loss: 3.1650	batch_accuracy: 39.67%	lr:0.000433
Ep: 29/48	It: 4051/8134	batch_loss: 3.2348	batch_accuracy: 40.01%	lr:0.000433
Ep: 29/48	It: 4101/8134	batch_loss: 3.1411	batch_accuracy: 40.89%	lr:0.000433
Ep: 29/48	It: 4151/8134	batch_loss: 3.2111	batch_accuracy: 39.87%	lr:0.000433
Ep: 29/48	It: 4201/8134	batch_loss: 3.1402	batch_accuracy: 39.38%	lr:0.000432
Ep: 29/48	It: 4251/8134	batch_loss: 3.1956	batch_accuracy: 39.31%	lr:0.000432
Ep: 29/48	It: 4301/8134	batch_loss: 3.0864	batch_accuracy: 41.09%	lr:0.000432
Ep: 29/48	It: 4351/8134	batch_loss: 3.0992	batch_accuracy: 39.87%	lr:0.000432
Ep: 29/48	It: 4401/8134	batch_loss: 3.1034	batch_accuracy: 40.09%	lr:0.000431
Ep: 29/48	It: 4451/8134	batch_loss: 3.0894	batch_accuracy: 41.28%	lr:0.000431
Ep: 29/48	It: 4501/8134	batch_loss: 3.0410	batch_accuracy: 41.46%	lr:0.000431
Ep: 29/48	It: 4551/8134	batch_loss: 3.2992	batch_accuracy: 37.26%	lr:0.000431
Ep: 29/48	It: 4601/8134	batch_loss: 3.1257	batch_accuracy: 40.67%	lr:0.000431
Ep: 29/48	It: 4651/8134	batch_loss: 3.0091	batch_accuracy: 41.94%	lr:0.000430
Ep: 29/48	It: 4701/8134	batch_loss: 3.1045	batch_accuracy: 41.26%	lr:0.000430
Ep: 29/48	It: 4751/8134	batch_loss: 3.1065	batch_accuracy: 39.67%	lr:0.000430
Ep: 29/48	It: 4801/8134	batch_loss: 3.1248	batch_accuracy: 41.36%	lr:0.000430
Ep: 29/48	It: 4851/8134	batch_loss: 3.1977	batch_accuracy: 38.79%	lr:0.000429
Ep: 29/48	It: 4901/8134	batch_loss: 3.0643	batch_accuracy: 42.31%	lr:0.000429
Ep: 29/48	It: 4951/8134	batch_loss: 3.2005	batch_accuracy: 39.33%	lr:0.000429
Ep: 29/48	It: 5001/8134	batch_loss: 3.0220	batch_accuracy: 41.82%	lr:0.000429
Ep: 29/48	It: 5051/8134	batch_loss: 3.2491	batch_accuracy: 39.70%	lr:0.000429
Ep: 29/48	It: 5101/8134	batch_loss: 3.1604	batch_accuracy: 40.31%	lr:0.000428
Ep: 29/48	It: 5151/8134	batch_loss: 3.1884	batch_accuracy: 39.60%	lr:0.000428
Ep: 29/48	It: 5201/8134	batch_loss: 3.0388	batch_accuracy: 41.02%	lr:0.000428
Ep: 29/48	It: 5251/8134	batch_loss: 3.0702	batch_accuracy: 41.67%	lr:0.000428
Ep: 29/48	It: 5301/8134	batch_loss: 3.0907	batch_accuracy: 41.21%	lr:0.000428
Ep: 29/48	It: 5351/8134	batch_loss: 3.0301	batch_accuracy: 42.63%	lr:0.000427
Ep: 29/48	It: 5401/8134	batch_loss: 3.2251	batch_accuracy: 40.21%	lr:0.000427
Ep: 29/48	It: 5451/8134	batch_loss: 3.1802	batch_accuracy: 40.16%	lr:0.000427
Ep: 29/48	It: 5501/8134	batch_loss: 3.2023	batch_accuracy: 39.23%	lr:0.000427
Ep: 29/48	It: 5551/8134	batch_loss: 3.1267	batch_accuracy: 40.50%	lr:0.000426
Ep: 29/48	It: 5601/8134	batch_loss: 3.0536	batch_accuracy: 40.58%	lr:0.000426
Ep: 29/48	It: 5651/8134	batch_loss: 3.1765	batch_accuracy: 39.16%	lr:0.000426
Ep: 29/48	It: 5701/8134	batch_loss: 3.2183	batch_accuracy: 39.40%	lr:0.000426
Ep: 29/48	It: 5751/8134	batch_loss: 3.1658	batch_accuracy: 39.58%	lr:0.000426
Ep: 29/48	It: 5801/8134	batch_loss: 3.1935	batch_accuracy: 39.92%	lr:0.000425
Ep: 29/48	It: 5851/8134	batch_loss: 3.0310	batch_accuracy: 41.19%	lr:0.000425
Ep: 29/48	It: 5901/8134	batch_loss: 3.1318	batch_accuracy: 40.55%	lr:0.000425
Ep: 29/48	It: 5951/8134	batch_loss: 3.1272	batch_accuracy: 41.16%	lr:0.000425
Ep: 29/48	It: 6001/8134	batch_loss: 3.1814	batch_accuracy: 40.19%	lr:0.000424
Ep: 29/48	It: 6051/8134	batch_loss: 3.2530	batch_accuracy: 38.62%	lr:0.000424
Ep: 29/48	It: 6101/8134	batch_loss: 3.1437	batch_accuracy: 40.58%	lr:0.000424
Ep: 29/48	It: 6151/8134	batch_loss: 3.0215	batch_accuracy: 41.85%	lr:0.000424
Ep: 29/48	It: 6201/8134	batch_loss: 3.1067	batch_accuracy: 40.70%	lr:0.000424
Ep: 29/48	It: 6251/8134	batch_loss: 3.1351	batch_accuracy: 39.79%	lr:0.000423
Ep: 29/48	It: 6301/8134	batch_loss: 3.1717	batch_accuracy: 40.48%	lr:0.000423
Ep: 29/48	It: 6351/8134	batch_loss: 3.1779	batch_accuracy: 39.94%	lr:0.000423
Ep: 29/48	It: 6401/8134	batch_loss: 3.0502	batch_accuracy: 42.48%	lr:0.000423
Ep: 29/48	It: 6451/8134	batch_loss: 3.1659	batch_accuracy: 39.75%	lr:0.000422
Ep: 29/48	It: 6501/8134	batch_loss: 3.1161	batch_accuracy: 40.62%	lr:0.000422
Ep: 29/48	It: 6551/8134	batch_loss: 3.1259	batch_accuracy: 41.26%	lr:0.000422
Ep: 29/48	It: 6601/8134	batch_loss: 3.0655	batch_accuracy: 41.48%	lr:0.000422
Ep: 29/48	It: 6651/8134	batch_loss: 3.2156	batch_accuracy: 39.82%	lr:0.000422
Ep: 29/48	It: 6701/8134	batch_loss: 3.0650	batch_accuracy: 40.62%	lr:0.000421
Ep: 29/48	It: 6751/8134	batch_loss: 3.0941	batch_accuracy: 40.48%	lr:0.000421
Ep: 29/48	It: 6801/8134	batch_loss: 3.2177	batch_accuracy: 39.97%	lr:0.000421
Ep: 29/48	It: 6851/8134	batch_loss: 3.1699	batch_accuracy: 40.80%	lr:0.000421
Ep: 29/48	It: 6901/8134	batch_loss: 3.0918	batch_accuracy: 40.60%	lr:0.000420
Ep: 29/48	It: 6951/8134	batch_loss: 3.1673	batch_accuracy: 40.19%	lr:0.000420
Ep: 29/48	It: 7001/8134	batch_loss: 3.1160	batch_accuracy: 41.28%	lr:0.000420
Ep: 29/48	It: 7051/8134	batch_loss: 3.1096	batch_accuracy: 40.82%	lr:0.000420
Ep: 29/48	It: 7101/8134	batch_loss: 3.2308	batch_accuracy: 39.06%	lr:0.000420
Ep: 29/48	It: 7151/8134	batch_loss: 3.0755	batch_accuracy: 41.21%	lr:0.000419
Ep: 29/48	It: 7201/8134	batch_loss: 3.1409	batch_accuracy: 40.72%	lr:0.000419
Ep: 29/48	It: 7251/8134	batch_loss: 3.1976	batch_accuracy: 39.53%	lr:0.000419
Ep: 29/48	It: 7301/8134	batch_loss: 3.2048	batch_accuracy: 39.53%	lr:0.000419
Ep: 29/48	It: 7351/8134	batch_loss: 3.0396	batch_accuracy: 41.38%	lr:0.000419
Ep: 29/48	It: 7401/8134	batch_loss: 3.1022	batch_accuracy: 39.87%	lr:0.000418
Ep: 29/48	It: 7451/8134	batch_loss: 3.0618	batch_accuracy: 41.70%	lr:0.000418
Ep: 29/48	It: 7501/8134	batch_loss: 3.1548	batch_accuracy: 40.77%	lr:0.000418
Ep: 29/48	It: 7551/8134	batch_loss: 3.1092	batch_accuracy: 41.31%	lr:0.000418
Ep: 29/48	It: 7601/8134	batch_loss: 3.0180	batch_accuracy: 41.89%	lr:0.000417
Ep: 29/48	It: 7651/8134	batch_loss: 3.2058	batch_accuracy: 39.75%	lr:0.000417
Ep: 29/48	It: 7701/8134	batch_loss: 3.0359	batch_accuracy: 40.89%	lr:0.000417
Ep: 29/48	It: 7751/8134	batch_loss: 3.2847	batch_accuracy: 38.82%	lr:0.000417
Ep: 29/48	It: 7801/8134	batch_loss: 3.1260	batch_accuracy: 40.31%	lr:0.000417
Ep: 29/48	It: 7851/8134	batch_loss: 3.0748	batch_accuracy: 42.02%	lr:0.000416
Ep: 29/48	It: 7901/8134	batch_loss: 2.9891	batch_accuracy: 42.21%	lr:0.000416
Ep: 29/48	It: 7951/8134	batch_loss: 3.0997	batch_accuracy: 41.16%	lr:0.000416
Ep: 29/48	It: 8001/8134	batch_loss: 3.1018	batch_accuracy: 39.01%	lr:0.000416
Ep: 29/48	It: 8051/8134	batch_loss: 3.2630	batch_accuracy: 39.45%	lr:0.000415
Ep: 29/48	It: 8101/8134	batch_loss: 3.1590	batch_accuracy: 40.43%	lr:0.000415
Ep: 29/48	It: 8134/8134	batch_loss: 3.0907	batch_accuracy: 41.17%	lr:0.000415


Generated text for input text "You" is:
Youis: C. Mcdar and M. Hart, G. Camali M A G M A L I R F L T T H L T N F F F E T A C F F F S E R S A P E C T W A R S E F E E L A N T N F A T E R E M S T E L T N B S T N E D P E R E P B E T S P S S P. T S W I A G R E R S S I P R S C N G A R A G S T R B S I R E R A L O P D S SI R E D U R E F A G B E T E R O S E I R D U D F E I R F T S A F T I R E F S B D U F I R O N T I E F R D I B I S P L O N T R F S I T A T T I N A L I D I R O T I R S I A T I S I S A T A L O T I A D I D U S I S T I R F T I A S A L I O


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 30/48	It: 1/8134	batch_loss: 3.1150	batch_accuracy: 41.14%	lr:0.000415
Ep: 30/48	It: 51/8134	batch_loss: 3.1771	batch_accuracy: 40.70%	lr:0.000415
Ep: 30/48	It: 101/8134	batch_loss: 3.1760	batch_accuracy: 40.26%	lr:0.000415
Ep: 30/48	It: 151/8134	batch_loss: 3.2420	batch_accuracy: 39.06%	lr:0.000414
Ep: 30/48	It: 201/8134	batch_loss: 3.1297	batch_accuracy: 40.97%	lr:0.000414
Ep: 30/48	It: 251/8134	batch_loss: 3.1895	batch_accuracy: 38.79%	lr:0.000414
Ep: 30/48	It: 301/8134	batch_loss: 3.1002	batch_accuracy: 41.21%	lr:0.000414
Ep: 30/48	It: 351/8134	batch_loss: 2.9792	batch_accuracy: 41.94%	lr:0.000414
Ep: 30/48	It: 401/8134	batch_loss: 3.1168	batch_accuracy: 39.94%	lr:0.000413
Ep: 30/48	It: 451/8134	batch_loss: 3.1409	batch_accuracy: 40.16%	lr:0.000413
Ep: 30/48	It: 501/8134	batch_loss: 3.0856	batch_accuracy: 40.50%	lr:0.000413
Ep: 30/48	It: 551/8134	batch_loss: 3.2583	batch_accuracy: 38.87%	lr:0.000413
Ep: 30/48	It: 601/8134	batch_loss: 3.1673	batch_accuracy: 38.94%	lr:0.000412
Ep: 30/48	It: 651/8134	batch_loss: 3.1816	batch_accuracy: 40.23%	lr:0.000412
Ep: 30/48	It: 701/8134	batch_loss: 3.1097	batch_accuracy: 40.84%	lr:0.000412
Ep: 30/48	It: 751/8134	batch_loss: 3.1242	batch_accuracy: 40.82%	lr:0.000412
Ep: 30/48	It: 801/8134	batch_loss: 3.1584	batch_accuracy: 39.11%	lr:0.000412
Ep: 30/48	It: 851/8134	batch_loss: 3.0291	batch_accuracy: 41.97%	lr:0.000411
Ep: 30/48	It: 901/8134	batch_loss: 3.0873	batch_accuracy: 40.89%	lr:0.000411
Ep: 30/48	It: 951/8134	batch_loss: 3.1808	batch_accuracy: 39.82%	lr:0.000411
Ep: 30/48	It: 1001/8134	batch_loss: 3.0690	batch_accuracy: 41.55%	lr:0.000411
Ep: 30/48	It: 1051/8134	batch_loss: 3.0709	batch_accuracy: 41.63%	lr:0.000410
Ep: 30/48	It: 1101/8134	batch_loss: 3.1130	batch_accuracy: 40.87%	lr:0.000410
Ep: 30/48	It: 1151/8134	batch_loss: 3.1276	batch_accuracy: 40.97%	lr:0.000410
Ep: 30/48	It: 1201/8134	batch_loss: 3.1535	batch_accuracy: 40.21%	lr:0.000410
Ep: 30/48	It: 1251/8134	batch_loss: 3.1587	batch_accuracy: 40.36%	lr:0.000410
Ep: 30/48	It: 1301/8134	batch_loss: 3.1729	batch_accuracy: 39.84%	lr:0.000409
Ep: 30/48	It: 1351/8134	batch_loss: 3.1937	batch_accuracy: 38.89%	lr:0.000409
Ep: 30/48	It: 1401/8134	batch_loss: 3.1446	batch_accuracy: 39.06%	lr:0.000409
Ep: 30/48	It: 1451/8134	batch_loss: 3.1116	batch_accuracy: 40.31%	lr:0.000409
Ep: 30/48	It: 1501/8134	batch_loss: 3.0263	batch_accuracy: 40.89%	lr:0.000409
Ep: 30/48	It: 1551/8134	batch_loss: 3.0530	batch_accuracy: 41.77%	lr:0.000408
Ep: 30/48	It: 1601/8134	batch_loss: 3.1136	batch_accuracy: 41.02%	lr:0.000408
Ep: 30/48	It: 1651/8134	batch_loss: 3.0572	batch_accuracy: 41.92%	lr:0.000408
Ep: 30/48	It: 1701/8134	batch_loss: 3.1084	batch_accuracy: 41.11%	lr:0.000408
Ep: 30/48	It: 1751/8134	batch_loss: 3.1744	batch_accuracy: 39.82%	lr:0.000407
Ep: 30/48	It: 1801/8134	batch_loss: 3.0349	batch_accuracy: 42.21%	lr:0.000407
Ep: 30/48	It: 1851/8134	batch_loss: 3.1876	batch_accuracy: 39.67%	lr:0.000407
Ep: 30/48	It: 1901/8134	batch_loss: 3.1095	batch_accuracy: 39.53%	lr:0.000407
Ep: 30/48	It: 1951/8134	batch_loss: 3.1588	batch_accuracy: 39.33%	lr:0.000407
Ep: 30/48	It: 2001/8134	batch_loss: 3.1047	batch_accuracy: 41.46%	lr:0.000406
Ep: 30/48	It: 2051/8134	batch_loss: 3.0858	batch_accuracy: 41.55%	lr:0.000406
Ep: 30/48	It: 2101/8134	batch_loss: 3.0962	batch_accuracy: 41.36%	lr:0.000406
Ep: 30/48	It: 2151/8134	batch_loss: 3.1136	batch_accuracy: 40.89%	lr:0.000406
Ep: 30/48	It: 2201/8134	batch_loss: 3.1258	batch_accuracy: 40.48%	lr:0.000405
Ep: 30/48	It: 2251/8134	batch_loss: 3.0622	batch_accuracy: 41.70%	lr:0.000405
Ep: 30/48	It: 2301/8134	batch_loss: 3.1507	batch_accuracy: 40.14%	lr:0.000405
Ep: 30/48	It: 2351/8134	batch_loss: 3.0856	batch_accuracy: 41.36%	lr:0.000405
Ep: 30/48	It: 2401/8134	batch_loss: 3.0977	batch_accuracy: 42.16%	lr:0.000405
Ep: 30/48	It: 2451/8134	batch_loss: 3.1232	batch_accuracy: 40.04%	lr:0.000404
Ep: 30/48	It: 2501/8134	batch_loss: 3.1007	batch_accuracy: 41.33%	lr:0.000404
Ep: 30/48	It: 2551/8134	batch_loss: 3.1323	batch_accuracy: 39.70%	lr:0.000404
Ep: 30/48	It: 2601/8134	batch_loss: 3.1060	batch_accuracy: 41.53%	lr:0.000404
Ep: 30/48	It: 2651/8134	batch_loss: 3.0202	batch_accuracy: 41.75%	lr:0.000404
Ep: 30/48	It: 2701/8134	batch_loss: 3.1279	batch_accuracy: 41.38%	lr:0.000403
Ep: 30/48	It: 2751/8134	batch_loss: 3.0757	batch_accuracy: 41.55%	lr:0.000403
Ep: 30/48	It: 2801/8134	batch_loss: 3.0457	batch_accuracy: 41.67%	lr:0.000403
Ep: 30/48	It: 2851/8134	batch_loss: 3.0422	batch_accuracy: 41.36%	lr:0.000403
Ep: 30/48	It: 2901/8134	batch_loss: 3.1157	batch_accuracy: 40.38%	lr:0.000402
Ep: 30/48	It: 2951/8134	batch_loss: 3.1996	batch_accuracy: 39.65%	lr:0.000402
Ep: 30/48	It: 3001/8134	batch_loss: 3.2189	batch_accuracy: 39.01%	lr:0.000402
Ep: 30/48	It: 3051/8134	batch_loss: 3.0824	batch_accuracy: 40.92%	lr:0.000402
Ep: 30/48	It: 3101/8134	batch_loss: 3.1738	batch_accuracy: 40.31%	lr:0.000402
Ep: 30/48	It: 3151/8134	batch_loss: 3.2664	batch_accuracy: 39.01%	lr:0.000401
Ep: 30/48	It: 3201/8134	batch_loss: 3.0890	batch_accuracy: 41.06%	lr:0.000401
Ep: 30/48	It: 3251/8134	batch_loss: 3.1429	batch_accuracy: 41.26%	lr:0.000401
Ep: 30/48	It: 3301/8134	batch_loss: 3.1408	batch_accuracy: 39.94%	lr:0.000401
Ep: 30/48	It: 3351/8134	batch_loss: 3.0962	batch_accuracy: 40.72%	lr:0.000400
Ep: 30/48	It: 3401/8134	batch_loss: 3.0517	batch_accuracy: 41.31%	lr:0.000400
Ep: 30/48	It: 3451/8134	batch_loss: 3.0032	batch_accuracy: 41.36%	lr:0.000400
Ep: 30/48	It: 3501/8134	batch_loss: 3.1506	batch_accuracy: 39.99%	lr:0.000400
Ep: 30/48	It: 3551/8134	batch_loss: 3.0940	batch_accuracy: 41.43%	lr:0.000400
Ep: 30/48	It: 3601/8134	batch_loss: 3.2332	batch_accuracy: 38.82%	lr:0.000399
Ep: 30/48	It: 3651/8134	batch_loss: 3.1071	batch_accuracy: 40.36%	lr:0.000399
Ep: 30/48	It: 3701/8134	batch_loss: 3.1042	batch_accuracy: 40.72%	lr:0.000399
Ep: 30/48	It: 3751/8134	batch_loss: 3.1109	batch_accuracy: 40.70%	lr:0.000399
Ep: 30/48	It: 3801/8134	batch_loss: 3.1042	batch_accuracy: 40.97%	lr:0.000399
Ep: 30/48	It: 3851/8134	batch_loss: 2.9883	batch_accuracy: 42.99%	lr:0.000398
Ep: 30/48	It: 3901/8134	batch_loss: 3.0231	batch_accuracy: 41.11%	lr:0.000398
Ep: 30/48	It: 3951/8134	batch_loss: 2.9848	batch_accuracy: 42.38%	lr:0.000398
Ep: 30/48	It: 4001/8134	batch_loss: 3.1155	batch_accuracy: 40.01%	lr:0.000398
Ep: 30/48	It: 4051/8134	batch_loss: 3.1637	batch_accuracy: 40.41%	lr:0.000397
Ep: 30/48	It: 4101/8134	batch_loss: 3.1691	batch_accuracy: 38.53%	lr:0.000397
Ep: 30/48	It: 4151/8134	batch_loss: 3.0999	batch_accuracy: 41.63%	lr:0.000397
Ep: 30/48	It: 4201/8134	batch_loss: 3.2624	batch_accuracy: 38.11%	lr:0.000397
Ep: 30/48	It: 4251/8134	batch_loss: 3.1086	batch_accuracy: 41.58%	lr:0.000397
Ep: 30/48	It: 4301/8134	batch_loss: 3.0697	batch_accuracy: 40.94%	lr:0.000396
Ep: 30/48	It: 4351/8134	batch_loss: 3.1516	batch_accuracy: 40.55%	lr:0.000396
Ep: 30/48	It: 4401/8134	batch_loss: 3.2167	batch_accuracy: 39.50%	lr:0.000396
Ep: 30/48	It: 4451/8134	batch_loss: 3.1248	batch_accuracy: 39.70%	lr:0.000396
Ep: 30/48	It: 4501/8134	batch_loss: 3.1877	batch_accuracy: 38.94%	lr:0.000395
Ep: 30/48	It: 4551/8134	batch_loss: 3.0203	batch_accuracy: 42.09%	lr:0.000395
Ep: 30/48	It: 4601/8134	batch_loss: 3.2142	batch_accuracy: 38.67%	lr:0.000395
Ep: 30/48	It: 4651/8134	batch_loss: 2.9803	batch_accuracy: 42.63%	lr:0.000395
Ep: 30/48	It: 4701/8134	batch_loss: 3.1274	batch_accuracy: 40.50%	lr:0.000395
Ep: 30/48	It: 4751/8134	batch_loss: 3.1483	batch_accuracy: 39.06%	lr:0.000394
Ep: 30/48	It: 4801/8134	batch_loss: 3.0618	batch_accuracy: 40.58%	lr:0.000394
Ep: 30/48	It: 4851/8134	batch_loss: 3.1520	batch_accuracy: 39.72%	lr:0.000394
Ep: 30/48	It: 4901/8134	batch_loss: 3.0931	batch_accuracy: 41.48%	lr:0.000394
Ep: 30/48	It: 4951/8134	batch_loss: 3.0933	batch_accuracy: 41.36%	lr:0.000394
Ep: 30/48	It: 5001/8134	batch_loss: 3.0186	batch_accuracy: 40.77%	lr:0.000393
Ep: 30/48	It: 5051/8134	batch_loss: 3.0135	batch_accuracy: 42.21%	lr:0.000393
Ep: 30/48	It: 5101/8134	batch_loss: 3.1222	batch_accuracy: 40.48%	lr:0.000393
Ep: 30/48	It: 5151/8134	batch_loss: 3.1910	batch_accuracy: 40.04%	lr:0.000393
Ep: 30/48	It: 5201/8134	batch_loss: 3.1052	batch_accuracy: 40.41%	lr:0.000392
Ep: 30/48	It: 5251/8134	batch_loss: 3.1048	batch_accuracy: 41.43%	lr:0.000392
Ep: 30/48	It: 5301/8134	batch_loss: 3.1432	batch_accuracy: 40.33%	lr:0.000392
Ep: 30/48	It: 5351/8134	batch_loss: 3.0713	batch_accuracy: 41.19%	lr:0.000392
Ep: 30/48	It: 5401/8134	batch_loss: 3.0475	batch_accuracy: 40.62%	lr:0.000392
Ep: 30/48	It: 5451/8134	batch_loss: 3.1128	batch_accuracy: 41.26%	lr:0.000391
Ep: 30/48	It: 5501/8134	batch_loss: 3.0084	batch_accuracy: 43.14%	lr:0.000391
Ep: 30/48	It: 5551/8134	batch_loss: 3.1401	batch_accuracy: 40.43%	lr:0.000391
Ep: 30/48	It: 5601/8134	batch_loss: 2.9966	batch_accuracy: 42.43%	lr:0.000391
Ep: 30/48	It: 5651/8134	batch_loss: 3.0922	batch_accuracy: 40.26%	lr:0.000391
Ep: 30/48	It: 5701/8134	batch_loss: 3.1904	batch_accuracy: 40.38%	lr:0.000390
Ep: 30/48	It: 5751/8134	batch_loss: 3.0570	batch_accuracy: 40.97%	lr:0.000390
Ep: 30/48	It: 5801/8134	batch_loss: 3.1550	batch_accuracy: 40.21%	lr:0.000390
Ep: 30/48	It: 5851/8134	batch_loss: 3.1359	batch_accuracy: 40.19%	lr:0.000390
Ep: 30/48	It: 5901/8134	batch_loss: 3.0834	batch_accuracy: 40.11%	lr:0.000389
Ep: 30/48	It: 5951/8134	batch_loss: 3.1221	batch_accuracy: 39.99%	lr:0.000389
Ep: 30/48	It: 6001/8134	batch_loss: 3.1175	batch_accuracy: 40.58%	lr:0.000389
Ep: 30/48	It: 6051/8134	batch_loss: 3.0969	batch_accuracy: 40.55%	lr:0.000389
Ep: 30/48	It: 6101/8134	batch_loss: 3.0425	batch_accuracy: 41.46%	lr:0.000389
Ep: 30/48	It: 6151/8134	batch_loss: 3.1395	batch_accuracy: 40.38%	lr:0.000388
Ep: 30/48	It: 6201/8134	batch_loss: 3.1651	batch_accuracy: 40.43%	lr:0.000388
Ep: 30/48	It: 6251/8134	batch_loss: 3.0528	batch_accuracy: 40.94%	lr:0.000388
Ep: 30/48	It: 6301/8134	batch_loss: 3.1108	batch_accuracy: 41.31%	lr:0.000388
Ep: 30/48	It: 6351/8134	batch_loss: 3.1015	batch_accuracy: 40.67%	lr:0.000387
Ep: 30/48	It: 6401/8134	batch_loss: 3.1239	batch_accuracy: 40.82%	lr:0.000387
Ep: 30/48	It: 6451/8134	batch_loss: 3.1974	batch_accuracy: 39.01%	lr:0.000387
Ep: 30/48	It: 6501/8134	batch_loss: 3.0921	batch_accuracy: 41.28%	lr:0.000387
Ep: 30/48	It: 6551/8134	batch_loss: 2.9321	batch_accuracy: 42.09%	lr:0.000387
Ep: 30/48	It: 6601/8134	batch_loss: 3.1454	batch_accuracy: 40.36%	lr:0.000386
Ep: 30/48	It: 6651/8134	batch_loss: 3.1027	batch_accuracy: 40.55%	lr:0.000386
Ep: 30/48	It: 6701/8134	batch_loss: 3.0812	batch_accuracy: 41.46%	lr:0.000386
Ep: 30/48	It: 6751/8134	batch_loss: 3.0289	batch_accuracy: 41.92%	lr:0.000386
Ep: 30/48	It: 6801/8134	batch_loss: 3.1037	batch_accuracy: 40.09%	lr:0.000386
Ep: 30/48	It: 6851/8134	batch_loss: 3.2328	batch_accuracy: 38.96%	lr:0.000385
Ep: 30/48	It: 6901/8134	batch_loss: 3.1485	batch_accuracy: 40.92%	lr:0.000385
Ep: 30/48	It: 6951/8134	batch_loss: 3.1163	batch_accuracy: 39.70%	lr:0.000385
Ep: 30/48	It: 7001/8134	batch_loss: 3.0947	batch_accuracy: 41.65%	lr:0.000385
Ep: 30/48	It: 7051/8134	batch_loss: 3.1618	batch_accuracy: 40.72%	lr:0.000384
Ep: 30/48	It: 7101/8134	batch_loss: 3.1805	batch_accuracy: 39.72%	lr:0.000384
Ep: 30/48	It: 7151/8134	batch_loss: 3.1642	batch_accuracy: 39.75%	lr:0.000384
Ep: 30/48	It: 7201/8134	batch_loss: 3.0971	batch_accuracy: 41.02%	lr:0.000384
Ep: 30/48	It: 7251/8134	batch_loss: 3.0945	batch_accuracy: 40.55%	lr:0.000384
Ep: 30/48	It: 7301/8134	batch_loss: 3.0365	batch_accuracy: 41.38%	lr:0.000383
Ep: 30/48	It: 7351/8134	batch_loss: 3.2211	batch_accuracy: 38.70%	lr:0.000383
Ep: 30/48	It: 7401/8134	batch_loss: 3.0149	batch_accuracy: 41.43%	lr:0.000383
Ep: 30/48	It: 7451/8134	batch_loss: 3.1044	batch_accuracy: 40.87%	lr:0.000383
Ep: 30/48	It: 7501/8134	batch_loss: 3.0258	batch_accuracy: 41.24%	lr:0.000383
Ep: 30/48	It: 7551/8134	batch_loss: 3.1666	batch_accuracy: 40.19%	lr:0.000382
Ep: 30/48	It: 7601/8134	batch_loss: 3.1243	batch_accuracy: 39.28%	lr:0.000382
Ep: 30/48	It: 7651/8134	batch_loss: 3.1642	batch_accuracy: 39.38%	lr:0.000382
Ep: 30/48	It: 7701/8134	batch_loss: 3.2369	batch_accuracy: 38.82%	lr:0.000382
Ep: 30/48	It: 7751/8134	batch_loss: 3.1627	batch_accuracy: 39.92%	lr:0.000381
Ep: 30/48	It: 7801/8134	batch_loss: 3.0754	batch_accuracy: 40.16%	lr:0.000381
Ep: 30/48	It: 7851/8134	batch_loss: 3.0612	batch_accuracy: 41.19%	lr:0.000381
Ep: 30/48	It: 7901/8134	batch_loss: 3.1002	batch_accuracy: 40.58%	lr:0.000381
Ep: 30/48	It: 7951/8134	batch_loss: 3.1710	batch_accuracy: 39.82%	lr:0.000381
Ep: 30/48	It: 8001/8134	batch_loss: 3.0967	batch_accuracy: 40.62%	lr:0.000380
Ep: 30/48	It: 8051/8134	batch_loss: 3.0954	batch_accuracy: 39.82%	lr:0.000380
Ep: 30/48	It: 8101/8134	batch_loss: 3.1301	batch_accuracy: 40.62%	lr:0.000380
Ep: 30/48	It: 8134/8134	batch_loss: 3.0861	batch_accuracy: 40.25%	lr:0.000380


Generated text for input text "You" is:
You, Robinson, and M, Jr.
The author discusses the role of theatre in this essay. I will also discuss theological and historical perspectives of theology, and theological, social theory. In theology of theology and philosophy of theology, and the psychology of theology, theologians of theology and the psychology of modern medicine, theology and philosophy of theology, theology, and psychology of mathematics. In the first section of the article, I will summarize the history of mathematics and philosophy of mathematics. I will also discuss the ways in which mathematics is applied to mathematics and mathematics. The third section is devoted to mathematics, and it will present mathematics in mathematics.
<eot>
<sot>
Multiple Strategies of Memory to Promote the Cognition of Memory in Children

Memory-based memory is a memory task that can be exploited to support cognitive and cognitive functions in children. Memory-based memory can be a useful model for children with memory impairment. However, the current Memory-based


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 31/48	It: 1/8134	batch_loss: 3.0715	batch_accuracy: 41.70%	lr:0.000380
Ep: 31/48	It: 51/8134	batch_loss: 3.0887	batch_accuracy: 41.16%	lr:0.000380
Ep: 31/48	It: 101/8134	batch_loss: 3.1167	batch_accuracy: 40.80%	lr:0.000379
Ep: 31/48	It: 151/8134	batch_loss: 3.0972	batch_accuracy: 40.43%	lr:0.000379
Ep: 31/48	It: 201/8134	batch_loss: 3.1314	batch_accuracy: 41.46%	lr:0.000379
Ep: 31/48	It: 251/8134	batch_loss: 3.0840	batch_accuracy: 40.67%	lr:0.000379
Ep: 31/48	It: 301/8134	batch_loss: 3.2195	batch_accuracy: 39.26%	lr:0.000379
Ep: 31/48	It: 351/8134	batch_loss: 3.0289	batch_accuracy: 42.16%	lr:0.000378
Ep: 31/48	It: 401/8134	batch_loss: 3.0889	batch_accuracy: 40.31%	lr:0.000378
Ep: 31/48	It: 451/8134	batch_loss: 3.0287	batch_accuracy: 42.63%	lr:0.000378
Ep: 31/48	It: 501/8134	batch_loss: 3.0345	batch_accuracy: 41.31%	lr:0.000378
Ep: 31/48	It: 551/8134	batch_loss: 3.1346	batch_accuracy: 40.84%	lr:0.000377
Ep: 31/48	It: 601/8134	batch_loss: 3.1083	batch_accuracy: 41.11%	lr:0.000377
Ep: 31/48	It: 651/8134	batch_loss: 3.0830	batch_accuracy: 40.43%	lr:0.000377
Ep: 31/48	It: 701/8134	batch_loss: 3.1735	batch_accuracy: 39.36%	lr:0.000377
Ep: 31/48	It: 751/8134	batch_loss: 3.0006	batch_accuracy: 41.28%	lr:0.000377
Ep: 31/48	It: 801/8134	batch_loss: 3.0134	batch_accuracy: 42.85%	lr:0.000376
Ep: 31/48	It: 851/8134	batch_loss: 3.1318	batch_accuracy: 40.65%	lr:0.000376
Ep: 31/48	It: 901/8134	batch_loss: 3.1027	batch_accuracy: 41.97%	lr:0.000376
Ep: 31/48	It: 951/8134	batch_loss: 3.1646	batch_accuracy: 39.53%	lr:0.000376
Ep: 31/48	It: 1001/8134	batch_loss: 3.1826	batch_accuracy: 39.26%	lr:0.000375
Ep: 31/48	It: 1051/8134	batch_loss: 3.0891	batch_accuracy: 40.58%	lr:0.000375
Ep: 31/48	It: 1101/8134	batch_loss: 3.1298	batch_accuracy: 41.11%	lr:0.000375
Ep: 31/48	It: 1151/8134	batch_loss: 3.1016	batch_accuracy: 41.09%	lr:0.000375
Ep: 31/48	It: 1201/8134	batch_loss: 3.1134	batch_accuracy: 41.55%	lr:0.000375
Ep: 31/48	It: 1251/8134	batch_loss: 3.2566	batch_accuracy: 38.26%	lr:0.000374
Ep: 31/48	It: 1301/8134	batch_loss: 3.0233	batch_accuracy: 42.11%	lr:0.000374
Ep: 31/48	It: 1351/8134	batch_loss: 3.0012	batch_accuracy: 42.50%	lr:0.000374
Ep: 31/48	It: 1401/8134	batch_loss: 3.0504	batch_accuracy: 42.24%	lr:0.000374
Ep: 31/48	It: 1451/8134	batch_loss: 3.0915	batch_accuracy: 40.11%	lr:0.000374
Ep: 31/48	It: 1501/8134	batch_loss: 3.1218	batch_accuracy: 40.65%	lr:0.000373
Ep: 31/48	It: 1551/8134	batch_loss: 3.1046	batch_accuracy: 41.31%	lr:0.000373
Ep: 31/48	It: 1601/8134	batch_loss: 2.9924	batch_accuracy: 42.24%	lr:0.000373
Ep: 31/48	It: 1651/8134	batch_loss: 3.0419	batch_accuracy: 41.55%	lr:0.000373
Ep: 31/48	It: 1701/8134	batch_loss: 3.1948	batch_accuracy: 39.67%	lr:0.000372
Ep: 31/48	It: 1751/8134	batch_loss: 3.1499	batch_accuracy: 39.60%	lr:0.000372
Ep: 31/48	It: 1801/8134	batch_loss: 3.1142	batch_accuracy: 40.09%	lr:0.000372
Ep: 31/48	It: 1851/8134	batch_loss: 3.0168	batch_accuracy: 42.41%	lr:0.000372
Ep: 31/48	It: 1901/8134	batch_loss: 3.1369	batch_accuracy: 40.55%	lr:0.000372
Ep: 31/48	It: 1951/8134	batch_loss: 3.1593	batch_accuracy: 40.23%	lr:0.000371
Ep: 31/48	It: 2001/8134	batch_loss: 3.1989	batch_accuracy: 39.16%	lr:0.000371
Ep: 31/48	It: 2051/8134	batch_loss: 3.2501	batch_accuracy: 38.62%	lr:0.000371
Ep: 31/48	It: 2101/8134	batch_loss: 3.1899	batch_accuracy: 39.97%	lr:0.000371
Ep: 31/48	It: 2151/8134	batch_loss: 3.1275	batch_accuracy: 40.38%	lr:0.000371
Ep: 31/48	It: 2201/8134	batch_loss: 3.2868	batch_accuracy: 37.33%	lr:0.000370
Ep: 31/48	It: 2251/8134	batch_loss: 3.0521	batch_accuracy: 41.75%	lr:0.000370
Ep: 31/48	It: 2301/8134	batch_loss: 3.2932	batch_accuracy: 38.13%	lr:0.000370
Ep: 31/48	It: 2351/8134	batch_loss: 3.1135	batch_accuracy: 40.48%	lr:0.000370
Ep: 31/48	It: 2401/8134	batch_loss: 3.1763	batch_accuracy: 39.84%	lr:0.000369
Ep: 31/48	It: 2451/8134	batch_loss: 3.0815	batch_accuracy: 40.62%	lr:0.000369
Ep: 31/48	It: 2501/8134	batch_loss: 3.0040	batch_accuracy: 42.38%	lr:0.000369
Ep: 31/48	It: 2551/8134	batch_loss: 3.0758	batch_accuracy: 40.99%	lr:0.000369
Ep: 31/48	It: 2601/8134	batch_loss: 3.0901	batch_accuracy: 40.62%	lr:0.000369
Ep: 31/48	It: 2651/8134	batch_loss: 3.1042	batch_accuracy: 41.75%	lr:0.000368
Ep: 31/48	It: 2701/8134	batch_loss: 3.1089	batch_accuracy: 42.16%	lr:0.000368
Ep: 31/48	It: 2751/8134	batch_loss: 3.0265	batch_accuracy: 41.80%	lr:0.000368
Ep: 31/48	It: 2801/8134	batch_loss: 3.0211	batch_accuracy: 41.06%	lr:0.000368
Ep: 31/48	It: 2851/8134	batch_loss: 3.1299	batch_accuracy: 39.09%	lr:0.000368
Ep: 31/48	It: 2901/8134	batch_loss: 3.1706	batch_accuracy: 40.11%	lr:0.000367
Ep: 31/48	It: 2951/8134	batch_loss: 3.2061	batch_accuracy: 38.89%	lr:0.000367
Ep: 31/48	It: 3001/8134	batch_loss: 3.0768	batch_accuracy: 41.09%	lr:0.000367
Ep: 31/48	It: 3051/8134	batch_loss: 3.1859	batch_accuracy: 39.70%	lr:0.000367
Ep: 31/48	It: 3101/8134	batch_loss: 3.1133	batch_accuracy: 40.19%	lr:0.000367
Ep: 31/48	It: 3151/8134	batch_loss: 3.1342	batch_accuracy: 40.26%	lr:0.000366
Ep: 31/48	It: 3201/8134	batch_loss: 2.9917	batch_accuracy: 42.19%	lr:0.000366
Ep: 31/48	It: 3251/8134	batch_loss: 3.0415	batch_accuracy: 40.60%	lr:0.000366
Ep: 31/48	It: 3301/8134	batch_loss: 3.1454	batch_accuracy: 40.06%	lr:0.000366
Ep: 31/48	It: 3351/8134	batch_loss: 3.0904	batch_accuracy: 40.41%	lr:0.000365
Ep: 31/48	It: 3401/8134	batch_loss: 2.9830	batch_accuracy: 42.92%	lr:0.000365
Ep: 31/48	It: 3451/8134	batch_loss: 3.1389	batch_accuracy: 39.60%	lr:0.000365
Ep: 31/48	It: 3501/8134	batch_loss: 3.2255	batch_accuracy: 38.67%	lr:0.000365
Ep: 31/48	It: 3551/8134	batch_loss: 3.1600	batch_accuracy: 40.80%	lr:0.000365
Ep: 31/48	It: 3601/8134	batch_loss: 3.1618	batch_accuracy: 40.50%	lr:0.000364
Ep: 31/48	It: 3651/8134	batch_loss: 3.1151	batch_accuracy: 40.48%	lr:0.000364
Ep: 31/48	It: 3701/8134	batch_loss: 3.0865	batch_accuracy: 41.43%	lr:0.000364
Ep: 31/48	It: 3751/8134	batch_loss: 3.0427	batch_accuracy: 41.89%	lr:0.000364
Ep: 31/48	It: 3801/8134	batch_loss: 3.1216	batch_accuracy: 40.09%	lr:0.000364
Ep: 31/48	It: 3851/8134	batch_loss: 3.0208	batch_accuracy: 42.58%	lr:0.000363
Ep: 31/48	It: 3901/8134	batch_loss: 2.9336	batch_accuracy: 43.60%	lr:0.000363
Ep: 31/48	It: 3951/8134	batch_loss: 3.0774	batch_accuracy: 41.85%	lr:0.000363
Ep: 31/48	It: 4001/8134	batch_loss: 3.1163	batch_accuracy: 40.97%	lr:0.000363
Ep: 31/48	It: 4051/8134	batch_loss: 3.2349	batch_accuracy: 39.82%	lr:0.000362
Ep: 31/48	It: 4101/8134	batch_loss: 3.1865	batch_accuracy: 39.23%	lr:0.000362
Ep: 31/48	It: 4151/8134	batch_loss: 2.9932	batch_accuracy: 41.72%	lr:0.000362
Ep: 31/48	It: 4201/8134	batch_loss: 3.1491	batch_accuracy: 40.50%	lr:0.000362
Ep: 31/48	It: 4251/8134	batch_loss: 3.2428	batch_accuracy: 38.84%	lr:0.000362
Ep: 31/48	It: 4301/8134	batch_loss: 3.0886	batch_accuracy: 41.67%	lr:0.000361
Ep: 31/48	It: 4351/8134	batch_loss: 3.0420	batch_accuracy: 41.53%	lr:0.000361
Ep: 31/48	It: 4401/8134	batch_loss: 3.0396	batch_accuracy: 41.48%	lr:0.000361
Ep: 31/48	It: 4451/8134	batch_loss: 3.1361	batch_accuracy: 40.21%	lr:0.000361
Ep: 31/48	It: 4501/8134	batch_loss: 3.1011	batch_accuracy: 40.65%	lr:0.000361
Ep: 31/48	It: 4551/8134	batch_loss: 3.0460	batch_accuracy: 40.82%	lr:0.000360
Ep: 31/48	It: 4601/8134	batch_loss: 3.1407	batch_accuracy: 39.36%	lr:0.000360
Ep: 31/48	It: 4651/8134	batch_loss: 3.1881	batch_accuracy: 39.43%	lr:0.000360
Ep: 31/48	It: 4701/8134	batch_loss: 3.1676	batch_accuracy: 40.01%	lr:0.000360
Ep: 31/48	It: 4751/8134	batch_loss: 3.1624	batch_accuracy: 39.45%	lr:0.000359
Ep: 31/48	It: 4801/8134	batch_loss: 2.9692	batch_accuracy: 43.14%	lr:0.000359
Ep: 31/48	It: 4851/8134	batch_loss: 3.1462	batch_accuracy: 40.16%	lr:0.000359
Ep: 31/48	It: 4901/8134	batch_loss: 3.0579	batch_accuracy: 41.58%	lr:0.000359
Ep: 31/48	It: 4951/8134	batch_loss: 3.0035	batch_accuracy: 41.77%	lr:0.000359
Ep: 31/48	It: 5001/8134	batch_loss: 3.1478	batch_accuracy: 39.48%	lr:0.000358
Ep: 31/48	It: 5051/8134	batch_loss: 2.9943	batch_accuracy: 42.60%	lr:0.000358
Ep: 31/48	It: 5101/8134	batch_loss: 3.1344	batch_accuracy: 39.38%	lr:0.000358
Ep: 31/48	It: 5151/8134	batch_loss: 3.1251	batch_accuracy: 40.89%	lr:0.000358
Ep: 31/48	It: 5201/8134	batch_loss: 3.2015	batch_accuracy: 39.72%	lr:0.000358
Ep: 31/48	It: 5251/8134	batch_loss: 2.9974	batch_accuracy: 42.92%	lr:0.000357
Ep: 31/48	It: 5301/8134	batch_loss: 2.9659	batch_accuracy: 42.46%	lr:0.000357
Ep: 31/48	It: 5351/8134	batch_loss: 3.1530	batch_accuracy: 39.75%	lr:0.000357
Ep: 31/48	It: 5401/8134	batch_loss: 3.2498	batch_accuracy: 38.38%	lr:0.000357
Ep: 31/48	It: 5451/8134	batch_loss: 3.1549	batch_accuracy: 39.94%	lr:0.000357
Ep: 31/48	It: 5501/8134	batch_loss: 3.0002	batch_accuracy: 41.99%	lr:0.000356
Ep: 31/48	It: 5551/8134	batch_loss: 3.1512	batch_accuracy: 40.04%	lr:0.000356
Ep: 31/48	It: 5601/8134	batch_loss: 3.1211	batch_accuracy: 40.65%	lr:0.000356
Ep: 31/48	It: 5651/8134	batch_loss: 3.0973	batch_accuracy: 39.45%	lr:0.000356
Ep: 31/48	It: 5701/8134	batch_loss: 3.0975	batch_accuracy: 39.72%	lr:0.000355
Ep: 31/48	It: 5751/8134	batch_loss: 3.1420	batch_accuracy: 39.97%	lr:0.000355
Ep: 31/48	It: 5801/8134	batch_loss: 3.0459	batch_accuracy: 41.50%	lr:0.000355
Ep: 31/48	It: 5851/8134	batch_loss: 3.0486	batch_accuracy: 41.16%	lr:0.000355
Ep: 31/48	It: 5901/8134	batch_loss: 3.0865	batch_accuracy: 39.84%	lr:0.000355
Ep: 31/48	It: 5951/8134	batch_loss: 3.0112	batch_accuracy: 42.09%	lr:0.000354
Ep: 31/48	It: 6001/8134	batch_loss: 3.0961	batch_accuracy: 40.43%	lr:0.000354
Ep: 31/48	It: 6051/8134	batch_loss: 3.0972	batch_accuracy: 40.23%	lr:0.000354
Ep: 31/48	It: 6101/8134	batch_loss: 3.0592	batch_accuracy: 40.77%	lr:0.000354
Ep: 31/48	It: 6151/8134	batch_loss: 3.2332	batch_accuracy: 38.75%	lr:0.000354
Ep: 31/48	It: 6201/8134	batch_loss: 3.1181	batch_accuracy: 41.63%	lr:0.000353
Ep: 31/48	It: 6251/8134	batch_loss: 3.1163	batch_accuracy: 40.92%	lr:0.000353
Ep: 31/48	It: 6301/8134	batch_loss: 3.1547	batch_accuracy: 40.21%	lr:0.000353
Ep: 31/48	It: 6351/8134	batch_loss: 3.1148	batch_accuracy: 40.09%	lr:0.000353
Ep: 31/48	It: 6401/8134	batch_loss: 3.0747	batch_accuracy: 40.67%	lr:0.000352
Ep: 31/48	It: 6451/8134	batch_loss: 3.1783	batch_accuracy: 40.28%	lr:0.000352
Ep: 31/48	It: 6501/8134	batch_loss: 2.9992	batch_accuracy: 42.50%	lr:0.000352
Ep: 31/48	It: 6551/8134	batch_loss: 3.0052	batch_accuracy: 42.11%	lr:0.000352
Ep: 31/48	It: 6601/8134	batch_loss: 3.2016	batch_accuracy: 39.50%	lr:0.000352
Ep: 31/48	It: 6651/8134	batch_loss: 3.0873	batch_accuracy: 41.58%	lr:0.000351
Ep: 31/48	It: 6701/8134	batch_loss: 3.1485	batch_accuracy: 39.40%	lr:0.000351
Ep: 31/48	It: 6751/8134	batch_loss: 2.9915	batch_accuracy: 42.99%	lr:0.000351
Ep: 31/48	It: 6801/8134	batch_loss: 3.1011	batch_accuracy: 41.58%	lr:0.000351
Ep: 31/48	It: 6851/8134	batch_loss: 3.1649	batch_accuracy: 38.87%	lr:0.000351
Ep: 31/48	It: 6901/8134	batch_loss: 3.0445	batch_accuracy: 41.19%	lr:0.000350
Ep: 31/48	It: 6951/8134	batch_loss: 3.0750	batch_accuracy: 41.72%	lr:0.000350
Ep: 31/48	It: 7001/8134	batch_loss: 3.1945	batch_accuracy: 39.43%	lr:0.000350
Ep: 31/48	It: 7051/8134	batch_loss: 3.1239	batch_accuracy: 40.48%	lr:0.000350
Ep: 31/48	It: 7101/8134	batch_loss: 3.1181	batch_accuracy: 41.06%	lr:0.000350
Ep: 31/48	It: 7151/8134	batch_loss: 3.1224	batch_accuracy: 39.36%	lr:0.000349
Ep: 31/48	It: 7201/8134	batch_loss: 3.0268	batch_accuracy: 42.60%	lr:0.000349
Ep: 31/48	It: 7251/8134	batch_loss: 3.2717	batch_accuracy: 38.65%	lr:0.000349
Ep: 31/48	It: 7301/8134	batch_loss: 3.1192	batch_accuracy: 40.70%	lr:0.000349
Ep: 31/48	It: 7351/8134	batch_loss: 3.0531	batch_accuracy: 41.41%	lr:0.000348
Ep: 31/48	It: 7401/8134	batch_loss: 3.1228	batch_accuracy: 41.19%	lr:0.000348
Ep: 31/48	It: 7451/8134	batch_loss: 3.1050	batch_accuracy: 40.84%	lr:0.000348
Ep: 31/48	It: 7501/8134	batch_loss: 3.1013	batch_accuracy: 41.33%	lr:0.000348
Ep: 31/48	It: 7551/8134	batch_loss: 3.0755	batch_accuracy: 40.70%	lr:0.000348
Ep: 31/48	It: 7601/8134	batch_loss: 3.1343	batch_accuracy: 41.72%	lr:0.000347
Ep: 31/48	It: 7651/8134	batch_loss: 3.1730	batch_accuracy: 39.48%	lr:0.000347
Ep: 31/48	It: 7701/8134	batch_loss: 3.1600	batch_accuracy: 40.87%	lr:0.000347
Ep: 31/48	It: 7751/8134	batch_loss: 2.9840	batch_accuracy: 42.31%	lr:0.000347
Ep: 31/48	It: 7801/8134	batch_loss: 2.9133	batch_accuracy: 44.48%	lr:0.000347
Ep: 31/48	It: 7851/8134	batch_loss: 3.1807	batch_accuracy: 40.45%	lr:0.000346
Ep: 31/48	It: 7901/8134	batch_loss: 3.0243	batch_accuracy: 41.24%	lr:0.000346
Ep: 31/48	It: 7951/8134	batch_loss: 3.0949	batch_accuracy: 40.26%	lr:0.000346
Ep: 31/48	It: 8001/8134	batch_loss: 3.2499	batch_accuracy: 39.67%	lr:0.000346
Ep: 31/48	It: 8051/8134	batch_loss: 3.2216	batch_accuracy: 39.43%	lr:0.000346
Ep: 31/48	It: 8101/8134	batch_loss: 3.2138	batch_accuracy: 37.94%	lr:0.000345
Ep: 31/48	It: 8134/8134	batch_loss: 3.1837	batch_accuracy: 40.01%	lr:0.000345


Generated text for input text "You" is:
Youx-Li-HL, theories of theology, and theologically, theology, and theology, and theology, and on theology of Hung in particular, in theorizing theologically and politically, and intimately, theories, and theological, social, and religious approaches. The essays and narratives are discussed as well as the main themes that are discussed in this paper. The article also shows how the author and the author had a significant influence on the relationship between the Soviet society and human beings. The author discusses the role of religion in the life of people and its implications in the form of an analysis of the work of the Soviet system, the concept of human being, the concept of human life, the creation of a social life, the creation of an international social space, the creation of an individual and the development of human life, and the emergence of social and cultural values. The article is dedicated to the formation of the political system of human life. The article concludes that the social, social, and cultural values of the society, of the world, and its socialization of the human being is an ideal of the nature of modern


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 32/48	It: 1/8134	batch_loss: 3.0638	batch_accuracy: 41.50%	lr:0.000345
Ep: 32/48	It: 51/8134	batch_loss: 3.2148	batch_accuracy: 39.50%	lr:0.000345
Ep: 32/48	It: 101/8134	batch_loss: 3.0582	batch_accuracy: 41.53%	lr:0.000345
Ep: 32/48	It: 151/8134	batch_loss: 3.0150	batch_accuracy: 41.31%	lr:0.000345
Ep: 32/48	It: 201/8134	batch_loss: 3.1389	batch_accuracy: 40.48%	lr:0.000344
Ep: 32/48	It: 251/8134	batch_loss: 3.2069	batch_accuracy: 39.79%	lr:0.000344
Ep: 32/48	It: 301/8134	batch_loss: 2.9698	batch_accuracy: 43.07%	lr:0.000344
Ep: 32/48	It: 351/8134	batch_loss: 3.1040	batch_accuracy: 39.67%	lr:0.000344
Ep: 32/48	It: 401/8134	batch_loss: 3.1221	batch_accuracy: 40.33%	lr:0.000343
Ep: 32/48	It: 451/8134	batch_loss: 3.2007	batch_accuracy: 38.96%	lr:0.000343
Ep: 32/48	It: 501/8134	batch_loss: 3.0546	batch_accuracy: 40.72%	lr:0.000343
Ep: 32/48	It: 551/8134	batch_loss: 3.0873	batch_accuracy: 41.60%	lr:0.000343
Ep: 32/48	It: 601/8134	batch_loss: 3.1601	batch_accuracy: 39.89%	lr:0.000343
Ep: 32/48	It: 651/8134	batch_loss: 3.0940	batch_accuracy: 40.23%	lr:0.000342
Ep: 32/48	It: 701/8134	batch_loss: 3.0716	batch_accuracy: 41.36%	lr:0.000342
Ep: 32/48	It: 751/8134	batch_loss: 3.2444	batch_accuracy: 38.33%	lr:0.000342
Ep: 32/48	It: 801/8134	batch_loss: 3.0508	batch_accuracy: 41.80%	lr:0.000342
Ep: 32/48	It: 851/8134	batch_loss: 3.0086	batch_accuracy: 41.94%	lr:0.000342
Ep: 32/48	It: 901/8134	batch_loss: 3.0923	batch_accuracy: 41.43%	lr:0.000341
Ep: 32/48	It: 951/8134	batch_loss: 3.1233	batch_accuracy: 40.75%	lr:0.000341
Ep: 32/48	It: 1001/8134	batch_loss: 3.1812	batch_accuracy: 39.84%	lr:0.000341
Ep: 32/48	It: 1051/8134	batch_loss: 3.1105	batch_accuracy: 39.84%	lr:0.000341
Ep: 32/48	It: 1101/8134	batch_loss: 3.1535	batch_accuracy: 40.26%	lr:0.000341
Ep: 32/48	It: 1151/8134	batch_loss: 3.0988	batch_accuracy: 41.72%	lr:0.000340
Ep: 32/48	It: 1201/8134	batch_loss: 3.0661	batch_accuracy: 41.55%	lr:0.000340
Ep: 32/48	It: 1251/8134	batch_loss: 3.0819	batch_accuracy: 40.80%	lr:0.000340
Ep: 32/48	It: 1301/8134	batch_loss: 3.0896	batch_accuracy: 41.41%	lr:0.000340
Ep: 32/48	It: 1351/8134	batch_loss: 3.1057	batch_accuracy: 40.50%	lr:0.000340
Ep: 32/48	It: 1401/8134	batch_loss: 3.1064	batch_accuracy: 40.36%	lr:0.000339
Ep: 32/48	It: 1451/8134	batch_loss: 3.0448	batch_accuracy: 41.11%	lr:0.000339
Ep: 32/48	It: 1501/8134	batch_loss: 2.9862	batch_accuracy: 41.60%	lr:0.000339
Ep: 32/48	It: 1551/8134	batch_loss: 3.2333	batch_accuracy: 38.96%	lr:0.000339
Ep: 32/48	It: 1601/8134	batch_loss: 3.0676	batch_accuracy: 41.28%	lr:0.000338
Ep: 32/48	It: 1651/8134	batch_loss: 3.0585	batch_accuracy: 40.77%	lr:0.000338
Ep: 32/48	It: 1701/8134	batch_loss: 2.9924	batch_accuracy: 42.55%	lr:0.000338
Ep: 32/48	It: 1751/8134	batch_loss: 3.1607	batch_accuracy: 40.48%	lr:0.000338
Ep: 32/48	It: 1801/8134	batch_loss: 3.1403	batch_accuracy: 39.58%	lr:0.000338
Ep: 32/48	It: 1851/8134	batch_loss: 2.9573	batch_accuracy: 44.34%	lr:0.000337
Ep: 32/48	It: 1901/8134	batch_loss: 3.0766	batch_accuracy: 41.46%	lr:0.000337
Ep: 32/48	It: 1951/8134	batch_loss: 3.0999	batch_accuracy: 40.28%	lr:0.000337
Ep: 32/48	It: 2001/8134	batch_loss: 3.0469	batch_accuracy: 41.02%	lr:0.000337
Ep: 32/48	It: 2051/8134	batch_loss: 2.9661	batch_accuracy: 43.04%	lr:0.000337
Ep: 32/48	It: 2101/8134	batch_loss: 3.0562	batch_accuracy: 42.53%	lr:0.000336
Ep: 32/48	It: 2151/8134	batch_loss: 3.0299	batch_accuracy: 41.36%	lr:0.000336
Ep: 32/48	It: 2201/8134	batch_loss: 2.9748	batch_accuracy: 42.70%	lr:0.000336
Ep: 32/48	It: 2251/8134	batch_loss: 3.0634	batch_accuracy: 42.02%	lr:0.000336
Ep: 32/48	It: 2301/8134	batch_loss: 3.0870	batch_accuracy: 41.41%	lr:0.000336
Ep: 32/48	It: 2351/8134	batch_loss: 2.9569	batch_accuracy: 42.75%	lr:0.000335
Ep: 32/48	It: 2401/8134	batch_loss: 3.1889	batch_accuracy: 39.26%	lr:0.000335
Ep: 32/48	It: 2451/8134	batch_loss: 3.0188	batch_accuracy: 42.31%	lr:0.000335
Ep: 32/48	It: 2501/8134	batch_loss: 3.1106	batch_accuracy: 40.97%	lr:0.000335
Ep: 32/48	It: 2551/8134	batch_loss: 3.2060	batch_accuracy: 38.40%	lr:0.000334
Ep: 32/48	It: 2601/8134	batch_loss: 3.0309	batch_accuracy: 42.53%	lr:0.000334
Ep: 32/48	It: 2651/8134	batch_loss: 3.1558	batch_accuracy: 39.62%	lr:0.000334
Ep: 32/48	It: 2701/8134	batch_loss: 3.2070	batch_accuracy: 38.65%	lr:0.000334
Ep: 32/48	It: 2751/8134	batch_loss: 3.2803	batch_accuracy: 38.43%	lr:0.000334
Ep: 32/48	It: 2801/8134	batch_loss: 3.1929	batch_accuracy: 39.77%	lr:0.000333
Ep: 32/48	It: 2851/8134	batch_loss: 3.1288	batch_accuracy: 40.48%	lr:0.000333
Ep: 32/48	It: 2901/8134	batch_loss: 3.0450	batch_accuracy: 40.60%	lr:0.000333
Ep: 32/48	It: 2951/8134	batch_loss: 3.1596	batch_accuracy: 39.75%	lr:0.000333
Ep: 32/48	It: 3001/8134	batch_loss: 3.1850	batch_accuracy: 39.04%	lr:0.000333
Ep: 32/48	It: 3051/8134	batch_loss: 3.0407	batch_accuracy: 41.50%	lr:0.000332
Ep: 32/48	It: 3101/8134	batch_loss: 3.0705	batch_accuracy: 40.67%	lr:0.000332
Ep: 32/48	It: 3151/8134	batch_loss: 3.2317	batch_accuracy: 39.09%	lr:0.000332
Ep: 32/48	It: 3201/8134	batch_loss: 3.1610	batch_accuracy: 40.28%	lr:0.000332
Ep: 32/48	It: 3251/8134	batch_loss: 3.1719	batch_accuracy: 40.11%	lr:0.000332
Ep: 32/48	It: 3301/8134	batch_loss: 3.1576	batch_accuracy: 40.19%	lr:0.000331
Ep: 32/48	It: 3351/8134	batch_loss: 3.1035	batch_accuracy: 41.19%	lr:0.000331
Ep: 32/48	It: 3401/8134	batch_loss: 3.2255	batch_accuracy: 39.72%	lr:0.000331
Ep: 32/48	It: 3451/8134	batch_loss: 3.2108	batch_accuracy: 39.50%	lr:0.000331
Ep: 32/48	It: 3501/8134	batch_loss: 3.0126	batch_accuracy: 41.24%	lr:0.000331
Ep: 32/48	It: 3551/8134	batch_loss: 2.9636	batch_accuracy: 43.04%	lr:0.000330
Ep: 32/48	It: 3601/8134	batch_loss: 3.1451	batch_accuracy: 39.82%	lr:0.000330
Ep: 32/48	It: 3651/8134	batch_loss: 3.2442	batch_accuracy: 37.38%	lr:0.000330
Ep: 32/48	It: 3701/8134	batch_loss: 3.2576	batch_accuracy: 38.60%	lr:0.000330
Ep: 32/48	It: 3751/8134	batch_loss: 3.1870	batch_accuracy: 40.04%	lr:0.000329
Ep: 32/48	It: 3801/8134	batch_loss: 3.1642	batch_accuracy: 40.43%	lr:0.000329
Ep: 32/48	It: 3851/8134	batch_loss: 3.1193	batch_accuracy: 39.94%	lr:0.000329
Ep: 32/48	It: 3901/8134	batch_loss: 3.2003	batch_accuracy: 40.43%	lr:0.000329
Ep: 32/48	It: 3951/8134	batch_loss: 2.9399	batch_accuracy: 43.41%	lr:0.000329
Ep: 32/48	It: 4001/8134	batch_loss: 3.2142	batch_accuracy: 39.72%	lr:0.000328
Ep: 32/48	It: 4051/8134	batch_loss: 3.0446	batch_accuracy: 42.11%	lr:0.000328
Ep: 32/48	It: 4101/8134	batch_loss: 3.2187	batch_accuracy: 39.01%	lr:0.000328
Ep: 32/48	It: 4151/8134	batch_loss: 3.1774	batch_accuracy: 39.48%	lr:0.000328
Ep: 32/48	It: 4201/8134	batch_loss: 3.0852	batch_accuracy: 40.14%	lr:0.000328
Ep: 32/48	It: 4251/8134	batch_loss: 3.0628	batch_accuracy: 40.55%	lr:0.000327
Ep: 32/48	It: 4301/8134	batch_loss: 3.0519	batch_accuracy: 41.46%	lr:0.000327
Ep: 32/48	It: 4351/8134	batch_loss: 3.1173	batch_accuracy: 40.41%	lr:0.000327
Ep: 32/48	It: 4401/8134	batch_loss: 3.0731	batch_accuracy: 41.48%	lr:0.000327
Ep: 32/48	It: 4451/8134	batch_loss: 3.1984	batch_accuracy: 39.18%	lr:0.000327
Ep: 32/48	It: 4501/8134	batch_loss: 3.0811	batch_accuracy: 41.06%	lr:0.000326
Ep: 32/48	It: 4551/8134	batch_loss: 3.1385	batch_accuracy: 40.53%	lr:0.000326
Ep: 32/48	It: 4601/8134	batch_loss: 3.0335	batch_accuracy: 41.99%	lr:0.000326
Ep: 32/48	It: 4651/8134	batch_loss: 3.0889	batch_accuracy: 40.62%	lr:0.000326
Ep: 32/48	It: 4701/8134	batch_loss: 2.9944	batch_accuracy: 41.53%	lr:0.000326
Ep: 32/48	It: 4751/8134	batch_loss: 3.0521	batch_accuracy: 42.19%	lr:0.000325
Ep: 32/48	It: 4801/8134	batch_loss: 3.0486	batch_accuracy: 40.89%	lr:0.000325
Ep: 32/48	It: 4851/8134	batch_loss: 3.0895	batch_accuracy: 41.75%	lr:0.000325
Ep: 32/48	It: 4901/8134	batch_loss: 3.0978	batch_accuracy: 40.48%	lr:0.000325
Ep: 32/48	It: 4951/8134	batch_loss: 3.0801	batch_accuracy: 40.77%	lr:0.000325
Ep: 32/48	It: 5001/8134	batch_loss: 3.1146	batch_accuracy: 40.84%	lr:0.000324
Ep: 32/48	It: 5051/8134	batch_loss: 3.1719	batch_accuracy: 40.72%	lr:0.000324
Ep: 32/48	It: 5101/8134	batch_loss: 3.0557	batch_accuracy: 40.67%	lr:0.000324
Ep: 32/48	It: 5151/8134	batch_loss: 3.1094	batch_accuracy: 40.14%	lr:0.000324
Ep: 32/48	It: 5201/8134	batch_loss: 3.1390	batch_accuracy: 40.19%	lr:0.000323
Ep: 32/48	It: 5251/8134	batch_loss: 3.0865	batch_accuracy: 40.58%	lr:0.000323
Ep: 32/48	It: 5301/8134	batch_loss: 2.9906	batch_accuracy: 43.26%	lr:0.000323
Ep: 32/48	It: 5351/8134	batch_loss: 3.0774	batch_accuracy: 42.07%	lr:0.000323
Ep: 32/48	It: 5401/8134	batch_loss: 3.0968	batch_accuracy: 40.55%	lr:0.000323
Ep: 32/48	It: 5451/8134	batch_loss: 3.0979	batch_accuracy: 41.02%	lr:0.000322
Ep: 32/48	It: 5501/8134	batch_loss: 3.2137	batch_accuracy: 38.75%	lr:0.000322
Ep: 32/48	It: 5551/8134	batch_loss: 3.0090	batch_accuracy: 41.92%	lr:0.000322
Ep: 32/48	It: 5601/8134	batch_loss: 3.2201	batch_accuracy: 38.75%	lr:0.000322
Ep: 32/48	It: 5651/8134	batch_loss: 3.1352	batch_accuracy: 40.28%	lr:0.000322
Ep: 32/48	It: 5701/8134	batch_loss: 3.1208	batch_accuracy: 40.36%	lr:0.000321
Ep: 32/48	It: 5751/8134	batch_loss: 3.1679	batch_accuracy: 40.01%	lr:0.000321
Ep: 32/48	It: 5801/8134	batch_loss: 3.0485	batch_accuracy: 41.77%	lr:0.000321
Ep: 32/48	It: 5851/8134	batch_loss: 3.0952	batch_accuracy: 40.99%	lr:0.000321
Ep: 32/48	It: 5901/8134	batch_loss: 3.1676	batch_accuracy: 39.28%	lr:0.000321
Ep: 32/48	It: 5951/8134	batch_loss: 3.0139	batch_accuracy: 41.46%	lr:0.000320
Ep: 32/48	It: 6001/8134	batch_loss: 3.1143	batch_accuracy: 40.99%	lr:0.000320
Ep: 32/48	It: 6051/8134	batch_loss: 3.0457	batch_accuracy: 42.04%	lr:0.000320
Ep: 32/48	It: 6101/8134	batch_loss: 3.0490	batch_accuracy: 41.58%	lr:0.000320
Ep: 32/48	It: 6151/8134	batch_loss: 3.1934	batch_accuracy: 39.18%	lr:0.000320
Ep: 32/48	It: 6201/8134	batch_loss: 3.0651	batch_accuracy: 40.06%	lr:0.000319
Ep: 32/48	It: 6251/8134	batch_loss: 3.0353	batch_accuracy: 41.92%	lr:0.000319
Ep: 32/48	It: 6301/8134	batch_loss: 3.0668	batch_accuracy: 40.67%	lr:0.000319
Ep: 32/48	It: 6351/8134	batch_loss: 3.0367	batch_accuracy: 42.60%	lr:0.000319
Ep: 32/48	It: 6401/8134	batch_loss: 3.2931	batch_accuracy: 38.04%	lr:0.000319
Ep: 32/48	It: 6451/8134	batch_loss: 3.0958	batch_accuracy: 40.50%	lr:0.000318
Ep: 32/48	It: 6501/8134	batch_loss: 3.1339	batch_accuracy: 40.38%	lr:0.000318
Ep: 32/48	It: 6551/8134	batch_loss: 3.2257	batch_accuracy: 39.67%	lr:0.000318
Ep: 32/48	It: 6601/8134	batch_loss: 3.1062	batch_accuracy: 41.11%	lr:0.000318
Ep: 32/48	It: 6651/8134	batch_loss: 3.1556	batch_accuracy: 40.19%	lr:0.000317
Ep: 32/48	It: 6701/8134	batch_loss: 3.0803	batch_accuracy: 41.21%	lr:0.000317
Ep: 32/48	It: 6751/8134	batch_loss: 3.1466	batch_accuracy: 40.36%	lr:0.000317
Ep: 32/48	It: 6801/8134	batch_loss: 3.1178	batch_accuracy: 39.38%	lr:0.000317
Ep: 32/48	It: 6851/8134	batch_loss: 3.1119	batch_accuracy: 39.82%	lr:0.000317
Ep: 32/48	It: 6901/8134	batch_loss: 3.0653	batch_accuracy: 41.38%	lr:0.000316
Ep: 32/48	It: 6951/8134	batch_loss: 3.1621	batch_accuracy: 39.67%	lr:0.000316
Ep: 32/48	It: 7001/8134	batch_loss: 3.1087	batch_accuracy: 39.92%	lr:0.000316
Ep: 32/48	It: 7051/8134	batch_loss: 3.0172	batch_accuracy: 41.72%	lr:0.000316
Ep: 32/48	It: 7101/8134	batch_loss: 3.1467	batch_accuracy: 39.94%	lr:0.000316
Ep: 32/48	It: 7151/8134	batch_loss: 3.2158	batch_accuracy: 38.06%	lr:0.000315
Ep: 32/48	It: 7201/8134	batch_loss: 3.0749	batch_accuracy: 42.14%	lr:0.000315
Ep: 32/48	It: 7251/8134	batch_loss: 3.1083	batch_accuracy: 40.41%	lr:0.000315
Ep: 32/48	It: 7301/8134	batch_loss: 3.1634	batch_accuracy: 40.67%	lr:0.000315
Ep: 32/48	It: 7351/8134	batch_loss: 3.1400	batch_accuracy: 40.28%	lr:0.000315
Ep: 32/48	It: 7401/8134	batch_loss: 3.0379	batch_accuracy: 41.77%	lr:0.000314
Ep: 32/48	It: 7451/8134	batch_loss: 3.0422	batch_accuracy: 41.97%	lr:0.000314
Ep: 32/48	It: 7501/8134	batch_loss: 3.0983	batch_accuracy: 41.11%	lr:0.000314
Ep: 32/48	It: 7551/8134	batch_loss: 3.1132	batch_accuracy: 38.79%	lr:0.000314
Ep: 32/48	It: 7601/8134	batch_loss: 3.1439	batch_accuracy: 39.28%	lr:0.000314
Ep: 32/48	It: 7651/8134	batch_loss: 3.0887	batch_accuracy: 39.99%	lr:0.000313
Ep: 32/48	It: 7701/8134	batch_loss: 3.0272	batch_accuracy: 41.36%	lr:0.000313
Ep: 32/48	It: 7751/8134	batch_loss: 3.1036	batch_accuracy: 40.58%	lr:0.000313
Ep: 32/48	It: 7801/8134	batch_loss: 3.1716	batch_accuracy: 39.04%	lr:0.000313
Ep: 32/48	It: 7851/8134	batch_loss: 3.0652	batch_accuracy: 41.16%	lr:0.000313
Ep: 32/48	It: 7901/8134	batch_loss: 3.0616	batch_accuracy: 41.24%	lr:0.000312
Ep: 32/48	It: 7951/8134	batch_loss: 3.2186	batch_accuracy: 40.04%	lr:0.000312
Ep: 32/48	It: 8001/8134	batch_loss: 3.1287	batch_accuracy: 39.75%	lr:0.000312
Ep: 32/48	It: 8051/8134	batch_loss: 3.1252	batch_accuracy: 39.82%	lr:0.000312
Ep: 32/48	It: 8101/8134	batch_loss: 3.1264	batch_accuracy: 41.24%	lr:0.000312
Ep: 32/48	It: 8134/8134	batch_loss: 2.9726	batch_accuracy: 43.14%	lr:0.000311


Generated text for input text "You" is:
You have developed a novel methodology for automatic classification. The method is based on the use of theories of t t t ’ to make the most relevant data for the analysis. In this study, the proposed method was successfully applied to the data set. This study aims to compare the proposed algorithm with the standard algorithm. The proposed algorithm is applied to the real-time traffic data set and it is shown that the proposed algorithm is well suited for this purpose.
<eot>
<sot>
Small-angle X-ray scattering and X-ray absorption fine structure of Cu-Pt/TiO2 films

We report on a new method to study the structure of Zn-Pt/TiO2 films, which can be easily tuned by the spin-density of Cu(111) and Co(111) atomic layer deposition. In this way, the morphology of the films was controlled by the doping of the dopant on the substrate. The dopant atomic layer deposition was also studied. In order to achieve high dopant concentration in the substrate, an electrochemical performance was obtained.
<eot>
<sot>
[Prediction of the effect of the use of


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 33/48	It: 1/8134	batch_loss: 3.0788	batch_accuracy: 40.97%	lr:0.000311
Ep: 33/48	It: 51/8134	batch_loss: 3.1843	batch_accuracy: 38.50%	lr:0.000311
Ep: 33/48	It: 101/8134	batch_loss: 3.2446	batch_accuracy: 38.13%	lr:0.000311
Ep: 33/48	It: 151/8134	batch_loss: 3.1648	batch_accuracy: 40.36%	lr:0.000311
Ep: 33/48	It: 201/8134	batch_loss: 3.0684	batch_accuracy: 42.38%	lr:0.000311
Ep: 33/48	It: 251/8134	batch_loss: 2.9385	batch_accuracy: 43.33%	lr:0.000310
Ep: 33/48	It: 301/8134	batch_loss: 3.0725	batch_accuracy: 41.04%	lr:0.000310
Ep: 33/48	It: 351/8134	batch_loss: 3.1425	batch_accuracy: 40.28%	lr:0.000310
Ep: 33/48	It: 401/8134	batch_loss: 3.1049	batch_accuracy: 40.80%	lr:0.000310
Ep: 33/48	It: 451/8134	batch_loss: 3.0025	batch_accuracy: 41.48%	lr:0.000310
Ep: 33/48	It: 501/8134	batch_loss: 2.9941	batch_accuracy: 42.19%	lr:0.000309
Ep: 33/48	It: 551/8134	batch_loss: 3.0980	batch_accuracy: 40.53%	lr:0.000309
Ep: 33/48	It: 601/8134	batch_loss: 3.1249	batch_accuracy: 40.38%	lr:0.000309
Ep: 33/48	It: 651/8134	batch_loss: 3.1663	batch_accuracy: 41.24%	lr:0.000309
Ep: 33/48	It: 701/8134	batch_loss: 3.1219	batch_accuracy: 40.33%	lr:0.000309
Ep: 33/48	It: 751/8134	batch_loss: 3.1089	batch_accuracy: 40.80%	lr:0.000308
Ep: 33/48	It: 801/8134	batch_loss: 3.1820	batch_accuracy: 40.09%	lr:0.000308
Ep: 33/48	It: 851/8134	batch_loss: 3.0587	batch_accuracy: 41.41%	lr:0.000308
Ep: 33/48	It: 901/8134	batch_loss: 3.1479	batch_accuracy: 39.40%	lr:0.000308
Ep: 33/48	It: 951/8134	batch_loss: 3.0652	batch_accuracy: 41.58%	lr:0.000308
Ep: 33/48	It: 1001/8134	batch_loss: 2.9888	batch_accuracy: 42.63%	lr:0.000307
Ep: 33/48	It: 1051/8134	batch_loss: 3.1638	batch_accuracy: 39.09%	lr:0.000307
Ep: 33/48	It: 1101/8134	batch_loss: 3.0385	batch_accuracy: 41.92%	lr:0.000307
Ep: 33/48	It: 1151/8134	batch_loss: 3.0446	batch_accuracy: 41.85%	lr:0.000307
Ep: 33/48	It: 1201/8134	batch_loss: 3.0985	batch_accuracy: 40.94%	lr:0.000307
Ep: 33/48	It: 1251/8134	batch_loss: 3.0332	batch_accuracy: 41.58%	lr:0.000306
Ep: 33/48	It: 1301/8134	batch_loss: 3.0808	batch_accuracy: 40.67%	lr:0.000306
Ep: 33/48	It: 1351/8134	batch_loss: 3.0289	batch_accuracy: 41.31%	lr:0.000306
Ep: 33/48	It: 1401/8134	batch_loss: 3.0432	batch_accuracy: 42.46%	lr:0.000306
Ep: 33/48	It: 1451/8134	batch_loss: 3.1944	batch_accuracy: 40.65%	lr:0.000305
Ep: 33/48	It: 1501/8134	batch_loss: 3.1131	batch_accuracy: 41.11%	lr:0.000305
Ep: 33/48	It: 1551/8134	batch_loss: 3.0770	batch_accuracy: 40.21%	lr:0.000305
Ep: 33/48	It: 1601/8134	batch_loss: 3.0716	batch_accuracy: 41.33%	lr:0.000305
Ep: 33/48	It: 1651/8134	batch_loss: 3.0496	batch_accuracy: 42.07%	lr:0.000305
Ep: 33/48	It: 1701/8134	batch_loss: 3.1884	batch_accuracy: 39.62%	lr:0.000304
Ep: 33/48	It: 1751/8134	batch_loss: 3.1190	batch_accuracy: 41.09%	lr:0.000304
Ep: 33/48	It: 1801/8134	batch_loss: 3.1159	batch_accuracy: 40.11%	lr:0.000304
Ep: 33/48	It: 1851/8134	batch_loss: 3.1075	batch_accuracy: 40.41%	lr:0.000304
Ep: 33/48	It: 1901/8134	batch_loss: 3.1438	batch_accuracy: 39.79%	lr:0.000304
Ep: 33/48	It: 1951/8134	batch_loss: 3.0504	batch_accuracy: 41.11%	lr:0.000303
Ep: 33/48	It: 2001/8134	batch_loss: 3.0972	batch_accuracy: 40.80%	lr:0.000303
Ep: 33/48	It: 2051/8134	batch_loss: 3.0997	batch_accuracy: 41.48%	lr:0.000303
Ep: 33/48	It: 2101/8134	batch_loss: 3.1507	batch_accuracy: 40.82%	lr:0.000303
Ep: 33/48	It: 2151/8134	batch_loss: 3.0221	batch_accuracy: 41.50%	lr:0.000303
Ep: 33/48	It: 2201/8134	batch_loss: 3.1455	batch_accuracy: 39.38%	lr:0.000302
Ep: 33/48	It: 2251/8134	batch_loss: 3.0186	batch_accuracy: 42.99%	lr:0.000302
Ep: 33/48	It: 2301/8134	batch_loss: 3.0558	batch_accuracy: 42.19%	lr:0.000302
Ep: 33/48	It: 2351/8134	batch_loss: 3.1304	batch_accuracy: 40.23%	lr:0.000302
Ep: 33/48	It: 2401/8134	batch_loss: 3.0583	batch_accuracy: 41.99%	lr:0.000302
Ep: 33/48	It: 2451/8134	batch_loss: 3.0512	batch_accuracy: 41.24%	lr:0.000301
Ep: 33/48	It: 2501/8134	batch_loss: 3.0335	batch_accuracy: 42.29%	lr:0.000301
Ep: 33/48	It: 2551/8134	batch_loss: 3.0980	batch_accuracy: 41.24%	lr:0.000301
Ep: 33/48	It: 2601/8134	batch_loss: 3.1303	batch_accuracy: 39.60%	lr:0.000301
Ep: 33/48	It: 2651/8134	batch_loss: 2.9803	batch_accuracy: 43.48%	lr:0.000301
Ep: 33/48	It: 2701/8134	batch_loss: 3.0633	batch_accuracy: 42.07%	lr:0.000300
Ep: 33/48	It: 2751/8134	batch_loss: 3.0429	batch_accuracy: 41.97%	lr:0.000300
Ep: 33/48	It: 2801/8134	batch_loss: 3.0617	batch_accuracy: 41.70%	lr:0.000300
Ep: 33/48	It: 2851/8134	batch_loss: 3.1357	batch_accuracy: 40.41%	lr:0.000300
Ep: 33/48	It: 2901/8134	batch_loss: 2.9995	batch_accuracy: 41.80%	lr:0.000300
Ep: 33/48	It: 2951/8134	batch_loss: 3.0599	batch_accuracy: 42.14%	lr:0.000299
Ep: 33/48	It: 3001/8134	batch_loss: 3.1500	batch_accuracy: 40.01%	lr:0.000299
Ep: 33/48	It: 3051/8134	batch_loss: 3.1712	batch_accuracy: 40.38%	lr:0.000299
Ep: 33/48	It: 3101/8134	batch_loss: 3.1100	batch_accuracy: 40.72%	lr:0.000299
Ep: 33/48	It: 3151/8134	batch_loss: 3.0889	batch_accuracy: 41.24%	lr:0.000299
Ep: 33/48	It: 3201/8134	batch_loss: 3.0895	batch_accuracy: 40.60%	lr:0.000298
Ep: 33/48	It: 3251/8134	batch_loss: 3.0264	batch_accuracy: 41.60%	lr:0.000298
Ep: 33/48	It: 3301/8134	batch_loss: 3.1265	batch_accuracy: 40.23%	lr:0.000298
Ep: 33/48	It: 3351/8134	batch_loss: 3.0748	batch_accuracy: 41.21%	lr:0.000298
Ep: 33/48	It: 3401/8134	batch_loss: 3.1003	batch_accuracy: 41.33%	lr:0.000298
Ep: 33/48	It: 3451/8134	batch_loss: 3.1624	batch_accuracy: 40.58%	lr:0.000297
Ep: 33/48	It: 3501/8134	batch_loss: 3.2526	batch_accuracy: 38.21%	lr:0.000297
Ep: 33/48	It: 3551/8134	batch_loss: 3.0869	batch_accuracy: 41.09%	lr:0.000297
Ep: 33/48	It: 3601/8134	batch_loss: 3.0434	batch_accuracy: 41.24%	lr:0.000297
Ep: 33/48	It: 3651/8134	batch_loss: 3.0305	batch_accuracy: 41.48%	lr:0.000297
Ep: 33/48	It: 3701/8134	batch_loss: 3.0118	batch_accuracy: 41.06%	lr:0.000296
Ep: 33/48	It: 3751/8134	batch_loss: 3.1334	batch_accuracy: 40.23%	lr:0.000296
Ep: 33/48	It: 3801/8134	batch_loss: 3.0961	batch_accuracy: 41.31%	lr:0.000296
Ep: 33/48	It: 3851/8134	batch_loss: 3.2200	batch_accuracy: 38.40%	lr:0.000296
Ep: 33/48	It: 3901/8134	batch_loss: 3.0298	batch_accuracy: 41.02%	lr:0.000296
Ep: 33/48	It: 3951/8134	batch_loss: 3.0579	batch_accuracy: 41.43%	lr:0.000295
Ep: 33/48	It: 4001/8134	batch_loss: 3.0967	batch_accuracy: 40.50%	lr:0.000295
Ep: 33/48	It: 4051/8134	batch_loss: 2.9587	batch_accuracy: 42.65%	lr:0.000295
Ep: 33/48	It: 4101/8134	batch_loss: 3.0403	batch_accuracy: 41.87%	lr:0.000295
Ep: 33/48	It: 4151/8134	batch_loss: 3.0243	batch_accuracy: 42.19%	lr:0.000295
Ep: 33/48	It: 4201/8134	batch_loss: 3.1197	batch_accuracy: 40.62%	lr:0.000294
Ep: 33/48	It: 4251/8134	batch_loss: 3.1082	batch_accuracy: 40.50%	lr:0.000294
Ep: 33/48	It: 4301/8134	batch_loss: 3.0142	batch_accuracy: 42.33%	lr:0.000294
Ep: 33/48	It: 4351/8134	batch_loss: 2.9666	batch_accuracy: 42.53%	lr:0.000294
Ep: 33/48	It: 4401/8134	batch_loss: 3.1171	batch_accuracy: 41.53%	lr:0.000294
Ep: 33/48	It: 4451/8134	batch_loss: 3.1326	batch_accuracy: 41.19%	lr:0.000293
Ep: 33/48	It: 4501/8134	batch_loss: 3.1625	batch_accuracy: 40.92%	lr:0.000293
Ep: 33/48	It: 4551/8134	batch_loss: 3.0422	batch_accuracy: 40.72%	lr:0.000293
Ep: 33/48	It: 4601/8134	batch_loss: 3.1591	batch_accuracy: 38.67%	lr:0.000293
Ep: 33/48	It: 4651/8134	batch_loss: 3.0495	batch_accuracy: 41.48%	lr:0.000293
Ep: 33/48	It: 4701/8134	batch_loss: 3.1322	batch_accuracy: 40.45%	lr:0.000292
Ep: 33/48	It: 4751/8134	batch_loss: 3.0277	batch_accuracy: 41.46%	lr:0.000292
Ep: 33/48	It: 4801/8134	batch_loss: 3.0016	batch_accuracy: 42.68%	lr:0.000292
Ep: 33/48	It: 4851/8134	batch_loss: 3.0575	batch_accuracy: 41.11%	lr:0.000292
Ep: 33/48	It: 4901/8134	batch_loss: 3.2355	batch_accuracy: 38.43%	lr:0.000292
Ep: 33/48	It: 4951/8134	batch_loss: 3.0557	batch_accuracy: 42.33%	lr:0.000291
Ep: 33/48	It: 5001/8134	batch_loss: 3.1933	batch_accuracy: 40.36%	lr:0.000291
Ep: 33/48	It: 5051/8134	batch_loss: 3.1013	batch_accuracy: 40.45%	lr:0.000291
Ep: 33/48	It: 5101/8134	batch_loss: 3.1586	batch_accuracy: 40.06%	lr:0.000291
Ep: 33/48	It: 5151/8134	batch_loss: 2.9901	batch_accuracy: 42.38%	lr:0.000291
Ep: 33/48	It: 5201/8134	batch_loss: 3.0478	batch_accuracy: 41.33%	lr:0.000290
Ep: 33/48	It: 5251/8134	batch_loss: 3.0387	batch_accuracy: 41.50%	lr:0.000290
Ep: 33/48	It: 5301/8134	batch_loss: 3.1079	batch_accuracy: 40.21%	lr:0.000290
Ep: 33/48	It: 5351/8134	batch_loss: 3.0276	batch_accuracy: 41.94%	lr:0.000290
Ep: 33/48	It: 5401/8134	batch_loss: 2.9893	batch_accuracy: 43.04%	lr:0.000290
Ep: 33/48	It: 5451/8134	batch_loss: 3.2637	batch_accuracy: 38.50%	lr:0.000289
Ep: 33/48	It: 5501/8134	batch_loss: 3.0671	batch_accuracy: 40.92%	lr:0.000289
Ep: 33/48	It: 5551/8134	batch_loss: 3.0312	batch_accuracy: 40.58%	lr:0.000289
Ep: 33/48	It: 5601/8134	batch_loss: 3.0523	batch_accuracy: 41.67%	lr:0.000289
Ep: 33/48	It: 5651/8134	batch_loss: 3.0476	batch_accuracy: 41.53%	lr:0.000289
Ep: 33/48	It: 5701/8134	batch_loss: 3.1281	batch_accuracy: 40.92%	lr:0.000288
Ep: 33/48	It: 5751/8134	batch_loss: 3.0057	batch_accuracy: 42.58%	lr:0.000288
Ep: 33/48	It: 5801/8134	batch_loss: 3.1992	batch_accuracy: 39.31%	lr:0.000288
Ep: 33/48	It: 5851/8134	batch_loss: 3.1477	batch_accuracy: 40.19%	lr:0.000288
Ep: 33/48	It: 5901/8134	batch_loss: 3.0091	batch_accuracy: 42.48%	lr:0.000288
Ep: 33/48	It: 5951/8134	batch_loss: 2.9593	batch_accuracy: 43.51%	lr:0.000287
Ep: 33/48	It: 6001/8134	batch_loss: 3.1088	batch_accuracy: 40.19%	lr:0.000287
Ep: 33/48	It: 6051/8134	batch_loss: 3.0390	batch_accuracy: 42.63%	lr:0.000287
Ep: 33/48	It: 6101/8134	batch_loss: 3.0748	batch_accuracy: 41.19%	lr:0.000287
Ep: 33/48	It: 6151/8134	batch_loss: 3.1033	batch_accuracy: 41.43%	lr:0.000287
Ep: 33/48	It: 6201/8134	batch_loss: 3.0362	batch_accuracy: 41.80%	lr:0.000286
Ep: 33/48	It: 6251/8134	batch_loss: 3.0093	batch_accuracy: 42.07%	lr:0.000286
Ep: 33/48	It: 6301/8134	batch_loss: 3.0152	batch_accuracy: 42.11%	lr:0.000286
Ep: 33/48	It: 6351/8134	batch_loss: 2.9830	batch_accuracy: 42.29%	lr:0.000286
Ep: 33/48	It: 6401/8134	batch_loss: 2.9842	batch_accuracy: 41.87%	lr:0.000286
Ep: 33/48	It: 6451/8134	batch_loss: 3.0639	batch_accuracy: 41.58%	lr:0.000285
Ep: 33/48	It: 6501/8134	batch_loss: 3.2339	batch_accuracy: 38.26%	lr:0.000285
Ep: 33/48	It: 6551/8134	batch_loss: 3.1500	batch_accuracy: 39.92%	lr:0.000285
Ep: 33/48	It: 6601/8134	batch_loss: 3.0540	batch_accuracy: 41.16%	lr:0.000285
Ep: 33/48	It: 6651/8134	batch_loss: 3.1084	batch_accuracy: 40.60%	lr:0.000285
Ep: 33/48	It: 6701/8134	batch_loss: 3.0532	batch_accuracy: 42.70%	lr:0.000284
Ep: 33/48	It: 6751/8134	batch_loss: 3.0537	batch_accuracy: 40.41%	lr:0.000284
Ep: 33/48	It: 6801/8134	batch_loss: 3.0551	batch_accuracy: 41.04%	lr:0.000284
Ep: 33/48	It: 6851/8134	batch_loss: 3.0728	batch_accuracy: 41.02%	lr:0.000284
Ep: 33/48	It: 6901/8134	batch_loss: 3.1303	batch_accuracy: 39.99%	lr:0.000284
Ep: 33/48	It: 6951/8134	batch_loss: 3.2310	batch_accuracy: 39.04%	lr:0.000283
Ep: 33/48	It: 7001/8134	batch_loss: 3.0233	batch_accuracy: 42.11%	lr:0.000283
Ep: 33/48	It: 7051/8134	batch_loss: 3.1999	batch_accuracy: 40.11%	lr:0.000283
Ep: 33/48	It: 7101/8134	batch_loss: 3.0531	batch_accuracy: 40.67%	lr:0.000283
Ep: 33/48	It: 7151/8134	batch_loss: 3.0861	batch_accuracy: 41.38%	lr:0.000283
Ep: 33/48	It: 7201/8134	batch_loss: 3.1097	batch_accuracy: 39.79%	lr:0.000282
Ep: 33/48	It: 7251/8134	batch_loss: 3.1058	batch_accuracy: 40.97%	lr:0.000282
Ep: 33/48	It: 7301/8134	batch_loss: 3.0580	batch_accuracy: 40.04%	lr:0.000282
Ep: 33/48	It: 7351/8134	batch_loss: 3.0879	batch_accuracy: 41.31%	lr:0.000282
Ep: 33/48	It: 7401/8134	batch_loss: 3.0790	batch_accuracy: 41.33%	lr:0.000282
Ep: 33/48	It: 7451/8134	batch_loss: 2.9964	batch_accuracy: 43.02%	lr:0.000281
Ep: 33/48	It: 7501/8134	batch_loss: 2.9865	batch_accuracy: 41.97%	lr:0.000281
Ep: 33/48	It: 7551/8134	batch_loss: 3.0716	batch_accuracy: 41.55%	lr:0.000281
Ep: 33/48	It: 7601/8134	batch_loss: 3.1498	batch_accuracy: 39.45%	lr:0.000281
Ep: 33/48	It: 7651/8134	batch_loss: 3.0735	batch_accuracy: 40.72%	lr:0.000281
Ep: 33/48	It: 7701/8134	batch_loss: 3.1505	batch_accuracy: 39.87%	lr:0.000280
Ep: 33/48	It: 7751/8134	batch_loss: 2.9016	batch_accuracy: 43.07%	lr:0.000280
Ep: 33/48	It: 7801/8134	batch_loss: 2.9553	batch_accuracy: 43.02%	lr:0.000280
Ep: 33/48	It: 7851/8134	batch_loss: 3.1889	batch_accuracy: 40.06%	lr:0.000280
Ep: 33/48	It: 7901/8134	batch_loss: 3.1756	batch_accuracy: 39.38%	lr:0.000280
Ep: 33/48	It: 7951/8134	batch_loss: 3.1174	batch_accuracy: 40.41%	lr:0.000279
Ep: 33/48	It: 8001/8134	batch_loss: 3.1823	batch_accuracy: 39.14%	lr:0.000279
Ep: 33/48	It: 8051/8134	batch_loss: 3.1595	batch_accuracy: 38.60%	lr:0.000279
Ep: 33/48	It: 8101/8134	batch_loss: 3.1048	batch_accuracy: 40.41%	lr:0.000279
Ep: 33/48	It: 8134/8134	batch_loss: 3.0310	batch_accuracy: 40.66%	lr:0.000279


Generated text for input text "You" is:
You, 1995.
Maugh it is not surprising that there are few data on whether the use of such models can be justified in thesis that we call ‘theory’ that we call ‘theory’ or that theorized, “theory” of theories of human development and will have a long way in the future.
<eot>
<sot>
Robust and fast algorithm for the motion of a robotic system

In this paper, we propose a new design of a robot with an arbitrary angle. The robot is a three-axis motion, and an arbitrary motion is taken into account. In the model, the robotic system can be built by a robot. The robot is designed to act as a vehicle to perform motion control in a real time. This model will be used to simulate motion control of a robotic system. The robot can automatically operate the obstacle avoidance, then its motion control is done using the robot. In order to perform the robotic system, the robot can operate in a single robot manipulator. The robot moves in a single position and it is able to control the obstacle, the robot arm's arm's movements


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 34/48	It: 1/8134	batch_loss: 3.0982	batch_accuracy: 41.53%	lr:0.000279
Ep: 34/48	It: 51/8134	batch_loss: 3.1425	batch_accuracy: 40.45%	lr:0.000278
Ep: 34/48	It: 101/8134	batch_loss: 3.1319	batch_accuracy: 40.19%	lr:0.000278
Ep: 34/48	It: 151/8134	batch_loss: 3.0364	batch_accuracy: 42.02%	lr:0.000278
Ep: 34/48	It: 201/8134	batch_loss: 3.0147	batch_accuracy: 42.85%	lr:0.000278
Ep: 34/48	It: 251/8134	batch_loss: 3.0751	batch_accuracy: 40.28%	lr:0.000278
Ep: 34/48	It: 301/8134	batch_loss: 2.9988	batch_accuracy: 41.33%	lr:0.000277
Ep: 34/48	It: 351/8134	batch_loss: 3.0870	batch_accuracy: 40.97%	lr:0.000277
Ep: 34/48	It: 401/8134	batch_loss: 3.1111	batch_accuracy: 39.97%	lr:0.000277
Ep: 34/48	It: 451/8134	batch_loss: 3.1436	batch_accuracy: 39.14%	lr:0.000277
Ep: 34/48	It: 501/8134	batch_loss: 3.1260	batch_accuracy: 40.72%	lr:0.000277
Ep: 34/48	It: 551/8134	batch_loss: 3.1168	batch_accuracy: 40.75%	lr:0.000276
Ep: 34/48	It: 601/8134	batch_loss: 3.0498	batch_accuracy: 41.16%	lr:0.000276
Ep: 34/48	It: 651/8134	batch_loss: 3.0403	batch_accuracy: 42.63%	lr:0.000276
Ep: 34/48	It: 701/8134	batch_loss: 3.0126	batch_accuracy: 42.19%	lr:0.000276
Ep: 34/48	It: 751/8134	batch_loss: 2.9189	batch_accuracy: 43.02%	lr:0.000276
Ep: 34/48	It: 801/8134	batch_loss: 3.0628	batch_accuracy: 40.60%	lr:0.000276
Ep: 34/48	It: 851/8134	batch_loss: 3.0261	batch_accuracy: 42.07%	lr:0.000275
Ep: 34/48	It: 901/8134	batch_loss: 3.0059	batch_accuracy: 42.14%	lr:0.000275
Ep: 34/48	It: 951/8134	batch_loss: 3.1348	batch_accuracy: 40.80%	lr:0.000275
Ep: 34/48	It: 1001/8134	batch_loss: 3.0099	batch_accuracy: 42.70%	lr:0.000275
Ep: 34/48	It: 1051/8134	batch_loss: 3.1455	batch_accuracy: 39.82%	lr:0.000275
Ep: 34/48	It: 1101/8134	batch_loss: 3.1884	batch_accuracy: 39.36%	lr:0.000274
Ep: 34/48	It: 1151/8134	batch_loss: 3.0250	batch_accuracy: 41.38%	lr:0.000274
Ep: 34/48	It: 1201/8134	batch_loss: 3.0573	batch_accuracy: 40.99%	lr:0.000274
Ep: 34/48	It: 1251/8134	batch_loss: 3.0983	batch_accuracy: 40.80%	lr:0.000274
Ep: 34/48	It: 1301/8134	batch_loss: 3.1807	batch_accuracy: 38.62%	lr:0.000274
Ep: 34/48	It: 1351/8134	batch_loss: 3.1354	batch_accuracy: 39.75%	lr:0.000273
Ep: 34/48	It: 1401/8134	batch_loss: 3.1630	batch_accuracy: 39.38%	lr:0.000273
Ep: 34/48	It: 1451/8134	batch_loss: 3.0034	batch_accuracy: 42.85%	lr:0.000273
Ep: 34/48	It: 1501/8134	batch_loss: 3.1102	batch_accuracy: 39.87%	lr:0.000273
Ep: 34/48	It: 1551/8134	batch_loss: 3.1614	batch_accuracy: 39.14%	lr:0.000273
Ep: 34/48	It: 1601/8134	batch_loss: 3.1174	batch_accuracy: 40.28%	lr:0.000272
Ep: 34/48	It: 1651/8134	batch_loss: 3.1741	batch_accuracy: 38.57%	lr:0.000272
Ep: 34/48	It: 1701/8134	batch_loss: 3.0505	batch_accuracy: 40.87%	lr:0.000272
Ep: 34/48	It: 1751/8134	batch_loss: 2.9523	batch_accuracy: 42.70%	lr:0.000272
Ep: 34/48	It: 1801/8134	batch_loss: 3.1000	batch_accuracy: 41.26%	lr:0.000272
Ep: 34/48	It: 1851/8134	batch_loss: 3.0070	batch_accuracy: 41.75%	lr:0.000271
Ep: 34/48	It: 1901/8134	batch_loss: 2.9982	batch_accuracy: 41.38%	lr:0.000271
Ep: 34/48	It: 1951/8134	batch_loss: 3.1597	batch_accuracy: 40.89%	lr:0.000271
Ep: 34/48	It: 2001/8134	batch_loss: 3.0403	batch_accuracy: 41.92%	lr:0.000271
Ep: 34/48	It: 2051/8134	batch_loss: 3.0865	batch_accuracy: 41.53%	lr:0.000271
Ep: 34/48	It: 2101/8134	batch_loss: 3.1184	batch_accuracy: 39.16%	lr:0.000270
Ep: 34/48	It: 2151/8134	batch_loss: 3.0766	batch_accuracy: 40.99%	lr:0.000270
Ep: 34/48	It: 2201/8134	batch_loss: 3.0914	batch_accuracy: 40.62%	lr:0.000270
Ep: 34/48	It: 2251/8134	batch_loss: 3.1407	batch_accuracy: 39.84%	lr:0.000270
Ep: 34/48	It: 2301/8134	batch_loss: 2.9846	batch_accuracy: 42.21%	lr:0.000270
Ep: 34/48	It: 2351/8134	batch_loss: 3.1637	batch_accuracy: 39.58%	lr:0.000269
Ep: 34/48	It: 2401/8134	batch_loss: 3.1416	batch_accuracy: 40.48%	lr:0.000269
Ep: 34/48	It: 2451/8134	batch_loss: 3.0697	batch_accuracy: 40.67%	lr:0.000269
Ep: 34/48	It: 2501/8134	batch_loss: 3.0168	batch_accuracy: 42.21%	lr:0.000269
Ep: 34/48	It: 2551/8134	batch_loss: 3.0393	batch_accuracy: 41.85%	lr:0.000269
Ep: 34/48	It: 2601/8134	batch_loss: 3.0806	batch_accuracy: 41.85%	lr:0.000268
Ep: 34/48	It: 2651/8134	batch_loss: 3.1234	batch_accuracy: 40.41%	lr:0.000268
Ep: 34/48	It: 2701/8134	batch_loss: 3.1110	batch_accuracy: 40.77%	lr:0.000268
Ep: 34/48	It: 2751/8134	batch_loss: 3.1297	batch_accuracy: 40.14%	lr:0.000268
Ep: 34/48	It: 2801/8134	batch_loss: 3.2401	batch_accuracy: 38.96%	lr:0.000268
Ep: 34/48	It: 2851/8134	batch_loss: 3.1789	batch_accuracy: 40.09%	lr:0.000267
Ep: 34/48	It: 2901/8134	batch_loss: 2.9846	batch_accuracy: 41.94%	lr:0.000267
Ep: 34/48	It: 2951/8134	batch_loss: 3.1591	batch_accuracy: 39.55%	lr:0.000267
Ep: 34/48	It: 3001/8134	batch_loss: 3.0861	batch_accuracy: 41.02%	lr:0.000267
Ep: 34/48	It: 3051/8134	batch_loss: 3.0532	batch_accuracy: 42.14%	lr:0.000267
Ep: 34/48	It: 3101/8134	batch_loss: 3.0599	batch_accuracy: 40.50%	lr:0.000266
Ep: 34/48	It: 3151/8134	batch_loss: 3.1587	batch_accuracy: 39.43%	lr:0.000266
Ep: 34/48	It: 3201/8134	batch_loss: 3.0680	batch_accuracy: 41.28%	lr:0.000266
Ep: 34/48	It: 3251/8134	batch_loss: 3.1690	batch_accuracy: 40.26%	lr:0.000266
Ep: 34/48	It: 3301/8134	batch_loss: 3.1130	batch_accuracy: 40.55%	lr:0.000266
Ep: 34/48	It: 3351/8134	batch_loss: 3.0634	batch_accuracy: 40.26%	lr:0.000266
Ep: 34/48	It: 3401/8134	batch_loss: 3.0910	batch_accuracy: 40.77%	lr:0.000265
Ep: 34/48	It: 3451/8134	batch_loss: 3.1281	batch_accuracy: 40.16%	lr:0.000265
Ep: 34/48	It: 3501/8134	batch_loss: 3.1049	batch_accuracy: 40.01%	lr:0.000265
Ep: 34/48	It: 3551/8134	batch_loss: 3.0907	batch_accuracy: 41.21%	lr:0.000265
Ep: 34/48	It: 3601/8134	batch_loss: 3.0291	batch_accuracy: 42.65%	lr:0.000265
Ep: 34/48	It: 3651/8134	batch_loss: 3.0829	batch_accuracy: 39.87%	lr:0.000264
Ep: 34/48	It: 3701/8134	batch_loss: 3.1874	batch_accuracy: 39.53%	lr:0.000264
Ep: 34/48	It: 3751/8134	batch_loss: 3.1128	batch_accuracy: 39.92%	lr:0.000264
Ep: 34/48	It: 3801/8134	batch_loss: 3.1259	batch_accuracy: 41.97%	lr:0.000264
Ep: 34/48	It: 3851/8134	batch_loss: 3.0822	batch_accuracy: 41.48%	lr:0.000264
Ep: 34/48	It: 3901/8134	batch_loss: 3.0045	batch_accuracy: 41.87%	lr:0.000263
Ep: 34/48	It: 3951/8134	batch_loss: 3.1017	batch_accuracy: 41.11%	lr:0.000263
Ep: 34/48	It: 4001/8134	batch_loss: 3.1625	batch_accuracy: 39.79%	lr:0.000263
Ep: 34/48	It: 4051/8134	batch_loss: 3.1502	batch_accuracy: 39.55%	lr:0.000263
Ep: 34/48	It: 4101/8134	batch_loss: 3.0268	batch_accuracy: 41.26%	lr:0.000263
Ep: 34/48	It: 4151/8134	batch_loss: 3.0851	batch_accuracy: 41.53%	lr:0.000262
Ep: 34/48	It: 4201/8134	batch_loss: 3.0491	batch_accuracy: 42.68%	lr:0.000262
Ep: 34/48	It: 4251/8134	batch_loss: 3.0440	batch_accuracy: 41.11%	lr:0.000262
Ep: 34/48	It: 4301/8134	batch_loss: 3.2239	batch_accuracy: 38.01%	lr:0.000262
Ep: 34/48	It: 4351/8134	batch_loss: 3.1206	batch_accuracy: 40.80%	lr:0.000262
Ep: 34/48	It: 4401/8134	batch_loss: 2.9968	batch_accuracy: 41.02%	lr:0.000261
Ep: 34/48	It: 4451/8134	batch_loss: 2.9485	batch_accuracy: 43.26%	lr:0.000261
Ep: 34/48	It: 4501/8134	batch_loss: 3.0498	batch_accuracy: 42.58%	lr:0.000261
Ep: 34/48	It: 4551/8134	batch_loss: 3.0559	batch_accuracy: 43.14%	lr:0.000261
Ep: 34/48	It: 4601/8134	batch_loss: 3.0689	batch_accuracy: 40.38%	lr:0.000261
Ep: 34/48	It: 4651/8134	batch_loss: 3.1372	batch_accuracy: 39.82%	lr:0.000260
Ep: 34/48	It: 4701/8134	batch_loss: 3.0976	batch_accuracy: 41.41%	lr:0.000260
Ep: 34/48	It: 4751/8134	batch_loss: 2.9527	batch_accuracy: 42.63%	lr:0.000260
Ep: 34/48	It: 4801/8134	batch_loss: 3.0846	batch_accuracy: 41.16%	lr:0.000260
Ep: 34/48	It: 4851/8134	batch_loss: 2.9799	batch_accuracy: 42.70%	lr:0.000260
Ep: 34/48	It: 4901/8134	batch_loss: 3.0746	batch_accuracy: 41.43%	lr:0.000260
Ep: 34/48	It: 4951/8134	batch_loss: 3.0226	batch_accuracy: 41.89%	lr:0.000259
Ep: 34/48	It: 5001/8134	batch_loss: 3.1744	batch_accuracy: 39.40%	lr:0.000259
Ep: 34/48	It: 5051/8134	batch_loss: 3.0577	batch_accuracy: 41.48%	lr:0.000259
Ep: 34/48	It: 5101/8134	batch_loss: 3.0684	batch_accuracy: 42.16%	lr:0.000259
Ep: 34/48	It: 5151/8134	batch_loss: 3.1185	batch_accuracy: 40.45%	lr:0.000259
Ep: 34/48	It: 5201/8134	batch_loss: 3.0317	batch_accuracy: 41.92%	lr:0.000258
Ep: 34/48	It: 5251/8134	batch_loss: 3.0505	batch_accuracy: 41.28%	lr:0.000258
Ep: 34/48	It: 5301/8134	batch_loss: 3.0064	batch_accuracy: 41.33%	lr:0.000258
Ep: 34/48	It: 5351/8134	batch_loss: 3.0962	batch_accuracy: 40.75%	lr:0.000258
Ep: 34/48	It: 5401/8134	batch_loss: 2.9087	batch_accuracy: 44.07%	lr:0.000258
Ep: 34/48	It: 5451/8134	batch_loss: 3.1436	batch_accuracy: 39.62%	lr:0.000257
Ep: 34/48	It: 5501/8134	batch_loss: 3.1096	batch_accuracy: 40.50%	lr:0.000257
Ep: 34/48	It: 5551/8134	batch_loss: 3.0411	batch_accuracy: 41.31%	lr:0.000257
Ep: 34/48	It: 5601/8134	batch_loss: 3.1969	batch_accuracy: 40.16%	lr:0.000257
Ep: 34/48	It: 5651/8134	batch_loss: 3.0347	batch_accuracy: 41.55%	lr:0.000257
Ep: 34/48	It: 5701/8134	batch_loss: 3.1888	batch_accuracy: 39.77%	lr:0.000256
Ep: 34/48	It: 5751/8134	batch_loss: 3.0126	batch_accuracy: 41.43%	lr:0.000256
Ep: 34/48	It: 5801/8134	batch_loss: 2.9570	batch_accuracy: 42.99%	lr:0.000256
Ep: 34/48	It: 5851/8134	batch_loss: 3.0076	batch_accuracy: 41.80%	lr:0.000256
Ep: 34/48	It: 5901/8134	batch_loss: 3.0408	batch_accuracy: 41.67%	lr:0.000256
Ep: 34/48	It: 5951/8134	batch_loss: 3.0294	batch_accuracy: 40.92%	lr:0.000255
Ep: 34/48	It: 6001/8134	batch_loss: 3.0804	batch_accuracy: 41.06%	lr:0.000255
Ep: 34/48	It: 6051/8134	batch_loss: 3.0705	batch_accuracy: 40.48%	lr:0.000255
Ep: 34/48	It: 6101/8134	batch_loss: 2.9189	batch_accuracy: 44.14%	lr:0.000255
Ep: 34/48	It: 6151/8134	batch_loss: 3.1434	batch_accuracy: 41.11%	lr:0.000255
Ep: 34/48	It: 6201/8134	batch_loss: 3.0261	batch_accuracy: 41.89%	lr:0.000255
Ep: 34/48	It: 6251/8134	batch_loss: 3.0911	batch_accuracy: 41.58%	lr:0.000254
Ep: 34/48	It: 6301/8134	batch_loss: 3.0939	batch_accuracy: 41.82%	lr:0.000254
Ep: 34/48	It: 6351/8134	batch_loss: 3.0289	batch_accuracy: 41.77%	lr:0.000254
Ep: 34/48	It: 6401/8134	batch_loss: 3.0539	batch_accuracy: 41.50%	lr:0.000254
Ep: 34/48	It: 6451/8134	batch_loss: 3.1311	batch_accuracy: 39.87%	lr:0.000254
Ep: 34/48	It: 6501/8134	batch_loss: 3.1030	batch_accuracy: 40.97%	lr:0.000253
Ep: 34/48	It: 6551/8134	batch_loss: 3.1147	batch_accuracy: 41.26%	lr:0.000253
Ep: 34/48	It: 6601/8134	batch_loss: 2.9999	batch_accuracy: 42.70%	lr:0.000253
Ep: 34/48	It: 6651/8134	batch_loss: 3.1626	batch_accuracy: 39.70%	lr:0.000253
Ep: 34/48	It: 6701/8134	batch_loss: 3.1431	batch_accuracy: 40.77%	lr:0.000253
Ep: 34/48	It: 6751/8134	batch_loss: 3.0519	batch_accuracy: 41.41%	lr:0.000252
Ep: 34/48	It: 6801/8134	batch_loss: 3.1386	batch_accuracy: 40.33%	lr:0.000252
Ep: 34/48	It: 6851/8134	batch_loss: 3.1611	batch_accuracy: 40.06%	lr:0.000252
Ep: 34/48	It: 6901/8134	batch_loss: 3.1973	batch_accuracy: 39.72%	lr:0.000252
Ep: 34/48	It: 6951/8134	batch_loss: 2.9867	batch_accuracy: 43.19%	lr:0.000252
Ep: 34/48	It: 7001/8134	batch_loss: 3.0853	batch_accuracy: 40.92%	lr:0.000251
Ep: 34/48	It: 7051/8134	batch_loss: 3.2282	batch_accuracy: 38.84%	lr:0.000251
Ep: 34/48	It: 7101/8134	batch_loss: 3.0702	batch_accuracy: 41.38%	lr:0.000251
Ep: 34/48	It: 7151/8134	batch_loss: 3.0291	batch_accuracy: 41.89%	lr:0.000251
Ep: 34/48	It: 7201/8134	batch_loss: 3.0372	batch_accuracy: 41.87%	lr:0.000251
Ep: 34/48	It: 7251/8134	batch_loss: 3.0838	batch_accuracy: 40.48%	lr:0.000250
Ep: 34/48	It: 7301/8134	batch_loss: 3.0612	batch_accuracy: 41.38%	lr:0.000250
Ep: 34/48	It: 7351/8134	batch_loss: 2.9916	batch_accuracy: 42.50%	lr:0.000250
Ep: 34/48	It: 7401/8134	batch_loss: 2.9904	batch_accuracy: 42.09%	lr:0.000250
Ep: 34/48	It: 7451/8134	batch_loss: 2.9355	batch_accuracy: 43.38%	lr:0.000250
Ep: 34/48	It: 7501/8134	batch_loss: 3.0987	batch_accuracy: 40.70%	lr:0.000250
Ep: 34/48	It: 7551/8134	batch_loss: 3.1412	batch_accuracy: 41.97%	lr:0.000249
Ep: 34/48	It: 7601/8134	batch_loss: 3.1332	batch_accuracy: 41.46%	lr:0.000249
Ep: 34/48	It: 7651/8134	batch_loss: 2.8574	batch_accuracy: 43.73%	lr:0.000249
Ep: 34/48	It: 7701/8134	batch_loss: 3.1478	batch_accuracy: 40.19%	lr:0.000249
Ep: 34/48	It: 7751/8134	batch_loss: 3.0527	batch_accuracy: 40.92%	lr:0.000249
Ep: 34/48	It: 7801/8134	batch_loss: 3.1129	batch_accuracy: 39.77%	lr:0.000248
Ep: 34/48	It: 7851/8134	batch_loss: 3.0530	batch_accuracy: 42.24%	lr:0.000248
Ep: 34/48	It: 7901/8134	batch_loss: 3.0996	batch_accuracy: 40.67%	lr:0.000248
Ep: 34/48	It: 7951/8134	batch_loss: 3.0730	batch_accuracy: 40.50%	lr:0.000248
Ep: 34/48	It: 8001/8134	batch_loss: 3.1677	batch_accuracy: 41.26%	lr:0.000248
Ep: 34/48	It: 8051/8134	batch_loss: 3.0771	batch_accuracy: 39.67%	lr:0.000247
Ep: 34/48	It: 8101/8134	batch_loss: 3.1234	batch_accuracy: 40.33%	lr:0.000247
Ep: 34/48	It: 8134/8134	batch_loss: 3.1347	batch_accuracy: 39.71%	lr:0.000247


Generated text for input text "You" is:
Youver, theorization of human beings. For this the purpose of this paper is to make an effort to find out how took ingrooves of theatheresis to theater to find out what the people to be in which they are being in the old and how they have taken. The research was conducted by two research groups, the first one comprising the main research group (the first one was the Federal District) and the second was the second in the second half of the sixth year of the first year of the study. The second part was an experiment of the second-year Gross-Portfolio Dynamics of Government Project. The sample of the second-year Global Bank of Government of Nigeria was a questionnaire. The sample of this study is the respondents of Government Government. The results of this study show that the financial statements of Government Government support the grant funding of Government Government Government Government Government Government Government Government Government Government Government Governance and Policy-Bowance


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 35/48	It: 1/8134	batch_loss: 3.0598	batch_accuracy: 42.24%	lr:0.000247
Ep: 35/48	It: 51/8134	batch_loss: 3.1010	batch_accuracy: 41.53%	lr:0.000247
Ep: 35/48	It: 101/8134	batch_loss: 3.0162	batch_accuracy: 41.38%	lr:0.000247
Ep: 35/48	It: 151/8134	batch_loss: 3.0120	batch_accuracy: 41.89%	lr:0.000247
Ep: 35/48	It: 201/8134	batch_loss: 3.1452	batch_accuracy: 41.26%	lr:0.000246
Ep: 35/48	It: 251/8134	batch_loss: 3.0138	batch_accuracy: 41.80%	lr:0.000246
Ep: 35/48	It: 301/8134	batch_loss: 3.1251	batch_accuracy: 40.50%	lr:0.000246
Ep: 35/48	It: 351/8134	batch_loss: 3.1409	batch_accuracy: 40.01%	lr:0.000246
Ep: 35/48	It: 401/8134	batch_loss: 3.0120	batch_accuracy: 42.87%	lr:0.000246
Ep: 35/48	It: 451/8134	batch_loss: 3.0090	batch_accuracy: 42.55%	lr:0.000245
Ep: 35/48	It: 501/8134	batch_loss: 3.0190	batch_accuracy: 41.28%	lr:0.000245
Ep: 35/48	It: 551/8134	batch_loss: 3.0483	batch_accuracy: 41.11%	lr:0.000245
Ep: 35/48	It: 601/8134	batch_loss: 3.1091	batch_accuracy: 39.65%	lr:0.000245
Ep: 35/48	It: 651/8134	batch_loss: 3.0573	batch_accuracy: 41.50%	lr:0.000245
Ep: 35/48	It: 701/8134	batch_loss: 3.0856	batch_accuracy: 40.94%	lr:0.000244
Ep: 35/48	It: 751/8134	batch_loss: 3.1216	batch_accuracy: 40.55%	lr:0.000244
Ep: 35/48	It: 801/8134	batch_loss: 3.1926	batch_accuracy: 40.21%	lr:0.000244
Ep: 35/48	It: 851/8134	batch_loss: 3.1198	batch_accuracy: 39.92%	lr:0.000244
Ep: 35/48	It: 901/8134	batch_loss: 3.0550	batch_accuracy: 40.70%	lr:0.000244
Ep: 35/48	It: 951/8134	batch_loss: 3.0287	batch_accuracy: 42.11%	lr:0.000244
Ep: 35/48	It: 1001/8134	batch_loss: 3.0373	batch_accuracy: 40.89%	lr:0.000243
Ep: 35/48	It: 1051/8134	batch_loss: 3.0667	batch_accuracy: 41.65%	lr:0.000243
Ep: 35/48	It: 1101/8134	batch_loss: 3.1379	batch_accuracy: 40.14%	lr:0.000243
Ep: 35/48	It: 1151/8134	batch_loss: 3.2337	batch_accuracy: 39.55%	lr:0.000243
Ep: 35/48	It: 1201/8134	batch_loss: 3.0465	batch_accuracy: 41.60%	lr:0.000243
Ep: 35/48	It: 1251/8134	batch_loss: 3.0790	batch_accuracy: 40.65%	lr:0.000242
Ep: 35/48	It: 1301/8134	batch_loss: 3.0127	batch_accuracy: 42.26%	lr:0.000242
Ep: 35/48	It: 1351/8134	batch_loss: 3.1204	batch_accuracy: 41.14%	lr:0.000242
Ep: 35/48	It: 1401/8134	batch_loss: 3.0888	batch_accuracy: 41.75%	lr:0.000242
Ep: 35/48	It: 1451/8134	batch_loss: 3.1739	batch_accuracy: 39.92%	lr:0.000242
Ep: 35/48	It: 1501/8134	batch_loss: 3.0400	batch_accuracy: 41.19%	lr:0.000241
Ep: 35/48	It: 1551/8134	batch_loss: 3.0437	batch_accuracy: 40.67%	lr:0.000241
Ep: 35/48	It: 1601/8134	batch_loss: 3.1234	batch_accuracy: 40.50%	lr:0.000241
Ep: 35/48	It: 1651/8134	batch_loss: 3.0224	batch_accuracy: 43.12%	lr:0.000241
Ep: 35/48	It: 1701/8134	batch_loss: 3.1384	batch_accuracy: 40.33%	lr:0.000241
Ep: 35/48	It: 1751/8134	batch_loss: 3.1370	batch_accuracy: 40.92%	lr:0.000241
Ep: 35/48	It: 1801/8134	batch_loss: 3.0709	batch_accuracy: 40.72%	lr:0.000240
Ep: 35/48	It: 1851/8134	batch_loss: 3.1317	batch_accuracy: 40.89%	lr:0.000240
Ep: 35/48	It: 1901/8134	batch_loss: 3.1006	batch_accuracy: 40.80%	lr:0.000240
Ep: 35/48	It: 1951/8134	batch_loss: 3.0513	batch_accuracy: 41.11%	lr:0.000240
Ep: 35/48	It: 2001/8134	batch_loss: 3.0229	batch_accuracy: 41.80%	lr:0.000240
Ep: 35/48	It: 2051/8134	batch_loss: 3.1628	batch_accuracy: 39.06%	lr:0.000239
Ep: 35/48	It: 2101/8134	batch_loss: 2.9740	batch_accuracy: 42.87%	lr:0.000239
Ep: 35/48	It: 2151/8134	batch_loss: 3.0704	batch_accuracy: 41.65%	lr:0.000239
Ep: 35/48	It: 2201/8134	batch_loss: 2.9609	batch_accuracy: 42.41%	lr:0.000239
Ep: 35/48	It: 2251/8134	batch_loss: 3.1712	batch_accuracy: 39.21%	lr:0.000239
Ep: 35/48	It: 2301/8134	batch_loss: 3.1299	batch_accuracy: 39.60%	lr:0.000238
Ep: 35/48	It: 2351/8134	batch_loss: 3.1397	batch_accuracy: 40.21%	lr:0.000238
Ep: 35/48	It: 2401/8134	batch_loss: 2.9717	batch_accuracy: 42.41%	lr:0.000238
Ep: 35/48	It: 2451/8134	batch_loss: 3.0490	batch_accuracy: 42.99%	lr:0.000238
Ep: 35/48	It: 2501/8134	batch_loss: 3.1538	batch_accuracy: 39.60%	lr:0.000238
Ep: 35/48	It: 2551/8134	batch_loss: 3.0126	batch_accuracy: 41.28%	lr:0.000238
Ep: 35/48	It: 2601/8134	batch_loss: 3.1936	batch_accuracy: 38.87%	lr:0.000237
Ep: 35/48	It: 2651/8134	batch_loss: 3.0020	batch_accuracy: 42.16%	lr:0.000237
Ep: 35/48	It: 2701/8134	batch_loss: 3.0724	batch_accuracy: 41.53%	lr:0.000237
Ep: 35/48	It: 2751/8134	batch_loss: 3.1168	batch_accuracy: 40.28%	lr:0.000237
Ep: 35/48	It: 2801/8134	batch_loss: 3.0131	batch_accuracy: 41.60%	lr:0.000237
Ep: 35/48	It: 2851/8134	batch_loss: 3.0758	batch_accuracy: 41.11%	lr:0.000236
Ep: 35/48	It: 2901/8134	batch_loss: 3.1041	batch_accuracy: 40.62%	lr:0.000236
Ep: 35/48	It: 2951/8134	batch_loss: 2.9806	batch_accuracy: 42.02%	lr:0.000236
Ep: 35/48	It: 3001/8134	batch_loss: 3.0213	batch_accuracy: 42.31%	lr:0.000236
Ep: 35/48	It: 3051/8134	batch_loss: 3.0235	batch_accuracy: 42.85%	lr:0.000236
Ep: 35/48	It: 3101/8134	batch_loss: 3.1240	batch_accuracy: 41.04%	lr:0.000235
Ep: 35/48	It: 3151/8134	batch_loss: 3.0150	batch_accuracy: 42.31%	lr:0.000235
Ep: 35/48	It: 3201/8134	batch_loss: 2.9948	batch_accuracy: 42.41%	lr:0.000235
Ep: 35/48	It: 3251/8134	batch_loss: 3.1755	batch_accuracy: 39.62%	lr:0.000235
Ep: 35/48	It: 3301/8134	batch_loss: 3.0332	batch_accuracy: 41.48%	lr:0.000235
Ep: 35/48	It: 3351/8134	batch_loss: 3.0227	batch_accuracy: 42.80%	lr:0.000235
Ep: 35/48	It: 3401/8134	batch_loss: 2.9291	batch_accuracy: 43.51%	lr:0.000234
Ep: 35/48	It: 3451/8134	batch_loss: 3.1290	batch_accuracy: 40.45%	lr:0.000234
Ep: 35/48	It: 3501/8134	batch_loss: 3.2702	batch_accuracy: 38.84%	lr:0.000234
Ep: 35/48	It: 3551/8134	batch_loss: 3.0820	batch_accuracy: 40.87%	lr:0.000234
Ep: 35/48	It: 3601/8134	batch_loss: 3.0213	batch_accuracy: 41.65%	lr:0.000234
Ep: 35/48	It: 3651/8134	batch_loss: 3.0163	batch_accuracy: 41.14%	lr:0.000233
Ep: 35/48	It: 3701/8134	batch_loss: 3.1141	batch_accuracy: 40.65%	lr:0.000233
Ep: 35/48	It: 3751/8134	batch_loss: 3.0653	batch_accuracy: 41.87%	lr:0.000233
Ep: 35/48	It: 3801/8134	batch_loss: 3.0639	batch_accuracy: 40.89%	lr:0.000233
Ep: 35/48	It: 3851/8134	batch_loss: 3.0254	batch_accuracy: 41.53%	lr:0.000233
Ep: 35/48	It: 3901/8134	batch_loss: 3.1139	batch_accuracy: 40.43%	lr:0.000232
Ep: 35/48	It: 3951/8134	batch_loss: 3.0498	batch_accuracy: 41.19%	lr:0.000232
Ep: 35/48	It: 4001/8134	batch_loss: 3.2627	batch_accuracy: 38.53%	lr:0.000232
Ep: 35/48	It: 4051/8134	batch_loss: 2.9911	batch_accuracy: 42.29%	lr:0.000232
Ep: 35/48	It: 4101/8134	batch_loss: 3.1342	batch_accuracy: 39.67%	lr:0.000232
Ep: 35/48	It: 4151/8134	batch_loss: 3.0750	batch_accuracy: 41.82%	lr:0.000232
Ep: 35/48	It: 4201/8134	batch_loss: 3.0440	batch_accuracy: 41.04%	lr:0.000231
Ep: 35/48	It: 4251/8134	batch_loss: 3.0741	batch_accuracy: 40.53%	lr:0.000231
Ep: 35/48	It: 4301/8134	batch_loss: 3.0481	batch_accuracy: 41.53%	lr:0.000231
Ep: 35/48	It: 4351/8134	batch_loss: 3.0435	batch_accuracy: 42.19%	lr:0.000231
Ep: 35/48	It: 4401/8134	batch_loss: 3.1205	batch_accuracy: 39.92%	lr:0.000231
Ep: 35/48	It: 4451/8134	batch_loss: 3.1807	batch_accuracy: 39.60%	lr:0.000230
Ep: 35/48	It: 4501/8134	batch_loss: 3.1011	batch_accuracy: 41.70%	lr:0.000230
Ep: 35/48	It: 4551/8134	batch_loss: 3.0451	batch_accuracy: 42.11%	lr:0.000230
Ep: 35/48	It: 4601/8134	batch_loss: 3.0301	batch_accuracy: 41.92%	lr:0.000230
Ep: 35/48	It: 4651/8134	batch_loss: 3.1396	batch_accuracy: 41.14%	lr:0.000230
Ep: 35/48	It: 4701/8134	batch_loss: 3.0720	batch_accuracy: 41.41%	lr:0.000230
Ep: 35/48	It: 4751/8134	batch_loss: 3.0542	batch_accuracy: 42.26%	lr:0.000229
Ep: 35/48	It: 4801/8134	batch_loss: 3.0764	batch_accuracy: 41.89%	lr:0.000229
Ep: 35/48	It: 4851/8134	batch_loss: 3.0426	batch_accuracy: 42.26%	lr:0.000229
Ep: 35/48	It: 4901/8134	batch_loss: 2.9917	batch_accuracy: 42.46%	lr:0.000229
Ep: 35/48	It: 4951/8134	batch_loss: 3.0605	batch_accuracy: 41.24%	lr:0.000229
Ep: 35/48	It: 5001/8134	batch_loss: 3.0237	batch_accuracy: 42.09%	lr:0.000228
Ep: 35/48	It: 5051/8134	batch_loss: 3.0269	batch_accuracy: 42.53%	lr:0.000228
Ep: 35/48	It: 5101/8134	batch_loss: 3.1486	batch_accuracy: 39.82%	lr:0.000228
Ep: 35/48	It: 5151/8134	batch_loss: 3.0821	batch_accuracy: 40.38%	lr:0.000228
Ep: 35/48	It: 5201/8134	batch_loss: 3.0942	batch_accuracy: 40.23%	lr:0.000228
Ep: 35/48	It: 5251/8134	batch_loss: 3.1787	batch_accuracy: 38.33%	lr:0.000228
Ep: 35/48	It: 5301/8134	batch_loss: 3.0735	batch_accuracy: 41.60%	lr:0.000227
Ep: 35/48	It: 5351/8134	batch_loss: 3.0051	batch_accuracy: 41.75%	lr:0.000227
Ep: 35/48	It: 5401/8134	batch_loss: 3.0171	batch_accuracy: 41.55%	lr:0.000227
Ep: 35/48	It: 5451/8134	batch_loss: 3.0585	batch_accuracy: 42.26%	lr:0.000227
Ep: 35/48	It: 5501/8134	batch_loss: 2.9852	batch_accuracy: 43.12%	lr:0.000227
Ep: 35/48	It: 5551/8134	batch_loss: 3.1628	batch_accuracy: 39.21%	lr:0.000226
Ep: 35/48	It: 5601/8134	batch_loss: 3.0485	batch_accuracy: 41.58%	lr:0.000226
Ep: 35/48	It: 5651/8134	batch_loss: 3.0546	batch_accuracy: 40.77%	lr:0.000226
Ep: 35/48	It: 5701/8134	batch_loss: 3.1036	batch_accuracy: 40.26%	lr:0.000226
Ep: 35/48	It: 5751/8134	batch_loss: 3.1400	batch_accuracy: 40.33%	lr:0.000226
Ep: 35/48	It: 5801/8134	batch_loss: 3.0720	batch_accuracy: 40.87%	lr:0.000225
Ep: 35/48	It: 5851/8134	batch_loss: 3.0663	batch_accuracy: 41.48%	lr:0.000225
Ep: 35/48	It: 5901/8134	batch_loss: 3.1086	batch_accuracy: 40.99%	lr:0.000225
Ep: 35/48	It: 5951/8134	batch_loss: 3.0543	batch_accuracy: 41.65%	lr:0.000225
Ep: 35/48	It: 6001/8134	batch_loss: 3.0548	batch_accuracy: 41.21%	lr:0.000225
Ep: 35/48	It: 6051/8134	batch_loss: 3.1128	batch_accuracy: 40.53%	lr:0.000225
Ep: 35/48	It: 6101/8134	batch_loss: 3.0100	batch_accuracy: 41.55%	lr:0.000224
Ep: 35/48	It: 6151/8134	batch_loss: 2.8821	batch_accuracy: 43.73%	lr:0.000224
Ep: 35/48	It: 6201/8134	batch_loss: 3.1705	batch_accuracy: 40.41%	lr:0.000224
Ep: 35/48	It: 6251/8134	batch_loss: 3.1355	batch_accuracy: 41.41%	lr:0.000224
Ep: 35/48	It: 6301/8134	batch_loss: 3.2731	batch_accuracy: 39.09%	lr:0.000224
Ep: 35/48	It: 6351/8134	batch_loss: 3.1631	batch_accuracy: 39.77%	lr:0.000223
Ep: 35/48	It: 6401/8134	batch_loss: 3.1028	batch_accuracy: 40.14%	lr:0.000223
Ep: 35/48	It: 6451/8134	batch_loss: 3.1327	batch_accuracy: 39.92%	lr:0.000223
Ep: 35/48	It: 6501/8134	batch_loss: 3.0178	batch_accuracy: 41.89%	lr:0.000223
Ep: 35/48	It: 6551/8134	batch_loss: 3.1200	batch_accuracy: 39.79%	lr:0.000223
Ep: 35/48	It: 6601/8134	batch_loss: 3.0080	batch_accuracy: 42.65%	lr:0.000223
Ep: 35/48	It: 6651/8134	batch_loss: 3.0931	batch_accuracy: 40.92%	lr:0.000222
Ep: 35/48	It: 6701/8134	batch_loss: 3.0598	batch_accuracy: 42.43%	lr:0.000222
Ep: 35/48	It: 6751/8134	batch_loss: 2.9501	batch_accuracy: 42.80%	lr:0.000222
Ep: 35/48	It: 6801/8134	batch_loss: 2.9297	batch_accuracy: 43.16%	lr:0.000222
Ep: 35/48	It: 6851/8134	batch_loss: 2.9262	batch_accuracy: 42.65%	lr:0.000222
Ep: 35/48	It: 6901/8134	batch_loss: 3.0549	batch_accuracy: 42.58%	lr:0.000221
Ep: 35/48	It: 6951/8134	batch_loss: 3.1349	batch_accuracy: 41.46%	lr:0.000221
Ep: 35/48	It: 7001/8134	batch_loss: 3.1572	batch_accuracy: 39.45%	lr:0.000221
Ep: 35/48	It: 7051/8134	batch_loss: 3.0587	batch_accuracy: 40.94%	lr:0.000221
Ep: 35/48	It: 7101/8134	batch_loss: 3.1478	batch_accuracy: 40.11%	lr:0.000221
Ep: 35/48	It: 7151/8134	batch_loss: 3.1248	batch_accuracy: 41.77%	lr:0.000221
Ep: 35/48	It: 7201/8134	batch_loss: 2.9408	batch_accuracy: 42.60%	lr:0.000220
Ep: 35/48	It: 7251/8134	batch_loss: 3.0437	batch_accuracy: 42.24%	lr:0.000220
Ep: 35/48	It: 7301/8134	batch_loss: 3.1387	batch_accuracy: 39.67%	lr:0.000220
Ep: 35/48	It: 7351/8134	batch_loss: 3.0469	batch_accuracy: 39.94%	lr:0.000220
Ep: 35/48	It: 7401/8134	batch_loss: 3.0934	batch_accuracy: 40.45%	lr:0.000220
Ep: 35/48	It: 7451/8134	batch_loss: 3.0875	batch_accuracy: 40.70%	lr:0.000219
Ep: 35/48	It: 7501/8134	batch_loss: 2.9760	batch_accuracy: 41.85%	lr:0.000219
Ep: 35/48	It: 7551/8134	batch_loss: 2.9633	batch_accuracy: 42.14%	lr:0.000219
Ep: 35/48	It: 7601/8134	batch_loss: 3.1022	batch_accuracy: 40.28%	lr:0.000219
Ep: 35/48	It: 7651/8134	batch_loss: 3.2576	batch_accuracy: 38.82%	lr:0.000219
Ep: 35/48	It: 7701/8134	batch_loss: 3.0649	batch_accuracy: 40.89%	lr:0.000219
Ep: 35/48	It: 7751/8134	batch_loss: 3.0661	batch_accuracy: 41.80%	lr:0.000218
Ep: 35/48	It: 7801/8134	batch_loss: 3.1033	batch_accuracy: 42.31%	lr:0.000218
Ep: 35/48	It: 7851/8134	batch_loss: 3.1632	batch_accuracy: 39.40%	lr:0.000218
Ep: 35/48	It: 7901/8134	batch_loss: 2.9832	batch_accuracy: 41.43%	lr:0.000218
Ep: 35/48	It: 7951/8134	batch_loss: 3.1289	batch_accuracy: 40.75%	lr:0.000218
Ep: 35/48	It: 8001/8134	batch_loss: 3.0995	batch_accuracy: 40.94%	lr:0.000217
Ep: 35/48	It: 8051/8134	batch_loss: 3.0824	batch_accuracy: 42.11%	lr:0.000217
Ep: 35/48	It: 8101/8134	batch_loss: 3.1065	batch_accuracy: 41.09%	lr:0.000217
Ep: 35/48	It: 8134/8134	batch_loss: 3.0731	batch_accuracy: 40.52%	lr:0.000217


Generated text for input text "You" is:
Youvia.
This study aimed to determine the effect of aromatic substituity on the accuracy of theta(ttt) and to theta(tttt), on the accuracy of the number of p is calculated. The results show that the method has good accuracy and its accuracy is about 10% on average.
<eot>
<sot>
Simulation of a Single-Crystal Plasma Displacement Load

The Single-Crystal Plasma Displacement Loaded Plasma Displacement Loaded Single Crystal Plasma Displacement Loaded with a Single-Crystal Plasma Displacement Loaded by a Structureless Pressure Shape

Single-crystal Plasma Displacement Loaded Single Crystal Plasma Displacement Loaded Single Crystal Phase-Shaped Single Crystal Phase Shifters

The high dielectric constant of silicon dioxide (SiO2) is achieved by the high dielectric constant, which is an important


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 36/48	It: 1/8134	batch_loss: 3.0870	batch_accuracy: 40.70%	lr:0.000217
Ep: 36/48	It: 51/8134	batch_loss: 3.1036	batch_accuracy: 40.80%	lr:0.000217
Ep: 36/48	It: 101/8134	batch_loss: 3.1097	batch_accuracy: 39.99%	lr:0.000217
Ep: 36/48	It: 151/8134	batch_loss: 3.1104	batch_accuracy: 41.38%	lr:0.000216
Ep: 36/48	It: 201/8134	batch_loss: 3.0421	batch_accuracy: 41.63%	lr:0.000216
Ep: 36/48	It: 251/8134	batch_loss: 3.0148	batch_accuracy: 41.70%	lr:0.000216
Ep: 36/48	It: 301/8134	batch_loss: 2.9968	batch_accuracy: 42.38%	lr:0.000216
Ep: 36/48	It: 351/8134	batch_loss: 2.9610	batch_accuracy: 43.75%	lr:0.000216
Ep: 36/48	It: 401/8134	batch_loss: 3.0107	batch_accuracy: 41.67%	lr:0.000216
Ep: 36/48	It: 451/8134	batch_loss: 3.0548	batch_accuracy: 41.65%	lr:0.000215
Ep: 36/48	It: 501/8134	batch_loss: 3.1080	batch_accuracy: 40.87%	lr:0.000215
Ep: 36/48	It: 551/8134	batch_loss: 3.0456	batch_accuracy: 42.41%	lr:0.000215
Ep: 36/48	It: 601/8134	batch_loss: 3.0113	batch_accuracy: 41.70%	lr:0.000215
Ep: 36/48	It: 651/8134	batch_loss: 3.0088	batch_accuracy: 41.11%	lr:0.000215
Ep: 36/48	It: 701/8134	batch_loss: 3.0938	batch_accuracy: 41.16%	lr:0.000214
Ep: 36/48	It: 751/8134	batch_loss: 3.0872	batch_accuracy: 41.02%	lr:0.000214
Ep: 36/48	It: 801/8134	batch_loss: 3.2279	batch_accuracy: 39.55%	lr:0.000214
Ep: 36/48	It: 851/8134	batch_loss: 2.9977	batch_accuracy: 42.09%	lr:0.000214
Ep: 36/48	It: 901/8134	batch_loss: 3.1076	batch_accuracy: 40.16%	lr:0.000214
Ep: 36/48	It: 951/8134	batch_loss: 3.0385	batch_accuracy: 41.06%	lr:0.000214
Ep: 36/48	It: 1001/8134	batch_loss: 3.0685	batch_accuracy: 41.41%	lr:0.000213
Ep: 36/48	It: 1051/8134	batch_loss: 3.0209	batch_accuracy: 41.63%	lr:0.000213
Ep: 36/48	It: 1101/8134	batch_loss: 3.1353	batch_accuracy: 39.87%	lr:0.000213
Ep: 36/48	It: 1151/8134	batch_loss: 3.1121	batch_accuracy: 40.94%	lr:0.000213
Ep: 36/48	It: 1201/8134	batch_loss: 3.1031	batch_accuracy: 40.65%	lr:0.000213
Ep: 36/48	It: 1251/8134	batch_loss: 3.0557	batch_accuracy: 42.07%	lr:0.000212
Ep: 36/48	It: 1301/8134	batch_loss: 3.0684	batch_accuracy: 41.46%	lr:0.000212
Ep: 36/48	It: 1351/8134	batch_loss: 3.2184	batch_accuracy: 39.62%	lr:0.000212
Ep: 36/48	It: 1401/8134	batch_loss: 3.0931	batch_accuracy: 41.14%	lr:0.000212
Ep: 36/48	It: 1451/8134	batch_loss: 3.1048	batch_accuracy: 40.60%	lr:0.000212
Ep: 36/48	It: 1501/8134	batch_loss: 3.1357	batch_accuracy: 40.48%	lr:0.000212
Ep: 36/48	It: 1551/8134	batch_loss: 3.1031	batch_accuracy: 40.72%	lr:0.000211
Ep: 36/48	It: 1601/8134	batch_loss: 3.1457	batch_accuracy: 40.97%	lr:0.000211
Ep: 36/48	It: 1651/8134	batch_loss: 3.0109	batch_accuracy: 41.36%	lr:0.000211
Ep: 36/48	It: 1701/8134	batch_loss: 3.1073	batch_accuracy: 40.23%	lr:0.000211
Ep: 36/48	It: 1751/8134	batch_loss: 3.0340	batch_accuracy: 42.36%	lr:0.000211
Ep: 36/48	It: 1801/8134	batch_loss: 3.0359	batch_accuracy: 42.33%	lr:0.000211
Ep: 36/48	It: 1851/8134	batch_loss: 3.0813	batch_accuracy: 40.82%	lr:0.000210
Ep: 36/48	It: 1901/8134	batch_loss: 2.9764	batch_accuracy: 42.33%	lr:0.000210
Ep: 36/48	It: 1951/8134	batch_loss: 3.1272	batch_accuracy: 40.75%	lr:0.000210
Ep: 36/48	It: 2001/8134	batch_loss: 2.9743	batch_accuracy: 43.02%	lr:0.000210
Ep: 36/48	It: 2051/8134	batch_loss: 3.0877	batch_accuracy: 40.50%	lr:0.000210
Ep: 36/48	It: 2101/8134	batch_loss: 3.0888	batch_accuracy: 41.58%	lr:0.000209
Ep: 36/48	It: 2151/8134	batch_loss: 3.0833	batch_accuracy: 40.75%	lr:0.000209
Ep: 36/48	It: 2201/8134	batch_loss: 2.9567	batch_accuracy: 42.48%	lr:0.000209
Ep: 36/48	It: 2251/8134	batch_loss: 3.1689	batch_accuracy: 39.89%	lr:0.000209
Ep: 36/48	It: 2301/8134	batch_loss: 3.0408	batch_accuracy: 41.28%	lr:0.000209
Ep: 36/48	It: 2351/8134	batch_loss: 3.0686	batch_accuracy: 42.31%	lr:0.000209
Ep: 36/48	It: 2401/8134	batch_loss: 3.0446	batch_accuracy: 41.87%	lr:0.000208
Ep: 36/48	It: 2451/8134	batch_loss: 2.9746	batch_accuracy: 42.02%	lr:0.000208
Ep: 36/48	It: 2501/8134	batch_loss: 3.0879	batch_accuracy: 40.97%	lr:0.000208
Ep: 36/48	It: 2551/8134	batch_loss: 3.1456	batch_accuracy: 40.72%	lr:0.000208
Ep: 36/48	It: 2601/8134	batch_loss: 3.0015	batch_accuracy: 41.75%	lr:0.000208
Ep: 36/48	It: 2651/8134	batch_loss: 3.0064	batch_accuracy: 42.80%	lr:0.000207
Ep: 36/48	It: 2701/8134	batch_loss: 3.0781	batch_accuracy: 41.63%	lr:0.000207
Ep: 36/48	It: 2751/8134	batch_loss: 3.0967	batch_accuracy: 41.97%	lr:0.000207
Ep: 36/48	It: 2801/8134	batch_loss: 3.1351	batch_accuracy: 39.87%	lr:0.000207
Ep: 36/48	It: 2851/8134	batch_loss: 3.0476	batch_accuracy: 41.26%	lr:0.000207
Ep: 36/48	It: 2901/8134	batch_loss: 3.0757	batch_accuracy: 41.67%	lr:0.000207
Ep: 36/48	It: 2951/8134	batch_loss: 3.1001	batch_accuracy: 41.04%	lr:0.000206
Ep: 36/48	It: 3001/8134	batch_loss: 2.9353	batch_accuracy: 44.04%	lr:0.000206
Ep: 36/48	It: 3051/8134	batch_loss: 2.9962	batch_accuracy: 42.77%	lr:0.000206
Ep: 36/48	It: 3101/8134	batch_loss: 3.0652	batch_accuracy: 41.04%	lr:0.000206
Ep: 36/48	It: 3151/8134	batch_loss: 2.9684	batch_accuracy: 41.65%	lr:0.000206
Ep: 36/48	It: 3201/8134	batch_loss: 3.1576	batch_accuracy: 39.99%	lr:0.000206
Ep: 36/48	It: 3251/8134	batch_loss: 3.0512	batch_accuracy: 40.80%	lr:0.000205
Ep: 36/48	It: 3301/8134	batch_loss: 3.1069	batch_accuracy: 40.04%	lr:0.000205
Ep: 36/48	It: 3351/8134	batch_loss: 3.0755	batch_accuracy: 41.65%	lr:0.000205
Ep: 36/48	It: 3401/8134	batch_loss: 3.0162	batch_accuracy: 41.60%	lr:0.000205
Ep: 36/48	It: 3451/8134	batch_loss: 3.0323	batch_accuracy: 40.97%	lr:0.000205
Ep: 36/48	It: 3501/8134	batch_loss: 3.1473	batch_accuracy: 40.04%	lr:0.000204
Ep: 36/48	It: 3551/8134	batch_loss: 3.0288	batch_accuracy: 42.19%	lr:0.000204
Ep: 36/48	It: 3601/8134	batch_loss: 3.1134	batch_accuracy: 40.48%	lr:0.000204
Ep: 36/48	It: 3651/8134	batch_loss: 3.0698	batch_accuracy: 41.04%	lr:0.000204
Ep: 36/48	It: 3701/8134	batch_loss: 3.0817	batch_accuracy: 42.60%	lr:0.000204
Ep: 36/48	It: 3751/8134	batch_loss: 3.0272	batch_accuracy: 42.14%	lr:0.000204
Ep: 36/48	It: 3801/8134	batch_loss: 2.9552	batch_accuracy: 43.02%	lr:0.000203
Ep: 36/48	It: 3851/8134	batch_loss: 3.0719	batch_accuracy: 41.24%	lr:0.000203
Ep: 36/48	It: 3901/8134	batch_loss: 3.0910	batch_accuracy: 40.26%	lr:0.000203
Ep: 36/48	It: 3951/8134	batch_loss: 3.1307	batch_accuracy: 41.31%	lr:0.000203
Ep: 36/48	It: 4001/8134	batch_loss: 3.1259	batch_accuracy: 39.55%	lr:0.000203
Ep: 36/48	It: 4051/8134	batch_loss: 2.9640	batch_accuracy: 42.63%	lr:0.000203
Ep: 36/48	It: 4101/8134	batch_loss: 2.9806	batch_accuracy: 43.33%	lr:0.000202
Ep: 36/48	It: 4151/8134	batch_loss: 3.1388	batch_accuracy: 40.80%	lr:0.000202
Ep: 36/48	It: 4201/8134	batch_loss: 3.1017	batch_accuracy: 40.60%	lr:0.000202
Ep: 36/48	It: 4251/8134	batch_loss: 3.1562	batch_accuracy: 39.21%	lr:0.000202
Ep: 36/48	It: 4301/8134	batch_loss: 3.1767	batch_accuracy: 40.33%	lr:0.000202
Ep: 36/48	It: 4351/8134	batch_loss: 3.0395	batch_accuracy: 41.28%	lr:0.000201
Ep: 36/48	It: 4401/8134	batch_loss: 3.0444	batch_accuracy: 42.02%	lr:0.000201
Ep: 36/48	It: 4451/8134	batch_loss: 3.1561	batch_accuracy: 38.87%	lr:0.000201
Ep: 36/48	It: 4501/8134	batch_loss: 3.0434	batch_accuracy: 41.46%	lr:0.000201
Ep: 36/48	It: 4551/8134	batch_loss: 3.0651	batch_accuracy: 42.55%	lr:0.000201
Ep: 36/48	It: 4601/8134	batch_loss: 3.0628	batch_accuracy: 41.19%	lr:0.000201
Ep: 36/48	It: 4651/8134	batch_loss: 2.9380	batch_accuracy: 43.48%	lr:0.000200
Ep: 36/48	It: 4701/8134	batch_loss: 3.1823	batch_accuracy: 39.67%	lr:0.000200
Ep: 36/48	It: 4751/8134	batch_loss: 3.0624	batch_accuracy: 41.87%	lr:0.000200
Ep: 36/48	It: 4801/8134	batch_loss: 3.0498	batch_accuracy: 41.50%	lr:0.000200
Ep: 36/48	It: 4851/8134	batch_loss: 3.0801	batch_accuracy: 41.43%	lr:0.000200
Ep: 36/48	It: 4901/8134	batch_loss: 2.9136	batch_accuracy: 43.51%	lr:0.000200
Ep: 36/48	It: 4951/8134	batch_loss: 3.0428	batch_accuracy: 41.48%	lr:0.000199
Ep: 36/48	It: 5001/8134	batch_loss: 3.0664	batch_accuracy: 41.48%	lr:0.000199
Ep: 36/48	It: 5051/8134	batch_loss: 2.9746	batch_accuracy: 41.46%	lr:0.000199
Ep: 36/48	It: 5101/8134	batch_loss: 3.1107	batch_accuracy: 41.82%	lr:0.000199
Ep: 36/48	It: 5151/8134	batch_loss: 3.0113	batch_accuracy: 41.80%	lr:0.000199
Ep: 36/48	It: 5201/8134	batch_loss: 3.0322	batch_accuracy: 42.02%	lr:0.000198
Ep: 36/48	It: 5251/8134	batch_loss: 3.0239	batch_accuracy: 42.46%	lr:0.000198
Ep: 36/48	It: 5301/8134	batch_loss: 3.1657	batch_accuracy: 39.99%	lr:0.000198
Ep: 36/48	It: 5351/8134	batch_loss: 3.1145	batch_accuracy: 41.19%	lr:0.000198
Ep: 36/48	It: 5401/8134	batch_loss: 3.1448	batch_accuracy: 38.84%	lr:0.000198
Ep: 36/48	It: 5451/8134	batch_loss: 2.9262	batch_accuracy: 43.38%	lr:0.000198
Ep: 36/48	It: 5501/8134	batch_loss: 3.0071	batch_accuracy: 42.21%	lr:0.000197
Ep: 36/48	It: 5551/8134	batch_loss: 2.9226	batch_accuracy: 43.19%	lr:0.000197
Ep: 36/48	It: 5601/8134	batch_loss: 3.1230	batch_accuracy: 40.84%	lr:0.000197
Ep: 36/48	It: 5651/8134	batch_loss: 3.0095	batch_accuracy: 41.21%	lr:0.000197
Ep: 36/48	It: 5701/8134	batch_loss: 3.0928	batch_accuracy: 41.87%	lr:0.000197
Ep: 36/48	It: 5751/8134	batch_loss: 3.0724	batch_accuracy: 42.09%	lr:0.000197
Ep: 36/48	It: 5801/8134	batch_loss: 3.1286	batch_accuracy: 40.11%	lr:0.000196
Ep: 36/48	It: 5851/8134	batch_loss: 3.1617	batch_accuracy: 40.58%	lr:0.000196
Ep: 36/48	It: 5901/8134	batch_loss: 3.1149	batch_accuracy: 40.21%	lr:0.000196
Ep: 36/48	It: 5951/8134	batch_loss: 2.9581	batch_accuracy: 43.24%	lr:0.000196
Ep: 36/48	It: 6001/8134	batch_loss: 3.0320	batch_accuracy: 42.65%	lr:0.000196
Ep: 36/48	It: 6051/8134	batch_loss: 3.0339	batch_accuracy: 41.48%	lr:0.000196
Ep: 36/48	It: 6101/8134	batch_loss: 3.0835	batch_accuracy: 41.09%	lr:0.000195
Ep: 36/48	It: 6151/8134	batch_loss: 3.0672	batch_accuracy: 41.33%	lr:0.000195
Ep: 36/48	It: 6201/8134	batch_loss: 3.2168	batch_accuracy: 39.36%	lr:0.000195
Ep: 36/48	It: 6251/8134	batch_loss: 3.0772	batch_accuracy: 41.14%	lr:0.000195
Ep: 36/48	It: 6301/8134	batch_loss: 3.1310	batch_accuracy: 40.55%	lr:0.000195
Ep: 36/48	It: 6351/8134	batch_loss: 2.9694	batch_accuracy: 42.75%	lr:0.000194
Ep: 36/48	It: 6401/8134	batch_loss: 2.9814	batch_accuracy: 42.55%	lr:0.000194
Ep: 36/48	It: 6451/8134	batch_loss: 3.1590	batch_accuracy: 39.58%	lr:0.000194
Ep: 36/48	It: 6501/8134	batch_loss: 2.9863	batch_accuracy: 42.58%	lr:0.000194
Ep: 36/48	It: 6551/8134	batch_loss: 2.9155	batch_accuracy: 43.77%	lr:0.000194
Ep: 36/48	It: 6601/8134	batch_loss: 3.0189	batch_accuracy: 42.16%	lr:0.000194
Ep: 36/48	It: 6651/8134	batch_loss: 3.1105	batch_accuracy: 41.28%	lr:0.000193
Ep: 36/48	It: 6701/8134	batch_loss: 2.9463	batch_accuracy: 43.12%	lr:0.000193
Ep: 36/48	It: 6751/8134	batch_loss: 3.0026	batch_accuracy: 42.50%	lr:0.000193
Ep: 36/48	It: 6801/8134	batch_loss: 3.0471	batch_accuracy: 40.53%	lr:0.000193
Ep: 36/48	It: 6851/8134	batch_loss: 3.0087	batch_accuracy: 42.82%	lr:0.000193
Ep: 36/48	It: 6901/8134	batch_loss: 3.2549	batch_accuracy: 39.36%	lr:0.000193
Ep: 36/48	It: 6951/8134	batch_loss: 3.2108	batch_accuracy: 39.89%	lr:0.000192
Ep: 36/48	It: 7001/8134	batch_loss: 3.1516	batch_accuracy: 40.48%	lr:0.000192
Ep: 36/48	It: 7051/8134	batch_loss: 3.1587	batch_accuracy: 39.38%	lr:0.000192
Ep: 36/48	It: 7101/8134	batch_loss: 3.0665	batch_accuracy: 41.04%	lr:0.000192
Ep: 36/48	It: 7151/8134	batch_loss: 3.0707	batch_accuracy: 41.50%	lr:0.000192
Ep: 36/48	It: 7201/8134	batch_loss: 2.9942	batch_accuracy: 43.19%	lr:0.000192
Ep: 36/48	It: 7251/8134	batch_loss: 3.0482	batch_accuracy: 40.92%	lr:0.000191
Ep: 36/48	It: 7301/8134	batch_loss: 3.1186	batch_accuracy: 40.70%	lr:0.000191
Ep: 36/48	It: 7351/8134	batch_loss: 3.0782	batch_accuracy: 41.16%	lr:0.000191
Ep: 36/48	It: 7401/8134	batch_loss: 3.0223	batch_accuracy: 41.75%	lr:0.000191
Ep: 36/48	It: 7451/8134	batch_loss: 3.0023	batch_accuracy: 42.07%	lr:0.000191
Ep: 36/48	It: 7501/8134	batch_loss: 3.0698	batch_accuracy: 40.70%	lr:0.000191
Ep: 36/48	It: 7551/8134	batch_loss: 3.0446	batch_accuracy: 41.77%	lr:0.000190
Ep: 36/48	It: 7601/8134	batch_loss: 3.0106	batch_accuracy: 41.97%	lr:0.000190
Ep: 36/48	It: 7651/8134	batch_loss: 3.1113	batch_accuracy: 41.31%	lr:0.000190
Ep: 36/48	It: 7701/8134	batch_loss: 3.1833	batch_accuracy: 39.21%	lr:0.000190
Ep: 36/48	It: 7751/8134	batch_loss: 3.1103	batch_accuracy: 41.38%	lr:0.000190
Ep: 36/48	It: 7801/8134	batch_loss: 2.9502	batch_accuracy: 43.19%	lr:0.000190
Ep: 36/48	It: 7851/8134	batch_loss: 3.0947	batch_accuracy: 40.53%	lr:0.000189
Ep: 36/48	It: 7901/8134	batch_loss: 3.0597	batch_accuracy: 40.72%	lr:0.000189
Ep: 36/48	It: 7951/8134	batch_loss: 3.2100	batch_accuracy: 38.99%	lr:0.000189
Ep: 36/48	It: 8001/8134	batch_loss: 3.1343	batch_accuracy: 40.84%	lr:0.000189
Ep: 36/48	It: 8051/8134	batch_loss: 3.0473	batch_accuracy: 41.09%	lr:0.000189
Ep: 36/48	It: 8101/8134	batch_loss: 3.0186	batch_accuracy: 41.94%	lr:0.000188
Ep: 36/48	It: 8134/8134	batch_loss: 2.8025	batch_accuracy: 45.01%	lr:0.000188


Generated text for input text "You" is:
You.

OBJECTIVE
To evaluate the effectiveness of a new, simple, androstep, and easy to use procedure in cases of acute pancreatitis.


This study was carried out to evaluate the clinical effectiveness of theophylline (100 mg) in cases of chronic pancreatitis (COCOCO) and its influence on patient outcomes.


METHODS
Twenty-one patients with acute pancreatitis were treated with oral acyclovir (OCA) and 6 with a placebo in a double-blind trial. The patients were treated with oral acyclovir and oral acyclovir (OCA) at a dose of 20 mg/kg/day for at least 12 weeks. Drug-induced adverse events (AEs) were recorded. Results: There was no significant difference in the incidence of adverse events, and no serious adverse events were noted. Conclusions: Close treatment may be required in cases of chronic obstructive pulmonary disease.
<eot>
<sot>
A new algorithm for multi-target detection and tracking of moving targets

In this paper, we propose a new algorithm for multi-target detection. The algorithm is based on a modified adaptive filter. This algorithm


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 37/48	It: 1/8134	batch_loss: 2.9529	batch_accuracy: 41.21%	lr:0.000188
Ep: 37/48	It: 51/8134	batch_loss: 2.9863	batch_accuracy: 42.75%	lr:0.000188
Ep: 37/48	It: 101/8134	batch_loss: 3.0497	batch_accuracy: 40.80%	lr:0.000188
Ep: 37/48	It: 151/8134	batch_loss: 3.1155	batch_accuracy: 40.77%	lr:0.000188
Ep: 37/48	It: 201/8134	batch_loss: 3.0448	batch_accuracy: 42.41%	lr:0.000188
Ep: 37/48	It: 251/8134	batch_loss: 3.0821	batch_accuracy: 40.99%	lr:0.000188
Ep: 37/48	It: 301/8134	batch_loss: 2.9792	batch_accuracy: 42.53%	lr:0.000187
Ep: 37/48	It: 351/8134	batch_loss: 3.0747	batch_accuracy: 41.38%	lr:0.000187
Ep: 37/48	It: 401/8134	batch_loss: 3.1035	batch_accuracy: 41.31%	lr:0.000187
Ep: 37/48	It: 451/8134	batch_loss: 3.1098	batch_accuracy: 41.41%	lr:0.000187
Ep: 37/48	It: 501/8134	batch_loss: 3.1256	batch_accuracy: 40.38%	lr:0.000187
Ep: 37/48	It: 551/8134	batch_loss: 3.1007	batch_accuracy: 41.43%	lr:0.000186
Ep: 37/48	It: 601/8134	batch_loss: 3.1825	batch_accuracy: 40.23%	lr:0.000186
Ep: 37/48	It: 651/8134	batch_loss: 3.0603	batch_accuracy: 41.63%	lr:0.000186
Ep: 37/48	It: 701/8134	batch_loss: 3.1184	batch_accuracy: 41.04%	lr:0.000186
Ep: 37/48	It: 751/8134	batch_loss: 3.0336	batch_accuracy: 41.14%	lr:0.000186
Ep: 37/48	It: 801/8134	batch_loss: 3.1488	batch_accuracy: 39.48%	lr:0.000186
Ep: 37/48	It: 851/8134	batch_loss: 3.1181	batch_accuracy: 41.21%	lr:0.000185
Ep: 37/48	It: 901/8134	batch_loss: 3.0310	batch_accuracy: 42.50%	lr:0.000185
Ep: 37/48	It: 951/8134	batch_loss: 2.9350	batch_accuracy: 43.21%	lr:0.000185
Ep: 37/48	It: 1001/8134	batch_loss: 3.1325	batch_accuracy: 41.26%	lr:0.000185
Ep: 37/48	It: 1051/8134	batch_loss: 3.1618	batch_accuracy: 39.01%	lr:0.000185
Ep: 37/48	It: 1101/8134	batch_loss: 3.1515	batch_accuracy: 40.77%	lr:0.000185
Ep: 37/48	It: 1151/8134	batch_loss: 3.0356	batch_accuracy: 42.24%	lr:0.000184
Ep: 37/48	It: 1201/8134	batch_loss: 2.9828	batch_accuracy: 41.72%	lr:0.000184
Ep: 37/48	It: 1251/8134	batch_loss: 3.1180	batch_accuracy: 40.65%	lr:0.000184
Ep: 37/48	It: 1301/8134	batch_loss: 2.9836	batch_accuracy: 41.92%	lr:0.000184
Ep: 37/48	It: 1351/8134	batch_loss: 2.9839	batch_accuracy: 41.67%	lr:0.000184
Ep: 37/48	It: 1401/8134	batch_loss: 3.0693	batch_accuracy: 40.60%	lr:0.000184
Ep: 37/48	It: 1451/8134	batch_loss: 3.1053	batch_accuracy: 40.36%	lr:0.000183
Ep: 37/48	It: 1501/8134	batch_loss: 3.0133	batch_accuracy: 41.72%	lr:0.000183
Ep: 37/48	It: 1551/8134	batch_loss: 3.1155	batch_accuracy: 41.55%	lr:0.000183
Ep: 37/48	It: 1601/8134	batch_loss: 3.1215	batch_accuracy: 41.38%	lr:0.000183
Ep: 37/48	It: 1651/8134	batch_loss: 3.0328	batch_accuracy: 41.63%	lr:0.000183
Ep: 37/48	It: 1701/8134	batch_loss: 3.1532	batch_accuracy: 39.84%	lr:0.000183
Ep: 37/48	It: 1751/8134	batch_loss: 2.9710	batch_accuracy: 42.46%	lr:0.000182
Ep: 37/48	It: 1801/8134	batch_loss: 3.1515	batch_accuracy: 40.50%	lr:0.000182
Ep: 37/48	It: 1851/8134	batch_loss: 2.9237	batch_accuracy: 43.92%	lr:0.000182
Ep: 37/48	It: 1901/8134	batch_loss: 3.1717	batch_accuracy: 39.79%	lr:0.000182
Ep: 37/48	It: 1951/8134	batch_loss: 3.1604	batch_accuracy: 40.31%	lr:0.000182
Ep: 37/48	It: 2001/8134	batch_loss: 3.1264	batch_accuracy: 40.87%	lr:0.000182
Ep: 37/48	It: 2051/8134	batch_loss: 3.1394	batch_accuracy: 41.33%	lr:0.000181
Ep: 37/48	It: 2101/8134	batch_loss: 3.0378	batch_accuracy: 41.04%	lr:0.000181
Ep: 37/48	It: 2151/8134	batch_loss: 3.1971	batch_accuracy: 40.41%	lr:0.000181
Ep: 37/48	It: 2201/8134	batch_loss: 3.0004	batch_accuracy: 42.43%	lr:0.000181
Ep: 37/48	It: 2251/8134	batch_loss: 3.0396	batch_accuracy: 41.63%	lr:0.000181
Ep: 37/48	It: 2301/8134	batch_loss: 3.0178	batch_accuracy: 42.07%	lr:0.000181
Ep: 37/48	It: 2351/8134	batch_loss: 3.0484	batch_accuracy: 41.38%	lr:0.000180
Ep: 37/48	It: 2401/8134	batch_loss: 2.9717	batch_accuracy: 42.11%	lr:0.000180
Ep: 37/48	It: 2451/8134	batch_loss: 3.0494	batch_accuracy: 41.99%	lr:0.000180
Ep: 37/48	It: 2501/8134	batch_loss: 3.0663	batch_accuracy: 40.36%	lr:0.000180
Ep: 37/48	It: 2551/8134	batch_loss: 2.9372	batch_accuracy: 42.38%	lr:0.000180
Ep: 37/48	It: 2601/8134	batch_loss: 3.0294	batch_accuracy: 40.58%	lr:0.000180
Ep: 37/48	It: 2651/8134	batch_loss: 3.1564	batch_accuracy: 40.41%	lr:0.000179
Ep: 37/48	It: 2701/8134	batch_loss: 3.1119	batch_accuracy: 41.02%	lr:0.000179
Ep: 37/48	It: 2751/8134	batch_loss: 3.0727	batch_accuracy: 41.28%	lr:0.000179
Ep: 37/48	It: 2801/8134	batch_loss: 3.1254	batch_accuracy: 40.26%	lr:0.000179
Ep: 37/48	It: 2851/8134	batch_loss: 3.0956	batch_accuracy: 41.14%	lr:0.000179
Ep: 37/48	It: 2901/8134	batch_loss: 3.1242	batch_accuracy: 39.45%	lr:0.000179
Ep: 37/48	It: 2951/8134	batch_loss: 3.1570	batch_accuracy: 39.89%	lr:0.000178
Ep: 37/48	It: 3001/8134	batch_loss: 3.0899	batch_accuracy: 42.07%	lr:0.000178
Ep: 37/48	It: 3051/8134	batch_loss: 3.0409	batch_accuracy: 41.46%	lr:0.000178
Ep: 37/48	It: 3101/8134	batch_loss: 3.1309	batch_accuracy: 40.33%	lr:0.000178
Ep: 37/48	It: 3151/8134	batch_loss: 3.1506	batch_accuracy: 39.53%	lr:0.000178
Ep: 37/48	It: 3201/8134	batch_loss: 3.0051	batch_accuracy: 42.24%	lr:0.000178
Ep: 37/48	It: 3251/8134	batch_loss: 2.9848	batch_accuracy: 43.14%	lr:0.000177
Ep: 37/48	It: 3301/8134	batch_loss: 3.0502	batch_accuracy: 41.04%	lr:0.000177
Ep: 37/48	It: 3351/8134	batch_loss: 3.0854	batch_accuracy: 40.99%	lr:0.000177
Ep: 37/48	It: 3401/8134	batch_loss: 3.0375	batch_accuracy: 40.70%	lr:0.000177
Ep: 37/48	It: 3451/8134	batch_loss: 2.9799	batch_accuracy: 42.04%	lr:0.000177
Ep: 37/48	It: 3501/8134	batch_loss: 2.9978	batch_accuracy: 42.38%	lr:0.000177
Ep: 37/48	It: 3551/8134	batch_loss: 3.0152	batch_accuracy: 42.50%	lr:0.000176
Ep: 37/48	It: 3601/8134	batch_loss: 2.9341	batch_accuracy: 41.99%	lr:0.000176
Ep: 37/48	It: 3651/8134	batch_loss: 3.0394	batch_accuracy: 41.46%	lr:0.000176
Ep: 37/48	It: 3701/8134	batch_loss: 2.9833	batch_accuracy: 42.04%	lr:0.000176
Ep: 37/48	It: 3751/8134	batch_loss: 3.0278	batch_accuracy: 42.65%	lr:0.000176
Ep: 37/48	It: 3801/8134	batch_loss: 3.0535	batch_accuracy: 41.33%	lr:0.000176
Ep: 37/48	It: 3851/8134	batch_loss: 3.0569	batch_accuracy: 41.65%	lr:0.000175
Ep: 37/48	It: 3901/8134	batch_loss: 3.0745	batch_accuracy: 41.38%	lr:0.000175
Ep: 37/48	It: 3951/8134	batch_loss: 3.1012	batch_accuracy: 40.82%	lr:0.000175
Ep: 37/48	It: 4001/8134	batch_loss: 2.9327	batch_accuracy: 42.99%	lr:0.000175
Ep: 37/48	It: 4051/8134	batch_loss: 3.1624	batch_accuracy: 41.63%	lr:0.000175
Ep: 37/48	It: 4101/8134	batch_loss: 2.9216	batch_accuracy: 43.46%	lr:0.000175
Ep: 37/48	It: 4151/8134	batch_loss: 2.9920	batch_accuracy: 42.68%	lr:0.000174
Ep: 37/48	It: 4201/8134	batch_loss: 3.1254	batch_accuracy: 40.97%	lr:0.000174
Ep: 37/48	It: 4251/8134	batch_loss: 3.0625	batch_accuracy: 41.04%	lr:0.000174
Ep: 37/48	It: 4301/8134	batch_loss: 3.0905	batch_accuracy: 41.24%	lr:0.000174
Ep: 37/48	It: 4351/8134	batch_loss: 2.9964	batch_accuracy: 42.14%	lr:0.000174
Ep: 37/48	It: 4401/8134	batch_loss: 3.0251	batch_accuracy: 41.77%	lr:0.000174
Ep: 37/48	It: 4451/8134	batch_loss: 3.0442	batch_accuracy: 40.55%	lr:0.000173
Ep: 37/48	It: 4501/8134	batch_loss: 2.9776	batch_accuracy: 42.41%	lr:0.000173
Ep: 37/48	It: 4551/8134	batch_loss: 3.0745	batch_accuracy: 41.58%	lr:0.000173
Ep: 37/48	It: 4601/8134	batch_loss: 3.1337	batch_accuracy: 39.38%	lr:0.000173
Ep: 37/48	It: 4651/8134	batch_loss: 2.9733	batch_accuracy: 42.92%	lr:0.000173
Ep: 37/48	It: 4701/8134	batch_loss: 3.1029	batch_accuracy: 40.62%	lr:0.000173
Ep: 37/48	It: 4751/8134	batch_loss: 2.9798	batch_accuracy: 42.70%	lr:0.000172
Ep: 37/48	It: 4801/8134	batch_loss: 2.8900	batch_accuracy: 44.07%	lr:0.000172
Ep: 37/48	It: 4851/8134	batch_loss: 3.1255	batch_accuracy: 39.94%	lr:0.000172
Ep: 37/48	It: 4901/8134	batch_loss: 3.0827	batch_accuracy: 41.75%	lr:0.000172
Ep: 37/48	It: 4951/8134	batch_loss: 2.9944	batch_accuracy: 42.70%	lr:0.000172
Ep: 37/48	It: 5001/8134	batch_loss: 3.0599	batch_accuracy: 40.67%	lr:0.000172
Ep: 37/48	It: 5051/8134	batch_loss: 3.0396	batch_accuracy: 42.21%	lr:0.000171
Ep: 37/48	It: 5101/8134	batch_loss: 3.1538	batch_accuracy: 40.70%	lr:0.000171
Ep: 37/48	It: 5151/8134	batch_loss: 3.0824	batch_accuracy: 41.53%	lr:0.000171
Ep: 37/48	It: 5201/8134	batch_loss: 3.1051	batch_accuracy: 40.77%	lr:0.000171
Ep: 37/48	It: 5251/8134	batch_loss: 3.0566	batch_accuracy: 42.26%	lr:0.000171
Ep: 37/48	It: 5301/8134	batch_loss: 3.0550	batch_accuracy: 42.02%	lr:0.000171
Ep: 37/48	It: 5351/8134	batch_loss: 3.0884	batch_accuracy: 41.16%	lr:0.000170
Ep: 37/48	It: 5401/8134	batch_loss: 2.9798	batch_accuracy: 42.58%	lr:0.000170
Ep: 37/48	It: 5451/8134	batch_loss: 2.9456	batch_accuracy: 43.12%	lr:0.000170
Ep: 37/48	It: 5501/8134	batch_loss: 3.1523	batch_accuracy: 40.75%	lr:0.000170
Ep: 37/48	It: 5551/8134	batch_loss: 3.1384	batch_accuracy: 40.38%	lr:0.000170
Ep: 37/48	It: 5601/8134	batch_loss: 3.0774	batch_accuracy: 40.55%	lr:0.000170
Ep: 37/48	It: 5651/8134	batch_loss: 2.9830	batch_accuracy: 42.19%	lr:0.000169
Ep: 37/48	It: 5701/8134	batch_loss: 3.0282	batch_accuracy: 41.19%	lr:0.000169
Ep: 37/48	It: 5751/8134	batch_loss: 2.9508	batch_accuracy: 43.29%	lr:0.000169
Ep: 37/48	It: 5801/8134	batch_loss: 3.1549	batch_accuracy: 40.65%	lr:0.000169
Ep: 37/48	It: 5851/8134	batch_loss: 3.0666	batch_accuracy: 40.84%	lr:0.000169
Ep: 37/48	It: 5901/8134	batch_loss: 3.0656	batch_accuracy: 41.80%	lr:0.000169
Ep: 37/48	It: 5951/8134	batch_loss: 2.9055	batch_accuracy: 43.46%	lr:0.000168
Ep: 37/48	It: 6001/8134	batch_loss: 2.9971	batch_accuracy: 41.99%	lr:0.000168
Ep: 37/48	It: 6051/8134	batch_loss: 3.0350	batch_accuracy: 41.70%	lr:0.000168
Ep: 37/48	It: 6101/8134	batch_loss: 2.9937	batch_accuracy: 41.33%	lr:0.000168
Ep: 37/48	It: 6151/8134	batch_loss: 3.1328	batch_accuracy: 40.65%	lr:0.000168
Ep: 37/48	It: 6201/8134	batch_loss: 2.9852	batch_accuracy: 42.90%	lr:0.000168
Ep: 37/48	It: 6251/8134	batch_loss: 2.9714	batch_accuracy: 43.38%	lr:0.000168
Ep: 37/48	It: 6301/8134	batch_loss: 3.1043	batch_accuracy: 41.41%	lr:0.000167
Ep: 37/48	It: 6351/8134	batch_loss: 3.0888	batch_accuracy: 39.43%	lr:0.000167
Ep: 37/48	It: 6401/8134	batch_loss: 2.9830	batch_accuracy: 41.75%	lr:0.000167
Ep: 37/48	It: 6451/8134	batch_loss: 3.0752	batch_accuracy: 41.50%	lr:0.000167
Ep: 37/48	It: 6501/8134	batch_loss: 3.0742	batch_accuracy: 41.43%	lr:0.000167
Ep: 37/48	It: 6551/8134	batch_loss: 3.1875	batch_accuracy: 40.26%	lr:0.000167
Ep: 37/48	It: 6601/8134	batch_loss: 3.1650	batch_accuracy: 40.62%	lr:0.000166
Ep: 37/48	It: 6651/8134	batch_loss: 2.9835	batch_accuracy: 42.50%	lr:0.000166
Ep: 37/48	It: 6701/8134	batch_loss: 3.1402	batch_accuracy: 40.94%	lr:0.000166
Ep: 37/48	It: 6751/8134	batch_loss: 3.0361	batch_accuracy: 41.21%	lr:0.000166
Ep: 37/48	It: 6801/8134	batch_loss: 3.0101	batch_accuracy: 41.97%	lr:0.000166
Ep: 37/48	It: 6851/8134	batch_loss: 3.0619	batch_accuracy: 41.16%	lr:0.000166
Ep: 37/48	It: 6901/8134	batch_loss: 3.0467	batch_accuracy: 41.87%	lr:0.000165
Ep: 37/48	It: 6951/8134	batch_loss: 3.0837	batch_accuracy: 41.55%	lr:0.000165
Ep: 37/48	It: 7001/8134	batch_loss: 2.9643	batch_accuracy: 42.48%	lr:0.000165
Ep: 37/48	It: 7051/8134	batch_loss: 3.0696	batch_accuracy: 41.58%	lr:0.000165
Ep: 37/48	It: 7101/8134	batch_loss: 3.1227	batch_accuracy: 39.99%	lr:0.000165
Ep: 37/48	It: 7151/8134	batch_loss: 3.0538	batch_accuracy: 41.82%	lr:0.000165
Ep: 37/48	It: 7201/8134	batch_loss: 3.0735	batch_accuracy: 40.75%	lr:0.000164
Ep: 37/48	It: 7251/8134	batch_loss: 3.0318	batch_accuracy: 41.87%	lr:0.000164
Ep: 37/48	It: 7301/8134	batch_loss: 2.9886	batch_accuracy: 42.92%	lr:0.000164
Ep: 37/48	It: 7351/8134	batch_loss: 3.0139	batch_accuracy: 41.21%	lr:0.000164
Ep: 37/48	It: 7401/8134	batch_loss: 3.0338	batch_accuracy: 42.02%	lr:0.000164
Ep: 37/48	It: 7451/8134	batch_loss: 2.9986	batch_accuracy: 41.53%	lr:0.000164
Ep: 37/48	It: 7501/8134	batch_loss: 3.0572	batch_accuracy: 42.29%	lr:0.000163
Ep: 37/48	It: 7551/8134	batch_loss: 2.9620	batch_accuracy: 43.09%	lr:0.000163
Ep: 37/48	It: 7601/8134	batch_loss: 3.0643	batch_accuracy: 40.77%	lr:0.000163
Ep: 37/48	It: 7651/8134	batch_loss: 3.1286	batch_accuracy: 40.09%	lr:0.000163
Ep: 37/48	It: 7701/8134	batch_loss: 3.1832	batch_accuracy: 39.14%	lr:0.000163
Ep: 37/48	It: 7751/8134	batch_loss: 3.0557	batch_accuracy: 41.65%	lr:0.000163
Ep: 37/48	It: 7801/8134	batch_loss: 3.1061	batch_accuracy: 41.02%	lr:0.000163
Ep: 37/48	It: 7851/8134	batch_loss: 2.8658	batch_accuracy: 44.73%	lr:0.000162
Ep: 37/48	It: 7901/8134	batch_loss: 3.0352	batch_accuracy: 41.24%	lr:0.000162
Ep: 37/48	It: 7951/8134	batch_loss: 3.0610	batch_accuracy: 42.24%	lr:0.000162
Ep: 37/48	It: 8001/8134	batch_loss: 2.9321	batch_accuracy: 43.31%	lr:0.000162
Ep: 37/48	It: 8051/8134	batch_loss: 3.1721	batch_accuracy: 39.26%	lr:0.000162
Ep: 37/48	It: 8101/8134	batch_loss: 2.9976	batch_accuracy: 42.07%	lr:0.000162
Ep: 37/48	It: 8134/8134	batch_loss: 3.0451	batch_accuracy: 41.20%	lr:0.000161


Generated text for input text "You" is:
You, and theorists of Law and Poke (L) asks to argue that theologians and that theologians view it as “the most important” and theologically, theologically, theologically, theologically, theologically, theologically uneasy and theologically.
<eot>
<sot>
The Impact of the Self-Testing on the Development of a Family Life Questionnaire

The aim of this study was to examine the impact of self-reported physical activity on the development of self-efficacy and self-efficacy in a family caregiver–sex interaction with self-efficacy. Data were collected from self-reported self-efficacy and self-efficacy for self-efficacy and self-efficacy. Structural equation modeling was used to test the mediation mediation effect. Results: The results showed that self-efficacy, self-efficacy, and self-efficacy positively correlated with self-efficacy, and self-efficacy. The mediation model showed significant relationship between self-efficacy and self-efficacy, but not with self


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 38/48	It: 1/8134	batch_loss: 3.0128	batch_accuracy: 41.26%	lr:0.000161
Ep: 38/48	It: 51/8134	batch_loss: 3.0451	batch_accuracy: 41.16%	lr:0.000161
Ep: 38/48	It: 101/8134	batch_loss: 3.1030	batch_accuracy: 40.82%	lr:0.000161
Ep: 38/48	It: 151/8134	batch_loss: 3.0640	batch_accuracy: 41.28%	lr:0.000161
Ep: 38/48	It: 201/8134	batch_loss: 3.0828	batch_accuracy: 41.02%	lr:0.000161
Ep: 38/48	It: 251/8134	batch_loss: 2.9978	batch_accuracy: 41.09%	lr:0.000161
Ep: 38/48	It: 301/8134	batch_loss: 2.9740	batch_accuracy: 42.70%	lr:0.000160
Ep: 38/48	It: 351/8134	batch_loss: 3.0703	batch_accuracy: 41.58%	lr:0.000160
Ep: 38/48	It: 401/8134	batch_loss: 3.0398	batch_accuracy: 40.65%	lr:0.000160
Ep: 38/48	It: 451/8134	batch_loss: 3.1228	batch_accuracy: 41.26%	lr:0.000160
Ep: 38/48	It: 501/8134	batch_loss: 3.1328	batch_accuracy: 41.11%	lr:0.000160
Ep: 38/48	It: 551/8134	batch_loss: 3.0352	batch_accuracy: 43.16%	lr:0.000160
Ep: 38/48	It: 601/8134	batch_loss: 3.0076	batch_accuracy: 41.87%	lr:0.000160
Ep: 38/48	It: 651/8134	batch_loss: 3.0236	batch_accuracy: 41.38%	lr:0.000159
Ep: 38/48	It: 701/8134	batch_loss: 2.9134	batch_accuracy: 43.60%	lr:0.000159
Ep: 38/48	It: 751/8134	batch_loss: 3.0480	batch_accuracy: 42.80%	lr:0.000159
Ep: 38/48	It: 801/8134	batch_loss: 3.0372	batch_accuracy: 42.58%	lr:0.000159
Ep: 38/48	It: 851/8134	batch_loss: 3.1535	batch_accuracy: 38.48%	lr:0.000159
Ep: 38/48	It: 901/8134	batch_loss: 3.0570	batch_accuracy: 40.31%	lr:0.000159
Ep: 38/48	It: 951/8134	batch_loss: 3.0242	batch_accuracy: 40.97%	lr:0.000158
Ep: 38/48	It: 1001/8134	batch_loss: 3.0676	batch_accuracy: 41.70%	lr:0.000158
Ep: 38/48	It: 1051/8134	batch_loss: 3.0787	batch_accuracy: 39.89%	lr:0.000158
Ep: 38/48	It: 1101/8134	batch_loss: 2.9841	batch_accuracy: 42.19%	lr:0.000158
Ep: 38/48	It: 1151/8134	batch_loss: 3.1708	batch_accuracy: 40.45%	lr:0.000158
Ep: 38/48	It: 1201/8134	batch_loss: 3.1541	batch_accuracy: 39.40%	lr:0.000158
Ep: 38/48	It: 1251/8134	batch_loss: 2.9576	batch_accuracy: 41.89%	lr:0.000157
Ep: 38/48	It: 1301/8134	batch_loss: 3.0678	batch_accuracy: 41.04%	lr:0.000157
Ep: 38/48	It: 1351/8134	batch_loss: 3.0832	batch_accuracy: 40.67%	lr:0.000157
Ep: 38/48	It: 1401/8134	batch_loss: 3.0669	batch_accuracy: 41.46%	lr:0.000157
Ep: 38/48	It: 1451/8134	batch_loss: 3.0384	batch_accuracy: 41.60%	lr:0.000157
Ep: 38/48	It: 1501/8134	batch_loss: 3.0913	batch_accuracy: 41.75%	lr:0.000157
Ep: 38/48	It: 1551/8134	batch_loss: 3.0606	batch_accuracy: 41.06%	lr:0.000157
Ep: 38/48	It: 1601/8134	batch_loss: 3.1707	batch_accuracy: 40.11%	lr:0.000156
Ep: 38/48	It: 1651/8134	batch_loss: 3.1366	batch_accuracy: 40.11%	lr:0.000156
Ep: 38/48	It: 1701/8134	batch_loss: 3.0733	batch_accuracy: 41.28%	lr:0.000156
Ep: 38/48	It: 1751/8134	batch_loss: 3.1256	batch_accuracy: 40.36%	lr:0.000156
Ep: 38/48	It: 1801/8134	batch_loss: 3.1910	batch_accuracy: 40.19%	lr:0.000156
Ep: 38/48	It: 1851/8134	batch_loss: 3.0185	batch_accuracy: 41.75%	lr:0.000156
Ep: 38/48	It: 1901/8134	batch_loss: 3.1166	batch_accuracy: 40.43%	lr:0.000155
Ep: 38/48	It: 1951/8134	batch_loss: 3.1044	batch_accuracy: 40.92%	lr:0.000155
Ep: 38/48	It: 2001/8134	batch_loss: 3.1298	batch_accuracy: 40.62%	lr:0.000155
Ep: 38/48	It: 2051/8134	batch_loss: 3.0714	batch_accuracy: 41.31%	lr:0.000155
Ep: 38/48	It: 2101/8134	batch_loss: 3.0122	batch_accuracy: 41.46%	lr:0.000155
Ep: 38/48	It: 2151/8134	batch_loss: 3.0851	batch_accuracy: 41.06%	lr:0.000155
Ep: 38/48	It: 2201/8134	batch_loss: 2.9617	batch_accuracy: 43.16%	lr:0.000154
Ep: 38/48	It: 2251/8134	batch_loss: 3.1089	batch_accuracy: 41.24%	lr:0.000154
Ep: 38/48	It: 2301/8134	batch_loss: 3.1687	batch_accuracy: 40.23%	lr:0.000154
Ep: 38/48	It: 2351/8134	batch_loss: 3.1213	batch_accuracy: 40.14%	lr:0.000154
Ep: 38/48	It: 2401/8134	batch_loss: 3.0456	batch_accuracy: 41.16%	lr:0.000154
Ep: 38/48	It: 2451/8134	batch_loss: 3.0245	batch_accuracy: 41.75%	lr:0.000154
Ep: 38/48	It: 2501/8134	batch_loss: 3.1241	batch_accuracy: 40.50%	lr:0.000154
Ep: 38/48	It: 2551/8134	batch_loss: 3.0063	batch_accuracy: 41.26%	lr:0.000153
Ep: 38/48	It: 2601/8134	batch_loss: 2.9014	batch_accuracy: 42.53%	lr:0.000153
Ep: 38/48	It: 2651/8134	batch_loss: 3.1003	batch_accuracy: 40.70%	lr:0.000153
Ep: 38/48	It: 2701/8134	batch_loss: 3.0827	batch_accuracy: 41.82%	lr:0.000153
Ep: 38/48	It: 2751/8134	batch_loss: 3.0445	batch_accuracy: 40.55%	lr:0.000153
Ep: 38/48	It: 2801/8134	batch_loss: 3.0386	batch_accuracy: 41.46%	lr:0.000153
Ep: 38/48	It: 2851/8134	batch_loss: 3.0543	batch_accuracy: 42.46%	lr:0.000152
Ep: 38/48	It: 2901/8134	batch_loss: 3.0341	batch_accuracy: 41.55%	lr:0.000152
Ep: 38/48	It: 2951/8134	batch_loss: 2.9828	batch_accuracy: 42.33%	lr:0.000152
Ep: 38/48	It: 3001/8134	batch_loss: 3.0959	batch_accuracy: 41.36%	lr:0.000152
Ep: 38/48	It: 3051/8134	batch_loss: 3.0565	batch_accuracy: 41.89%	lr:0.000152
Ep: 38/48	It: 3101/8134	batch_loss: 3.0933	batch_accuracy: 40.80%	lr:0.000152
Ep: 38/48	It: 3151/8134	batch_loss: 3.0750	batch_accuracy: 40.53%	lr:0.000151
Ep: 38/48	It: 3201/8134	batch_loss: 3.1366	batch_accuracy: 39.72%	lr:0.000151
Ep: 38/48	It: 3251/8134	batch_loss: 3.1866	batch_accuracy: 40.84%	lr:0.000151
Ep: 38/48	It: 3301/8134	batch_loss: 2.9957	batch_accuracy: 42.19%	lr:0.000151
Ep: 38/48	It: 3351/8134	batch_loss: 3.0158	batch_accuracy: 41.60%	lr:0.000151
Ep: 38/48	It: 3401/8134	batch_loss: 3.1408	batch_accuracy: 40.80%	lr:0.000151
Ep: 38/48	It: 3451/8134	batch_loss: 3.1233	batch_accuracy: 39.97%	lr:0.000151
Ep: 38/48	It: 3501/8134	batch_loss: 2.9820	batch_accuracy: 41.85%	lr:0.000150
Ep: 38/48	It: 3551/8134	batch_loss: 2.9677	batch_accuracy: 42.38%	lr:0.000150
Ep: 38/48	It: 3601/8134	batch_loss: 3.0959	batch_accuracy: 41.41%	lr:0.000150
Ep: 38/48	It: 3651/8134	batch_loss: 3.0372	batch_accuracy: 41.50%	lr:0.000150
Ep: 38/48	It: 3701/8134	batch_loss: 3.0738	batch_accuracy: 41.19%	lr:0.000150
Ep: 38/48	It: 3751/8134	batch_loss: 3.0219	batch_accuracy: 41.55%	lr:0.000150
Ep: 38/48	It: 3801/8134	batch_loss: 2.9864	batch_accuracy: 41.87%	lr:0.000149
Ep: 38/48	It: 3851/8134	batch_loss: 3.0083	batch_accuracy: 41.67%	lr:0.000149
Ep: 38/48	It: 3901/8134	batch_loss: 3.0420	batch_accuracy: 41.67%	lr:0.000149
Ep: 38/48	It: 3951/8134	batch_loss: 3.0390	batch_accuracy: 42.72%	lr:0.000149
Ep: 38/48	It: 4001/8134	batch_loss: 3.0598	batch_accuracy: 41.55%	lr:0.000149
Ep: 38/48	It: 4051/8134	batch_loss: 3.0312	batch_accuracy: 41.31%	lr:0.000149
Ep: 38/48	It: 4101/8134	batch_loss: 3.1787	batch_accuracy: 39.72%	lr:0.000149
Ep: 38/48	It: 4151/8134	batch_loss: 3.0466	batch_accuracy: 41.04%	lr:0.000148
Ep: 38/48	It: 4201/8134	batch_loss: 2.9785	batch_accuracy: 43.51%	lr:0.000148
Ep: 38/48	It: 4251/8134	batch_loss: 2.9988	batch_accuracy: 42.50%	lr:0.000148
Ep: 38/48	It: 4301/8134	batch_loss: 3.0197	batch_accuracy: 42.41%	lr:0.000148
Ep: 38/48	It: 4351/8134	batch_loss: 3.1787	batch_accuracy: 40.53%	lr:0.000148
Ep: 38/48	It: 4401/8134	batch_loss: 3.1071	batch_accuracy: 41.21%	lr:0.000148
Ep: 38/48	It: 4451/8134	batch_loss: 3.0267	batch_accuracy: 41.19%	lr:0.000147
Ep: 38/48	It: 4501/8134	batch_loss: 3.1525	batch_accuracy: 39.87%	lr:0.000147
Ep: 38/48	It: 4551/8134	batch_loss: 3.0560	batch_accuracy: 41.63%	lr:0.000147
Ep: 38/48	It: 4601/8134	batch_loss: 3.1349	batch_accuracy: 40.23%	lr:0.000147
Ep: 38/48	It: 4651/8134	batch_loss: 2.9993	batch_accuracy: 42.50%	lr:0.000147
Ep: 38/48	It: 4701/8134	batch_loss: 3.1336	batch_accuracy: 39.40%	lr:0.000147
Ep: 38/48	It: 4751/8134	batch_loss: 3.1114	batch_accuracy: 40.94%	lr:0.000147
Ep: 38/48	It: 4801/8134	batch_loss: 3.1132	batch_accuracy: 39.40%	lr:0.000146
Ep: 38/48	It: 4851/8134	batch_loss: 3.0511	batch_accuracy: 40.99%	lr:0.000146
Ep: 38/48	It: 4901/8134	batch_loss: 2.9993	batch_accuracy: 42.68%	lr:0.000146
Ep: 38/48	It: 4951/8134	batch_loss: 3.1202	batch_accuracy: 39.89%	lr:0.000146
Ep: 38/48	It: 5001/8134	batch_loss: 3.0851	batch_accuracy: 40.80%	lr:0.000146
Ep: 38/48	It: 5051/8134	batch_loss: 3.0907	batch_accuracy: 41.43%	lr:0.000146
Ep: 38/48	It: 5101/8134	batch_loss: 3.0589	batch_accuracy: 40.67%	lr:0.000145
Ep: 38/48	It: 5151/8134	batch_loss: 3.0358	batch_accuracy: 42.09%	lr:0.000145
Ep: 38/48	It: 5201/8134	batch_loss: 3.0373	batch_accuracy: 42.21%	lr:0.000145
Ep: 38/48	It: 5251/8134	batch_loss: 3.1347	batch_accuracy: 40.60%	lr:0.000145
Ep: 38/48	It: 5301/8134	batch_loss: 2.9841	batch_accuracy: 42.36%	lr:0.000145
Ep: 38/48	It: 5351/8134	batch_loss: 3.1009	batch_accuracy: 41.19%	lr:0.000145
Ep: 38/48	It: 5401/8134	batch_loss: 2.9272	batch_accuracy: 43.36%	lr:0.000145
Ep: 38/48	It: 5451/8134	batch_loss: 3.0245	batch_accuracy: 41.82%	lr:0.000144
Ep: 38/48	It: 5501/8134	batch_loss: 2.9443	batch_accuracy: 42.43%	lr:0.000144
Ep: 38/48	It: 5551/8134	batch_loss: 3.0847	batch_accuracy: 41.11%	lr:0.000144
Ep: 38/48	It: 5601/8134	batch_loss: 3.0734	batch_accuracy: 41.26%	lr:0.000144
Ep: 38/48	It: 5651/8134	batch_loss: 3.1316	batch_accuracy: 40.41%	lr:0.000144
Ep: 38/48	It: 5701/8134	batch_loss: 3.0876	batch_accuracy: 40.75%	lr:0.000144
Ep: 38/48	It: 5751/8134	batch_loss: 3.1006	batch_accuracy: 41.09%	lr:0.000143
Ep: 38/48	It: 5801/8134	batch_loss: 3.0303	batch_accuracy: 42.97%	lr:0.000143
Ep: 38/48	It: 5851/8134	batch_loss: 3.1469	batch_accuracy: 41.60%	lr:0.000143
Ep: 38/48	It: 5901/8134	batch_loss: 3.0298	batch_accuracy: 41.28%	lr:0.000143
Ep: 38/48	It: 5951/8134	batch_loss: 3.0772	batch_accuracy: 41.31%	lr:0.000143
Ep: 38/48	It: 6001/8134	batch_loss: 3.1404	batch_accuracy: 40.16%	lr:0.000143
Ep: 38/48	It: 6051/8134	batch_loss: 3.0050	batch_accuracy: 42.53%	lr:0.000143
Ep: 38/48	It: 6101/8134	batch_loss: 3.1065	batch_accuracy: 40.80%	lr:0.000142
Ep: 38/48	It: 6151/8134	batch_loss: 3.1137	batch_accuracy: 40.38%	lr:0.000142
Ep: 38/48	It: 6201/8134	batch_loss: 3.0174	batch_accuracy: 41.58%	lr:0.000142
Ep: 38/48	It: 6251/8134	batch_loss: 3.0871	batch_accuracy: 41.31%	lr:0.000142
Ep: 38/48	It: 6301/8134	batch_loss: 3.0098	batch_accuracy: 43.48%	lr:0.000142
Ep: 38/48	It: 6351/8134	batch_loss: 3.0487	batch_accuracy: 41.70%	lr:0.000142
Ep: 38/48	It: 6401/8134	batch_loss: 3.0352	batch_accuracy: 42.36%	lr:0.000142
Ep: 38/48	It: 6451/8134	batch_loss: 3.0134	batch_accuracy: 41.72%	lr:0.000141
Ep: 38/48	It: 6501/8134	batch_loss: 3.1646	batch_accuracy: 38.77%	lr:0.000141
Ep: 38/48	It: 6551/8134	batch_loss: 3.0526	batch_accuracy: 40.97%	lr:0.000141
Ep: 38/48	It: 6601/8134	batch_loss: 3.1296	batch_accuracy: 40.36%	lr:0.000141
Ep: 38/48	It: 6651/8134	batch_loss: 3.0136	batch_accuracy: 41.16%	lr:0.000141
Ep: 38/48	It: 6701/8134	batch_loss: 3.0741	batch_accuracy: 41.99%	lr:0.000141
Ep: 38/48	It: 6751/8134	batch_loss: 3.0458	batch_accuracy: 41.70%	lr:0.000140
Ep: 38/48	It: 6801/8134	batch_loss: 3.1039	batch_accuracy: 40.84%	lr:0.000140
Ep: 38/48	It: 6851/8134	batch_loss: 3.0653	batch_accuracy: 40.80%	lr:0.000140
Ep: 38/48	It: 6901/8134	batch_loss: 3.0479	batch_accuracy: 41.99%	lr:0.000140
Ep: 38/48	It: 6951/8134	batch_loss: 3.0676	batch_accuracy: 41.55%	lr:0.000140
Ep: 38/48	It: 7001/8134	batch_loss: 3.0960	batch_accuracy: 41.46%	lr:0.000140
Ep: 38/48	It: 7051/8134	batch_loss: 3.1247	batch_accuracy: 41.16%	lr:0.000140
Ep: 38/48	It: 7101/8134	batch_loss: 3.1487	batch_accuracy: 39.26%	lr:0.000139
Ep: 38/48	It: 7151/8134	batch_loss: 3.1248	batch_accuracy: 40.70%	lr:0.000139
Ep: 38/48	It: 7201/8134	batch_loss: 2.9772	batch_accuracy: 42.43%	lr:0.000139
Ep: 38/48	It: 7251/8134	batch_loss: 3.1886	batch_accuracy: 39.99%	lr:0.000139
Ep: 38/48	It: 7301/8134	batch_loss: 3.0231	batch_accuracy: 41.06%	lr:0.000139
Ep: 38/48	It: 7351/8134	batch_loss: 3.0330	batch_accuracy: 42.16%	lr:0.000139
Ep: 38/48	It: 7401/8134	batch_loss: 3.1222	batch_accuracy: 39.99%	lr:0.000139
Ep: 38/48	It: 7451/8134	batch_loss: 3.1213	batch_accuracy: 40.48%	lr:0.000138
Ep: 38/48	It: 7501/8134	batch_loss: 3.0152	batch_accuracy: 41.65%	lr:0.000138
Ep: 38/48	It: 7551/8134	batch_loss: 3.1047	batch_accuracy: 41.36%	lr:0.000138
Ep: 38/48	It: 7601/8134	batch_loss: 3.0790	batch_accuracy: 42.38%	lr:0.000138
Ep: 38/48	It: 7651/8134	batch_loss: 3.0860	batch_accuracy: 40.84%	lr:0.000138
Ep: 38/48	It: 7701/8134	batch_loss: 3.0111	batch_accuracy: 42.02%	lr:0.000138
Ep: 38/48	It: 7751/8134	batch_loss: 3.0704	batch_accuracy: 41.55%	lr:0.000137
Ep: 38/48	It: 7801/8134	batch_loss: 3.1440	batch_accuracy: 40.80%	lr:0.000137
Ep: 38/48	It: 7851/8134	batch_loss: 3.0401	batch_accuracy: 42.07%	lr:0.000137
Ep: 38/48	It: 7901/8134	batch_loss: 3.1427	batch_accuracy: 40.67%	lr:0.000137
Ep: 38/48	It: 7951/8134	batch_loss: 3.0377	batch_accuracy: 41.48%	lr:0.000137
Ep: 38/48	It: 8001/8134	batch_loss: 3.0177	batch_accuracy: 41.53%	lr:0.000137
Ep: 38/48	It: 8051/8134	batch_loss: 3.1021	batch_accuracy: 39.89%	lr:0.000137
Ep: 38/48	It: 8101/8134	batch_loss: 3.0106	batch_accuracy: 42.82%	lr:0.000136
Ep: 38/48	It: 8134/8134	batch_loss: 3.0964	batch_accuracy: 40.83%	lr:0.000136


Generated text for input text "You" is:
You, theorizations of theater, as a result of their own. The aim of thesis is to show how it is a soundness of aesthetics. The authors have taken this year’s philosophical work. Theoretically, theologically, as well as theologically-theological, theological, theological, and theological, theological and theological (ca.n.m)ological, and theological and theological activities of the Russian Federation. The study shows that the textbooks are more than theological and theologically-founding (information, theological and philosophical theological, theological and theological) than the other are more general and are more closely related to theology than the one of the modernist. Theological and theological approaches to theological and theological (gender) literature are also theologically complex. Indeed, in the case of the philosophical and theological literature, it is suggested that theologian of art, theology, and philosophy of art, are not a fundamental subject. Theology is a general textbook which will not be written, but rather as a source


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 39/48	It: 1/8134	batch_loss: 3.0544	batch_accuracy: 41.09%	lr:0.000136
Ep: 39/48	It: 51/8134	batch_loss: 3.0369	batch_accuracy: 41.14%	lr:0.000136
Ep: 39/48	It: 101/8134	batch_loss: 3.0823	batch_accuracy: 40.67%	lr:0.000136
Ep: 39/48	It: 151/8134	batch_loss: 2.9319	batch_accuracy: 43.04%	lr:0.000136
Ep: 39/48	It: 201/8134	batch_loss: 3.0969	batch_accuracy: 39.82%	lr:0.000136
Ep: 39/48	It: 251/8134	batch_loss: 3.0444	batch_accuracy: 41.02%	lr:0.000136
Ep: 39/48	It: 301/8134	batch_loss: 2.9576	batch_accuracy: 41.80%	lr:0.000135
Ep: 39/48	It: 351/8134	batch_loss: 3.2201	batch_accuracy: 39.26%	lr:0.000135
Ep: 39/48	It: 401/8134	batch_loss: 3.0697	batch_accuracy: 40.60%	lr:0.000135
Ep: 39/48	It: 451/8134	batch_loss: 2.9348	batch_accuracy: 43.90%	lr:0.000135
Ep: 39/48	It: 501/8134	batch_loss: 3.0630	batch_accuracy: 41.26%	lr:0.000135
Ep: 39/48	It: 551/8134	batch_loss: 3.1271	batch_accuracy: 40.43%	lr:0.000135
Ep: 39/48	It: 601/8134	batch_loss: 3.0797	batch_accuracy: 41.80%	lr:0.000135
Ep: 39/48	It: 651/8134	batch_loss: 3.0045	batch_accuracy: 42.21%	lr:0.000134
Ep: 39/48	It: 701/8134	batch_loss: 3.0887	batch_accuracy: 42.33%	lr:0.000134
Ep: 39/48	It: 751/8134	batch_loss: 3.1617	batch_accuracy: 41.33%	lr:0.000134
Ep: 39/48	It: 801/8134	batch_loss: 3.1019	batch_accuracy: 41.89%	lr:0.000134
Ep: 39/48	It: 851/8134	batch_loss: 3.0197	batch_accuracy: 41.67%	lr:0.000134
Ep: 39/48	It: 901/8134	batch_loss: 3.0564	batch_accuracy: 41.38%	lr:0.000134
Ep: 39/48	It: 951/8134	batch_loss: 3.0614	batch_accuracy: 39.36%	lr:0.000134
Ep: 39/48	It: 1001/8134	batch_loss: 3.0484	batch_accuracy: 41.41%	lr:0.000133
Ep: 39/48	It: 1051/8134	batch_loss: 3.0619	batch_accuracy: 41.65%	lr:0.000133
Ep: 39/48	It: 1101/8134	batch_loss: 3.0685	batch_accuracy: 41.02%	lr:0.000133
Ep: 39/48	It: 1151/8134	batch_loss: 3.0832	batch_accuracy: 40.28%	lr:0.000133
Ep: 39/48	It: 1201/8134	batch_loss: 3.0845	batch_accuracy: 41.24%	lr:0.000133
Ep: 39/48	It: 1251/8134	batch_loss: 3.0649	batch_accuracy: 40.80%	lr:0.000133
Ep: 39/48	It: 1301/8134	batch_loss: 2.9026	batch_accuracy: 43.33%	lr:0.000133
Ep: 39/48	It: 1351/8134	batch_loss: 2.9921	batch_accuracy: 41.97%	lr:0.000132
Ep: 39/48	It: 1401/8134	batch_loss: 2.9845	batch_accuracy: 42.46%	lr:0.000132
Ep: 39/48	It: 1451/8134	batch_loss: 3.0936	batch_accuracy: 40.65%	lr:0.000132
Ep: 39/48	It: 1501/8134	batch_loss: 3.0360	batch_accuracy: 42.33%	lr:0.000132
Ep: 39/48	It: 1551/8134	batch_loss: 2.9823	batch_accuracy: 42.60%	lr:0.000132
Ep: 39/48	It: 1601/8134	batch_loss: 3.1399	batch_accuracy: 40.70%	lr:0.000132
Ep: 39/48	It: 1651/8134	batch_loss: 3.0223	batch_accuracy: 41.67%	lr:0.000131
Ep: 39/48	It: 1701/8134	batch_loss: 3.0527	batch_accuracy: 40.65%	lr:0.000131
Ep: 39/48	It: 1751/8134	batch_loss: 3.0636	batch_accuracy: 41.65%	lr:0.000131
Ep: 39/48	It: 1801/8134	batch_loss: 3.0772	batch_accuracy: 41.19%	lr:0.000131
Ep: 39/48	It: 1851/8134	batch_loss: 3.0201	batch_accuracy: 41.97%	lr:0.000131
Ep: 39/48	It: 1901/8134	batch_loss: 2.9977	batch_accuracy: 42.11%	lr:0.000131
Ep: 39/48	It: 1951/8134	batch_loss: 3.0130	batch_accuracy: 42.72%	lr:0.000131
Ep: 39/48	It: 2001/8134	batch_loss: 3.0915	batch_accuracy: 40.62%	lr:0.000130
Ep: 39/48	It: 2051/8134	batch_loss: 3.0310	batch_accuracy: 41.72%	lr:0.000130
Ep: 39/48	It: 2101/8134	batch_loss: 3.0607	batch_accuracy: 41.04%	lr:0.000130
Ep: 39/48	It: 2151/8134	batch_loss: 3.0165	batch_accuracy: 42.50%	lr:0.000130
Ep: 39/48	It: 2201/8134	batch_loss: 3.0920	batch_accuracy: 40.77%	lr:0.000130
Ep: 39/48	It: 2251/8134	batch_loss: 3.1423	batch_accuracy: 39.38%	lr:0.000130
Ep: 39/48	It: 2301/8134	batch_loss: 2.9835	batch_accuracy: 43.48%	lr:0.000130
Ep: 39/48	It: 2351/8134	batch_loss: 3.0997	batch_accuracy: 40.70%	lr:0.000129
Ep: 39/48	It: 2401/8134	batch_loss: 3.0547	batch_accuracy: 40.92%	lr:0.000129
Ep: 39/48	It: 2451/8134	batch_loss: 2.9616	batch_accuracy: 42.77%	lr:0.000129
Ep: 39/48	It: 2501/8134	batch_loss: 3.0097	batch_accuracy: 42.77%	lr:0.000129
Ep: 39/48	It: 2551/8134	batch_loss: 3.0715	batch_accuracy: 41.72%	lr:0.000129
Ep: 39/48	It: 2601/8134	batch_loss: 3.0379	batch_accuracy: 40.84%	lr:0.000129
Ep: 39/48	It: 2651/8134	batch_loss: 3.1285	batch_accuracy: 40.72%	lr:0.000129
Ep: 39/48	It: 2701/8134	batch_loss: 3.1701	batch_accuracy: 40.87%	lr:0.000128
Ep: 39/48	It: 2751/8134	batch_loss: 3.0227	batch_accuracy: 42.07%	lr:0.000128
Ep: 39/48	It: 2801/8134	batch_loss: 3.0791	batch_accuracy: 41.16%	lr:0.000128
Ep: 39/48	It: 2851/8134	batch_loss: 3.1142	batch_accuracy: 40.65%	lr:0.000128
Ep: 39/48	It: 2901/8134	batch_loss: 3.0956	batch_accuracy: 41.33%	lr:0.000128
Ep: 39/48	It: 2951/8134	batch_loss: 2.9794	batch_accuracy: 40.99%	lr:0.000128
Ep: 39/48	It: 3001/8134	batch_loss: 3.0472	batch_accuracy: 41.60%	lr:0.000128
Ep: 39/48	It: 3051/8134	batch_loss: 3.0514	batch_accuracy: 42.24%	lr:0.000127
Ep: 39/48	It: 3101/8134	batch_loss: 3.0809	batch_accuracy: 40.41%	lr:0.000127
Ep: 39/48	It: 3151/8134	batch_loss: 3.0199	batch_accuracy: 42.24%	lr:0.000127
Ep: 39/48	It: 3201/8134	batch_loss: 3.1348	batch_accuracy: 40.53%	lr:0.000127
Ep: 39/48	It: 3251/8134	batch_loss: 3.1185	batch_accuracy: 40.94%	lr:0.000127
Ep: 39/48	It: 3301/8134	batch_loss: 3.0066	batch_accuracy: 41.19%	lr:0.000127
Ep: 39/48	It: 3351/8134	batch_loss: 3.0279	batch_accuracy: 40.82%	lr:0.000127
Ep: 39/48	It: 3401/8134	batch_loss: 2.8747	batch_accuracy: 44.43%	lr:0.000126
Ep: 39/48	It: 3451/8134	batch_loss: 2.9874	batch_accuracy: 42.33%	lr:0.000126
Ep: 39/48	It: 3501/8134	batch_loss: 3.0354	batch_accuracy: 41.92%	lr:0.000126
Ep: 39/48	It: 3551/8134	batch_loss: 3.0256	batch_accuracy: 42.46%	lr:0.000126
Ep: 39/48	It: 3601/8134	batch_loss: 3.0417	batch_accuracy: 41.63%	lr:0.000126
Ep: 39/48	It: 3651/8134	batch_loss: 3.1169	batch_accuracy: 41.41%	lr:0.000126
Ep: 39/48	It: 3701/8134	batch_loss: 3.0776	batch_accuracy: 41.70%	lr:0.000126
Ep: 39/48	It: 3751/8134	batch_loss: 3.0115	batch_accuracy: 40.94%	lr:0.000125
Ep: 39/48	It: 3801/8134	batch_loss: 3.1268	batch_accuracy: 39.60%	lr:0.000125
Ep: 39/48	It: 3851/8134	batch_loss: 3.0254	batch_accuracy: 41.02%	lr:0.000125
Ep: 39/48	It: 3901/8134	batch_loss: 3.1063	batch_accuracy: 39.45%	lr:0.000125
Ep: 39/48	It: 3951/8134	batch_loss: 2.9741	batch_accuracy: 42.26%	lr:0.000125
Ep: 39/48	It: 4001/8134	batch_loss: 3.0920	batch_accuracy: 41.28%	lr:0.000125
Ep: 39/48	It: 4051/8134	batch_loss: 3.0362	batch_accuracy: 42.04%	lr:0.000125
Ep: 39/48	It: 4101/8134	batch_loss: 3.0893	batch_accuracy: 41.24%	lr:0.000124
Ep: 39/48	It: 4151/8134	batch_loss: 3.0876	batch_accuracy: 41.09%	lr:0.000124
Ep: 39/48	It: 4201/8134	batch_loss: 3.0314	batch_accuracy: 41.97%	lr:0.000124
Ep: 39/48	It: 4251/8134	batch_loss: 3.0967	batch_accuracy: 40.77%	lr:0.000124
Ep: 39/48	It: 4301/8134	batch_loss: 2.9741	batch_accuracy: 42.16%	lr:0.000124
Ep: 39/48	It: 4351/8134	batch_loss: 3.0392	batch_accuracy: 41.43%	lr:0.000124
Ep: 39/48	It: 4401/8134	batch_loss: 3.1982	batch_accuracy: 39.53%	lr:0.000124
Ep: 39/48	It: 4451/8134	batch_loss: 2.9436	batch_accuracy: 42.68%	lr:0.000123
Ep: 39/48	It: 4501/8134	batch_loss: 3.0530	batch_accuracy: 42.48%	lr:0.000123
Ep: 39/48	It: 4551/8134	batch_loss: 3.1427	batch_accuracy: 40.62%	lr:0.000123
Ep: 39/48	It: 4601/8134	batch_loss: 3.1268	batch_accuracy: 38.67%	lr:0.000123
Ep: 39/48	It: 4651/8134	batch_loss: 2.9378	batch_accuracy: 42.09%	lr:0.000123
Ep: 39/48	It: 4701/8134	batch_loss: 2.9965	batch_accuracy: 42.21%	lr:0.000123
Ep: 39/48	It: 4751/8134	batch_loss: 2.9786	batch_accuracy: 42.07%	lr:0.000123
Ep: 39/48	It: 4801/8134	batch_loss: 3.0746	batch_accuracy: 41.63%	lr:0.000122
Ep: 39/48	It: 4851/8134	batch_loss: 3.1090	batch_accuracy: 41.09%	lr:0.000122
Ep: 39/48	It: 4901/8134	batch_loss: 2.9924	batch_accuracy: 42.68%	lr:0.000122
Ep: 39/48	It: 4951/8134	batch_loss: 3.0754	batch_accuracy: 40.82%	lr:0.000122
Ep: 39/48	It: 5001/8134	batch_loss: 2.9906	batch_accuracy: 42.55%	lr:0.000122
Ep: 39/48	It: 5051/8134	batch_loss: 3.0559	batch_accuracy: 41.14%	lr:0.000122
Ep: 39/48	It: 5101/8134	batch_loss: 3.0854	batch_accuracy: 40.75%	lr:0.000122
Ep: 39/48	It: 5151/8134	batch_loss: 2.9590	batch_accuracy: 42.48%	lr:0.000121
Ep: 39/48	It: 5201/8134	batch_loss: 2.8907	batch_accuracy: 43.55%	lr:0.000121
Ep: 39/48	It: 5251/8134	batch_loss: 2.9823	batch_accuracy: 42.92%	lr:0.000121
Ep: 39/48	It: 5301/8134	batch_loss: 2.9848	batch_accuracy: 41.92%	lr:0.000121
Ep: 39/48	It: 5351/8134	batch_loss: 2.9295	batch_accuracy: 43.38%	lr:0.000121
Ep: 39/48	It: 5401/8134	batch_loss: 3.0662	batch_accuracy: 42.38%	lr:0.000121
Ep: 39/48	It: 5451/8134	batch_loss: 3.1014	batch_accuracy: 40.16%	lr:0.000121
Ep: 39/48	It: 5501/8134	batch_loss: 3.0518	batch_accuracy: 41.28%	lr:0.000120
Ep: 39/48	It: 5551/8134	batch_loss: 3.1311	batch_accuracy: 41.31%	lr:0.000120
Ep: 39/48	It: 5601/8134	batch_loss: 3.0898	batch_accuracy: 40.45%	lr:0.000120
Ep: 39/48	It: 5651/8134	batch_loss: 3.1783	batch_accuracy: 40.14%	lr:0.000120
Ep: 39/48	It: 5701/8134	batch_loss: 3.1167	batch_accuracy: 40.55%	lr:0.000120
Ep: 39/48	It: 5751/8134	batch_loss: 2.9718	batch_accuracy: 42.63%	lr:0.000120
Ep: 39/48	It: 5801/8134	batch_loss: 2.9199	batch_accuracy: 42.97%	lr:0.000120
Ep: 39/48	It: 5851/8134	batch_loss: 3.2148	batch_accuracy: 38.53%	lr:0.000119
Ep: 39/48	It: 5901/8134	batch_loss: 3.0307	batch_accuracy: 41.80%	lr:0.000119
Ep: 39/48	It: 5951/8134	batch_loss: 3.1074	batch_accuracy: 40.45%	lr:0.000119
Ep: 39/48	It: 6001/8134	batch_loss: 3.1911	batch_accuracy: 38.04%	lr:0.000119
Ep: 39/48	It: 6051/8134	batch_loss: 3.0935	batch_accuracy: 40.84%	lr:0.000119
Ep: 39/48	It: 6101/8134	batch_loss: 3.1623	batch_accuracy: 40.36%	lr:0.000119
Ep: 39/48	It: 6151/8134	batch_loss: 2.9834	batch_accuracy: 41.80%	lr:0.000119
Ep: 39/48	It: 6201/8134	batch_loss: 3.1606	batch_accuracy: 39.72%	lr:0.000119
Ep: 39/48	It: 6251/8134	batch_loss: 3.0442	batch_accuracy: 41.75%	lr:0.000118
Ep: 39/48	It: 6301/8134	batch_loss: 2.9395	batch_accuracy: 43.07%	lr:0.000118
Ep: 39/48	It: 6351/8134	batch_loss: 2.9755	batch_accuracy: 41.87%	lr:0.000118
Ep: 39/48	It: 6401/8134	batch_loss: 2.9663	batch_accuracy: 42.90%	lr:0.000118
Ep: 39/48	It: 6451/8134	batch_loss: 3.0093	batch_accuracy: 41.99%	lr:0.000118
Ep: 39/48	It: 6501/8134	batch_loss: 3.0843	batch_accuracy: 40.48%	lr:0.000118
Ep: 39/48	It: 6551/8134	batch_loss: 3.0435	batch_accuracy: 42.46%	lr:0.000118
Ep: 39/48	It: 6601/8134	batch_loss: 2.9976	batch_accuracy: 42.60%	lr:0.000117
Ep: 39/48	It: 6651/8134	batch_loss: 2.9703	batch_accuracy: 42.21%	lr:0.000117
Ep: 39/48	It: 6701/8134	batch_loss: 3.1289	batch_accuracy: 40.48%	lr:0.000117
Ep: 39/48	It: 6751/8134	batch_loss: 3.0376	batch_accuracy: 42.90%	lr:0.000117
Ep: 39/48	It: 6801/8134	batch_loss: 2.9140	batch_accuracy: 44.31%	lr:0.000117
Ep: 39/48	It: 6851/8134	batch_loss: 3.0387	batch_accuracy: 41.24%	lr:0.000117
Ep: 39/48	It: 6901/8134	batch_loss: 3.1910	batch_accuracy: 39.16%	lr:0.000117
Ep: 39/48	It: 6951/8134	batch_loss: 3.1020	batch_accuracy: 41.46%	lr:0.000116
Ep: 39/48	It: 7001/8134	batch_loss: 3.0918	batch_accuracy: 41.16%	lr:0.000116
Ep: 39/48	It: 7051/8134	batch_loss: 3.0767	batch_accuracy: 40.62%	lr:0.000116
Ep: 39/48	It: 7101/8134	batch_loss: 3.0386	batch_accuracy: 42.04%	lr:0.000116
Ep: 39/48	It: 7151/8134	batch_loss: 2.9856	batch_accuracy: 41.97%	lr:0.000116
Ep: 39/48	It: 7201/8134	batch_loss: 3.1164	batch_accuracy: 40.28%	lr:0.000116
Ep: 39/48	It: 7251/8134	batch_loss: 2.9640	batch_accuracy: 41.77%	lr:0.000116
Ep: 39/48	It: 7301/8134	batch_loss: 2.9475	batch_accuracy: 43.41%	lr:0.000115
Ep: 39/48	It: 7351/8134	batch_loss: 3.0985	batch_accuracy: 40.41%	lr:0.000115
Ep: 39/48	It: 7401/8134	batch_loss: 2.9977	batch_accuracy: 41.82%	lr:0.000115
Ep: 39/48	It: 7451/8134	batch_loss: 3.1275	batch_accuracy: 40.94%	lr:0.000115
Ep: 39/48	It: 7501/8134	batch_loss: 3.0888	batch_accuracy: 39.77%	lr:0.000115
Ep: 39/48	It: 7551/8134	batch_loss: 2.9513	batch_accuracy: 42.53%	lr:0.000115
Ep: 39/48	It: 7601/8134	batch_loss: 3.0682	batch_accuracy: 41.33%	lr:0.000115
Ep: 39/48	It: 7651/8134	batch_loss: 3.0346	batch_accuracy: 41.65%	lr:0.000115
Ep: 39/48	It: 7701/8134	batch_loss: 3.0555	batch_accuracy: 41.58%	lr:0.000114
Ep: 39/48	It: 7751/8134	batch_loss: 3.1060	batch_accuracy: 40.72%	lr:0.000114
Ep: 39/48	It: 7801/8134	batch_loss: 3.0797	batch_accuracy: 40.77%	lr:0.000114
Ep: 39/48	It: 7851/8134	batch_loss: 3.0107	batch_accuracy: 42.11%	lr:0.000114
Ep: 39/48	It: 7901/8134	batch_loss: 2.9972	batch_accuracy: 42.46%	lr:0.000114
Ep: 39/48	It: 7951/8134	batch_loss: 3.0725	batch_accuracy: 41.53%	lr:0.000114
Ep: 39/48	It: 8001/8134	batch_loss: 2.9336	batch_accuracy: 43.04%	lr:0.000114
Ep: 39/48	It: 8051/8134	batch_loss: 3.1458	batch_accuracy: 39.97%	lr:0.000113
Ep: 39/48	It: 8101/8134	batch_loss: 2.8656	batch_accuracy: 43.21%	lr:0.000113
Ep: 39/48	It: 8134/8134	batch_loss: 3.0608	batch_accuracy: 40.86%	lr:0.000113


Generated text for input text "You" is:
Youx, and other methods have shown the potential of this method to be more effective than the most common method. In the method of extracting the bases of each b is used. It is the most effective method. This method is the first step to extract the most relevant samples, and the most suitable sample is the second step of the process. The experimental results show that the method can be used for the extraction of the bags of the samples.
<eot>
<sot>
Critical Realism: A New Essay on Foreign Aid and its Practices

The article explores the way in which the concept of “sustainable” is applied to the process of formation of the “sustainable” and “sustainable” society. The purpose of this article is to analyse the process of creation of the concept of the ‘sustainable’ and to identify its main features and functions. The main objective of the study is to analyze the factors affecting the development of the organization of the organization of the process of formation of the formation of the organization of the organization of the organization of the organization of the organization of the organization of the organization of the organization of activities of the


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 40/48	It: 1/8134	batch_loss: 2.9549	batch_accuracy: 42.92%	lr:0.000113
Ep: 40/48	It: 51/8134	batch_loss: 3.0899	batch_accuracy: 41.53%	lr:0.000113
Ep: 40/48	It: 101/8134	batch_loss: 2.9873	batch_accuracy: 43.04%	lr:0.000113
Ep: 40/48	It: 151/8134	batch_loss: 3.0275	batch_accuracy: 40.99%	lr:0.000113
Ep: 40/48	It: 201/8134	batch_loss: 3.0282	batch_accuracy: 41.99%	lr:0.000113
Ep: 40/48	It: 251/8134	batch_loss: 2.9948	batch_accuracy: 42.24%	lr:0.000113
Ep: 40/48	It: 301/8134	batch_loss: 3.1008	batch_accuracy: 40.87%	lr:0.000112
Ep: 40/48	It: 351/8134	batch_loss: 3.0423	batch_accuracy: 41.63%	lr:0.000112
Ep: 40/48	It: 401/8134	batch_loss: 3.0921	batch_accuracy: 39.99%	lr:0.000112
Ep: 40/48	It: 451/8134	batch_loss: 3.0870	batch_accuracy: 41.09%	lr:0.000112
Ep: 40/48	It: 501/8134	batch_loss: 3.1184	batch_accuracy: 40.36%	lr:0.000112
Ep: 40/48	It: 551/8134	batch_loss: 3.0836	batch_accuracy: 41.28%	lr:0.000112
Ep: 40/48	It: 601/8134	batch_loss: 2.9436	batch_accuracy: 43.02%	lr:0.000112
Ep: 40/48	It: 651/8134	batch_loss: 2.9855	batch_accuracy: 41.72%	lr:0.000111
Ep: 40/48	It: 701/8134	batch_loss: 2.9752	batch_accuracy: 42.26%	lr:0.000111
Ep: 40/48	It: 751/8134	batch_loss: 3.0763	batch_accuracy: 41.33%	lr:0.000111
Ep: 40/48	It: 801/8134	batch_loss: 3.0611	batch_accuracy: 41.50%	lr:0.000111
Ep: 40/48	It: 851/8134	batch_loss: 3.0607	batch_accuracy: 42.02%	lr:0.000111
Ep: 40/48	It: 901/8134	batch_loss: 3.0771	batch_accuracy: 41.63%	lr:0.000111
Ep: 40/48	It: 951/8134	batch_loss: 2.9272	batch_accuracy: 43.21%	lr:0.000111
Ep: 40/48	It: 1001/8134	batch_loss: 2.9900	batch_accuracy: 42.80%	lr:0.000111
Ep: 40/48	It: 1051/8134	batch_loss: 3.0437	batch_accuracy: 41.43%	lr:0.000110
Ep: 40/48	It: 1101/8134	batch_loss: 3.1195	batch_accuracy: 40.41%	lr:0.000110
Ep: 40/48	It: 1151/8134	batch_loss: 3.0833	batch_accuracy: 40.82%	lr:0.000110
Ep: 40/48	It: 1201/8134	batch_loss: 3.1567	batch_accuracy: 40.50%	lr:0.000110
Ep: 40/48	It: 1251/8134	batch_loss: 3.0178	batch_accuracy: 40.89%	lr:0.000110
Ep: 40/48	It: 1301/8134	batch_loss: 3.0981	batch_accuracy: 40.11%	lr:0.000110
Ep: 40/48	It: 1351/8134	batch_loss: 2.9489	batch_accuracy: 42.55%	lr:0.000110
Ep: 40/48	It: 1401/8134	batch_loss: 3.0445	batch_accuracy: 41.04%	lr:0.000109
Ep: 40/48	It: 1451/8134	batch_loss: 2.9688	batch_accuracy: 42.90%	lr:0.000109
Ep: 40/48	It: 1501/8134	batch_loss: 3.0819	batch_accuracy: 41.26%	lr:0.000109
Ep: 40/48	It: 1551/8134	batch_loss: 3.0583	batch_accuracy: 42.31%	lr:0.000109
Ep: 40/48	It: 1601/8134	batch_loss: 2.9512	batch_accuracy: 42.60%	lr:0.000109
Ep: 40/48	It: 1651/8134	batch_loss: 3.0892	batch_accuracy: 41.02%	lr:0.000109
Ep: 40/48	It: 1701/8134	batch_loss: 2.9134	batch_accuracy: 43.97%	lr:0.000109
Ep: 40/48	It: 1751/8134	batch_loss: 3.0384	batch_accuracy: 41.92%	lr:0.000108
Ep: 40/48	It: 1801/8134	batch_loss: 2.9413	batch_accuracy: 43.09%	lr:0.000108
Ep: 40/48	It: 1851/8134	batch_loss: 3.0109	batch_accuracy: 42.46%	lr:0.000108
Ep: 40/48	It: 1901/8134	batch_loss: 3.0669	batch_accuracy: 41.02%	lr:0.000108
Ep: 40/48	It: 1951/8134	batch_loss: 2.9558	batch_accuracy: 42.55%	lr:0.000108
Ep: 40/48	It: 2001/8134	batch_loss: 3.0204	batch_accuracy: 42.24%	lr:0.000108
Ep: 40/48	It: 2051/8134	batch_loss: 2.9760	batch_accuracy: 41.58%	lr:0.000108
Ep: 40/48	It: 2101/8134	batch_loss: 3.0901	batch_accuracy: 40.77%	lr:0.000108
Ep: 40/48	It: 2151/8134	batch_loss: 3.0675	batch_accuracy: 41.97%	lr:0.000107
Ep: 40/48	It: 2201/8134	batch_loss: 3.0376	batch_accuracy: 41.09%	lr:0.000107
Ep: 40/48	It: 2251/8134	batch_loss: 3.0293	batch_accuracy: 42.43%	lr:0.000107
Ep: 40/48	It: 2301/8134	batch_loss: 3.0689	batch_accuracy: 40.80%	lr:0.000107
Ep: 40/48	It: 2351/8134	batch_loss: 3.0239	batch_accuracy: 41.48%	lr:0.000107
Ep: 40/48	It: 2401/8134	batch_loss: 3.0468	batch_accuracy: 41.53%	lr:0.000107
Ep: 40/48	It: 2451/8134	batch_loss: 3.1417	batch_accuracy: 41.09%	lr:0.000107
Ep: 40/48	It: 2501/8134	batch_loss: 3.1266	batch_accuracy: 39.82%	lr:0.000107
Ep: 40/48	It: 2551/8134	batch_loss: 3.0649	batch_accuracy: 40.75%	lr:0.000106
Ep: 40/48	It: 2601/8134	batch_loss: 3.0759	batch_accuracy: 40.01%	lr:0.000106
Ep: 40/48	It: 2651/8134	batch_loss: 3.0865	batch_accuracy: 41.85%	lr:0.000106
Ep: 40/48	It: 2701/8134	batch_loss: 2.9967	batch_accuracy: 41.48%	lr:0.000106
Ep: 40/48	It: 2751/8134	batch_loss: 2.9582	batch_accuracy: 42.90%	lr:0.000106
Ep: 40/48	It: 2801/8134	batch_loss: 3.0280	batch_accuracy: 42.53%	lr:0.000106
Ep: 40/48	It: 2851/8134	batch_loss: 3.1062	batch_accuracy: 41.28%	lr:0.000106
Ep: 40/48	It: 2901/8134	batch_loss: 3.1061	batch_accuracy: 40.67%	lr:0.000105
Ep: 40/48	It: 2951/8134	batch_loss: 3.0574	batch_accuracy: 41.38%	lr:0.000105
Ep: 40/48	It: 3001/8134	batch_loss: 3.1172	batch_accuracy: 40.53%	lr:0.000105
Ep: 40/48	It: 3051/8134	batch_loss: 3.0282	batch_accuracy: 41.70%	lr:0.000105
Ep: 40/48	It: 3101/8134	batch_loss: 3.0467	batch_accuracy: 41.48%	lr:0.000105
Ep: 40/48	It: 3151/8134	batch_loss: 2.9482	batch_accuracy: 43.29%	lr:0.000105
Ep: 40/48	It: 3201/8134	batch_loss: 2.9822	batch_accuracy: 42.02%	lr:0.000105
Ep: 40/48	It: 3251/8134	batch_loss: 3.1123	batch_accuracy: 41.55%	lr:0.000105
Ep: 40/48	It: 3301/8134	batch_loss: 3.1721	batch_accuracy: 39.72%	lr:0.000104
Ep: 40/48	It: 3351/8134	batch_loss: 2.9704	batch_accuracy: 43.80%	lr:0.000104
Ep: 40/48	It: 3401/8134	batch_loss: 3.0966	batch_accuracy: 40.84%	lr:0.000104
Ep: 40/48	It: 3451/8134	batch_loss: 3.1859	batch_accuracy: 39.04%	lr:0.000104
Ep: 40/48	It: 3501/8134	batch_loss: 3.0295	batch_accuracy: 42.02%	lr:0.000104
Ep: 40/48	It: 3551/8134	batch_loss: 3.0531	batch_accuracy: 42.82%	lr:0.000104
Ep: 40/48	It: 3601/8134	batch_loss: 2.9854	batch_accuracy: 42.43%	lr:0.000104
Ep: 40/48	It: 3651/8134	batch_loss: 3.1064	batch_accuracy: 40.87%	lr:0.000104
Ep: 40/48	It: 3701/8134	batch_loss: 3.0560	batch_accuracy: 41.50%	lr:0.000103
Ep: 40/48	It: 3751/8134	batch_loss: 3.1195	batch_accuracy: 40.31%	lr:0.000103
Ep: 40/48	It: 3801/8134	batch_loss: 2.9970	batch_accuracy: 43.04%	lr:0.000103
Ep: 40/48	It: 3851/8134	batch_loss: 3.0390	batch_accuracy: 41.67%	lr:0.000103
Ep: 40/48	It: 3901/8134	batch_loss: 3.1030	batch_accuracy: 40.87%	lr:0.000103
Ep: 40/48	It: 3951/8134	batch_loss: 3.0292	batch_accuracy: 40.82%	lr:0.000103
Ep: 40/48	It: 4001/8134	batch_loss: 3.0631	batch_accuracy: 41.11%	lr:0.000103
Ep: 40/48	It: 4051/8134	batch_loss: 3.2045	batch_accuracy: 39.67%	lr:0.000102
Ep: 40/48	It: 4101/8134	batch_loss: 3.1108	batch_accuracy: 40.28%	lr:0.000102
Ep: 40/48	It: 4151/8134	batch_loss: 2.9496	batch_accuracy: 43.19%	lr:0.000102
Ep: 40/48	It: 4201/8134	batch_loss: 3.0246	batch_accuracy: 41.41%	lr:0.000102
Ep: 40/48	It: 4251/8134	batch_loss: 3.1054	batch_accuracy: 41.11%	lr:0.000102
Ep: 40/48	It: 4301/8134	batch_loss: 3.0041	batch_accuracy: 41.50%	lr:0.000102
Ep: 40/48	It: 4351/8134	batch_loss: 3.0345	batch_accuracy: 41.48%	lr:0.000102
Ep: 40/48	It: 4401/8134	batch_loss: 3.0160	batch_accuracy: 41.67%	lr:0.000102
Ep: 40/48	It: 4451/8134	batch_loss: 3.1121	batch_accuracy: 42.02%	lr:0.000101
Ep: 40/48	It: 4501/8134	batch_loss: 3.0219	batch_accuracy: 42.21%	lr:0.000101
Ep: 40/48	It: 4551/8134	batch_loss: 3.0000	batch_accuracy: 41.85%	lr:0.000101
Ep: 40/48	It: 4601/8134	batch_loss: 3.0129	batch_accuracy: 41.75%	lr:0.000101
Ep: 40/48	It: 4651/8134	batch_loss: 2.9468	batch_accuracy: 42.87%	lr:0.000101
Ep: 40/48	It: 4701/8134	batch_loss: 3.0296	batch_accuracy: 41.63%	lr:0.000101
Ep: 40/48	It: 4751/8134	batch_loss: 2.9258	batch_accuracy: 43.43%	lr:0.000101
Ep: 40/48	It: 4801/8134	batch_loss: 2.9256	batch_accuracy: 42.63%	lr:0.000101
Ep: 40/48	It: 4851/8134	batch_loss: 3.1143	batch_accuracy: 40.41%	lr:0.000100
Ep: 40/48	It: 4901/8134	batch_loss: 3.0078	batch_accuracy: 42.75%	lr:0.000100
Ep: 40/48	It: 4951/8134	batch_loss: 3.0227	batch_accuracy: 41.65%	lr:0.000100
Ep: 40/48	It: 5001/8134	batch_loss: 3.0827	batch_accuracy: 40.58%	lr:0.000100
Ep: 40/48	It: 5051/8134	batch_loss: 3.1667	batch_accuracy: 39.89%	lr:0.000100
Ep: 40/48	It: 5101/8134	batch_loss: 3.0783	batch_accuracy: 41.21%	lr:0.000100
Ep: 40/48	It: 5151/8134	batch_loss: 3.1064	batch_accuracy: 39.92%	lr:0.000100
Ep: 40/48	It: 5201/8134	batch_loss: 3.0851	batch_accuracy: 40.92%	lr:0.000100
Ep: 40/48	It: 5251/8134	batch_loss: 3.0334	batch_accuracy: 42.09%	lr:0.000099
Ep: 40/48	It: 5301/8134	batch_loss: 2.9807	batch_accuracy: 43.16%	lr:0.000099
Ep: 40/48	It: 5351/8134	batch_loss: 3.0878	batch_accuracy: 41.58%	lr:0.000099
Ep: 40/48	It: 5401/8134	batch_loss: 2.9771	batch_accuracy: 42.48%	lr:0.000099
Ep: 40/48	It: 5451/8134	batch_loss: 3.0811	batch_accuracy: 40.92%	lr:0.000099
Ep: 40/48	It: 5501/8134	batch_loss: 3.0142	batch_accuracy: 41.50%	lr:0.000099
Ep: 40/48	It: 5551/8134	batch_loss: 3.1108	batch_accuracy: 40.58%	lr:0.000099
Ep: 40/48	It: 5601/8134	batch_loss: 3.1000	batch_accuracy: 41.14%	lr:0.000098
Ep: 40/48	It: 5651/8134	batch_loss: 3.0502	batch_accuracy: 40.77%	lr:0.000098
Ep: 40/48	It: 5701/8134	batch_loss: 2.9935	batch_accuracy: 42.26%	lr:0.000098
Ep: 40/48	It: 5751/8134	batch_loss: 3.0959	batch_accuracy: 41.16%	lr:0.000098
Ep: 40/48	It: 5801/8134	batch_loss: 3.0558	batch_accuracy: 41.31%	lr:0.000098
Ep: 40/48	It: 5851/8134	batch_loss: 3.0194	batch_accuracy: 41.24%	lr:0.000098
Ep: 40/48	It: 5901/8134	batch_loss: 3.0624	batch_accuracy: 41.19%	lr:0.000098
Ep: 40/48	It: 5951/8134	batch_loss: 3.0666	batch_accuracy: 40.94%	lr:0.000098
Ep: 40/48	It: 6001/8134	batch_loss: 2.9893	batch_accuracy: 43.24%	lr:0.000097
Ep: 40/48	It: 6051/8134	batch_loss: 2.9146	batch_accuracy: 43.75%	lr:0.000097
Ep: 40/48	It: 6101/8134	batch_loss: 3.0678	batch_accuracy: 40.89%	lr:0.000097
Ep: 40/48	It: 6151/8134	batch_loss: 3.0720	batch_accuracy: 40.99%	lr:0.000097
Ep: 40/48	It: 6201/8134	batch_loss: 3.0137	batch_accuracy: 41.41%	lr:0.000097
Ep: 40/48	It: 6251/8134	batch_loss: 3.0783	batch_accuracy: 41.21%	lr:0.000097
Ep: 40/48	It: 6301/8134	batch_loss: 3.0002	batch_accuracy: 43.26%	lr:0.000097
Ep: 40/48	It: 6351/8134	batch_loss: 3.0416	batch_accuracy: 41.21%	lr:0.000097
Ep: 40/48	It: 6401/8134	batch_loss: 3.0583	batch_accuracy: 42.31%	lr:0.000096
Ep: 40/48	It: 6451/8134	batch_loss: 3.0847	batch_accuracy: 40.67%	lr:0.000096
Ep: 40/48	It: 6501/8134	batch_loss: 3.0164	batch_accuracy: 42.33%	lr:0.000096
Ep: 40/48	It: 6551/8134	batch_loss: 3.1051	batch_accuracy: 40.99%	lr:0.000096
Ep: 40/48	It: 6601/8134	batch_loss: 3.0907	batch_accuracy: 40.48%	lr:0.000096
Ep: 40/48	It: 6651/8134	batch_loss: 3.0246	batch_accuracy: 42.24%	lr:0.000096
Ep: 40/48	It: 6701/8134	batch_loss: 3.0262	batch_accuracy: 41.99%	lr:0.000096
Ep: 40/48	It: 6751/8134	batch_loss: 3.0837	batch_accuracy: 40.75%	lr:0.000096
Ep: 40/48	It: 6801/8134	batch_loss: 3.0153	batch_accuracy: 42.41%	lr:0.000095
Ep: 40/48	It: 6851/8134	batch_loss: 2.9189	batch_accuracy: 44.07%	lr:0.000095
Ep: 40/48	It: 6901/8134	batch_loss: 3.0495	batch_accuracy: 41.92%	lr:0.000095
Ep: 40/48	It: 6951/8134	batch_loss: 2.9364	batch_accuracy: 43.60%	lr:0.000095
Ep: 40/48	It: 7001/8134	batch_loss: 2.7317	batch_accuracy: 45.56%	lr:0.000095
Ep: 40/48	It: 7051/8134	batch_loss: 3.0789	batch_accuracy: 40.75%	lr:0.000095
Ep: 40/48	It: 7101/8134	batch_loss: 3.1734	batch_accuracy: 40.06%	lr:0.000095
Ep: 40/48	It: 7151/8134	batch_loss: 2.9643	batch_accuracy: 42.53%	lr:0.000095
Ep: 40/48	It: 7201/8134	batch_loss: 3.1941	batch_accuracy: 40.09%	lr:0.000094
Ep: 40/48	It: 7251/8134	batch_loss: 2.9974	batch_accuracy: 43.02%	lr:0.000094
Ep: 40/48	It: 7301/8134	batch_loss: 2.9439	batch_accuracy: 43.36%	lr:0.000094
Ep: 40/48	It: 7351/8134	batch_loss: 3.0654	batch_accuracy: 41.58%	lr:0.000094
Ep: 40/48	It: 7401/8134	batch_loss: 2.9694	batch_accuracy: 42.04%	lr:0.000094
Ep: 40/48	It: 7451/8134	batch_loss: 3.1367	batch_accuracy: 40.43%	lr:0.000094
Ep: 40/48	It: 7501/8134	batch_loss: 3.0397	batch_accuracy: 41.77%	lr:0.000094
Ep: 40/48	It: 7551/8134	batch_loss: 2.9030	batch_accuracy: 43.63%	lr:0.000094
Ep: 40/48	It: 7601/8134	batch_loss: 3.0444	batch_accuracy: 41.14%	lr:0.000093
Ep: 40/48	It: 7651/8134	batch_loss: 2.9758	batch_accuracy: 43.02%	lr:0.000093
Ep: 40/48	It: 7701/8134	batch_loss: 3.1092	batch_accuracy: 40.62%	lr:0.000093
Ep: 40/48	It: 7751/8134	batch_loss: 2.9843	batch_accuracy: 42.38%	lr:0.000093
Ep: 40/48	It: 7801/8134	batch_loss: 3.0771	batch_accuracy: 40.26%	lr:0.000093
Ep: 40/48	It: 7851/8134	batch_loss: 3.0156	batch_accuracy: 42.07%	lr:0.000093
Ep: 40/48	It: 7901/8134	batch_loss: 3.0102	batch_accuracy: 41.97%	lr:0.000093
Ep: 40/48	It: 7951/8134	batch_loss: 2.9919	batch_accuracy: 42.94%	lr:0.000093
Ep: 40/48	It: 8001/8134	batch_loss: 3.2340	batch_accuracy: 39.84%	lr:0.000092
Ep: 40/48	It: 8051/8134	batch_loss: 3.1604	batch_accuracy: 40.01%	lr:0.000092
Ep: 40/48	It: 8101/8134	batch_loss: 3.0014	batch_accuracy: 42.21%	lr:0.000092
Ep: 40/48	It: 8134/8134	batch_loss: 3.0902	batch_accuracy: 40.73%	lr:0.000092


Generated text for input text "You" is:
Youx-M algorithm is introduced to reduce the error and improve the accuracy. In this paper, the effect of the fault parameters and the number of fault on the fault detection is investigated. Then, the simulation experiment result shows that the fault fault diagnosis algorithm can be effectively and the fault diagnosis method is able to accurately detect fault and cause faults. And the fault diagnosis algorithm is put forward in the proposed method.
<eot>
<sot>
Towards the Promotion of Equity: A New Method to Promote Equity and Return

This paper presents an empirical investigation of the effectiveness of a new technology that can help the development of economic activity of a new technology. The main focus is to increase the efficiency of a new technology in a new technology. The research was carried out using a combination of data-driven methods, data-driven techniques, and data-driven methodologies. The method is based on the theory of data-driven information. The method used in this paper is an efficient algorithm. In the process of selecting the model, the method has been used to select the most suitable sample size for the whole sample, and the method is based on two-dimensional data-driven


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 41/48	It: 1/8134	batch_loss: 3.0076	batch_accuracy: 41.63%	lr:0.000092
Ep: 41/48	It: 51/8134	batch_loss: 3.0554	batch_accuracy: 41.48%	lr:0.000092
Ep: 41/48	It: 101/8134	batch_loss: 2.9725	batch_accuracy: 43.16%	lr:0.000092
Ep: 41/48	It: 151/8134	batch_loss: 3.0572	batch_accuracy: 42.33%	lr:0.000092
Ep: 41/48	It: 201/8134	batch_loss: 3.0695	batch_accuracy: 41.75%	lr:0.000092
Ep: 41/48	It: 251/8134	batch_loss: 3.0394	batch_accuracy: 41.70%	lr:0.000092
Ep: 41/48	It: 301/8134	batch_loss: 3.0549	batch_accuracy: 41.04%	lr:0.000091
Ep: 41/48	It: 351/8134	batch_loss: 3.0426	batch_accuracy: 41.16%	lr:0.000091
Ep: 41/48	It: 401/8134	batch_loss: 3.0457	batch_accuracy: 40.50%	lr:0.000091
Ep: 41/48	It: 451/8134	batch_loss: 3.0363	batch_accuracy: 42.68%	lr:0.000091
Ep: 41/48	It: 501/8134	batch_loss: 3.1121	batch_accuracy: 41.48%	lr:0.000091
Ep: 41/48	It: 551/8134	batch_loss: 2.9587	batch_accuracy: 43.31%	lr:0.000091
Ep: 41/48	It: 601/8134	batch_loss: 3.0430	batch_accuracy: 41.48%	lr:0.000091
Ep: 41/48	It: 651/8134	batch_loss: 3.0156	batch_accuracy: 41.75%	lr:0.000091
Ep: 41/48	It: 701/8134	batch_loss: 3.2084	batch_accuracy: 38.72%	lr:0.000090
Ep: 41/48	It: 751/8134	batch_loss: 3.0124	batch_accuracy: 42.19%	lr:0.000090
Ep: 41/48	It: 801/8134	batch_loss: 3.0467	batch_accuracy: 42.09%	lr:0.000090
Ep: 41/48	It: 851/8134	batch_loss: 2.9911	batch_accuracy: 43.02%	lr:0.000090
Ep: 41/48	It: 901/8134	batch_loss: 2.9987	batch_accuracy: 42.90%	lr:0.000090
Ep: 41/48	It: 951/8134	batch_loss: 3.0420	batch_accuracy: 42.46%	lr:0.000090
Ep: 41/48	It: 1001/8134	batch_loss: 3.1032	batch_accuracy: 40.60%	lr:0.000090
Ep: 41/48	It: 1051/8134	batch_loss: 3.0955	batch_accuracy: 40.77%	lr:0.000090
Ep: 41/48	It: 1101/8134	batch_loss: 3.0667	batch_accuracy: 41.28%	lr:0.000089
Ep: 41/48	It: 1151/8134	batch_loss: 3.2180	batch_accuracy: 38.94%	lr:0.000089
Ep: 41/48	It: 1201/8134	batch_loss: 3.1057	batch_accuracy: 40.26%	lr:0.000089
Ep: 41/48	It: 1251/8134	batch_loss: 2.9795	batch_accuracy: 42.41%	lr:0.000089
Ep: 41/48	It: 1301/8134	batch_loss: 3.0463	batch_accuracy: 42.29%	lr:0.000089
Ep: 41/48	It: 1351/8134	batch_loss: 3.1256	batch_accuracy: 40.33%	lr:0.000089
Ep: 41/48	It: 1401/8134	batch_loss: 3.0682	batch_accuracy: 40.97%	lr:0.000089
Ep: 41/48	It: 1451/8134	batch_loss: 2.9198	batch_accuracy: 43.58%	lr:0.000089
Ep: 41/48	It: 1501/8134	batch_loss: 3.0537	batch_accuracy: 41.80%	lr:0.000089
Ep: 41/48	It: 1551/8134	batch_loss: 2.9956	batch_accuracy: 42.19%	lr:0.000088
Ep: 41/48	It: 1601/8134	batch_loss: 2.8937	batch_accuracy: 44.34%	lr:0.000088
Ep: 41/48	It: 1651/8134	batch_loss: 3.0385	batch_accuracy: 42.11%	lr:0.000088
Ep: 41/48	It: 1701/8134	batch_loss: 3.0081	batch_accuracy: 42.16%	lr:0.000088
Ep: 41/48	It: 1751/8134	batch_loss: 3.0742	batch_accuracy: 42.14%	lr:0.000088
Ep: 41/48	It: 1801/8134	batch_loss: 3.0309	batch_accuracy: 42.19%	lr:0.000088
Ep: 41/48	It: 1851/8134	batch_loss: 3.0841	batch_accuracy: 40.77%	lr:0.000088
Ep: 41/48	It: 1901/8134	batch_loss: 2.8679	batch_accuracy: 43.29%	lr:0.000088
Ep: 41/48	It: 1951/8134	batch_loss: 3.0688	batch_accuracy: 40.94%	lr:0.000087
Ep: 41/48	It: 2001/8134	batch_loss: 3.0459	batch_accuracy: 41.63%	lr:0.000087
Ep: 41/48	It: 2051/8134	batch_loss: 3.0163	batch_accuracy: 41.41%	lr:0.000087
Ep: 41/48	It: 2101/8134	batch_loss: 3.0316	batch_accuracy: 42.07%	lr:0.000087
Ep: 41/48	It: 2151/8134	batch_loss: 3.1162	batch_accuracy: 41.41%	lr:0.000087
Ep: 41/48	It: 2201/8134	batch_loss: 2.9121	batch_accuracy: 42.85%	lr:0.000087
Ep: 41/48	It: 2251/8134	batch_loss: 3.0308	batch_accuracy: 41.75%	lr:0.000087
Ep: 41/48	It: 2301/8134	batch_loss: 3.1554	batch_accuracy: 39.43%	lr:0.000087
Ep: 41/48	It: 2351/8134	batch_loss: 2.9393	batch_accuracy: 43.09%	lr:0.000086
Ep: 41/48	It: 2401/8134	batch_loss: 2.9757	batch_accuracy: 42.94%	lr:0.000086
Ep: 41/48	It: 2451/8134	batch_loss: 3.1315	batch_accuracy: 40.87%	lr:0.000086
Ep: 41/48	It: 2501/8134	batch_loss: 3.0455	batch_accuracy: 41.53%	lr:0.000086
Ep: 41/48	It: 2551/8134	batch_loss: 3.1809	batch_accuracy: 39.77%	lr:0.000086
Ep: 41/48	It: 2601/8134	batch_loss: 3.0166	batch_accuracy: 42.75%	lr:0.000086
Ep: 41/48	It: 2651/8134	batch_loss: 2.9917	batch_accuracy: 42.77%	lr:0.000086
Ep: 41/48	It: 2701/8134	batch_loss: 3.0980	batch_accuracy: 40.50%	lr:0.000086
Ep: 41/48	It: 2751/8134	batch_loss: 3.0306	batch_accuracy: 41.67%	lr:0.000086
Ep: 41/48	It: 2801/8134	batch_loss: 3.0111	batch_accuracy: 42.21%	lr:0.000085
Ep: 41/48	It: 2851/8134	batch_loss: 2.9871	batch_accuracy: 42.63%	lr:0.000085
Ep: 41/48	It: 2901/8134	batch_loss: 3.0588	batch_accuracy: 40.99%	lr:0.000085
Ep: 41/48	It: 2951/8134	batch_loss: 3.0588	batch_accuracy: 41.31%	lr:0.000085
Ep: 41/48	It: 3001/8134	batch_loss: 3.1286	batch_accuracy: 40.14%	lr:0.000085
Ep: 41/48	It: 3051/8134	batch_loss: 2.9039	batch_accuracy: 43.07%	lr:0.000085
Ep: 41/48	It: 3101/8134	batch_loss: 3.0090	batch_accuracy: 42.63%	lr:0.000085
Ep: 41/48	It: 3151/8134	batch_loss: 3.0012	batch_accuracy: 42.72%	lr:0.000085
Ep: 41/48	It: 3201/8134	batch_loss: 3.0574	batch_accuracy: 41.31%	lr:0.000084
Ep: 41/48	It: 3251/8134	batch_loss: 2.9809	batch_accuracy: 42.50%	lr:0.000084
Ep: 41/48	It: 3301/8134	batch_loss: 3.0377	batch_accuracy: 41.09%	lr:0.000084
Ep: 41/48	It: 3351/8134	batch_loss: 3.0518	batch_accuracy: 42.63%	lr:0.000084
Ep: 41/48	It: 3401/8134	batch_loss: 2.9701	batch_accuracy: 42.19%	lr:0.000084
Ep: 41/48	It: 3451/8134	batch_loss: 3.0485	batch_accuracy: 42.41%	lr:0.000084
Ep: 41/48	It: 3501/8134	batch_loss: 2.9105	batch_accuracy: 43.07%	lr:0.000084
Ep: 41/48	It: 3551/8134	batch_loss: 3.0174	batch_accuracy: 41.55%	lr:0.000084
Ep: 41/48	It: 3601/8134	batch_loss: 3.0814	batch_accuracy: 40.99%	lr:0.000084
Ep: 41/48	It: 3651/8134	batch_loss: 3.0723	batch_accuracy: 41.36%	lr:0.000083
Ep: 41/48	It: 3701/8134	batch_loss: 2.9058	batch_accuracy: 44.26%	lr:0.000083
Ep: 41/48	It: 3751/8134	batch_loss: 3.0058	batch_accuracy: 43.43%	lr:0.000083
Ep: 41/48	It: 3801/8134	batch_loss: 3.1298	batch_accuracy: 39.79%	lr:0.000083
Ep: 41/48	It: 3851/8134	batch_loss: 3.1029	batch_accuracy: 41.65%	lr:0.000083
Ep: 41/48	It: 3901/8134	batch_loss: 2.9890	batch_accuracy: 42.60%	lr:0.000083
Ep: 41/48	It: 3951/8134	batch_loss: 2.9226	batch_accuracy: 43.19%	lr:0.000083
Ep: 41/48	It: 4001/8134	batch_loss: 3.1285	batch_accuracy: 40.06%	lr:0.000083
Ep: 41/48	It: 4051/8134	batch_loss: 3.2294	batch_accuracy: 38.99%	lr:0.000083
Ep: 41/48	It: 4101/8134	batch_loss: 3.0243	batch_accuracy: 43.07%	lr:0.000082
Ep: 41/48	It: 4151/8134	batch_loss: 3.0472	batch_accuracy: 40.99%	lr:0.000082
Ep: 41/48	It: 4201/8134	batch_loss: 3.0320	batch_accuracy: 42.07%	lr:0.000082
Ep: 41/48	It: 4251/8134	batch_loss: 3.0364	batch_accuracy: 42.24%	lr:0.000082
Ep: 41/48	It: 4301/8134	batch_loss: 2.9983	batch_accuracy: 41.77%	lr:0.000082
Ep: 41/48	It: 4351/8134	batch_loss: 2.9389	batch_accuracy: 42.87%	lr:0.000082
Ep: 41/48	It: 4401/8134	batch_loss: 2.9539	batch_accuracy: 42.09%	lr:0.000082
Ep: 41/48	It: 4451/8134	batch_loss: 2.9452	batch_accuracy: 42.48%	lr:0.000082
Ep: 41/48	It: 4501/8134	batch_loss: 2.9767	batch_accuracy: 42.14%	lr:0.000081
Ep: 41/48	It: 4551/8134	batch_loss: 3.1229	batch_accuracy: 40.72%	lr:0.000081
Ep: 41/48	It: 4601/8134	batch_loss: 3.0469	batch_accuracy: 42.55%	lr:0.000081
Ep: 41/48	It: 4651/8134	batch_loss: 3.1421	batch_accuracy: 40.53%	lr:0.000081
Ep: 41/48	It: 4701/8134	batch_loss: 3.0625	batch_accuracy: 41.87%	lr:0.000081
Ep: 41/48	It: 4751/8134	batch_loss: 2.9475	batch_accuracy: 42.75%	lr:0.000081
Ep: 41/48	It: 4801/8134	batch_loss: 3.0823	batch_accuracy: 41.97%	lr:0.000081
Ep: 41/48	It: 4851/8134	batch_loss: 3.0285	batch_accuracy: 40.92%	lr:0.000081
Ep: 41/48	It: 4901/8134	batch_loss: 3.0208	batch_accuracy: 41.75%	lr:0.000081
Ep: 41/48	It: 4951/8134	batch_loss: 3.1186	batch_accuracy: 41.16%	lr:0.000080
Ep: 41/48	It: 5001/8134	batch_loss: 3.1063	batch_accuracy: 41.67%	lr:0.000080
Ep: 41/48	It: 5051/8134	batch_loss: 3.1820	batch_accuracy: 39.16%	lr:0.000080
Ep: 41/48	It: 5101/8134	batch_loss: 3.1541	batch_accuracy: 40.14%	lr:0.000080
Ep: 41/48	It: 5151/8134	batch_loss: 3.0444	batch_accuracy: 41.53%	lr:0.000080
Ep: 41/48	It: 5201/8134	batch_loss: 3.0936	batch_accuracy: 41.72%	lr:0.000080
Ep: 41/48	It: 5251/8134	batch_loss: 3.0860	batch_accuracy: 41.14%	lr:0.000080
Ep: 41/48	It: 5301/8134	batch_loss: 2.9240	batch_accuracy: 42.38%	lr:0.000080
Ep: 41/48	It: 5351/8134	batch_loss: 2.9715	batch_accuracy: 42.92%	lr:0.000080
Ep: 41/48	It: 5401/8134	batch_loss: 3.0474	batch_accuracy: 41.85%	lr:0.000079
Ep: 41/48	It: 5451/8134	batch_loss: 2.9942	batch_accuracy: 42.24%	lr:0.000079
Ep: 41/48	It: 5501/8134	batch_loss: 3.0182	batch_accuracy: 41.70%	lr:0.000079
Ep: 41/48	It: 5551/8134	batch_loss: 2.9870	batch_accuracy: 41.82%	lr:0.000079
Ep: 41/48	It: 5601/8134	batch_loss: 3.0814	batch_accuracy: 41.46%	lr:0.000079
Ep: 41/48	It: 5651/8134	batch_loss: 3.1086	batch_accuracy: 41.70%	lr:0.000079
Ep: 41/48	It: 5701/8134	batch_loss: 3.1259	batch_accuracy: 40.14%	lr:0.000079
Ep: 41/48	It: 5751/8134	batch_loss: 3.0818	batch_accuracy: 41.16%	lr:0.000079
Ep: 41/48	It: 5801/8134	batch_loss: 3.0873	batch_accuracy: 40.26%	lr:0.000079
Ep: 41/48	It: 5851/8134	batch_loss: 2.9842	batch_accuracy: 42.99%	lr:0.000078
Ep: 41/48	It: 5901/8134	batch_loss: 3.0180	batch_accuracy: 41.99%	lr:0.000078
Ep: 41/48	It: 5951/8134	batch_loss: 2.9559	batch_accuracy: 43.24%	lr:0.000078
Ep: 41/48	It: 6001/8134	batch_loss: 3.0011	batch_accuracy: 42.26%	lr:0.000078
Ep: 41/48	It: 6051/8134	batch_loss: 3.0515	batch_accuracy: 41.72%	lr:0.000078
Ep: 41/48	It: 6101/8134	batch_loss: 3.0420	batch_accuracy: 41.50%	lr:0.000078
Ep: 41/48	It: 6151/8134	batch_loss: 3.1040	batch_accuracy: 40.87%	lr:0.000078
Ep: 41/48	It: 6201/8134	batch_loss: 3.1488	batch_accuracy: 40.84%	lr:0.000078
Ep: 41/48	It: 6251/8134	batch_loss: 3.0151	batch_accuracy: 41.94%	lr:0.000077
Ep: 41/48	It: 6301/8134	batch_loss: 3.0631	batch_accuracy: 41.63%	lr:0.000077
Ep: 41/48	It: 6351/8134	batch_loss: 2.9815	batch_accuracy: 42.63%	lr:0.000077
Ep: 41/48	It: 6401/8134	batch_loss: 3.0240	batch_accuracy: 42.21%	lr:0.000077
Ep: 41/48	It: 6451/8134	batch_loss: 3.0220	batch_accuracy: 42.31%	lr:0.000077
Ep: 41/48	It: 6501/8134	batch_loss: 3.0960	batch_accuracy: 41.06%	lr:0.000077
Ep: 41/48	It: 6551/8134	batch_loss: 3.0342	batch_accuracy: 42.26%	lr:0.000077
Ep: 41/48	It: 6601/8134	batch_loss: 2.9847	batch_accuracy: 42.04%	lr:0.000077
Ep: 41/48	It: 6651/8134	batch_loss: 2.9963	batch_accuracy: 41.94%	lr:0.000077
Ep: 41/48	It: 6701/8134	batch_loss: 2.9880	batch_accuracy: 42.50%	lr:0.000076
Ep: 41/48	It: 6751/8134	batch_loss: 3.0706	batch_accuracy: 41.63%	lr:0.000076
Ep: 41/48	It: 6801/8134	batch_loss: 3.0889	batch_accuracy: 41.11%	lr:0.000076
Ep: 41/48	It: 6851/8134	batch_loss: 2.9226	batch_accuracy: 43.70%	lr:0.000076
Ep: 41/48	It: 6901/8134	batch_loss: 3.0097	batch_accuracy: 41.41%	lr:0.000076
Ep: 41/48	It: 6951/8134	batch_loss: 3.0995	batch_accuracy: 39.72%	lr:0.000076
Ep: 41/48	It: 7001/8134	batch_loss: 2.9528	batch_accuracy: 42.53%	lr:0.000076
Ep: 41/48	It: 7051/8134	batch_loss: 3.0638	batch_accuracy: 41.48%	lr:0.000076
Ep: 41/48	It: 7101/8134	batch_loss: 2.9545	batch_accuracy: 42.31%	lr:0.000076
Ep: 41/48	It: 7151/8134	batch_loss: 3.0346	batch_accuracy: 41.97%	lr:0.000075
Ep: 41/48	It: 7201/8134	batch_loss: 3.1657	batch_accuracy: 40.31%	lr:0.000075
Ep: 41/48	It: 7251/8134	batch_loss: 2.9620	batch_accuracy: 43.92%	lr:0.000075
Ep: 41/48	It: 7301/8134	batch_loss: 3.0889	batch_accuracy: 41.50%	lr:0.000075
Ep: 41/48	It: 7351/8134	batch_loss: 3.0614	batch_accuracy: 42.36%	lr:0.000075
Ep: 41/48	It: 7401/8134	batch_loss: 2.9316	batch_accuracy: 43.26%	lr:0.000075
Ep: 41/48	It: 7451/8134	batch_loss: 2.9607	batch_accuracy: 42.29%	lr:0.000075
Ep: 41/48	It: 7501/8134	batch_loss: 2.8594	batch_accuracy: 43.58%	lr:0.000075
Ep: 41/48	It: 7551/8134	batch_loss: 2.9643	batch_accuracy: 42.14%	lr:0.000075
Ep: 41/48	It: 7601/8134	batch_loss: 3.0710	batch_accuracy: 40.89%	lr:0.000075
Ep: 41/48	It: 7651/8134	batch_loss: 3.0354	batch_accuracy: 42.75%	lr:0.000074
Ep: 41/48	It: 7701/8134	batch_loss: 3.0971	batch_accuracy: 41.21%	lr:0.000074
Ep: 41/48	It: 7751/8134	batch_loss: 3.0271	batch_accuracy: 42.26%	lr:0.000074
Ep: 41/48	It: 7801/8134	batch_loss: 3.1607	batch_accuracy: 40.62%	lr:0.000074
Ep: 41/48	It: 7851/8134	batch_loss: 2.9619	batch_accuracy: 42.29%	lr:0.000074
Ep: 41/48	It: 7901/8134	batch_loss: 3.1953	batch_accuracy: 39.75%	lr:0.000074
Ep: 41/48	It: 7951/8134	batch_loss: 3.0377	batch_accuracy: 41.28%	lr:0.000074
Ep: 41/48	It: 8001/8134	batch_loss: 3.0692	batch_accuracy: 41.06%	lr:0.000074
Ep: 41/48	It: 8051/8134	batch_loss: 3.1666	batch_accuracy: 40.50%	lr:0.000074
Ep: 41/48	It: 8101/8134	batch_loss: 2.9199	batch_accuracy: 42.19%	lr:0.000073
Ep: 41/48	It: 8134/8134	batch_loss: 2.9789	batch_accuracy: 43.07%	lr:0.000073


Generated text for input text "You" is:
You-SN is not sufficiently integrated to enable thesis of thesis. It is a lt nt n t r i e n t r t o a n c i t i e a n lt to . The m ~ 2 2 1 4 2 ??!! T is a m ? 2 1 x i 2 , which is a t h o n s i n s * l l ?l i t r s ( ), where X is a m ! l , ? r e r r i i t r r , a n , a * ? , xn is the number of s n , xn, … ! m is the set of all vertices, xn, n. This is the same in the number of generators of an invertible k and k and the number of k matches of all vertices of the set of vertices is a finite subgroup of Γ. It is shown that if every finite group of the set of vertices is n+1, then the set of vertices of Γ ∈ G, then Γ is a finite group. The existence of a graph of Γ ∈ G and Γ �


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 42/48	It: 1/8134	batch_loss: 3.0316	batch_accuracy: 41.43%	lr:0.000073
Ep: 42/48	It: 51/8134	batch_loss: 3.0153	batch_accuracy: 41.82%	lr:0.000073
Ep: 42/48	It: 101/8134	batch_loss: 3.0064	batch_accuracy: 41.48%	lr:0.000073
Ep: 42/48	It: 151/8134	batch_loss: 3.0372	batch_accuracy: 42.36%	lr:0.000073
Ep: 42/48	It: 201/8134	batch_loss: 2.9889	batch_accuracy: 42.48%	lr:0.000073
Ep: 42/48	It: 251/8134	batch_loss: 3.0630	batch_accuracy: 41.55%	lr:0.000073
Ep: 42/48	It: 301/8134	batch_loss: 3.1342	batch_accuracy: 40.36%	lr:0.000073
Ep: 42/48	It: 351/8134	batch_loss: 3.0737	batch_accuracy: 41.19%	lr:0.000073
Ep: 42/48	It: 401/8134	batch_loss: 3.0723	batch_accuracy: 40.43%	lr:0.000072
Ep: 42/48	It: 451/8134	batch_loss: 3.0953	batch_accuracy: 41.14%	lr:0.000072
Ep: 42/48	It: 501/8134	batch_loss: 3.0013	batch_accuracy: 41.67%	lr:0.000072
Ep: 42/48	It: 551/8134	batch_loss: 3.0668	batch_accuracy: 42.26%	lr:0.000072
Ep: 42/48	It: 601/8134	batch_loss: 3.0815	batch_accuracy: 40.55%	lr:0.000072
Ep: 42/48	It: 651/8134	batch_loss: 3.0472	batch_accuracy: 41.60%	lr:0.000072
Ep: 42/48	It: 701/8134	batch_loss: 3.0959	batch_accuracy: 41.26%	lr:0.000072
Ep: 42/48	It: 751/8134	batch_loss: 3.0052	batch_accuracy: 42.26%	lr:0.000072
Ep: 42/48	It: 801/8134	batch_loss: 3.2143	batch_accuracy: 39.11%	lr:0.000072
Ep: 42/48	It: 851/8134	batch_loss: 3.0229	batch_accuracy: 42.24%	lr:0.000071
Ep: 42/48	It: 901/8134	batch_loss: 3.0053	batch_accuracy: 43.26%	lr:0.000071
Ep: 42/48	It: 951/8134	batch_loss: 3.0181	batch_accuracy: 40.80%	lr:0.000071
Ep: 42/48	It: 1001/8134	batch_loss: 2.9658	batch_accuracy: 43.33%	lr:0.000071
Ep: 42/48	It: 1051/8134	batch_loss: 3.0261	batch_accuracy: 42.77%	lr:0.000071
Ep: 42/48	It: 1101/8134	batch_loss: 2.9510	batch_accuracy: 41.63%	lr:0.000071
Ep: 42/48	It: 1151/8134	batch_loss: 2.9444	batch_accuracy: 43.43%	lr:0.000071
Ep: 42/48	It: 1201/8134	batch_loss: 3.1682	batch_accuracy: 40.09%	lr:0.000071
Ep: 42/48	It: 1251/8134	batch_loss: 3.0123	batch_accuracy: 41.99%	lr:0.000071
Ep: 42/48	It: 1301/8134	batch_loss: 3.0446	batch_accuracy: 41.67%	lr:0.000071
Ep: 42/48	It: 1351/8134	batch_loss: 3.0950	batch_accuracy: 40.99%	lr:0.000070
Ep: 42/48	It: 1401/8134	batch_loss: 2.9854	batch_accuracy: 41.97%	lr:0.000070
Ep: 42/48	It: 1451/8134	batch_loss: 3.1296	batch_accuracy: 40.06%	lr:0.000070
Ep: 42/48	It: 1501/8134	batch_loss: 2.9706	batch_accuracy: 42.65%	lr:0.000070
Ep: 42/48	It: 1551/8134	batch_loss: 3.0013	batch_accuracy: 42.33%	lr:0.000070
Ep: 42/48	It: 1601/8134	batch_loss: 3.0312	batch_accuracy: 40.75%	lr:0.000070
Ep: 42/48	It: 1651/8134	batch_loss: 2.8808	batch_accuracy: 43.70%	lr:0.000070
Ep: 42/48	It: 1701/8134	batch_loss: 3.1446	batch_accuracy: 40.65%	lr:0.000070
Ep: 42/48	It: 1751/8134	batch_loss: 3.1498	batch_accuracy: 40.94%	lr:0.000070
Ep: 42/48	It: 1801/8134	batch_loss: 3.0304	batch_accuracy: 41.24%	lr:0.000069
Ep: 42/48	It: 1851/8134	batch_loss: 3.0811	batch_accuracy: 41.60%	lr:0.000069
Ep: 42/48	It: 1901/8134	batch_loss: 3.0816	batch_accuracy: 40.62%	lr:0.000069
Ep: 42/48	It: 1951/8134	batch_loss: 2.9528	batch_accuracy: 43.29%	lr:0.000069
Ep: 42/48	It: 2001/8134	batch_loss: 3.0359	batch_accuracy: 41.70%	lr:0.000069
Ep: 42/48	It: 2051/8134	batch_loss: 3.0571	batch_accuracy: 41.46%	lr:0.000069
Ep: 42/48	It: 2101/8134	batch_loss: 3.0383	batch_accuracy: 42.53%	lr:0.000069
Ep: 42/48	It: 2151/8134	batch_loss: 2.9629	batch_accuracy: 42.58%	lr:0.000069
Ep: 42/48	It: 2201/8134	batch_loss: 2.9607	batch_accuracy: 43.02%	lr:0.000069
Ep: 42/48	It: 2251/8134	batch_loss: 3.0507	batch_accuracy: 42.04%	lr:0.000069
Ep: 42/48	It: 2301/8134	batch_loss: 2.9520	batch_accuracy: 42.65%	lr:0.000068
Ep: 42/48	It: 2351/8134	batch_loss: 3.1641	batch_accuracy: 40.06%	lr:0.000068
Ep: 42/48	It: 2401/8134	batch_loss: 2.8846	batch_accuracy: 43.63%	lr:0.000068
Ep: 42/48	It: 2451/8134	batch_loss: 3.1428	batch_accuracy: 39.84%	lr:0.000068
Ep: 42/48	It: 2501/8134	batch_loss: 3.1364	batch_accuracy: 39.67%	lr:0.000068
Ep: 42/48	It: 2551/8134	batch_loss: 3.0280	batch_accuracy: 40.84%	lr:0.000068
Ep: 42/48	It: 2601/8134	batch_loss: 3.0047	batch_accuracy: 43.02%	lr:0.000068
Ep: 42/48	It: 2651/8134	batch_loss: 2.9866	batch_accuracy: 40.55%	lr:0.000068
Ep: 42/48	It: 2701/8134	batch_loss: 3.0510	batch_accuracy: 41.38%	lr:0.000068
Ep: 42/48	It: 2751/8134	batch_loss: 3.1091	batch_accuracy: 40.50%	lr:0.000067
Ep: 42/48	It: 2801/8134	batch_loss: 2.9860	batch_accuracy: 42.41%	lr:0.000067
Ep: 42/48	It: 2851/8134	batch_loss: 2.9769	batch_accuracy: 42.70%	lr:0.000067
Ep: 42/48	It: 2901/8134	batch_loss: 3.0172	batch_accuracy: 42.02%	lr:0.000067
Ep: 42/48	It: 2951/8134	batch_loss: 3.1263	batch_accuracy: 39.77%	lr:0.000067
Ep: 42/48	It: 3001/8134	batch_loss: 3.0101	batch_accuracy: 43.09%	lr:0.000067
Ep: 42/48	It: 3051/8134	batch_loss: 3.0650	batch_accuracy: 42.07%	lr:0.000067
Ep: 42/48	It: 3101/8134	batch_loss: 3.1163	batch_accuracy: 41.46%	lr:0.000067
Ep: 42/48	It: 3151/8134	batch_loss: 3.0331	batch_accuracy: 42.04%	lr:0.000067
Ep: 42/48	It: 3201/8134	batch_loss: 3.0523	batch_accuracy: 41.48%	lr:0.000067
Ep: 42/48	It: 3251/8134	batch_loss: 2.9944	batch_accuracy: 43.04%	lr:0.000066
Ep: 42/48	It: 3301/8134	batch_loss: 2.9461	batch_accuracy: 43.77%	lr:0.000066
Ep: 42/48	It: 3351/8134	batch_loss: 3.0794	batch_accuracy: 40.70%	lr:0.000066
Ep: 42/48	It: 3401/8134	batch_loss: 3.0115	batch_accuracy: 42.82%	lr:0.000066
Ep: 42/48	It: 3451/8134	batch_loss: 3.0124	batch_accuracy: 42.36%	lr:0.000066
Ep: 42/48	It: 3501/8134	batch_loss: 2.9992	batch_accuracy: 42.41%	lr:0.000066
Ep: 42/48	It: 3551/8134	batch_loss: 2.9692	batch_accuracy: 43.33%	lr:0.000066
Ep: 42/48	It: 3601/8134	batch_loss: 3.1099	batch_accuracy: 40.43%	lr:0.000066
Ep: 42/48	It: 3651/8134	batch_loss: 3.0673	batch_accuracy: 41.36%	lr:0.000066
Ep: 42/48	It: 3701/8134	batch_loss: 3.0946	batch_accuracy: 40.80%	lr:0.000066
Ep: 42/48	It: 3751/8134	batch_loss: 3.0525	batch_accuracy: 41.46%	lr:0.000065
Ep: 42/48	It: 3801/8134	batch_loss: 2.9237	batch_accuracy: 42.24%	lr:0.000065
Ep: 42/48	It: 3851/8134	batch_loss: 3.1499	batch_accuracy: 39.33%	lr:0.000065
Ep: 42/48	It: 3901/8134	batch_loss: 2.9164	batch_accuracy: 43.04%	lr:0.000065
Ep: 42/48	It: 3951/8134	batch_loss: 2.8484	batch_accuracy: 44.92%	lr:0.000065
Ep: 42/48	It: 4001/8134	batch_loss: 3.0055	batch_accuracy: 42.14%	lr:0.000065
Ep: 42/48	It: 4051/8134	batch_loss: 3.0184	batch_accuracy: 41.99%	lr:0.000065
Ep: 42/48	It: 4101/8134	batch_loss: 3.0397	batch_accuracy: 41.41%	lr:0.000065
Ep: 42/48	It: 4151/8134	batch_loss: 3.0638	batch_accuracy: 41.11%	lr:0.000065
Ep: 42/48	It: 4201/8134	batch_loss: 3.0709	batch_accuracy: 40.60%	lr:0.000065
Ep: 42/48	It: 4251/8134	batch_loss: 3.0059	batch_accuracy: 42.24%	lr:0.000064
Ep: 42/48	It: 4301/8134	batch_loss: 3.0549	batch_accuracy: 40.97%	lr:0.000064
Ep: 42/48	It: 4351/8134	batch_loss: 3.0870	batch_accuracy: 41.19%	lr:0.000064
Ep: 42/48	It: 4401/8134	batch_loss: 3.0590	batch_accuracy: 40.33%	lr:0.000064
Ep: 42/48	It: 4451/8134	batch_loss: 2.9623	batch_accuracy: 42.99%	lr:0.000064
Ep: 42/48	It: 4501/8134	batch_loss: 2.9459	batch_accuracy: 41.94%	lr:0.000064
Ep: 42/48	It: 4551/8134	batch_loss: 3.0242	batch_accuracy: 42.02%	lr:0.000064
Ep: 42/48	It: 4601/8134	batch_loss: 3.1789	batch_accuracy: 40.23%	lr:0.000064
Ep: 42/48	It: 4651/8134	batch_loss: 2.9891	batch_accuracy: 42.72%	lr:0.000064
Ep: 42/48	It: 4701/8134	batch_loss: 3.0350	batch_accuracy: 42.07%	lr:0.000063
Ep: 42/48	It: 4751/8134	batch_loss: 2.9392	batch_accuracy: 44.09%	lr:0.000063
Ep: 42/48	It: 4801/8134	batch_loss: 3.0047	batch_accuracy: 42.38%	lr:0.000063
Ep: 42/48	It: 4851/8134	batch_loss: 2.9709	batch_accuracy: 42.70%	lr:0.000063
Ep: 42/48	It: 4901/8134	batch_loss: 3.1243	batch_accuracy: 41.94%	lr:0.000063
Ep: 42/48	It: 4951/8134	batch_loss: 3.0283	batch_accuracy: 41.99%	lr:0.000063
Ep: 42/48	It: 5001/8134	batch_loss: 2.9825	batch_accuracy: 41.55%	lr:0.000063
Ep: 42/48	It: 5051/8134	batch_loss: 3.1201	batch_accuracy: 40.53%	lr:0.000063
Ep: 42/48	It: 5101/8134	batch_loss: 2.9484	batch_accuracy: 42.04%	lr:0.000063
Ep: 42/48	It: 5151/8134	batch_loss: 2.9663	batch_accuracy: 42.11%	lr:0.000063
Ep: 42/48	It: 5201/8134	batch_loss: 3.0252	batch_accuracy: 42.24%	lr:0.000062
Ep: 42/48	It: 5251/8134	batch_loss: 2.9864	batch_accuracy: 41.89%	lr:0.000062
Ep: 42/48	It: 5301/8134	batch_loss: 3.0449	batch_accuracy: 41.43%	lr:0.000062
Ep: 42/48	It: 5351/8134	batch_loss: 2.8899	batch_accuracy: 44.56%	lr:0.000062
Ep: 42/48	It: 5401/8134	batch_loss: 2.9825	batch_accuracy: 42.24%	lr:0.000062
Ep: 42/48	It: 5451/8134	batch_loss: 3.0028	batch_accuracy: 42.38%	lr:0.000062
Ep: 42/48	It: 5501/8134	batch_loss: 3.0597	batch_accuracy: 41.85%	lr:0.000062
Ep: 42/48	It: 5551/8134	batch_loss: 3.0535	batch_accuracy: 41.99%	lr:0.000062
Ep: 42/48	It: 5601/8134	batch_loss: 2.9832	batch_accuracy: 42.09%	lr:0.000062
Ep: 42/48	It: 5651/8134	batch_loss: 2.9303	batch_accuracy: 43.95%	lr:0.000062
Ep: 42/48	It: 5701/8134	batch_loss: 3.0860	batch_accuracy: 40.65%	lr:0.000062
Ep: 42/48	It: 5751/8134	batch_loss: 3.1436	batch_accuracy: 40.26%	lr:0.000061
Ep: 42/48	It: 5801/8134	batch_loss: 2.9217	batch_accuracy: 43.97%	lr:0.000061
Ep: 42/48	It: 5851/8134	batch_loss: 3.0243	batch_accuracy: 40.84%	lr:0.000061
Ep: 42/48	It: 5901/8134	batch_loss: 2.9657	batch_accuracy: 43.38%	lr:0.000061
Ep: 42/48	It: 5951/8134	batch_loss: 2.9526	batch_accuracy: 41.99%	lr:0.000061
Ep: 42/48	It: 6001/8134	batch_loss: 3.0562	batch_accuracy: 40.75%	lr:0.000061
Ep: 42/48	It: 6051/8134	batch_loss: 2.9736	batch_accuracy: 41.94%	lr:0.000061
Ep: 42/48	It: 6101/8134	batch_loss: 3.0721	batch_accuracy: 40.62%	lr:0.000061
Ep: 42/48	It: 6151/8134	batch_loss: 3.0268	batch_accuracy: 41.36%	lr:0.000061
Ep: 42/48	It: 6201/8134	batch_loss: 3.0264	batch_accuracy: 41.43%	lr:0.000061
Ep: 42/48	It: 6251/8134	batch_loss: 2.9708	batch_accuracy: 42.16%	lr:0.000060
Ep: 42/48	It: 6301/8134	batch_loss: 2.9807	batch_accuracy: 42.21%	lr:0.000060
Ep: 42/48	It: 6351/8134	batch_loss: 2.9131	batch_accuracy: 43.12%	lr:0.000060
Ep: 42/48	It: 6401/8134	batch_loss: 2.9577	batch_accuracy: 43.09%	lr:0.000060
Ep: 42/48	It: 6451/8134	batch_loss: 3.2422	batch_accuracy: 38.77%	lr:0.000060
Ep: 42/48	It: 6501/8134	batch_loss: 3.0313	batch_accuracy: 41.14%	lr:0.000060
Ep: 42/48	It: 6551/8134	batch_loss: 3.1628	batch_accuracy: 40.28%	lr:0.000060
Ep: 42/48	It: 6601/8134	batch_loss: 2.9864	batch_accuracy: 42.46%	lr:0.000060
Ep: 42/48	It: 6651/8134	batch_loss: 3.0497	batch_accuracy: 40.99%	lr:0.000060
Ep: 42/48	It: 6701/8134	batch_loss: 3.0943	batch_accuracy: 40.36%	lr:0.000060
Ep: 42/48	It: 6751/8134	batch_loss: 3.0433	batch_accuracy: 41.02%	lr:0.000059
Ep: 42/48	It: 6801/8134	batch_loss: 2.9138	batch_accuracy: 42.99%	lr:0.000059
Ep: 42/48	It: 6851/8134	batch_loss: 2.9918	batch_accuracy: 43.55%	lr:0.000059
Ep: 42/48	It: 6901/8134	batch_loss: 3.0750	batch_accuracy: 41.26%	lr:0.000059
Ep: 42/48	It: 6951/8134	batch_loss: 2.9519	batch_accuracy: 43.14%	lr:0.000059
Ep: 42/48	It: 7001/8134	batch_loss: 3.0979	batch_accuracy: 40.01%	lr:0.000059
Ep: 42/48	It: 7051/8134	batch_loss: 3.0322	batch_accuracy: 41.55%	lr:0.000059
Ep: 42/48	It: 7101/8134	batch_loss: 3.0487	batch_accuracy: 42.48%	lr:0.000059
Ep: 42/48	It: 7151/8134	batch_loss: 3.0447	batch_accuracy: 41.38%	lr:0.000059
Ep: 42/48	It: 7201/8134	batch_loss: 3.0911	batch_accuracy: 41.16%	lr:0.000059
Ep: 42/48	It: 7251/8134	batch_loss: 3.0920	batch_accuracy: 40.82%	lr:0.000058
Ep: 42/48	It: 7301/8134	batch_loss: 2.9628	batch_accuracy: 43.31%	lr:0.000058
Ep: 42/48	It: 7351/8134	batch_loss: 2.9365	batch_accuracy: 43.12%	lr:0.000058
Ep: 42/48	It: 7401/8134	batch_loss: 2.9185	batch_accuracy: 42.87%	lr:0.000058
Ep: 42/48	It: 7451/8134	batch_loss: 3.0150	batch_accuracy: 41.21%	lr:0.000058
Ep: 42/48	It: 7501/8134	batch_loss: 2.9776	batch_accuracy: 41.87%	lr:0.000058
Ep: 42/48	It: 7551/8134	batch_loss: 3.0887	batch_accuracy: 41.60%	lr:0.000058
Ep: 42/48	It: 7601/8134	batch_loss: 2.9689	batch_accuracy: 42.53%	lr:0.000058
Ep: 42/48	It: 7651/8134	batch_loss: 3.1023	batch_accuracy: 41.02%	lr:0.000058
Ep: 42/48	It: 7701/8134	batch_loss: 3.0982	batch_accuracy: 41.72%	lr:0.000058
Ep: 42/48	It: 7751/8134	batch_loss: 3.0389	batch_accuracy: 42.33%	lr:0.000058
Ep: 42/48	It: 7801/8134	batch_loss: 2.9106	batch_accuracy: 43.97%	lr:0.000057
Ep: 42/48	It: 7851/8134	batch_loss: 3.0877	batch_accuracy: 40.28%	lr:0.000057
Ep: 42/48	It: 7901/8134	batch_loss: 3.0568	batch_accuracy: 41.87%	lr:0.000057
Ep: 42/48	It: 7951/8134	batch_loss: 3.0581	batch_accuracy: 42.11%	lr:0.000057
Ep: 42/48	It: 8001/8134	batch_loss: 3.0083	batch_accuracy: 42.58%	lr:0.000057
Ep: 42/48	It: 8051/8134	batch_loss: 2.9840	batch_accuracy: 41.82%	lr:0.000057
Ep: 42/48	It: 8101/8134	batch_loss: 3.0021	batch_accuracy: 42.11%	lr:0.000057
Ep: 42/48	It: 8134/8134	batch_loss: 3.1505	batch_accuracy: 40.08%	lr:0.000057


Generated text for input text "You" is:
You-NUVE) to theorize how to rely build up with theories, models, and simply theories of theories, and how theories are adapted. This article provides a brief overview of theories, and concludes with some suggestions.
<eot>
<sot>
A new algorithm for automatic determination of soil water properties

In this paper, we propose a new algorithm for extraction of soil water from soil water samples in a synthetic soil. The algorithm is based on the assumption that the soil water content is higher than the ground water content. The algorithm is based on the algorithm of a least squares, the least absolute error is -0.79. The algorithm can be used to estimate soil water content in a variety of scenarios.
<eot>
<sot>
The Effect of Soluble Lactic Acid on the Spermatogenesis of Breast Cancer Cells

In vitro tests of the spermatogonia, lactic acid bacteria (LAB) and lactic acid bacteria (LAB), have been performed in order to determine whether LAB and LAB should be used as markers of the germination of broiler chickens. The


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 43/48	It: 1/8134	batch_loss: 2.9742	batch_accuracy: 42.60%	lr:0.000057
Ep: 43/48	It: 51/8134	batch_loss: 3.0396	batch_accuracy: 41.31%	lr:0.000057
Ep: 43/48	It: 101/8134	batch_loss: 2.9776	batch_accuracy: 42.24%	lr:0.000057
Ep: 43/48	It: 151/8134	batch_loss: 3.0002	batch_accuracy: 41.89%	lr:0.000057
Ep: 43/48	It: 201/8134	batch_loss: 3.0901	batch_accuracy: 40.43%	lr:0.000056
Ep: 43/48	It: 251/8134	batch_loss: 3.0555	batch_accuracy: 41.46%	lr:0.000056
Ep: 43/48	It: 301/8134	batch_loss: 3.0361	batch_accuracy: 41.50%	lr:0.000056
Ep: 43/48	It: 351/8134	batch_loss: 3.0271	batch_accuracy: 40.89%	lr:0.000056
Ep: 43/48	It: 401/8134	batch_loss: 2.9860	batch_accuracy: 43.24%	lr:0.000056
Ep: 43/48	It: 451/8134	batch_loss: 3.2328	batch_accuracy: 38.75%	lr:0.000056
Ep: 43/48	It: 501/8134	batch_loss: 2.9536	batch_accuracy: 43.36%	lr:0.000056
Ep: 43/48	It: 551/8134	batch_loss: 3.1485	batch_accuracy: 40.67%	lr:0.000056
Ep: 43/48	It: 601/8134	batch_loss: 2.9382	batch_accuracy: 44.26%	lr:0.000056
Ep: 43/48	It: 651/8134	batch_loss: 3.0112	batch_accuracy: 42.82%	lr:0.000056
Ep: 43/48	It: 701/8134	batch_loss: 3.1028	batch_accuracy: 40.94%	lr:0.000055
Ep: 43/48	It: 751/8134	batch_loss: 2.9256	batch_accuracy: 42.92%	lr:0.000055
Ep: 43/48	It: 801/8134	batch_loss: 3.0388	batch_accuracy: 41.50%	lr:0.000055
Ep: 43/48	It: 851/8134	batch_loss: 3.0130	batch_accuracy: 42.43%	lr:0.000055
Ep: 43/48	It: 901/8134	batch_loss: 3.1004	batch_accuracy: 41.38%	lr:0.000055
Ep: 43/48	It: 951/8134	batch_loss: 2.8907	batch_accuracy: 44.04%	lr:0.000055
Ep: 43/48	It: 1001/8134	batch_loss: 3.0003	batch_accuracy: 42.31%	lr:0.000055
Ep: 43/48	It: 1051/8134	batch_loss: 2.9950	batch_accuracy: 41.80%	lr:0.000055
Ep: 43/48	It: 1101/8134	batch_loss: 3.1152	batch_accuracy: 40.94%	lr:0.000055
Ep: 43/48	It: 1151/8134	batch_loss: 3.0648	batch_accuracy: 41.24%	lr:0.000055
Ep: 43/48	It: 1201/8134	batch_loss: 3.0241	batch_accuracy: 40.92%	lr:0.000055
Ep: 43/48	It: 1251/8134	batch_loss: 2.9418	batch_accuracy: 42.38%	lr:0.000054
Ep: 43/48	It: 1301/8134	batch_loss: 3.1548	batch_accuracy: 39.55%	lr:0.000054
Ep: 43/48	It: 1351/8134	batch_loss: 3.1221	batch_accuracy: 40.16%	lr:0.000054
Ep: 43/48	It: 1401/8134	batch_loss: 3.0328	batch_accuracy: 41.48%	lr:0.000054
Ep: 43/48	It: 1451/8134	batch_loss: 3.1337	batch_accuracy: 40.70%	lr:0.000054
Ep: 43/48	It: 1501/8134	batch_loss: 2.9725	batch_accuracy: 42.77%	lr:0.000054
Ep: 43/48	It: 1551/8134	batch_loss: 3.1485	batch_accuracy: 39.50%	lr:0.000054
Ep: 43/48	It: 1601/8134	batch_loss: 3.1054	batch_accuracy: 40.04%	lr:0.000054
Ep: 43/48	It: 1651/8134	batch_loss: 3.0325	batch_accuracy: 42.16%	lr:0.000054
Ep: 43/48	It: 1701/8134	batch_loss: 2.9753	batch_accuracy: 41.50%	lr:0.000054
Ep: 43/48	It: 1751/8134	batch_loss: 2.9618	batch_accuracy: 42.26%	lr:0.000054
Ep: 43/48	It: 1801/8134	batch_loss: 3.0741	batch_accuracy: 41.19%	lr:0.000053
Ep: 43/48	It: 1851/8134	batch_loss: 3.0650	batch_accuracy: 41.43%	lr:0.000053
Ep: 43/48	It: 1901/8134	batch_loss: 2.9848	batch_accuracy: 41.41%	lr:0.000053
Ep: 43/48	It: 1951/8134	batch_loss: 2.9570	batch_accuracy: 43.21%	lr:0.000053
Ep: 43/48	It: 2001/8134	batch_loss: 3.0009	batch_accuracy: 40.67%	lr:0.000053
Ep: 43/48	It: 2051/8134	batch_loss: 3.0161	batch_accuracy: 41.89%	lr:0.000053
Ep: 43/48	It: 2101/8134	batch_loss: 2.9872	batch_accuracy: 42.53%	lr:0.000053
Ep: 43/48	It: 2151/8134	batch_loss: 2.9835	batch_accuracy: 43.31%	lr:0.000053
Ep: 43/48	It: 2201/8134	batch_loss: 3.0097	batch_accuracy: 41.02%	lr:0.000053
Ep: 43/48	It: 2251/8134	batch_loss: 3.0381	batch_accuracy: 41.02%	lr:0.000053
Ep: 43/48	It: 2301/8134	batch_loss: 3.0667	batch_accuracy: 40.72%	lr:0.000053
Ep: 43/48	It: 2351/8134	batch_loss: 2.9830	batch_accuracy: 41.80%	lr:0.000052
Ep: 43/48	It: 2401/8134	batch_loss: 3.0309	batch_accuracy: 42.60%	lr:0.000052
Ep: 43/48	It: 2451/8134	batch_loss: 3.0625	batch_accuracy: 40.77%	lr:0.000052
Ep: 43/48	It: 2501/8134	batch_loss: 2.8844	batch_accuracy: 42.60%	lr:0.000052
Ep: 43/48	It: 2551/8134	batch_loss: 3.0128	batch_accuracy: 42.85%	lr:0.000052
Ep: 43/48	It: 2601/8134	batch_loss: 2.9595	batch_accuracy: 42.43%	lr:0.000052
Ep: 43/48	It: 2651/8134	batch_loss: 3.1762	batch_accuracy: 40.26%	lr:0.000052
Ep: 43/48	It: 2701/8134	batch_loss: 2.9388	batch_accuracy: 42.31%	lr:0.000052
Ep: 43/48	It: 2751/8134	batch_loss: 3.0484	batch_accuracy: 41.99%	lr:0.000052
Ep: 43/48	It: 2801/8134	batch_loss: 3.0437	batch_accuracy: 41.60%	lr:0.000052
Ep: 43/48	It: 2851/8134	batch_loss: 3.0995	batch_accuracy: 39.79%	lr:0.000052
Ep: 43/48	It: 2901/8134	batch_loss: 3.0107	batch_accuracy: 40.82%	lr:0.000051
Ep: 43/48	It: 2951/8134	batch_loss: 3.1516	batch_accuracy: 40.77%	lr:0.000051
Ep: 43/48	It: 3001/8134	batch_loss: 2.9421	batch_accuracy: 42.46%	lr:0.000051
Ep: 43/48	It: 3051/8134	batch_loss: 3.0894	batch_accuracy: 41.09%	lr:0.000051
Ep: 43/48	It: 3101/8134	batch_loss: 2.8977	batch_accuracy: 44.09%	lr:0.000051
Ep: 43/48	It: 3151/8134	batch_loss: 3.0642	batch_accuracy: 41.31%	lr:0.000051
Ep: 43/48	It: 3201/8134	batch_loss: 3.1173	batch_accuracy: 40.80%	lr:0.000051
Ep: 43/48	It: 3251/8134	batch_loss: 3.1109	batch_accuracy: 40.72%	lr:0.000051
Ep: 43/48	It: 3301/8134	batch_loss: 2.9790	batch_accuracy: 42.48%	lr:0.000051
Ep: 43/48	It: 3351/8134	batch_loss: 3.0973	batch_accuracy: 40.70%	lr:0.000051
Ep: 43/48	It: 3401/8134	batch_loss: 2.9601	batch_accuracy: 41.94%	lr:0.000051
Ep: 43/48	It: 3451/8134	batch_loss: 2.8850	batch_accuracy: 43.41%	lr:0.000051
Ep: 43/48	It: 3501/8134	batch_loss: 3.0429	batch_accuracy: 40.31%	lr:0.000050
Ep: 43/48	It: 3551/8134	batch_loss: 2.9863	batch_accuracy: 42.97%	lr:0.000050
Ep: 43/48	It: 3601/8134	batch_loss: 3.1030	batch_accuracy: 40.04%	lr:0.000050
Ep: 43/48	It: 3651/8134	batch_loss: 2.9630	batch_accuracy: 42.29%	lr:0.000050
Ep: 43/48	It: 3701/8134	batch_loss: 2.9834	batch_accuracy: 42.33%	lr:0.000050
Ep: 43/48	It: 3751/8134	batch_loss: 3.0507	batch_accuracy: 41.67%	lr:0.000050
Ep: 43/48	It: 3801/8134	batch_loss: 3.0510	batch_accuracy: 41.28%	lr:0.000050
Ep: 43/48	It: 3851/8134	batch_loss: 2.9873	batch_accuracy: 42.94%	lr:0.000050
Ep: 43/48	It: 3901/8134	batch_loss: 3.1038	batch_accuracy: 40.72%	lr:0.000050
Ep: 43/48	It: 3951/8134	batch_loss: 3.0900	batch_accuracy: 40.53%	lr:0.000050
Ep: 43/48	It: 4001/8134	batch_loss: 2.9972	batch_accuracy: 41.77%	lr:0.000050
Ep: 43/48	It: 4051/8134	batch_loss: 2.9980	batch_accuracy: 42.16%	lr:0.000049
Ep: 43/48	It: 4101/8134	batch_loss: 3.1524	batch_accuracy: 39.79%	lr:0.000049
Ep: 43/48	It: 4151/8134	batch_loss: 3.1613	batch_accuracy: 40.94%	lr:0.000049
Ep: 43/48	It: 4201/8134	batch_loss: 2.9766	batch_accuracy: 42.63%	lr:0.000049
Ep: 43/48	It: 4251/8134	batch_loss: 3.0238	batch_accuracy: 42.97%	lr:0.000049
Ep: 43/48	It: 4301/8134	batch_loss: 3.0073	batch_accuracy: 41.80%	lr:0.000049
Ep: 43/48	It: 4351/8134	batch_loss: 2.9778	batch_accuracy: 41.92%	lr:0.000049
Ep: 43/48	It: 4401/8134	batch_loss: 3.1155	batch_accuracy: 40.75%	lr:0.000049
Ep: 43/48	It: 4451/8134	batch_loss: 2.9277	batch_accuracy: 43.85%	lr:0.000049
Ep: 43/48	It: 4501/8134	batch_loss: 3.0129	batch_accuracy: 41.55%	lr:0.000049
Ep: 43/48	It: 4551/8134	batch_loss: 2.9927	batch_accuracy: 42.24%	lr:0.000049
Ep: 43/48	It: 4601/8134	batch_loss: 2.9677	batch_accuracy: 42.99%	lr:0.000049
Ep: 43/48	It: 4651/8134	batch_loss: 3.0374	batch_accuracy: 42.38%	lr:0.000048
Ep: 43/48	It: 4701/8134	batch_loss: 3.1041	batch_accuracy: 40.62%	lr:0.000048
Ep: 43/48	It: 4751/8134	batch_loss: 3.0253	batch_accuracy: 41.53%	lr:0.000048
Ep: 43/48	It: 4801/8134	batch_loss: 3.1078	batch_accuracy: 41.63%	lr:0.000048
Ep: 43/48	It: 4851/8134	batch_loss: 3.1277	batch_accuracy: 40.43%	lr:0.000048
Ep: 43/48	It: 4901/8134	batch_loss: 3.0679	batch_accuracy: 41.38%	lr:0.000048
Ep: 43/48	It: 4951/8134	batch_loss: 3.1147	batch_accuracy: 40.92%	lr:0.000048
Ep: 43/48	It: 5001/8134	batch_loss: 3.0736	batch_accuracy: 41.85%	lr:0.000048
Ep: 43/48	It: 5051/8134	batch_loss: 3.0685	batch_accuracy: 41.70%	lr:0.000048
Ep: 43/48	It: 5101/8134	batch_loss: 3.0709	batch_accuracy: 40.36%	lr:0.000048
Ep: 43/48	It: 5151/8134	batch_loss: 3.0971	batch_accuracy: 40.65%	lr:0.000048
Ep: 43/48	It: 5201/8134	batch_loss: 3.1110	batch_accuracy: 40.75%	lr:0.000047
Ep: 43/48	It: 5251/8134	batch_loss: 3.0468	batch_accuracy: 41.63%	lr:0.000047
Ep: 43/48	It: 5301/8134	batch_loss: 3.1362	batch_accuracy: 40.23%	lr:0.000047
Ep: 43/48	It: 5351/8134	batch_loss: 2.9132	batch_accuracy: 42.46%	lr:0.000047
Ep: 43/48	It: 5401/8134	batch_loss: 3.0742	batch_accuracy: 41.63%	lr:0.000047
Ep: 43/48	It: 5451/8134	batch_loss: 3.0315	batch_accuracy: 41.26%	lr:0.000047
Ep: 43/48	It: 5501/8134	batch_loss: 3.0858	batch_accuracy: 41.70%	lr:0.000047
Ep: 43/48	It: 5551/8134	batch_loss: 3.0924	batch_accuracy: 41.24%	lr:0.000047
Ep: 43/48	It: 5601/8134	batch_loss: 3.0390	batch_accuracy: 41.06%	lr:0.000047
Ep: 43/48	It: 5651/8134	batch_loss: 2.9103	batch_accuracy: 44.34%	lr:0.000047
Ep: 43/48	It: 5701/8134	batch_loss: 3.0610	batch_accuracy: 41.58%	lr:0.000047
Ep: 43/48	It: 5751/8134	batch_loss: 3.0716	batch_accuracy: 41.72%	lr:0.000047
Ep: 43/48	It: 5801/8134	batch_loss: 2.9899	batch_accuracy: 41.89%	lr:0.000046
Ep: 43/48	It: 5851/8134	batch_loss: 2.9235	batch_accuracy: 43.46%	lr:0.000046
Ep: 43/48	It: 5901/8134	batch_loss: 3.0574	batch_accuracy: 42.31%	lr:0.000046
Ep: 43/48	It: 5951/8134	batch_loss: 2.9365	batch_accuracy: 43.21%	lr:0.000046
Ep: 43/48	It: 6001/8134	batch_loss: 3.0226	batch_accuracy: 42.87%	lr:0.000046
Ep: 43/48	It: 6051/8134	batch_loss: 2.9928	batch_accuracy: 42.36%	lr:0.000046
Ep: 43/48	It: 6101/8134	batch_loss: 3.0215	batch_accuracy: 41.06%	lr:0.000046
Ep: 43/48	It: 6151/8134	batch_loss: 3.0624	batch_accuracy: 41.72%	lr:0.000046
Ep: 43/48	It: 6201/8134	batch_loss: 3.0561	batch_accuracy: 41.72%	lr:0.000046
Ep: 43/48	It: 6251/8134	batch_loss: 3.1422	batch_accuracy: 41.09%	lr:0.000046
Ep: 43/48	It: 6301/8134	batch_loss: 3.1180	batch_accuracy: 40.04%	lr:0.000046
Ep: 43/48	It: 6351/8134	batch_loss: 3.1482	batch_accuracy: 40.01%	lr:0.000046
Ep: 43/48	It: 6401/8134	batch_loss: 2.9716	batch_accuracy: 42.94%	lr:0.000045
Ep: 43/48	It: 6451/8134	batch_loss: 2.9978	batch_accuracy: 42.16%	lr:0.000045
Ep: 43/48	It: 6501/8134	batch_loss: 2.9831	batch_accuracy: 43.29%	lr:0.000045
Ep: 43/48	It: 6551/8134	batch_loss: 3.0061	batch_accuracy: 42.58%	lr:0.000045
Ep: 43/48	It: 6601/8134	batch_loss: 3.0549	batch_accuracy: 40.67%	lr:0.000045
Ep: 43/48	It: 6651/8134	batch_loss: 3.0173	batch_accuracy: 42.19%	lr:0.000045
Ep: 43/48	It: 6701/8134	batch_loss: 3.0663	batch_accuracy: 41.21%	lr:0.000045
Ep: 43/48	It: 6751/8134	batch_loss: 3.1318	batch_accuracy: 40.77%	lr:0.000045
Ep: 43/48	It: 6801/8134	batch_loss: 3.0842	batch_accuracy: 40.92%	lr:0.000045
Ep: 43/48	It: 6851/8134	batch_loss: 2.9699	batch_accuracy: 42.43%	lr:0.000045
Ep: 43/48	It: 6901/8134	batch_loss: 2.9481	batch_accuracy: 42.21%	lr:0.000045
Ep: 43/48	It: 6951/8134	batch_loss: 3.0702	batch_accuracy: 40.62%	lr:0.000045
Ep: 43/48	It: 7001/8134	batch_loss: 3.1161	batch_accuracy: 40.11%	lr:0.000044
Ep: 43/48	It: 7051/8134	batch_loss: 3.0937	batch_accuracy: 39.94%	lr:0.000044
Ep: 43/48	It: 7101/8134	batch_loss: 3.0398	batch_accuracy: 41.60%	lr:0.000044
Ep: 43/48	It: 7151/8134	batch_loss: 3.0219	batch_accuracy: 42.09%	lr:0.000044
Ep: 43/48	It: 7201/8134	batch_loss: 3.0394	batch_accuracy: 42.70%	lr:0.000044
Ep: 43/48	It: 7251/8134	batch_loss: 2.9664	batch_accuracy: 43.07%	lr:0.000044
Ep: 43/48	It: 7301/8134	batch_loss: 2.9907	batch_accuracy: 42.11%	lr:0.000044
Ep: 43/48	It: 7351/8134	batch_loss: 3.1830	batch_accuracy: 39.75%	lr:0.000044
Ep: 43/48	It: 7401/8134	batch_loss: 2.9987	batch_accuracy: 41.43%	lr:0.000044
Ep: 43/48	It: 7451/8134	batch_loss: 3.0171	batch_accuracy: 42.41%	lr:0.000044
Ep: 43/48	It: 7501/8134	batch_loss: 3.0719	batch_accuracy: 41.80%	lr:0.000044
Ep: 43/48	It: 7551/8134	batch_loss: 3.0964	batch_accuracy: 40.87%	lr:0.000044
Ep: 43/48	It: 7601/8134	batch_loss: 2.9846	batch_accuracy: 41.94%	lr:0.000044
Ep: 43/48	It: 7651/8134	batch_loss: 3.1395	batch_accuracy: 39.99%	lr:0.000043
Ep: 43/48	It: 7701/8134	batch_loss: 2.9513	batch_accuracy: 42.58%	lr:0.000043
Ep: 43/48	It: 7751/8134	batch_loss: 3.0187	batch_accuracy: 42.77%	lr:0.000043
Ep: 43/48	It: 7801/8134	batch_loss: 2.9966	batch_accuracy: 43.24%	lr:0.000043
Ep: 43/48	It: 7851/8134	batch_loss: 3.1535	batch_accuracy: 40.19%	lr:0.000043
Ep: 43/48	It: 7901/8134	batch_loss: 3.0712	batch_accuracy: 42.24%	lr:0.000043
Ep: 43/48	It: 7951/8134	batch_loss: 3.0580	batch_accuracy: 40.70%	lr:0.000043
Ep: 43/48	It: 8001/8134	batch_loss: 3.0544	batch_accuracy: 41.99%	lr:0.000043
Ep: 43/48	It: 8051/8134	batch_loss: 2.9878	batch_accuracy: 42.48%	lr:0.000043
Ep: 43/48	It: 8101/8134	batch_loss: 2.8737	batch_accuracy: 43.80%	lr:0.000043
Ep: 43/48	It: 8134/8134	batch_loss: 2.9931	batch_accuracy: 43.48%	lr:0.000043


Generated text for input text "You" is:
Youh, and to theologians in thesis.
Arbaum, E E S T N A C T R O N S I A S R R E N P E E N O P E S A T E N A T U N T O S A C S I N N T I O N G E N T I A S I R A R I R A D S T I S I A C A C O T I R A N A C T I N T A C O R C U T I A C U T I R E F R A R A C A T I N G E F T A N A F S I R D U R E A C A C V I A F G E R E N S L I E S A C S E T R T E T E A C E S E C T W O N N T T E S I A S E L A R B E R E L S C O N N U S R C E O S T T N N I A T R O R T T N T S A M T S E C A C E S E S A C T T N G N E A S T H T S E R E N A


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 44/48	It: 1/8134	batch_loss: 3.0101	batch_accuracy: 41.75%	lr:0.000043
Ep: 44/48	It: 51/8134	batch_loss: 3.0319	batch_accuracy: 41.46%	lr:0.000043
Ep: 44/48	It: 101/8134	batch_loss: 3.1261	batch_accuracy: 41.82%	lr:0.000043
Ep: 44/48	It: 151/8134	batch_loss: 3.0651	batch_accuracy: 41.14%	lr:0.000042
Ep: 44/48	It: 201/8134	batch_loss: 3.0587	batch_accuracy: 40.38%	lr:0.000042
Ep: 44/48	It: 251/8134	batch_loss: 3.0814	batch_accuracy: 41.11%	lr:0.000042
Ep: 44/48	It: 301/8134	batch_loss: 3.0649	batch_accuracy: 42.02%	lr:0.000042
Ep: 44/48	It: 351/8134	batch_loss: 2.9915	batch_accuracy: 41.82%	lr:0.000042
Ep: 44/48	It: 401/8134	batch_loss: 2.9854	batch_accuracy: 42.87%	lr:0.000042
Ep: 44/48	It: 451/8134	batch_loss: 3.0189	batch_accuracy: 42.48%	lr:0.000042
Ep: 44/48	It: 501/8134	batch_loss: 3.0127	batch_accuracy: 42.21%	lr:0.000042
Ep: 44/48	It: 551/8134	batch_loss: 2.9898	batch_accuracy: 42.04%	lr:0.000042
Ep: 44/48	It: 601/8134	batch_loss: 3.0392	batch_accuracy: 42.09%	lr:0.000042
Ep: 44/48	It: 651/8134	batch_loss: 2.9609	batch_accuracy: 42.53%	lr:0.000042
Ep: 44/48	It: 701/8134	batch_loss: 3.0870	batch_accuracy: 41.63%	lr:0.000042
Ep: 44/48	It: 751/8134	batch_loss: 3.0242	batch_accuracy: 41.67%	lr:0.000041
Ep: 44/48	It: 801/8134	batch_loss: 3.0125	batch_accuracy: 41.97%	lr:0.000041
Ep: 44/48	It: 851/8134	batch_loss: 3.0806	batch_accuracy: 41.04%	lr:0.000041
Ep: 44/48	It: 901/8134	batch_loss: 3.0670	batch_accuracy: 41.87%	lr:0.000041
Ep: 44/48	It: 951/8134	batch_loss: 3.1370	batch_accuracy: 40.04%	lr:0.000041
Ep: 44/48	It: 1001/8134	batch_loss: 3.0103	batch_accuracy: 42.36%	lr:0.000041
Ep: 44/48	It: 1051/8134	batch_loss: 2.8794	batch_accuracy: 44.14%	lr:0.000041
Ep: 44/48	It: 1101/8134	batch_loss: 3.0388	batch_accuracy: 41.50%	lr:0.000041
Ep: 44/48	It: 1151/8134	batch_loss: 3.1180	batch_accuracy: 41.63%	lr:0.000041
Ep: 44/48	It: 1201/8134	batch_loss: 3.1230	batch_accuracy: 40.38%	lr:0.000041
Ep: 44/48	It: 1251/8134	batch_loss: 3.0956	batch_accuracy: 40.33%	lr:0.000041
Ep: 44/48	It: 1301/8134	batch_loss: 2.9785	batch_accuracy: 42.50%	lr:0.000041
Ep: 44/48	It: 1351/8134	batch_loss: 3.1632	batch_accuracy: 40.62%	lr:0.000041
Ep: 44/48	It: 1401/8134	batch_loss: 3.0281	batch_accuracy: 41.41%	lr:0.000040
Ep: 44/48	It: 1451/8134	batch_loss: 3.0455	batch_accuracy: 40.60%	lr:0.000040
Ep: 44/48	It: 1501/8134	batch_loss: 2.9816	batch_accuracy: 42.87%	lr:0.000040
Ep: 44/48	It: 1551/8134	batch_loss: 3.0250	batch_accuracy: 42.46%	lr:0.000040
Ep: 44/48	It: 1601/8134	batch_loss: 3.0247	batch_accuracy: 42.72%	lr:0.000040
Ep: 44/48	It: 1651/8134	batch_loss: 2.9951	batch_accuracy: 41.24%	lr:0.000040
Ep: 44/48	It: 1701/8134	batch_loss: 3.0484	batch_accuracy: 41.55%	lr:0.000040
Ep: 44/48	It: 1751/8134	batch_loss: 2.9986	batch_accuracy: 42.07%	lr:0.000040
Ep: 44/48	It: 1801/8134	batch_loss: 3.0479	batch_accuracy: 41.36%	lr:0.000040
Ep: 44/48	It: 1851/8134	batch_loss: 3.0178	batch_accuracy: 42.24%	lr:0.000040
Ep: 44/48	It: 1901/8134	batch_loss: 3.0287	batch_accuracy: 41.48%	lr:0.000040
Ep: 44/48	It: 1951/8134	batch_loss: 2.9684	batch_accuracy: 42.70%	lr:0.000040
Ep: 44/48	It: 2001/8134	batch_loss: 3.0501	batch_accuracy: 41.26%	lr:0.000040
Ep: 44/48	It: 2051/8134	batch_loss: 2.9930	batch_accuracy: 41.14%	lr:0.000039
Ep: 44/48	It: 2101/8134	batch_loss: 3.0119	batch_accuracy: 41.82%	lr:0.000039
Ep: 44/48	It: 2151/8134	batch_loss: 3.0191	batch_accuracy: 41.36%	lr:0.000039
Ep: 44/48	It: 2201/8134	batch_loss: 3.0119	batch_accuracy: 41.89%	lr:0.000039
Ep: 44/48	It: 2251/8134	batch_loss: 3.1181	batch_accuracy: 40.84%	lr:0.000039
Ep: 44/48	It: 2301/8134	batch_loss: 2.9167	batch_accuracy: 43.55%	lr:0.000039
Ep: 44/48	It: 2351/8134	batch_loss: 2.9931	batch_accuracy: 41.41%	lr:0.000039
Ep: 44/48	It: 2401/8134	batch_loss: 3.0027	batch_accuracy: 41.94%	lr:0.000039
Ep: 44/48	It: 2451/8134	batch_loss: 2.9877	batch_accuracy: 42.48%	lr:0.000039
Ep: 44/48	It: 2501/8134	batch_loss: 2.8268	batch_accuracy: 44.60%	lr:0.000039
Ep: 44/48	It: 2551/8134	batch_loss: 3.0582	batch_accuracy: 40.58%	lr:0.000039
Ep: 44/48	It: 2601/8134	batch_loss: 3.0557	batch_accuracy: 42.04%	lr:0.000039
Ep: 44/48	It: 2651/8134	batch_loss: 3.1529	batch_accuracy: 39.62%	lr:0.000039
Ep: 44/48	It: 2701/8134	batch_loss: 3.0089	batch_accuracy: 41.87%	lr:0.000039
Ep: 44/48	It: 2751/8134	batch_loss: 3.1252	batch_accuracy: 40.19%	lr:0.000038
Ep: 44/48	It: 2801/8134	batch_loss: 2.9963	batch_accuracy: 42.60%	lr:0.000038
Ep: 44/48	It: 2851/8134	batch_loss: 2.9221	batch_accuracy: 43.14%	lr:0.000038
Ep: 44/48	It: 2901/8134	batch_loss: 3.0483	batch_accuracy: 41.04%	lr:0.000038
Ep: 44/48	It: 2951/8134	batch_loss: 3.0233	batch_accuracy: 42.24%	lr:0.000038
Ep: 44/48	It: 3001/8134	batch_loss: 2.9839	batch_accuracy: 44.21%	lr:0.000038
Ep: 44/48	It: 3051/8134	batch_loss: 2.9627	batch_accuracy: 43.12%	lr:0.000038
Ep: 44/48	It: 3101/8134	batch_loss: 2.9767	batch_accuracy: 42.87%	lr:0.000038
Ep: 44/48	It: 3151/8134	batch_loss: 3.1021	batch_accuracy: 41.48%	lr:0.000038
Ep: 44/48	It: 3201/8134	batch_loss: 3.0632	batch_accuracy: 41.19%	lr:0.000038
Ep: 44/48	It: 3251/8134	batch_loss: 3.0420	batch_accuracy: 42.75%	lr:0.000038
Ep: 44/48	It: 3301/8134	batch_loss: 3.0550	batch_accuracy: 41.60%	lr:0.000038
Ep: 44/48	It: 3351/8134	batch_loss: 3.0728	batch_accuracy: 40.48%	lr:0.000038
Ep: 44/48	It: 3401/8134	batch_loss: 2.9777	batch_accuracy: 42.41%	lr:0.000037
Ep: 44/48	It: 3451/8134	batch_loss: 2.9549	batch_accuracy: 42.50%	lr:0.000037
Ep: 44/48	It: 3501/8134	batch_loss: 3.0631	batch_accuracy: 41.46%	lr:0.000037
Ep: 44/48	It: 3551/8134	batch_loss: 3.0357	batch_accuracy: 43.12%	lr:0.000037
Ep: 44/48	It: 3601/8134	batch_loss: 2.9456	batch_accuracy: 43.12%	lr:0.000037
Ep: 44/48	It: 3651/8134	batch_loss: 2.9425	batch_accuracy: 42.33%	lr:0.000037
Ep: 44/48	It: 3701/8134	batch_loss: 2.9567	batch_accuracy: 43.24%	lr:0.000037
Ep: 44/48	It: 3751/8134	batch_loss: 3.1780	batch_accuracy: 39.87%	lr:0.000037
Ep: 44/48	It: 3801/8134	batch_loss: 3.0856	batch_accuracy: 39.82%	lr:0.000037
Ep: 44/48	It: 3851/8134	batch_loss: 3.0430	batch_accuracy: 42.60%	lr:0.000037
Ep: 44/48	It: 3901/8134	batch_loss: 2.9286	batch_accuracy: 43.04%	lr:0.000037
Ep: 44/48	It: 3951/8134	batch_loss: 3.1064	batch_accuracy: 40.92%	lr:0.000037
Ep: 44/48	It: 4001/8134	batch_loss: 3.0488	batch_accuracy: 41.28%	lr:0.000037
Ep: 44/48	It: 4051/8134	batch_loss: 3.0073	batch_accuracy: 41.87%	lr:0.000037
Ep: 44/48	It: 4101/8134	batch_loss: 2.9380	batch_accuracy: 43.70%	lr:0.000036
Ep: 44/48	It: 4151/8134	batch_loss: 3.0134	batch_accuracy: 42.14%	lr:0.000036
Ep: 44/48	It: 4201/8134	batch_loss: 2.9912	batch_accuracy: 42.55%	lr:0.000036
Ep: 44/48	It: 4251/8134	batch_loss: 3.1166	batch_accuracy: 39.67%	lr:0.000036
Ep: 44/48	It: 4301/8134	batch_loss: 3.0463	batch_accuracy: 42.70%	lr:0.000036
Ep: 44/48	It: 4351/8134	batch_loss: 3.0200	batch_accuracy: 42.72%	lr:0.000036
Ep: 44/48	It: 4401/8134	batch_loss: 2.9539	batch_accuracy: 42.99%	lr:0.000036
Ep: 44/48	It: 4451/8134	batch_loss: 3.1444	batch_accuracy: 41.48%	lr:0.000036
Ep: 44/48	It: 4501/8134	batch_loss: 3.0671	batch_accuracy: 41.63%	lr:0.000036
Ep: 44/48	It: 4551/8134	batch_loss: 2.9628	batch_accuracy: 42.21%	lr:0.000036
Ep: 44/48	It: 4601/8134	batch_loss: 2.9677	batch_accuracy: 42.77%	lr:0.000036
Ep: 44/48	It: 4651/8134	batch_loss: 3.1225	batch_accuracy: 40.77%	lr:0.000036
Ep: 44/48	It: 4701/8134	batch_loss: 3.0595	batch_accuracy: 41.63%	lr:0.000036
Ep: 44/48	It: 4751/8134	batch_loss: 3.0404	batch_accuracy: 42.04%	lr:0.000036
Ep: 44/48	It: 4801/8134	batch_loss: 3.0268	batch_accuracy: 41.87%	lr:0.000035
Ep: 44/48	It: 4851/8134	batch_loss: 3.0488	batch_accuracy: 41.14%	lr:0.000035
Ep: 44/48	It: 4901/8134	batch_loss: 3.0825	batch_accuracy: 40.92%	lr:0.000035
Ep: 44/48	It: 4951/8134	batch_loss: 3.1210	batch_accuracy: 40.99%	lr:0.000035
Ep: 44/48	It: 5001/8134	batch_loss: 3.0946	batch_accuracy: 41.55%	lr:0.000035
Ep: 44/48	It: 5051/8134	batch_loss: 3.0053	batch_accuracy: 43.21%	lr:0.000035
Ep: 44/48	It: 5101/8134	batch_loss: 3.1130	batch_accuracy: 40.23%	lr:0.000035
Ep: 44/48	It: 5151/8134	batch_loss: 2.9354	batch_accuracy: 42.90%	lr:0.000035
Ep: 44/48	It: 5201/8134	batch_loss: 3.0352	batch_accuracy: 41.16%	lr:0.000035
Ep: 44/48	It: 5251/8134	batch_loss: 3.0459	batch_accuracy: 41.09%	lr:0.000035
Ep: 44/48	It: 5301/8134	batch_loss: 3.0619	batch_accuracy: 41.04%	lr:0.000035
Ep: 44/48	It: 5351/8134	batch_loss: 2.9419	batch_accuracy: 42.36%	lr:0.000035
Ep: 44/48	It: 5401/8134	batch_loss: 3.0450	batch_accuracy: 40.99%	lr:0.000035
Ep: 44/48	It: 5451/8134	batch_loss: 2.9974	batch_accuracy: 42.31%	lr:0.000035
Ep: 44/48	It: 5501/8134	batch_loss: 3.1055	batch_accuracy: 40.53%	lr:0.000034
Ep: 44/48	It: 5551/8134	batch_loss: 3.0527	batch_accuracy: 41.58%	lr:0.000034
Ep: 44/48	It: 5601/8134	batch_loss: 3.1144	batch_accuracy: 41.09%	lr:0.000034
Ep: 44/48	It: 5651/8134	batch_loss: 2.9837	batch_accuracy: 42.29%	lr:0.000034
Ep: 44/48	It: 5701/8134	batch_loss: 2.9229	batch_accuracy: 43.33%	lr:0.000034
Ep: 44/48	It: 5751/8134	batch_loss: 2.9704	batch_accuracy: 42.50%	lr:0.000034
Ep: 44/48	It: 5801/8134	batch_loss: 3.1460	batch_accuracy: 40.19%	lr:0.000034
Ep: 44/48	It: 5851/8134	batch_loss: 3.0540	batch_accuracy: 41.14%	lr:0.000034
Ep: 44/48	It: 5901/8134	batch_loss: 3.0000	batch_accuracy: 43.02%	lr:0.000034
Ep: 44/48	It: 5951/8134	batch_loss: 3.0427	batch_accuracy: 41.36%	lr:0.000034
Ep: 44/48	It: 6001/8134	batch_loss: 3.0692	batch_accuracy: 40.45%	lr:0.000034
Ep: 44/48	It: 6051/8134	batch_loss: 2.9711	batch_accuracy: 43.53%	lr:0.000034
Ep: 44/48	It: 6101/8134	batch_loss: 3.0438	batch_accuracy: 41.58%	lr:0.000034
Ep: 44/48	It: 6151/8134	batch_loss: 2.9877	batch_accuracy: 42.65%	lr:0.000034
Ep: 44/48	It: 6201/8134	batch_loss: 2.9796	batch_accuracy: 42.90%	lr:0.000034
Ep: 44/48	It: 6251/8134	batch_loss: 3.0575	batch_accuracy: 41.92%	lr:0.000033
Ep: 44/48	It: 6301/8134	batch_loss: 2.9152	batch_accuracy: 44.38%	lr:0.000033
Ep: 44/48	It: 6351/8134	batch_loss: 3.1941	batch_accuracy: 40.19%	lr:0.000033
Ep: 44/48	It: 6401/8134	batch_loss: 3.1663	batch_accuracy: 39.67%	lr:0.000033
Ep: 44/48	It: 6451/8134	batch_loss: 3.0623	batch_accuracy: 41.38%	lr:0.000033
Ep: 44/48	It: 6501/8134	batch_loss: 3.1584	batch_accuracy: 40.06%	lr:0.000033
Ep: 44/48	It: 6551/8134	batch_loss: 2.9534	batch_accuracy: 43.12%	lr:0.000033
Ep: 44/48	It: 6601/8134	batch_loss: 3.0131	batch_accuracy: 42.21%	lr:0.000033
Ep: 44/48	It: 6651/8134	batch_loss: 3.0477	batch_accuracy: 42.41%	lr:0.000033
Ep: 44/48	It: 6701/8134	batch_loss: 3.1086	batch_accuracy: 40.60%	lr:0.000033
Ep: 44/48	It: 6751/8134	batch_loss: 2.9789	batch_accuracy: 43.07%	lr:0.000033
Ep: 44/48	It: 6801/8134	batch_loss: 3.0685	batch_accuracy: 40.87%	lr:0.000033
Ep: 44/48	It: 6851/8134	batch_loss: 2.9921	batch_accuracy: 42.33%	lr:0.000033
Ep: 44/48	It: 6901/8134	batch_loss: 2.9786	batch_accuracy: 43.60%	lr:0.000033
Ep: 44/48	It: 6951/8134	batch_loss: 3.0042	batch_accuracy: 43.24%	lr:0.000033
Ep: 44/48	It: 7001/8134	batch_loss: 3.0818	batch_accuracy: 42.41%	lr:0.000032
Ep: 44/48	It: 7051/8134	batch_loss: 3.0212	batch_accuracy: 42.85%	lr:0.000032
Ep: 44/48	It: 7101/8134	batch_loss: 3.1470	batch_accuracy: 40.31%	lr:0.000032
Ep: 44/48	It: 7151/8134	batch_loss: 3.0107	batch_accuracy: 41.89%	lr:0.000032
Ep: 44/48	It: 7201/8134	batch_loss: 2.9629	batch_accuracy: 42.94%	lr:0.000032
Ep: 44/48	It: 7251/8134	batch_loss: 3.1175	batch_accuracy: 40.89%	lr:0.000032
Ep: 44/48	It: 7301/8134	batch_loss: 3.1434	batch_accuracy: 39.14%	lr:0.000032
Ep: 44/48	It: 7351/8134	batch_loss: 3.0997	batch_accuracy: 41.50%	lr:0.000032
Ep: 44/48	It: 7401/8134	batch_loss: 3.0877	batch_accuracy: 40.58%	lr:0.000032
Ep: 44/48	It: 7451/8134	batch_loss: 2.9331	batch_accuracy: 44.19%	lr:0.000032
Ep: 44/48	It: 7501/8134	batch_loss: 3.0254	batch_accuracy: 42.26%	lr:0.000032
Ep: 44/48	It: 7551/8134	batch_loss: 3.0825	batch_accuracy: 41.16%	lr:0.000032
Ep: 44/48	It: 7601/8134	batch_loss: 3.0205	batch_accuracy: 41.97%	lr:0.000032
Ep: 44/48	It: 7651/8134	batch_loss: 2.8939	batch_accuracy: 44.07%	lr:0.000032
Ep: 44/48	It: 7701/8134	batch_loss: 2.9259	batch_accuracy: 44.21%	lr:0.000032
Ep: 44/48	It: 7751/8134	batch_loss: 3.1501	batch_accuracy: 40.26%	lr:0.000031
Ep: 44/48	It: 7801/8134	batch_loss: 3.0435	batch_accuracy: 40.53%	lr:0.000031
Ep: 44/48	It: 7851/8134	batch_loss: 2.9944	batch_accuracy: 42.29%	lr:0.000031
Ep: 44/48	It: 7901/8134	batch_loss: 3.0171	batch_accuracy: 41.21%	lr:0.000031
Ep: 44/48	It: 7951/8134	batch_loss: 2.9904	batch_accuracy: 42.53%	lr:0.000031
Ep: 44/48	It: 8001/8134	batch_loss: 3.1288	batch_accuracy: 39.92%	lr:0.000031
Ep: 44/48	It: 8051/8134	batch_loss: 3.1453	batch_accuracy: 41.09%	lr:0.000031
Ep: 44/48	It: 8101/8134	batch_loss: 3.0889	batch_accuracy: 42.33%	lr:0.000031
Ep: 44/48	It: 8134/8134	batch_loss: 3.0757	batch_accuracy: 40.83%	lr:0.000031


Generated text for input text "You" is:
You’s “N”, “N”, “H”, “A”, “TC”, “MN”, “TTTC”, “B” and “AAAAAAAAAAAAAAAA-1AAA) were used. The results showed that the mean score of the AAAAA score was 4.8 (SD 0.5) in the SAAAA group and 5.2 (SD 0.5) in the SAAA group. SAAA was higher in the CAS group than in the SAA group (p = 0.005).


CONCLUSION
Our findings suggest that CAS can be used as a screening tool for CAS.
<eot>
<sot>
Detection of Myocardial Infarction by Near-Infrared Spectroscopy

The identification of the myocardium and cardiac diseases is a key part of the treatment of patients with chest pain. The aim of this study was to evaluate the accuracy of magnetic resonance (MR) imaging for the detection of the myocardium and heart, skeletal, and skeletal muscles


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 45/48	It: 1/8134	batch_loss: 3.0536	batch_accuracy: 40.82%	lr:0.000031
Ep: 45/48	It: 51/8134	batch_loss: 3.1044	batch_accuracy: 40.82%	lr:0.000031
Ep: 45/48	It: 101/8134	batch_loss: 2.9689	batch_accuracy: 43.38%	lr:0.000031
Ep: 45/48	It: 151/8134	batch_loss: 2.9451	batch_accuracy: 43.85%	lr:0.000031
Ep: 45/48	It: 201/8134	batch_loss: 2.9988	batch_accuracy: 42.58%	lr:0.000031
Ep: 45/48	It: 251/8134	batch_loss: 2.9701	batch_accuracy: 42.68%	lr:0.000031
Ep: 45/48	It: 301/8134	batch_loss: 2.9173	batch_accuracy: 43.33%	lr:0.000031
Ep: 45/48	It: 351/8134	batch_loss: 3.0020	batch_accuracy: 42.02%	lr:0.000031
Ep: 45/48	It: 401/8134	batch_loss: 3.0452	batch_accuracy: 42.43%	lr:0.000030
Ep: 45/48	It: 451/8134	batch_loss: 3.0523	batch_accuracy: 41.65%	lr:0.000030
Ep: 45/48	It: 501/8134	batch_loss: 3.0534	batch_accuracy: 41.43%	lr:0.000030
Ep: 45/48	It: 551/8134	batch_loss: 2.9688	batch_accuracy: 42.58%	lr:0.000030
Ep: 45/48	It: 601/8134	batch_loss: 2.9829	batch_accuracy: 42.77%	lr:0.000030
Ep: 45/48	It: 651/8134	batch_loss: 3.0254	batch_accuracy: 42.65%	lr:0.000030
Ep: 45/48	It: 701/8134	batch_loss: 3.0712	batch_accuracy: 41.53%	lr:0.000030
Ep: 45/48	It: 751/8134	batch_loss: 2.9974	batch_accuracy: 43.04%	lr:0.000030
Ep: 45/48	It: 801/8134	batch_loss: 2.9988	batch_accuracy: 41.63%	lr:0.000030
Ep: 45/48	It: 851/8134	batch_loss: 3.0106	batch_accuracy: 41.92%	lr:0.000030
Ep: 45/48	It: 901/8134	batch_loss: 3.1562	batch_accuracy: 39.97%	lr:0.000030
Ep: 45/48	It: 951/8134	batch_loss: 2.9844	batch_accuracy: 42.77%	lr:0.000030
Ep: 45/48	It: 1001/8134	batch_loss: 3.0248	batch_accuracy: 41.89%	lr:0.000030
Ep: 45/48	It: 1051/8134	batch_loss: 3.0673	batch_accuracy: 41.58%	lr:0.000030
Ep: 45/48	It: 1101/8134	batch_loss: 3.0096	batch_accuracy: 43.04%	lr:0.000030
Ep: 45/48	It: 1151/8134	batch_loss: 3.0519	batch_accuracy: 41.55%	lr:0.000030
Ep: 45/48	It: 1201/8134	batch_loss: 3.1640	batch_accuracy: 40.58%	lr:0.000029
Ep: 45/48	It: 1251/8134	batch_loss: 2.9713	batch_accuracy: 41.89%	lr:0.000029
Ep: 45/48	It: 1301/8134	batch_loss: 3.0428	batch_accuracy: 41.80%	lr:0.000029
Ep: 45/48	It: 1351/8134	batch_loss: 3.1303	batch_accuracy: 40.60%	lr:0.000029
Ep: 45/48	It: 1401/8134	batch_loss: 3.0415	batch_accuracy: 41.77%	lr:0.000029
Ep: 45/48	It: 1451/8134	batch_loss: 2.9941	batch_accuracy: 42.09%	lr:0.000029
Ep: 45/48	It: 1501/8134	batch_loss: 3.0131	batch_accuracy: 41.94%	lr:0.000029
Ep: 45/48	It: 1551/8134	batch_loss: 2.9998	batch_accuracy: 42.41%	lr:0.000029
Ep: 45/48	It: 1601/8134	batch_loss: 2.9947	batch_accuracy: 42.09%	lr:0.000029
Ep: 45/48	It: 1651/8134	batch_loss: 3.0796	batch_accuracy: 40.65%	lr:0.000029
Ep: 45/48	It: 1701/8134	batch_loss: 3.0531	batch_accuracy: 41.63%	lr:0.000029
Ep: 45/48	It: 1751/8134	batch_loss: 3.1108	batch_accuracy: 40.62%	lr:0.000029
Ep: 45/48	It: 1801/8134	batch_loss: 3.1107	batch_accuracy: 40.09%	lr:0.000029
Ep: 45/48	It: 1851/8134	batch_loss: 2.8880	batch_accuracy: 43.80%	lr:0.000029
Ep: 45/48	It: 1901/8134	batch_loss: 3.0154	batch_accuracy: 42.24%	lr:0.000029
Ep: 45/48	It: 1951/8134	batch_loss: 2.9895	batch_accuracy: 41.58%	lr:0.000029
Ep: 45/48	It: 2001/8134	batch_loss: 3.0592	batch_accuracy: 40.82%	lr:0.000029
Ep: 45/48	It: 2051/8134	batch_loss: 3.0513	batch_accuracy: 41.99%	lr:0.000028
Ep: 45/48	It: 2101/8134	batch_loss: 2.9615	batch_accuracy: 43.77%	lr:0.000028
Ep: 45/48	It: 2151/8134	batch_loss: 2.9697	batch_accuracy: 42.43%	lr:0.000028
Ep: 45/48	It: 2201/8134	batch_loss: 2.9757	batch_accuracy: 42.31%	lr:0.000028
Ep: 45/48	It: 2251/8134	batch_loss: 3.0849	batch_accuracy: 41.16%	lr:0.000028
Ep: 45/48	It: 2301/8134	batch_loss: 2.9952	batch_accuracy: 42.48%	lr:0.000028
Ep: 45/48	It: 2351/8134	batch_loss: 3.1083	batch_accuracy: 40.55%	lr:0.000028
Ep: 45/48	It: 2401/8134	batch_loss: 3.0353	batch_accuracy: 41.70%	lr:0.000028
Ep: 45/48	It: 2451/8134	batch_loss: 3.0638	batch_accuracy: 40.87%	lr:0.000028
Ep: 45/48	It: 2501/8134	batch_loss: 2.9303	batch_accuracy: 43.12%	lr:0.000028
Ep: 45/48	It: 2551/8134	batch_loss: 2.9606	batch_accuracy: 43.24%	lr:0.000028
Ep: 45/48	It: 2601/8134	batch_loss: 3.0148	batch_accuracy: 42.16%	lr:0.000028
Ep: 45/48	It: 2651/8134	batch_loss: 3.0195	batch_accuracy: 41.43%	lr:0.000028
Ep: 45/48	It: 2701/8134	batch_loss: 3.1005	batch_accuracy: 40.33%	lr:0.000028
Ep: 45/48	It: 2751/8134	batch_loss: 2.9880	batch_accuracy: 41.99%	lr:0.000028
Ep: 45/48	It: 2801/8134	batch_loss: 3.0585	batch_accuracy: 41.16%	lr:0.000028
Ep: 45/48	It: 2851/8134	batch_loss: 2.9849	batch_accuracy: 42.63%	lr:0.000027
Ep: 45/48	It: 2901/8134	batch_loss: 3.0098	batch_accuracy: 42.33%	lr:0.000027
Ep: 45/48	It: 2951/8134	batch_loss: 3.0078	batch_accuracy: 41.77%	lr:0.000027
Ep: 45/48	It: 3001/8134	batch_loss: 2.9110	batch_accuracy: 42.58%	lr:0.000027
Ep: 45/48	It: 3051/8134	batch_loss: 2.9894	batch_accuracy: 41.85%	lr:0.000027
Ep: 45/48	It: 3101/8134	batch_loss: 2.8529	batch_accuracy: 44.07%	lr:0.000027
Ep: 45/48	It: 3151/8134	batch_loss: 2.9413	batch_accuracy: 44.26%	lr:0.000027
Ep: 45/48	It: 3201/8134	batch_loss: 3.0661	batch_accuracy: 41.58%	lr:0.000027
Ep: 45/48	It: 3251/8134	batch_loss: 3.0620	batch_accuracy: 41.02%	lr:0.000027
Ep: 45/48	It: 3301/8134	batch_loss: 3.1648	batch_accuracy: 39.99%	lr:0.000027
Ep: 45/48	It: 3351/8134	batch_loss: 2.9842	batch_accuracy: 42.92%	lr:0.000027
Ep: 45/48	It: 3401/8134	batch_loss: 3.0269	batch_accuracy: 41.87%	lr:0.000027
Ep: 45/48	It: 3451/8134	batch_loss: 3.2037	batch_accuracy: 39.58%	lr:0.000027
Ep: 45/48	It: 3501/8134	batch_loss: 3.0698	batch_accuracy: 41.97%	lr:0.000027
Ep: 45/48	It: 3551/8134	batch_loss: 3.0404	batch_accuracy: 41.75%	lr:0.000027
Ep: 45/48	It: 3601/8134	batch_loss: 2.9882	batch_accuracy: 42.94%	lr:0.000027
Ep: 45/48	It: 3651/8134	batch_loss: 2.9108	batch_accuracy: 43.51%	lr:0.000027
Ep: 45/48	It: 3701/8134	batch_loss: 3.1116	batch_accuracy: 41.02%	lr:0.000027
Ep: 45/48	It: 3751/8134	batch_loss: 3.0085	batch_accuracy: 42.24%	lr:0.000026
Ep: 45/48	It: 3801/8134	batch_loss: 2.9974	batch_accuracy: 41.99%	lr:0.000026
Ep: 45/48	It: 3851/8134	batch_loss: 3.1089	batch_accuracy: 40.26%	lr:0.000026
Ep: 45/48	It: 3901/8134	batch_loss: 2.9935	batch_accuracy: 42.29%	lr:0.000026
Ep: 45/48	It: 3951/8134	batch_loss: 2.9015	batch_accuracy: 43.09%	lr:0.000026
Ep: 45/48	It: 4001/8134	batch_loss: 3.0974	batch_accuracy: 41.31%	lr:0.000026
Ep: 45/48	It: 4051/8134	batch_loss: 3.1330	batch_accuracy: 39.75%	lr:0.000026
Ep: 45/48	It: 4101/8134	batch_loss: 2.9776	batch_accuracy: 42.92%	lr:0.000026
Ep: 45/48	It: 4151/8134	batch_loss: 3.0355	batch_accuracy: 41.77%	lr:0.000026
Ep: 45/48	It: 4201/8134	batch_loss: 2.9331	batch_accuracy: 44.78%	lr:0.000026
Ep: 45/48	It: 4251/8134	batch_loss: 2.9243	batch_accuracy: 42.87%	lr:0.000026
Ep: 45/48	It: 4301/8134	batch_loss: 3.1178	batch_accuracy: 40.65%	lr:0.000026
Ep: 45/48	It: 4351/8134	batch_loss: 2.9975	batch_accuracy: 41.50%	lr:0.000026
Ep: 45/48	It: 4401/8134	batch_loss: 3.0550	batch_accuracy: 41.31%	lr:0.000026
Ep: 45/48	It: 4451/8134	batch_loss: 3.0353	batch_accuracy: 41.72%	lr:0.000026
Ep: 45/48	It: 4501/8134	batch_loss: 3.0963	batch_accuracy: 40.45%	lr:0.000026
Ep: 45/48	It: 4551/8134	batch_loss: 3.0151	batch_accuracy: 42.70%	lr:0.000026
Ep: 45/48	It: 4601/8134	batch_loss: 3.0388	batch_accuracy: 41.19%	lr:0.000026
Ep: 45/48	It: 4651/8134	batch_loss: 2.9953	batch_accuracy: 42.36%	lr:0.000025
Ep: 45/48	It: 4701/8134	batch_loss: 3.1350	batch_accuracy: 40.75%	lr:0.000025
Ep: 45/48	It: 4751/8134	batch_loss: 2.9803	batch_accuracy: 41.43%	lr:0.000025
Ep: 45/48	It: 4801/8134	batch_loss: 3.0710	batch_accuracy: 41.43%	lr:0.000025
Ep: 45/48	It: 4851/8134	batch_loss: 3.0237	batch_accuracy: 42.26%	lr:0.000025
Ep: 45/48	It: 4901/8134	batch_loss: 3.0984	batch_accuracy: 40.67%	lr:0.000025
Ep: 45/48	It: 4951/8134	batch_loss: 3.0485	batch_accuracy: 41.94%	lr:0.000025
Ep: 45/48	It: 5001/8134	batch_loss: 2.9380	batch_accuracy: 42.36%	lr:0.000025
Ep: 45/48	It: 5051/8134	batch_loss: 3.0611	batch_accuracy: 42.04%	lr:0.000025
Ep: 45/48	It: 5101/8134	batch_loss: 3.1662	batch_accuracy: 39.89%	lr:0.000025
Ep: 45/48	It: 5151/8134	batch_loss: 3.1006	batch_accuracy: 41.28%	lr:0.000025
Ep: 45/48	It: 5201/8134	batch_loss: 2.9975	batch_accuracy: 43.26%	lr:0.000025
Ep: 45/48	It: 5251/8134	batch_loss: 3.0484	batch_accuracy: 41.70%	lr:0.000025
Ep: 45/48	It: 5301/8134	batch_loss: 3.0758	batch_accuracy: 41.70%	lr:0.000025
Ep: 45/48	It: 5351/8134	batch_loss: 3.1182	batch_accuracy: 40.09%	lr:0.000025
Ep: 45/48	It: 5401/8134	batch_loss: 3.1007	batch_accuracy: 40.31%	lr:0.000025
Ep: 45/48	It: 5451/8134	batch_loss: 2.8790	batch_accuracy: 43.60%	lr:0.000025
Ep: 45/48	It: 5501/8134	batch_loss: 3.0170	batch_accuracy: 41.67%	lr:0.000025
Ep: 45/48	It: 5551/8134	batch_loss: 3.0939	batch_accuracy: 41.77%	lr:0.000024
Ep: 45/48	It: 5601/8134	batch_loss: 3.0080	batch_accuracy: 42.55%	lr:0.000024
Ep: 45/48	It: 5651/8134	batch_loss: 2.9458	batch_accuracy: 43.14%	lr:0.000024
Ep: 45/48	It: 5701/8134	batch_loss: 3.1390	batch_accuracy: 41.38%	lr:0.000024
Ep: 45/48	It: 5751/8134	batch_loss: 3.1118	batch_accuracy: 40.33%	lr:0.000024
Ep: 45/48	It: 5801/8134	batch_loss: 3.1052	batch_accuracy: 40.50%	lr:0.000024
Ep: 45/48	It: 5851/8134	batch_loss: 2.9693	batch_accuracy: 42.26%	lr:0.000024
Ep: 45/48	It: 5901/8134	batch_loss: 2.9587	batch_accuracy: 42.85%	lr:0.000024
Ep: 45/48	It: 5951/8134	batch_loss: 2.9655	batch_accuracy: 42.63%	lr:0.000024
Ep: 45/48	It: 6001/8134	batch_loss: 3.0214	batch_accuracy: 41.70%	lr:0.000024
Ep: 45/48	It: 6051/8134	batch_loss: 3.0111	batch_accuracy: 41.87%	lr:0.000024
Ep: 45/48	It: 6101/8134	batch_loss: 3.1297	batch_accuracy: 40.92%	lr:0.000024
Ep: 45/48	It: 6151/8134	batch_loss: 3.0182	batch_accuracy: 41.80%	lr:0.000024
Ep: 45/48	It: 6201/8134	batch_loss: 3.0412	batch_accuracy: 41.60%	lr:0.000024
Ep: 45/48	It: 6251/8134	batch_loss: 3.1001	batch_accuracy: 40.55%	lr:0.000024
Ep: 45/48	It: 6301/8134	batch_loss: 3.0591	batch_accuracy: 40.33%	lr:0.000024
Ep: 45/48	It: 6351/8134	batch_loss: 2.8844	batch_accuracy: 44.60%	lr:0.000024
Ep: 45/48	It: 6401/8134	batch_loss: 2.9479	batch_accuracy: 42.94%	lr:0.000024
Ep: 45/48	It: 6451/8134	batch_loss: 3.0338	batch_accuracy: 42.16%	lr:0.000024
Ep: 45/48	It: 6501/8134	batch_loss: 3.0130	batch_accuracy: 42.53%	lr:0.000023
Ep: 45/48	It: 6551/8134	batch_loss: 2.9741	batch_accuracy: 42.31%	lr:0.000023
Ep: 45/48	It: 6601/8134	batch_loss: 2.9805	batch_accuracy: 43.73%	lr:0.000023
Ep: 45/48	It: 6651/8134	batch_loss: 3.1382	batch_accuracy: 40.80%	lr:0.000023
Ep: 45/48	It: 6701/8134	batch_loss: 2.9667	batch_accuracy: 41.70%	lr:0.000023
Ep: 45/48	It: 6751/8134	batch_loss: 2.9363	batch_accuracy: 42.21%	lr:0.000023
Ep: 45/48	It: 6801/8134	batch_loss: 2.9137	batch_accuracy: 44.31%	lr:0.000023
Ep: 45/48	It: 6851/8134	batch_loss: 2.9754	batch_accuracy: 42.65%	lr:0.000023
Ep: 45/48	It: 6901/8134	batch_loss: 2.9198	batch_accuracy: 42.38%	lr:0.000023
Ep: 45/48	It: 6951/8134	batch_loss: 2.9639	batch_accuracy: 43.07%	lr:0.000023
Ep: 45/48	It: 7001/8134	batch_loss: 2.9693	batch_accuracy: 43.33%	lr:0.000023
Ep: 45/48	It: 7051/8134	batch_loss: 2.9988	batch_accuracy: 43.38%	lr:0.000023
Ep: 45/48	It: 7101/8134	batch_loss: 3.0532	batch_accuracy: 41.55%	lr:0.000023
Ep: 45/48	It: 7151/8134	batch_loss: 3.0487	batch_accuracy: 42.02%	lr:0.000023
Ep: 45/48	It: 7201/8134	batch_loss: 3.0432	batch_accuracy: 42.19%	lr:0.000023
Ep: 45/48	It: 7251/8134	batch_loss: 2.9992	batch_accuracy: 42.29%	lr:0.000023
Ep: 45/48	It: 7301/8134	batch_loss: 2.9570	batch_accuracy: 42.36%	lr:0.000023
Ep: 45/48	It: 7351/8134	batch_loss: 3.0625	batch_accuracy: 42.02%	lr:0.000023
Ep: 45/48	It: 7401/8134	batch_loss: 2.9964	batch_accuracy: 43.19%	lr:0.000023
Ep: 45/48	It: 7451/8134	batch_loss: 2.9345	batch_accuracy: 43.02%	lr:0.000023
Ep: 45/48	It: 7501/8134	batch_loss: 2.9496	batch_accuracy: 42.77%	lr:0.000022
Ep: 45/48	It: 7551/8134	batch_loss: 2.9688	batch_accuracy: 42.94%	lr:0.000022
Ep: 45/48	It: 7601/8134	batch_loss: 3.0269	batch_accuracy: 42.31%	lr:0.000022
Ep: 45/48	It: 7651/8134	batch_loss: 3.1332	batch_accuracy: 39.92%	lr:0.000022
Ep: 45/48	It: 7701/8134	batch_loss: 3.1452	batch_accuracy: 39.21%	lr:0.000022
Ep: 45/48	It: 7751/8134	batch_loss: 3.1810	batch_accuracy: 39.28%	lr:0.000022
Ep: 45/48	It: 7801/8134	batch_loss: 3.0381	batch_accuracy: 41.72%	lr:0.000022
Ep: 45/48	It: 7851/8134	batch_loss: 3.0289	batch_accuracy: 42.02%	lr:0.000022
Ep: 45/48	It: 7901/8134	batch_loss: 2.9505	batch_accuracy: 43.21%	lr:0.000022
Ep: 45/48	It: 7951/8134	batch_loss: 2.9631	batch_accuracy: 43.63%	lr:0.000022
Ep: 45/48	It: 8001/8134	batch_loss: 3.0295	batch_accuracy: 42.16%	lr:0.000022
Ep: 45/48	It: 8051/8134	batch_loss: 3.0949	batch_accuracy: 40.89%	lr:0.000022
Ep: 45/48	It: 8101/8134	batch_loss: 2.9729	batch_accuracy: 42.55%	lr:0.000022
Ep: 45/48	It: 8134/8134	batch_loss: 2.9527	batch_accuracy: 42.66%	lr:0.000022


Generated text for input text "You" is:
Youville, Member. All rights reserved.




This is a review of Saudi Ara, AJ, and of theologians, of theophrenia, and from Achie, Sao, and Granada.
<eot>
<sot>
[Postoperative complications of the primary surgery in the treatment of benign prostatic hyperplasia].

In patients with malignant prostatic hyperplasia, the treatment of benign prostatic hyperplasia (BPH) is described. The primary objective of this study was to determine the effectiveness of treatment of patients with a high risk of stage IB. Patients and Methods: The present study was conducted on 30 patients with a stage IB of disease of the prostate, who underwent surgical resection of the prostate and in 18 patients with a stage IIB cancer of the prostate. The primary outcome was recurrence and survival. Patients with a stage II or III disease were divided into two groups according to the stage of the disease. Patients with stage I and II stage III disease (stage II and III disease) were divided into two groups. In the stage I and II stage, the disease duration and the progression time were compared.


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 46/48	It: 1/8134	batch_loss: 3.0314	batch_accuracy: 40.65%	lr:0.000022
Ep: 46/48	It: 51/8134	batch_loss: 3.1299	batch_accuracy: 41.04%	lr:0.000022
Ep: 46/48	It: 101/8134	batch_loss: 2.9733	batch_accuracy: 42.46%	lr:0.000022
Ep: 46/48	It: 151/8134	batch_loss: 2.9142	batch_accuracy: 43.68%	lr:0.000022
Ep: 46/48	It: 201/8134	batch_loss: 3.0101	batch_accuracy: 41.50%	lr:0.000022
Ep: 46/48	It: 251/8134	batch_loss: 2.9921	batch_accuracy: 41.99%	lr:0.000022
Ep: 46/48	It: 301/8134	batch_loss: 2.8128	batch_accuracy: 45.02%	lr:0.000022
Ep: 46/48	It: 351/8134	batch_loss: 3.0959	batch_accuracy: 40.84%	lr:0.000022
Ep: 46/48	It: 401/8134	batch_loss: 2.9608	batch_accuracy: 43.07%	lr:0.000021
Ep: 46/48	It: 451/8134	batch_loss: 3.0425	batch_accuracy: 41.31%	lr:0.000021
Ep: 46/48	It: 501/8134	batch_loss: 3.0681	batch_accuracy: 41.28%	lr:0.000021
Ep: 46/48	It: 551/8134	batch_loss: 2.9975	batch_accuracy: 42.41%	lr:0.000021
Ep: 46/48	It: 601/8134	batch_loss: 2.8716	batch_accuracy: 43.33%	lr:0.000021
Ep: 46/48	It: 651/8134	batch_loss: 3.0276	batch_accuracy: 42.14%	lr:0.000021
Ep: 46/48	It: 701/8134	batch_loss: 3.0897	batch_accuracy: 41.04%	lr:0.000021
Ep: 46/48	It: 751/8134	batch_loss: 3.0480	batch_accuracy: 40.75%	lr:0.000021
Ep: 46/48	It: 801/8134	batch_loss: 3.0761	batch_accuracy: 41.48%	lr:0.000021
Ep: 46/48	It: 851/8134	batch_loss: 2.9974	batch_accuracy: 41.72%	lr:0.000021
Ep: 46/48	It: 901/8134	batch_loss: 3.0237	batch_accuracy: 41.87%	lr:0.000021
Ep: 46/48	It: 951/8134	batch_loss: 3.0881	batch_accuracy: 40.58%	lr:0.000021
Ep: 46/48	It: 1001/8134	batch_loss: 3.0239	batch_accuracy: 42.33%	lr:0.000021
Ep: 46/48	It: 1051/8134	batch_loss: 2.9400	batch_accuracy: 42.53%	lr:0.000021
Ep: 46/48	It: 1101/8134	batch_loss: 2.9746	batch_accuracy: 42.46%	lr:0.000021
Ep: 46/48	It: 1151/8134	batch_loss: 2.9888	batch_accuracy: 42.82%	lr:0.000021
Ep: 46/48	It: 1201/8134	batch_loss: 2.8537	batch_accuracy: 44.48%	lr:0.000021
Ep: 46/48	It: 1251/8134	batch_loss: 2.9069	batch_accuracy: 43.80%	lr:0.000021
Ep: 46/48	It: 1301/8134	batch_loss: 3.1535	batch_accuracy: 39.48%	lr:0.000021
Ep: 46/48	It: 1351/8134	batch_loss: 2.9785	batch_accuracy: 41.94%	lr:0.000021
Ep: 46/48	It: 1401/8134	batch_loss: 2.9390	batch_accuracy: 42.77%	lr:0.000021
Ep: 46/48	It: 1451/8134	batch_loss: 3.0420	batch_accuracy: 42.72%	lr:0.000020
Ep: 46/48	It: 1501/8134	batch_loss: 3.0170	batch_accuracy: 42.60%	lr:0.000020
Ep: 46/48	It: 1551/8134	batch_loss: 3.0497	batch_accuracy: 41.36%	lr:0.000020
Ep: 46/48	It: 1601/8134	batch_loss: 3.0801	batch_accuracy: 40.89%	lr:0.000020
Ep: 46/48	It: 1651/8134	batch_loss: 2.9932	batch_accuracy: 42.90%	lr:0.000020
Ep: 46/48	It: 1701/8134	batch_loss: 3.0894	batch_accuracy: 40.19%	lr:0.000020
Ep: 46/48	It: 1751/8134	batch_loss: 3.0770	batch_accuracy: 41.19%	lr:0.000020
Ep: 46/48	It: 1801/8134	batch_loss: 2.9915	batch_accuracy: 41.75%	lr:0.000020
Ep: 46/48	It: 1851/8134	batch_loss: 2.9853	batch_accuracy: 43.21%	lr:0.000020
Ep: 46/48	It: 1901/8134	batch_loss: 3.0140	batch_accuracy: 41.89%	lr:0.000020
Ep: 46/48	It: 1951/8134	batch_loss: 3.0063	batch_accuracy: 41.85%	lr:0.000020
Ep: 46/48	It: 2001/8134	batch_loss: 3.0967	batch_accuracy: 40.48%	lr:0.000020
Ep: 46/48	It: 2051/8134	batch_loss: 3.0495	batch_accuracy: 40.67%	lr:0.000020
Ep: 46/48	It: 2101/8134	batch_loss: 3.0437	batch_accuracy: 41.24%	lr:0.000020
Ep: 46/48	It: 2151/8134	batch_loss: 2.9877	batch_accuracy: 42.87%	lr:0.000020
Ep: 46/48	It: 2201/8134	batch_loss: 3.1077	batch_accuracy: 40.41%	lr:0.000020
Ep: 46/48	It: 2251/8134	batch_loss: 2.9948	batch_accuracy: 42.77%	lr:0.000020
Ep: 46/48	It: 2301/8134	batch_loss: 3.0254	batch_accuracy: 40.99%	lr:0.000020
Ep: 46/48	It: 2351/8134	batch_loss: 2.9562	batch_accuracy: 43.19%	lr:0.000020
Ep: 46/48	It: 2401/8134	batch_loss: 2.9681	batch_accuracy: 43.46%	lr:0.000020
Ep: 46/48	It: 2451/8134	batch_loss: 2.9722	batch_accuracy: 42.94%	lr:0.000020
Ep: 46/48	It: 2501/8134	batch_loss: 3.0729	batch_accuracy: 40.26%	lr:0.000020
Ep: 46/48	It: 2551/8134	batch_loss: 3.1342	batch_accuracy: 40.94%	lr:0.000020
Ep: 46/48	It: 2601/8134	batch_loss: 2.9102	batch_accuracy: 42.48%	lr:0.000019
Ep: 46/48	It: 2651/8134	batch_loss: 3.1351	batch_accuracy: 41.33%	lr:0.000019
Ep: 46/48	It: 2701/8134	batch_loss: 3.0989	batch_accuracy: 40.89%	lr:0.000019
Ep: 46/48	It: 2751/8134	batch_loss: 3.1228	batch_accuracy: 39.62%	lr:0.000019
Ep: 46/48	It: 2801/8134	batch_loss: 3.0603	batch_accuracy: 41.89%	lr:0.000019
Ep: 46/48	It: 2851/8134	batch_loss: 3.0695	batch_accuracy: 40.55%	lr:0.000019
Ep: 46/48	It: 2901/8134	batch_loss: 3.0356	batch_accuracy: 42.31%	lr:0.000019
Ep: 46/48	It: 2951/8134	batch_loss: 3.0691	batch_accuracy: 41.19%	lr:0.000019
Ep: 46/48	It: 3001/8134	batch_loss: 3.0026	batch_accuracy: 42.04%	lr:0.000019
Ep: 46/48	It: 3051/8134	batch_loss: 3.0724	batch_accuracy: 41.65%	lr:0.000019
Ep: 46/48	It: 3101/8134	batch_loss: 3.0750	batch_accuracy: 41.82%	lr:0.000019
Ep: 46/48	It: 3151/8134	batch_loss: 3.0200	batch_accuracy: 40.65%	lr:0.000019
Ep: 46/48	It: 3201/8134	batch_loss: 3.1003	batch_accuracy: 40.26%	lr:0.000019
Ep: 46/48	It: 3251/8134	batch_loss: 3.0660	batch_accuracy: 41.99%	lr:0.000019
Ep: 46/48	It: 3301/8134	batch_loss: 3.0478	batch_accuracy: 41.58%	lr:0.000019
Ep: 46/48	It: 3351/8134	batch_loss: 2.9657	batch_accuracy: 42.97%	lr:0.000019
Ep: 46/48	It: 3401/8134	batch_loss: 3.1463	batch_accuracy: 40.50%	lr:0.000019
Ep: 46/48	It: 3451/8134	batch_loss: 3.0218	batch_accuracy: 41.33%	lr:0.000019
Ep: 46/48	It: 3501/8134	batch_loss: 3.0208	batch_accuracy: 42.26%	lr:0.000019
Ep: 46/48	It: 3551/8134	batch_loss: 3.0768	batch_accuracy: 41.94%	lr:0.000019
Ep: 46/48	It: 3601/8134	batch_loss: 3.1836	batch_accuracy: 40.26%	lr:0.000019
Ep: 46/48	It: 3651/8134	batch_loss: 3.0199	batch_accuracy: 41.02%	lr:0.000019
Ep: 46/48	It: 3701/8134	batch_loss: 3.0006	batch_accuracy: 42.29%	lr:0.000019
Ep: 46/48	It: 3751/8134	batch_loss: 3.0067	batch_accuracy: 42.97%	lr:0.000018
Ep: 46/48	It: 3801/8134	batch_loss: 3.0134	batch_accuracy: 43.07%	lr:0.000018
Ep: 46/48	It: 3851/8134	batch_loss: 3.0353	batch_accuracy: 42.09%	lr:0.000018
Ep: 46/48	It: 3901/8134	batch_loss: 2.9984	batch_accuracy: 42.04%	lr:0.000018
Ep: 46/48	It: 3951/8134	batch_loss: 2.9605	batch_accuracy: 42.99%	lr:0.000018
Ep: 46/48	It: 4001/8134	batch_loss: 3.0068	batch_accuracy: 41.85%	lr:0.000018
Ep: 46/48	It: 4051/8134	batch_loss: 2.9286	batch_accuracy: 42.65%	lr:0.000018
Ep: 46/48	It: 4101/8134	batch_loss: 2.9638	batch_accuracy: 42.99%	lr:0.000018
Ep: 46/48	It: 4151/8134	batch_loss: 3.0610	batch_accuracy: 40.80%	lr:0.000018
Ep: 46/48	It: 4201/8134	batch_loss: 3.0375	batch_accuracy: 42.04%	lr:0.000018
Ep: 46/48	It: 4251/8134	batch_loss: 3.1087	batch_accuracy: 40.84%	lr:0.000018
Ep: 46/48	It: 4301/8134	batch_loss: 3.0766	batch_accuracy: 40.70%	lr:0.000018
Ep: 46/48	It: 4351/8134	batch_loss: 2.9281	batch_accuracy: 42.43%	lr:0.000018
Ep: 46/48	It: 4401/8134	batch_loss: 2.9552	batch_accuracy: 43.04%	lr:0.000018
Ep: 46/48	It: 4451/8134	batch_loss: 3.0030	batch_accuracy: 42.75%	lr:0.000018
Ep: 46/48	It: 4501/8134	batch_loss: 3.1228	batch_accuracy: 40.21%	lr:0.000018
Ep: 46/48	It: 4551/8134	batch_loss: 2.9741	batch_accuracy: 43.48%	lr:0.000018
Ep: 46/48	It: 4601/8134	batch_loss: 2.9284	batch_accuracy: 42.75%	lr:0.000018
Ep: 46/48	It: 4651/8134	batch_loss: 3.1155	batch_accuracy: 40.60%	lr:0.000018
Ep: 46/48	It: 4701/8134	batch_loss: 2.9943	batch_accuracy: 41.80%	lr:0.000018
Ep: 46/48	It: 4751/8134	batch_loss: 3.1123	batch_accuracy: 41.67%	lr:0.000018
Ep: 46/48	It: 4801/8134	batch_loss: 2.9635	batch_accuracy: 43.14%	lr:0.000018
Ep: 46/48	It: 4851/8134	batch_loss: 2.9621	batch_accuracy: 43.16%	lr:0.000018
Ep: 46/48	It: 4901/8134	batch_loss: 2.9726	batch_accuracy: 42.99%	lr:0.000018
Ep: 46/48	It: 4951/8134	batch_loss: 3.0425	batch_accuracy: 42.46%	lr:0.000018
Ep: 46/48	It: 5001/8134	batch_loss: 3.0224	batch_accuracy: 42.11%	lr:0.000017
Ep: 46/48	It: 5051/8134	batch_loss: 3.0085	batch_accuracy: 41.70%	lr:0.000017
Ep: 46/48	It: 5101/8134	batch_loss: 2.9208	batch_accuracy: 44.09%	lr:0.000017
Ep: 46/48	It: 5151/8134	batch_loss: 3.0985	batch_accuracy: 40.82%	lr:0.000017
Ep: 46/48	It: 5201/8134	batch_loss: 2.9119	batch_accuracy: 43.87%	lr:0.000017
Ep: 46/48	It: 5251/8134	batch_loss: 3.0887	batch_accuracy: 40.36%	lr:0.000017
Ep: 46/48	It: 5301/8134	batch_loss: 3.1314	batch_accuracy: 40.41%	lr:0.000017
Ep: 46/48	It: 5351/8134	batch_loss: 2.9213	batch_accuracy: 43.16%	lr:0.000017
Ep: 46/48	It: 5401/8134	batch_loss: 2.9403	batch_accuracy: 41.75%	lr:0.000017
Ep: 46/48	It: 5451/8134	batch_loss: 3.0110	batch_accuracy: 42.16%	lr:0.000017
Ep: 46/48	It: 5501/8134	batch_loss: 3.0070	batch_accuracy: 41.38%	lr:0.000017
Ep: 46/48	It: 5551/8134	batch_loss: 3.0046	batch_accuracy: 41.99%	lr:0.000017
Ep: 46/48	It: 5601/8134	batch_loss: 3.0265	batch_accuracy: 42.02%	lr:0.000017
Ep: 46/48	It: 5651/8134	batch_loss: 2.8653	batch_accuracy: 44.53%	lr:0.000017
Ep: 46/48	It: 5701/8134	batch_loss: 3.0021	batch_accuracy: 41.31%	lr:0.000017
Ep: 46/48	It: 5751/8134	batch_loss: 3.0616	batch_accuracy: 41.31%	lr:0.000017
Ep: 46/48	It: 5801/8134	batch_loss: 3.0666	batch_accuracy: 41.41%	lr:0.000017
Ep: 46/48	It: 5851/8134	batch_loss: 3.1266	batch_accuracy: 39.36%	lr:0.000017
Ep: 46/48	It: 5901/8134	batch_loss: 3.0525	batch_accuracy: 41.06%	lr:0.000017
Ep: 46/48	It: 5951/8134	batch_loss: 3.1320	batch_accuracy: 40.62%	lr:0.000017
Ep: 46/48	It: 6001/8134	batch_loss: 2.9395	batch_accuracy: 42.33%	lr:0.000017
Ep: 46/48	It: 6051/8134	batch_loss: 3.0517	batch_accuracy: 42.11%	lr:0.000017
Ep: 46/48	It: 6101/8134	batch_loss: 2.9517	batch_accuracy: 42.29%	lr:0.000017
Ep: 46/48	It: 6151/8134	batch_loss: 3.1337	batch_accuracy: 41.28%	lr:0.000017
Ep: 46/48	It: 6201/8134	batch_loss: 3.0537	batch_accuracy: 41.46%	lr:0.000017
Ep: 46/48	It: 6251/8134	batch_loss: 2.9726	batch_accuracy: 42.43%	lr:0.000017
Ep: 46/48	It: 6301/8134	batch_loss: 3.0911	batch_accuracy: 40.65%	lr:0.000017
Ep: 46/48	It: 6351/8134	batch_loss: 2.8779	batch_accuracy: 44.07%	lr:0.000016
Ep: 46/48	It: 6401/8134	batch_loss: 3.0772	batch_accuracy: 40.89%	lr:0.000016
Ep: 46/48	It: 6451/8134	batch_loss: 3.0197	batch_accuracy: 41.65%	lr:0.000016
Ep: 46/48	It: 6501/8134	batch_loss: 2.9881	batch_accuracy: 42.75%	lr:0.000016
Ep: 46/48	It: 6551/8134	batch_loss: 2.9855	batch_accuracy: 42.70%	lr:0.000016
Ep: 46/48	It: 6601/8134	batch_loss: 2.8446	batch_accuracy: 44.68%	lr:0.000016
Ep: 46/48	It: 6651/8134	batch_loss: 3.0374	batch_accuracy: 41.67%	lr:0.000016
Ep: 46/48	It: 6701/8134	batch_loss: 3.1098	batch_accuracy: 41.24%	lr:0.000016
Ep: 46/48	It: 6751/8134	batch_loss: 3.0651	batch_accuracy: 41.36%	lr:0.000016
Ep: 46/48	It: 6801/8134	batch_loss: 2.9541	batch_accuracy: 43.19%	lr:0.000016
Ep: 46/48	It: 6851/8134	batch_loss: 3.0482	batch_accuracy: 41.50%	lr:0.000016
Ep: 46/48	It: 6901/8134	batch_loss: 2.9995	batch_accuracy: 41.21%	lr:0.000016
Ep: 46/48	It: 6951/8134	batch_loss: 3.0389	batch_accuracy: 41.55%	lr:0.000016
Ep: 46/48	It: 7001/8134	batch_loss: 3.0238	batch_accuracy: 41.82%	lr:0.000016
Ep: 46/48	It: 7051/8134	batch_loss: 3.0529	batch_accuracy: 42.70%	lr:0.000016
Ep: 46/48	It: 7101/8134	batch_loss: 2.9672	batch_accuracy: 43.36%	lr:0.000016
Ep: 46/48	It: 7151/8134	batch_loss: 3.0117	batch_accuracy: 42.72%	lr:0.000016
Ep: 46/48	It: 7201/8134	batch_loss: 3.1160	batch_accuracy: 39.79%	lr:0.000016
Ep: 46/48	It: 7251/8134	batch_loss: 3.0246	batch_accuracy: 42.63%	lr:0.000016
Ep: 46/48	It: 7301/8134	batch_loss: 2.8736	batch_accuracy: 44.38%	lr:0.000016
Ep: 46/48	It: 7351/8134	batch_loss: 2.9864	batch_accuracy: 42.24%	lr:0.000016
Ep: 46/48	It: 7401/8134	batch_loss: 3.0235	batch_accuracy: 41.85%	lr:0.000016
Ep: 46/48	It: 7451/8134	batch_loss: 3.0689	batch_accuracy: 41.19%	lr:0.000016
Ep: 46/48	It: 7501/8134	batch_loss: 2.9757	batch_accuracy: 42.75%	lr:0.000016
Ep: 46/48	It: 7551/8134	batch_loss: 3.1124	batch_accuracy: 40.65%	lr:0.000016
Ep: 46/48	It: 7601/8134	batch_loss: 3.0975	batch_accuracy: 40.72%	lr:0.000016
Ep: 46/48	It: 7651/8134	batch_loss: 2.9995	batch_accuracy: 43.29%	lr:0.000016
Ep: 46/48	It: 7701/8134	batch_loss: 3.1099	batch_accuracy: 41.16%	lr:0.000016
Ep: 46/48	It: 7751/8134	batch_loss: 2.9740	batch_accuracy: 43.31%	lr:0.000016
Ep: 46/48	It: 7801/8134	batch_loss: 2.9744	batch_accuracy: 42.09%	lr:0.000015
Ep: 46/48	It: 7851/8134	batch_loss: 3.0827	batch_accuracy: 41.09%	lr:0.000015
Ep: 46/48	It: 7901/8134	batch_loss: 3.0997	batch_accuracy: 41.50%	lr:0.000015
Ep: 46/48	It: 7951/8134	batch_loss: 2.9631	batch_accuracy: 42.29%	lr:0.000015
Ep: 46/48	It: 8001/8134	batch_loss: 3.0078	batch_accuracy: 41.80%	lr:0.000015
Ep: 46/48	It: 8051/8134	batch_loss: 3.0667	batch_accuracy: 41.67%	lr:0.000015
Ep: 46/48	It: 8101/8134	batch_loss: 3.0739	batch_accuracy: 41.55%	lr:0.000015
Ep: 46/48	It: 8134/8134	batch_loss: 3.0245	batch_accuracy: 42.05%	lr:0.000015


Generated text for input text "You" is:
Youro-LC and SH-SLLC-59, were used for the study. The results showed that the concentration of AA in theophylline decreased by 20%. The most effective concentration was in 0. The maximum adsorption capacity of the extract was found to be in vitro as high as 97.91%. The results showed that the extract extract of the E. coli oil was more active than other extracts of the E. coli, Trichoderma spp. and Trichoderma spp. as the main contributor to the reduction of the total antioxidant capacity of E. coli.
<eot>
<sot>
A new method for the analysis of tribological properties of a mixture of polyethylene glycol and aromatic hydrocarbons

The present work aims to solve the extraction of tribological properties of polyethylene glycol (PEG) by using the technique of polyethylene glycol (PEG) and hydroxyethylene glycol (HETG) as the precursor in the solvent. The aim of this work was to develop a polymer matrix based on a polyethylene glycol (PEG) monomer


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 47/48	It: 1/8134	batch_loss: 2.9980	batch_accuracy: 42.26%	lr:0.000015
Ep: 47/48	It: 51/8134	batch_loss: 2.9727	batch_accuracy: 43.33%	lr:0.000015
Ep: 47/48	It: 101/8134	batch_loss: 3.0371	batch_accuracy: 41.94%	lr:0.000015
Ep: 47/48	It: 151/8134	batch_loss: 3.0510	batch_accuracy: 41.82%	lr:0.000015
Ep: 47/48	It: 201/8134	batch_loss: 3.0247	batch_accuracy: 42.38%	lr:0.000015
Ep: 47/48	It: 251/8134	batch_loss: 3.0166	batch_accuracy: 41.65%	lr:0.000015
Ep: 47/48	It: 301/8134	batch_loss: 3.0024	batch_accuracy: 42.38%	lr:0.000015
Ep: 47/48	It: 351/8134	batch_loss: 3.0477	batch_accuracy: 41.67%	lr:0.000015
Ep: 47/48	It: 401/8134	batch_loss: 2.9778	batch_accuracy: 42.70%	lr:0.000015
Ep: 47/48	It: 451/8134	batch_loss: 3.0800	batch_accuracy: 41.31%	lr:0.000015
Ep: 47/48	It: 501/8134	batch_loss: 3.0764	batch_accuracy: 41.36%	lr:0.000015
Ep: 47/48	It: 551/8134	batch_loss: 3.0932	batch_accuracy: 41.33%	lr:0.000015
Ep: 47/48	It: 601/8134	batch_loss: 3.0908	batch_accuracy: 40.65%	lr:0.000015
Ep: 47/48	It: 651/8134	batch_loss: 3.0506	batch_accuracy: 41.31%	lr:0.000015
Ep: 47/48	It: 701/8134	batch_loss: 3.0663	batch_accuracy: 41.09%	lr:0.000015
Ep: 47/48	It: 751/8134	batch_loss: 2.9293	batch_accuracy: 42.50%	lr:0.000015
Ep: 47/48	It: 801/8134	batch_loss: 3.0540	batch_accuracy: 41.28%	lr:0.000015
Ep: 47/48	It: 851/8134	batch_loss: 3.2855	batch_accuracy: 39.40%	lr:0.000015
Ep: 47/48	It: 901/8134	batch_loss: 3.0170	batch_accuracy: 42.38%	lr:0.000015
Ep: 47/48	It: 951/8134	batch_loss: 3.0018	batch_accuracy: 42.31%	lr:0.000015
Ep: 47/48	It: 1001/8134	batch_loss: 3.0463	batch_accuracy: 42.24%	lr:0.000015
Ep: 47/48	It: 1051/8134	batch_loss: 3.0270	batch_accuracy: 42.33%	lr:0.000015
Ep: 47/48	It: 1101/8134	batch_loss: 3.0752	batch_accuracy: 41.09%	lr:0.000015
Ep: 47/48	It: 1151/8134	batch_loss: 2.9508	batch_accuracy: 42.72%	lr:0.000015
Ep: 47/48	It: 1201/8134	batch_loss: 3.0022	batch_accuracy: 42.26%	lr:0.000015
Ep: 47/48	It: 1251/8134	batch_loss: 2.9469	batch_accuracy: 43.24%	lr:0.000014
Ep: 47/48	It: 1301/8134	batch_loss: 2.9693	batch_accuracy: 43.26%	lr:0.000014
Ep: 47/48	It: 1351/8134	batch_loss: 2.8996	batch_accuracy: 43.60%	lr:0.000014
Ep: 47/48	It: 1401/8134	batch_loss: 2.9546	batch_accuracy: 42.33%	lr:0.000014
Ep: 47/48	It: 1451/8134	batch_loss: 3.0155	batch_accuracy: 41.63%	lr:0.000014
Ep: 47/48	It: 1501/8134	batch_loss: 2.9780	batch_accuracy: 41.53%	lr:0.000014
Ep: 47/48	It: 1551/8134	batch_loss: 3.0445	batch_accuracy: 42.29%	lr:0.000014
Ep: 47/48	It: 1601/8134	batch_loss: 3.0145	batch_accuracy: 41.33%	lr:0.000014
Ep: 47/48	It: 1651/8134	batch_loss: 3.0851	batch_accuracy: 41.14%	lr:0.000014
Ep: 47/48	It: 1701/8134	batch_loss: 3.0507	batch_accuracy: 42.65%	lr:0.000014
Ep: 47/48	It: 1751/8134	batch_loss: 3.1738	batch_accuracy: 40.94%	lr:0.000014
Ep: 47/48	It: 1801/8134	batch_loss: 2.9459	batch_accuracy: 43.73%	lr:0.000014
Ep: 47/48	It: 1851/8134	batch_loss: 3.0565	batch_accuracy: 41.70%	lr:0.000014
Ep: 47/48	It: 1901/8134	batch_loss: 3.0637	batch_accuracy: 40.45%	lr:0.000014
Ep: 47/48	It: 1951/8134	batch_loss: 3.1640	batch_accuracy: 39.36%	lr:0.000014
Ep: 47/48	It: 2001/8134	batch_loss: 3.0705	batch_accuracy: 41.24%	lr:0.000014
Ep: 47/48	It: 2051/8134	batch_loss: 2.9985	batch_accuracy: 41.28%	lr:0.000014
Ep: 47/48	It: 2101/8134	batch_loss: 3.0749	batch_accuracy: 40.84%	lr:0.000014
Ep: 47/48	It: 2151/8134	batch_loss: 2.9507	batch_accuracy: 42.50%	lr:0.000014
Ep: 47/48	It: 2201/8134	batch_loss: 3.0150	batch_accuracy: 42.16%	lr:0.000014
Ep: 47/48	It: 2251/8134	batch_loss: 2.8805	batch_accuracy: 44.46%	lr:0.000014
Ep: 47/48	It: 2301/8134	batch_loss: 3.1090	batch_accuracy: 40.45%	lr:0.000014
Ep: 47/48	It: 2351/8134	batch_loss: 2.9339	batch_accuracy: 43.58%	lr:0.000014
Ep: 47/48	It: 2401/8134	batch_loss: 3.1181	batch_accuracy: 40.21%	lr:0.000014
Ep: 47/48	It: 2451/8134	batch_loss: 3.0444	batch_accuracy: 41.72%	lr:0.000014
Ep: 47/48	It: 2501/8134	batch_loss: 3.0361	batch_accuracy: 41.89%	lr:0.000014
Ep: 47/48	It: 2551/8134	batch_loss: 2.9734	batch_accuracy: 42.80%	lr:0.000014
Ep: 47/48	It: 2601/8134	batch_loss: 2.9561	batch_accuracy: 43.14%	lr:0.000014
Ep: 47/48	It: 2651/8134	batch_loss: 3.0394	batch_accuracy: 41.85%	lr:0.000014
Ep: 47/48	It: 2701/8134	batch_loss: 3.0282	batch_accuracy: 42.41%	lr:0.000014
Ep: 47/48	It: 2751/8134	batch_loss: 2.9780	batch_accuracy: 43.33%	lr:0.000014
Ep: 47/48	It: 2801/8134	batch_loss: 3.0317	batch_accuracy: 42.48%	lr:0.000014
Ep: 47/48	It: 2851/8134	batch_loss: 2.9321	batch_accuracy: 42.24%	lr:0.000014
Ep: 47/48	It: 2901/8134	batch_loss: 3.0123	batch_accuracy: 42.77%	lr:0.000014
Ep: 47/48	It: 2951/8134	batch_loss: 2.9392	batch_accuracy: 42.92%	lr:0.000014
Ep: 47/48	It: 3001/8134	batch_loss: 2.9713	batch_accuracy: 42.70%	lr:0.000014
Ep: 47/48	It: 3051/8134	batch_loss: 3.0695	batch_accuracy: 42.43%	lr:0.000013
Ep: 47/48	It: 3101/8134	batch_loss: 2.9725	batch_accuracy: 42.68%	lr:0.000013
Ep: 47/48	It: 3151/8134	batch_loss: 2.9623	batch_accuracy: 43.04%	lr:0.000013
Ep: 47/48	It: 3201/8134	batch_loss: 3.0783	batch_accuracy: 40.14%	lr:0.000013
Ep: 47/48	It: 3251/8134	batch_loss: 2.8789	batch_accuracy: 43.73%	lr:0.000013
Ep: 47/48	It: 3301/8134	batch_loss: 2.8809	batch_accuracy: 42.99%	lr:0.000013
Ep: 47/48	It: 3351/8134	batch_loss: 2.9878	batch_accuracy: 42.38%	lr:0.000013
Ep: 47/48	It: 3401/8134	batch_loss: 2.9145	batch_accuracy: 43.43%	lr:0.000013
Ep: 47/48	It: 3451/8134	batch_loss: 3.0399	batch_accuracy: 40.94%	lr:0.000013
Ep: 47/48	It: 3501/8134	batch_loss: 2.9845	batch_accuracy: 42.90%	lr:0.000013
Ep: 47/48	It: 3551/8134	batch_loss: 2.9830	batch_accuracy: 41.97%	lr:0.000013
Ep: 47/48	It: 3601/8134	batch_loss: 3.1419	batch_accuracy: 40.99%	lr:0.000013
Ep: 47/48	It: 3651/8134	batch_loss: 3.0009	batch_accuracy: 41.85%	lr:0.000013
Ep: 47/48	It: 3701/8134	batch_loss: 2.9925	batch_accuracy: 42.55%	lr:0.000013
Ep: 47/48	It: 3751/8134	batch_loss: 3.0125	batch_accuracy: 41.82%	lr:0.000013
Ep: 47/48	It: 3801/8134	batch_loss: 2.9591	batch_accuracy: 42.77%	lr:0.000013
Ep: 47/48	It: 3851/8134	batch_loss: 2.9318	batch_accuracy: 43.68%	lr:0.000013
Ep: 47/48	It: 3901/8134	batch_loss: 3.1136	batch_accuracy: 40.97%	lr:0.000013
Ep: 47/48	It: 3951/8134	batch_loss: 2.9569	batch_accuracy: 43.73%	lr:0.000013
Ep: 47/48	It: 4001/8134	batch_loss: 3.0156	batch_accuracy: 42.43%	lr:0.000013
Ep: 47/48	It: 4051/8134	batch_loss: 3.0535	batch_accuracy: 41.70%	lr:0.000013
Ep: 47/48	It: 4101/8134	batch_loss: 3.0116	batch_accuracy: 42.65%	lr:0.000013
Ep: 47/48	It: 4151/8134	batch_loss: 3.0514	batch_accuracy: 40.89%	lr:0.000013
Ep: 47/48	It: 4201/8134	batch_loss: 3.0288	batch_accuracy: 41.55%	lr:0.000013
Ep: 47/48	It: 4251/8134	batch_loss: 2.9882	batch_accuracy: 42.46%	lr:0.000013
Ep: 47/48	It: 4301/8134	batch_loss: 3.1254	batch_accuracy: 40.72%	lr:0.000013
Ep: 47/48	It: 4351/8134	batch_loss: 3.0650	batch_accuracy: 41.55%	lr:0.000013
Ep: 47/48	It: 4401/8134	batch_loss: 2.9321	batch_accuracy: 43.12%	lr:0.000013
Ep: 47/48	It: 4451/8134	batch_loss: 2.9848	batch_accuracy: 41.24%	lr:0.000013
Ep: 47/48	It: 4501/8134	batch_loss: 2.9998	batch_accuracy: 42.46%	lr:0.000013
Ep: 47/48	It: 4551/8134	batch_loss: 3.0529	batch_accuracy: 40.75%	lr:0.000013
Ep: 47/48	It: 4601/8134	batch_loss: 3.0878	batch_accuracy: 41.33%	lr:0.000013
Ep: 47/48	It: 4651/8134	batch_loss: 2.9274	batch_accuracy: 42.63%	lr:0.000013
Ep: 47/48	It: 4701/8134	batch_loss: 3.0220	batch_accuracy: 41.26%	lr:0.000013
Ep: 47/48	It: 4751/8134	batch_loss: 3.1327	batch_accuracy: 40.16%	lr:0.000013
Ep: 47/48	It: 4801/8134	batch_loss: 2.9903	batch_accuracy: 42.55%	lr:0.000013
Ep: 47/48	It: 4851/8134	batch_loss: 3.0063	batch_accuracy: 41.70%	lr:0.000013
Ep: 47/48	It: 4901/8134	batch_loss: 2.9075	batch_accuracy: 43.73%	lr:0.000013
Ep: 47/48	It: 4951/8134	batch_loss: 3.0299	batch_accuracy: 41.16%	lr:0.000013
Ep: 47/48	It: 5001/8134	batch_loss: 3.0346	batch_accuracy: 41.46%	lr:0.000013
Ep: 47/48	It: 5051/8134	batch_loss: 3.1209	batch_accuracy: 40.04%	lr:0.000013
Ep: 47/48	It: 5101/8134	batch_loss: 3.0192	batch_accuracy: 42.53%	lr:0.000012
Ep: 47/48	It: 5151/8134	batch_loss: 3.0330	batch_accuracy: 42.50%	lr:0.000012
Ep: 47/48	It: 5201/8134	batch_loss: 2.9973	batch_accuracy: 42.07%	lr:0.000012
Ep: 47/48	It: 5251/8134	batch_loss: 3.1158	batch_accuracy: 40.97%	lr:0.000012
Ep: 47/48	It: 5301/8134	batch_loss: 2.9946	batch_accuracy: 41.75%	lr:0.000012
Ep: 47/48	It: 5351/8134	batch_loss: 2.9934	batch_accuracy: 41.80%	lr:0.000012
Ep: 47/48	It: 5401/8134	batch_loss: 3.0962	batch_accuracy: 41.21%	lr:0.000012
Ep: 47/48	It: 5451/8134	batch_loss: 2.9720	batch_accuracy: 42.55%	lr:0.000012
Ep: 47/48	It: 5501/8134	batch_loss: 3.0246	batch_accuracy: 41.09%	lr:0.000012
Ep: 47/48	It: 5551/8134	batch_loss: 3.0466	batch_accuracy: 40.89%	lr:0.000012
Ep: 47/48	It: 5601/8134	batch_loss: 3.0658	batch_accuracy: 41.36%	lr:0.000012
Ep: 47/48	It: 5651/8134	batch_loss: 3.0574	batch_accuracy: 41.99%	lr:0.000012
Ep: 47/48	It: 5701/8134	batch_loss: 2.9786	batch_accuracy: 42.99%	lr:0.000012
Ep: 47/48	It: 5751/8134	batch_loss: 3.0055	batch_accuracy: 42.60%	lr:0.000012
Ep: 47/48	It: 5801/8134	batch_loss: 3.0331	batch_accuracy: 41.82%	lr:0.000012
Ep: 47/48	It: 5851/8134	batch_loss: 2.9713	batch_accuracy: 42.09%	lr:0.000012
Ep: 47/48	It: 5901/8134	batch_loss: 2.9312	batch_accuracy: 42.80%	lr:0.000012
Ep: 47/48	It: 5951/8134	batch_loss: 2.8865	batch_accuracy: 43.87%	lr:0.000012
Ep: 47/48	It: 6001/8134	batch_loss: 3.0084	batch_accuracy: 42.41%	lr:0.000012
Ep: 47/48	It: 6051/8134	batch_loss: 3.0333	batch_accuracy: 41.92%	lr:0.000012
Ep: 47/48	It: 6101/8134	batch_loss: 3.0769	batch_accuracy: 41.26%	lr:0.000012
Ep: 47/48	It: 6151/8134	batch_loss: 3.0405	batch_accuracy: 41.77%	lr:0.000012
Ep: 47/48	It: 6201/8134	batch_loss: 2.9806	batch_accuracy: 43.38%	lr:0.000012
Ep: 47/48	It: 6251/8134	batch_loss: 3.0518	batch_accuracy: 40.94%	lr:0.000012
Ep: 47/48	It: 6301/8134	batch_loss: 2.9828	batch_accuracy: 42.68%	lr:0.000012
Ep: 47/48	It: 6351/8134	batch_loss: 2.9487	batch_accuracy: 42.04%	lr:0.000012
Ep: 47/48	It: 6401/8134	batch_loss: 3.2295	batch_accuracy: 38.67%	lr:0.000012
Ep: 47/48	It: 6451/8134	batch_loss: 2.9763	batch_accuracy: 43.33%	lr:0.000012
Ep: 47/48	It: 6501/8134	batch_loss: 3.1272	batch_accuracy: 40.09%	lr:0.000012
Ep: 47/48	It: 6551/8134	batch_loss: 3.0094	batch_accuracy: 42.19%	lr:0.000012
Ep: 47/48	It: 6601/8134	batch_loss: 3.0005	batch_accuracy: 42.14%	lr:0.000012
Ep: 47/48	It: 6651/8134	batch_loss: 3.0495	batch_accuracy: 40.26%	lr:0.000012
Ep: 47/48	It: 6701/8134	batch_loss: 3.1068	batch_accuracy: 41.50%	lr:0.000012
Ep: 47/48	It: 6751/8134	batch_loss: 2.9396	batch_accuracy: 43.31%	lr:0.000012
Ep: 47/48	It: 6801/8134	batch_loss: 3.1428	batch_accuracy: 40.23%	lr:0.000012
Ep: 47/48	It: 6851/8134	batch_loss: 3.2025	batch_accuracy: 40.14%	lr:0.000012
Ep: 47/48	It: 6901/8134	batch_loss: 3.0711	batch_accuracy: 41.72%	lr:0.000012
Ep: 47/48	It: 6951/8134	batch_loss: 3.1045	batch_accuracy: 40.41%	lr:0.000012
Ep: 47/48	It: 7001/8134	batch_loss: 3.0662	batch_accuracy: 41.65%	lr:0.000012
Ep: 47/48	It: 7051/8134	batch_loss: 3.0570	batch_accuracy: 42.65%	lr:0.000012
Ep: 47/48	It: 7101/8134	batch_loss: 3.0272	batch_accuracy: 42.14%	lr:0.000012
Ep: 47/48	It: 7151/8134	batch_loss: 2.9592	batch_accuracy: 43.41%	lr:0.000012
Ep: 47/48	It: 7201/8134	batch_loss: 3.0313	batch_accuracy: 41.33%	lr:0.000012
Ep: 47/48	It: 7251/8134	batch_loss: 3.0945	batch_accuracy: 40.97%	lr:0.000012
Ep: 47/48	It: 7301/8134	batch_loss: 3.1138	batch_accuracy: 40.75%	lr:0.000012
Ep: 47/48	It: 7351/8134	batch_loss: 3.1978	batch_accuracy: 39.67%	lr:0.000012
Ep: 47/48	It: 7401/8134	batch_loss: 2.9306	batch_accuracy: 43.51%	lr:0.000012
Ep: 47/48	It: 7451/8134	batch_loss: 3.0782	batch_accuracy: 40.65%	lr:0.000012
Ep: 47/48	It: 7501/8134	batch_loss: 3.0439	batch_accuracy: 41.80%	lr:0.000012
Ep: 47/48	It: 7551/8134	batch_loss: 3.0715	batch_accuracy: 40.92%	lr:0.000012
Ep: 47/48	It: 7601/8134	batch_loss: 2.9742	batch_accuracy: 43.09%	lr:0.000011
Ep: 47/48	It: 7651/8134	batch_loss: 3.0487	batch_accuracy: 41.38%	lr:0.000011
Ep: 47/48	It: 7701/8134	batch_loss: 3.0586	batch_accuracy: 41.87%	lr:0.000011
Ep: 47/48	It: 7751/8134	batch_loss: 3.0227	batch_accuracy: 41.48%	lr:0.000011
Ep: 47/48	It: 7801/8134	batch_loss: 3.0456	batch_accuracy: 41.16%	lr:0.000011
Ep: 47/48	It: 7851/8134	batch_loss: 3.1268	batch_accuracy: 40.31%	lr:0.000011
Ep: 47/48	It: 7901/8134	batch_loss: 3.0805	batch_accuracy: 42.04%	lr:0.000011
Ep: 47/48	It: 7951/8134	batch_loss: 3.0187	batch_accuracy: 42.68%	lr:0.000011
Ep: 47/48	It: 8001/8134	batch_loss: 3.1739	batch_accuracy: 39.36%	lr:0.000011
Ep: 47/48	It: 8051/8134	batch_loss: 2.9808	batch_accuracy: 42.77%	lr:0.000011
Ep: 47/48	It: 8101/8134	batch_loss: 2.9614	batch_accuracy: 42.99%	lr:0.000011
Ep: 47/48	It: 8134/8134	batch_loss: 2.9540	batch_accuracy: 42.19%	lr:0.000011


Generated text for input text "You" is:
You’ (M) and (ii) theorizing theses of militant and the ‘intern’ theories, as well as its role in theorizing theatonic, and theatonic, and theological, and/or social. These examples demonstrate how the concept can be used to analyze and explain the nature of militarism in the post-Soviet period.
<eot>
<sot>
Multimodal Pediatric Epilepsy

Abstract Pediatric Epilepsy is a major cause of childhood epilepsy in the United States, which has caused the death of a child. The first two cases of epilepsy are associated with epilepsy, a condition caused by epilepsy and a syndrome that is usually manifested by a progressive loss of neural function. The present case is the first case of epilepsy in the adult brain and the epilepsy of a child with epilepsy.
<eot>
<sot>
Early diagnosis of epilepsy in a neonate.

Early diagnosis of epilepsy in neonates requires careful early diagnosis. Aim of the study: The aim of the study was to evaluate the


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Ep: 48/48	It: 1/8134	batch_loss: 2.9717	batch_accuracy: 42.63%	lr:0.000011
Ep: 48/48	It: 51/8134	batch_loss: 2.9238	batch_accuracy: 42.24%	lr:0.000011
Ep: 48/48	It: 101/8134	batch_loss: 3.0431	batch_accuracy: 41.72%	lr:0.000011
Ep: 48/48	It: 151/8134	batch_loss: 3.0524	batch_accuracy: 41.65%	lr:0.000011
Ep: 48/48	It: 201/8134	batch_loss: 2.9765	batch_accuracy: 42.72%	lr:0.000011
Ep: 48/48	It: 251/8134	batch_loss: 3.0778	batch_accuracy: 40.89%	lr:0.000011
Ep: 48/48	It: 301/8134	batch_loss: 2.9261	batch_accuracy: 43.09%	lr:0.000011
Ep: 48/48	It: 351/8134	batch_loss: 3.0558	batch_accuracy: 41.11%	lr:0.000011
Ep: 48/48	It: 401/8134	batch_loss: 3.0970	batch_accuracy: 39.53%	lr:0.000011
Ep: 48/48	It: 451/8134	batch_loss: 3.0906	batch_accuracy: 40.84%	lr:0.000011
Ep: 48/48	It: 501/8134	batch_loss: 3.0157	batch_accuracy: 41.58%	lr:0.000011
Ep: 48/48	It: 551/8134	batch_loss: 3.0342	batch_accuracy: 41.82%	lr:0.000011
Ep: 48/48	It: 601/8134	batch_loss: 2.9635	batch_accuracy: 41.99%	lr:0.000011
Ep: 48/48	It: 651/8134	batch_loss: 3.0206	batch_accuracy: 42.07%	lr:0.000011
Ep: 48/48	It: 701/8134	batch_loss: 2.9594	batch_accuracy: 42.92%	lr:0.000011
Ep: 48/48	It: 751/8134	batch_loss: 2.9606	batch_accuracy: 42.04%	lr:0.000011
Ep: 48/48	It: 801/8134	batch_loss: 3.0290	batch_accuracy: 42.92%	lr:0.000011
Ep: 48/48	It: 851/8134	batch_loss: 2.9883	batch_accuracy: 42.33%	lr:0.000011
Ep: 48/48	It: 901/8134	batch_loss: 3.0288	batch_accuracy: 41.97%	lr:0.000011
Ep: 48/48	It: 951/8134	batch_loss: 3.0299	batch_accuracy: 41.28%	lr:0.000011
Ep: 48/48	It: 1001/8134	batch_loss: 3.0624	batch_accuracy: 41.50%	lr:0.000011
Ep: 48/48	It: 1051/8134	batch_loss: 2.9329	batch_accuracy: 42.90%	lr:0.000011
Ep: 48/48	It: 1101/8134	batch_loss: 3.1369	batch_accuracy: 40.89%	lr:0.000011
Ep: 48/48	It: 1151/8134	batch_loss: 2.9902	batch_accuracy: 42.65%	lr:0.000011
Ep: 48/48	It: 1201/8134	batch_loss: 2.9930	batch_accuracy: 42.65%	lr:0.000011
Ep: 48/48	It: 1251/8134	batch_loss: 2.9804	batch_accuracy: 42.29%	lr:0.000011
Ep: 48/48	It: 1301/8134	batch_loss: 3.0446	batch_accuracy: 41.38%	lr:0.000011
Ep: 48/48	It: 1351/8134	batch_loss: 3.1012	batch_accuracy: 41.99%	lr:0.000011
Ep: 48/48	It: 1401/8134	batch_loss: 3.1148	batch_accuracy: 41.94%	lr:0.000011
Ep: 48/48	It: 1451/8134	batch_loss: 3.0118	batch_accuracy: 42.16%	lr:0.000011
Ep: 48/48	It: 1501/8134	batch_loss: 2.9717	batch_accuracy: 42.38%	lr:0.000011
Ep: 48/48	It: 1551/8134	batch_loss: 3.0299	batch_accuracy: 41.67%	lr:0.000011
Ep: 48/48	It: 1601/8134	batch_loss: 3.0781	batch_accuracy: 41.43%	lr:0.000011
Ep: 48/48	It: 1651/8134	batch_loss: 3.0500	batch_accuracy: 41.33%	lr:0.000011
Ep: 48/48	It: 1701/8134	batch_loss: 2.9834	batch_accuracy: 42.77%	lr:0.000011
Ep: 48/48	It: 1751/8134	batch_loss: 2.9702	batch_accuracy: 42.58%	lr:0.000011
Ep: 48/48	It: 1801/8134	batch_loss: 2.9517	batch_accuracy: 43.51%	lr:0.000011
Ep: 48/48	It: 1851/8134	batch_loss: 3.0542	batch_accuracy: 42.21%	lr:0.000011
Ep: 48/48	It: 1901/8134	batch_loss: 3.0363	batch_accuracy: 41.24%	lr:0.000011
Ep: 48/48	It: 1951/8134	batch_loss: 3.0073	batch_accuracy: 43.29%	lr:0.000011
Ep: 48/48	It: 2001/8134	batch_loss: 3.1064	batch_accuracy: 40.97%	lr:0.000011
Ep: 48/48	It: 2051/8134	batch_loss: 3.0319	batch_accuracy: 41.82%	lr:0.000011
Ep: 48/48	It: 2101/8134	batch_loss: 3.1113	batch_accuracy: 40.38%	lr:0.000011
Ep: 48/48	It: 2151/8134	batch_loss: 2.9389	batch_accuracy: 43.38%	lr:0.000011
Ep: 48/48	It: 2201/8134	batch_loss: 3.1207	batch_accuracy: 39.79%	lr:0.000011
Ep: 48/48	It: 2251/8134	batch_loss: 3.0812	batch_accuracy: 40.87%	lr:0.000011
Ep: 48/48	It: 2301/8134	batch_loss: 3.0224	batch_accuracy: 43.02%	lr:0.000011
Ep: 48/48	It: 2351/8134	batch_loss: 3.1045	batch_accuracy: 41.14%	lr:0.000011
Ep: 48/48	It: 2401/8134	batch_loss: 3.1002	batch_accuracy: 41.60%	lr:0.000011
Ep: 48/48	It: 2451/8134	batch_loss: 3.0264	batch_accuracy: 41.28%	lr:0.000011
Ep: 48/48	It: 2501/8134	batch_loss: 2.9025	batch_accuracy: 44.53%	lr:0.000011
Ep: 48/48	It: 2551/8134	batch_loss: 3.0329	batch_accuracy: 41.97%	lr:0.000011
Ep: 48/48	It: 2601/8134	batch_loss: 3.0315	batch_accuracy: 42.02%	lr:0.000011
Ep: 48/48	It: 2651/8134	batch_loss: 3.0157	batch_accuracy: 41.53%	lr:0.000011
Ep: 48/48	It: 2701/8134	batch_loss: 3.0817	batch_accuracy: 41.87%	lr:0.000011
Ep: 48/48	It: 2751/8134	batch_loss: 3.1722	batch_accuracy: 40.72%	lr:0.000011
Ep: 48/48	It: 2801/8134	batch_loss: 3.1799	batch_accuracy: 39.36%	lr:0.000011
Ep: 48/48	It: 2851/8134	batch_loss: 3.1134	batch_accuracy: 40.84%	lr:0.000011
Ep: 48/48	It: 2901/8134	batch_loss: 2.9586	batch_accuracy: 42.94%	lr:0.000011
Ep: 48/48	It: 2951/8134	batch_loss: 3.0219	batch_accuracy: 42.70%	lr:0.000011
Ep: 48/48	It: 3001/8134	batch_loss: 3.0041	batch_accuracy: 41.94%	lr:0.000011
Ep: 48/48	It: 3051/8134	batch_loss: 2.9953	batch_accuracy: 41.46%	lr:0.000011
Ep: 48/48	It: 3101/8134	batch_loss: 3.0273	batch_accuracy: 42.41%	lr:0.000011
Ep: 48/48	It: 3151/8134	batch_loss: 3.0130	batch_accuracy: 41.46%	lr:0.000010
Ep: 48/48	It: 3201/8134	batch_loss: 2.9964	batch_accuracy: 42.29%	lr:0.000010
Ep: 48/48	It: 3251/8134	batch_loss: 3.0636	batch_accuracy: 41.72%	lr:0.000010
Ep: 48/48	It: 3301/8134	batch_loss: 2.9905	batch_accuracy: 42.43%	lr:0.000010
Ep: 48/48	It: 3351/8134	batch_loss: 3.1663	batch_accuracy: 39.70%	lr:0.000010
Ep: 48/48	It: 3401/8134	batch_loss: 2.9453	batch_accuracy: 41.72%	lr:0.000010
Ep: 48/48	It: 3451/8134	batch_loss: 2.9387	batch_accuracy: 43.60%	lr:0.000010
Ep: 48/48	It: 3501/8134	batch_loss: 3.0102	batch_accuracy: 41.80%	lr:0.000010
Ep: 48/48	It: 3551/8134	batch_loss: 3.0751	batch_accuracy: 40.67%	lr:0.000010
Ep: 48/48	It: 3601/8134	batch_loss: 3.1244	batch_accuracy: 40.80%	lr:0.000010
Ep: 48/48	It: 3651/8134	batch_loss: 3.1432	batch_accuracy: 40.23%	lr:0.000010
Ep: 48/48	It: 3701/8134	batch_loss: 3.0760	batch_accuracy: 41.85%	lr:0.000010
Ep: 48/48	It: 3751/8134	batch_loss: 3.0898	batch_accuracy: 40.62%	lr:0.000010
Ep: 48/48	It: 3801/8134	batch_loss: 3.0861	batch_accuracy: 41.58%	lr:0.000010
Ep: 48/48	It: 3851/8134	batch_loss: 3.0023	batch_accuracy: 42.11%	lr:0.000010
Ep: 48/48	It: 3901/8134	batch_loss: 2.9826	batch_accuracy: 42.36%	lr:0.000010
Ep: 48/48	It: 3951/8134	batch_loss: 3.0934	batch_accuracy: 41.04%	lr:0.000010
Ep: 48/48	It: 4001/8134	batch_loss: 3.2222	batch_accuracy: 39.84%	lr:0.000010
Ep: 48/48	It: 4051/8134	batch_loss: 2.9976	batch_accuracy: 42.87%	lr:0.000010
Ep: 48/48	It: 4101/8134	batch_loss: 2.8623	batch_accuracy: 44.60%	lr:0.000010
Ep: 48/48	It: 4151/8134	batch_loss: 3.0718	batch_accuracy: 41.33%	lr:0.000010
Ep: 48/48	It: 4201/8134	batch_loss: 2.9658	batch_accuracy: 42.53%	lr:0.000010
Ep: 48/48	It: 4251/8134	batch_loss: 3.0658	batch_accuracy: 40.89%	lr:0.000010
Ep: 48/48	It: 4301/8134	batch_loss: 2.9798	batch_accuracy: 42.75%	lr:0.000010
Ep: 48/48	It: 4351/8134	batch_loss: 2.9353	batch_accuracy: 43.26%	lr:0.000010
Ep: 48/48	It: 4401/8134	batch_loss: 3.0637	batch_accuracy: 40.92%	lr:0.000010
Ep: 48/48	It: 4451/8134	batch_loss: 3.0440	batch_accuracy: 41.97%	lr:0.000010
Ep: 48/48	It: 4501/8134	batch_loss: 3.1600	batch_accuracy: 40.84%	lr:0.000010
Ep: 48/48	It: 4551/8134	batch_loss: 3.1390	batch_accuracy: 40.99%	lr:0.000010
Ep: 48/48	It: 4601/8134	batch_loss: 3.0467	batch_accuracy: 42.16%	lr:0.000010
Ep: 48/48	It: 4651/8134	batch_loss: 3.0152	batch_accuracy: 41.85%	lr:0.000010
Ep: 48/48	It: 4701/8134	batch_loss: 3.0612	batch_accuracy: 41.72%	lr:0.000010
Ep: 48/48	It: 4751/8134	batch_loss: 3.0079	batch_accuracy: 41.77%	lr:0.000010
Ep: 48/48	It: 4801/8134	batch_loss: 3.0976	batch_accuracy: 40.92%	lr:0.000010
Ep: 48/48	It: 4851/8134	batch_loss: 2.9895	batch_accuracy: 42.11%	lr:0.000010
Ep: 48/48	It: 4901/8134	batch_loss: 2.9745	batch_accuracy: 41.63%	lr:0.000010
Ep: 48/48	It: 4951/8134	batch_loss: 3.1235	batch_accuracy: 40.21%	lr:0.000010
Ep: 48/48	It: 5001/8134	batch_loss: 3.1877	batch_accuracy: 40.55%	lr:0.000010
Ep: 48/48	It: 5051/8134	batch_loss: 2.9792	batch_accuracy: 42.58%	lr:0.000010
Ep: 48/48	It: 5101/8134	batch_loss: 3.1475	batch_accuracy: 40.77%	lr:0.000010
Ep: 48/48	It: 5151/8134	batch_loss: 3.0051	batch_accuracy: 42.36%	lr:0.000010
Ep: 48/48	It: 5201/8134	batch_loss: 3.0313	batch_accuracy: 42.60%	lr:0.000010
Ep: 48/48	It: 5251/8134	batch_loss: 2.9884	batch_accuracy: 43.09%	lr:0.000010
Ep: 48/48	It: 5301/8134	batch_loss: 2.9669	batch_accuracy: 43.29%	lr:0.000010
Ep: 48/48	It: 5351/8134	batch_loss: 3.0928	batch_accuracy: 41.58%	lr:0.000010
Ep: 48/48	It: 5401/8134	batch_loss: 3.0640	batch_accuracy: 41.26%	lr:0.000010
Ep: 48/48	It: 5451/8134	batch_loss: 3.0593	batch_accuracy: 40.43%	lr:0.000010
Ep: 48/48	It: 5501/8134	batch_loss: 2.9403	batch_accuracy: 42.29%	lr:0.000010
Ep: 48/48	It: 5551/8134	batch_loss: 2.9323	batch_accuracy: 42.11%	lr:0.000010
Ep: 48/48	It: 5601/8134	batch_loss: 2.9933	batch_accuracy: 43.14%	lr:0.000010
Ep: 48/48	It: 5651/8134	batch_loss: 2.9641	batch_accuracy: 43.63%	lr:0.000010
Ep: 48/48	It: 5701/8134	batch_loss: 3.0711	batch_accuracy: 41.67%	lr:0.000010
Ep: 48/48	It: 5751/8134	batch_loss: 3.0305	batch_accuracy: 41.26%	lr:0.000010
Ep: 48/48	It: 5801/8134	batch_loss: 3.0256	batch_accuracy: 42.68%	lr:0.000010
Ep: 48/48	It: 5851/8134	batch_loss: 3.1077	batch_accuracy: 40.41%	lr:0.000010
Ep: 48/48	It: 5901/8134	batch_loss: 2.9388	batch_accuracy: 42.43%	lr:0.000010
Ep: 48/48	It: 5951/8134	batch_loss: 3.0321	batch_accuracy: 41.04%	lr:0.000010
Ep: 48/48	It: 6001/8134	batch_loss: 3.1385	batch_accuracy: 40.41%	lr:0.000010
Ep: 48/48	It: 6051/8134	batch_loss: 3.0014	batch_accuracy: 42.72%	lr:0.000010
Ep: 48/48	It: 6101/8134	batch_loss: 3.2237	batch_accuracy: 40.26%	lr:0.000010
Ep: 48/48	It: 6151/8134	batch_loss: 2.9008	batch_accuracy: 43.75%	lr:0.000010
Ep: 48/48	It: 6201/8134	batch_loss: 3.1022	batch_accuracy: 41.28%	lr:0.000010
Ep: 48/48	It: 6251/8134	batch_loss: 3.0864	batch_accuracy: 41.31%	lr:0.000010
Ep: 48/48	It: 6301/8134	batch_loss: 2.9708	batch_accuracy: 42.80%	lr:0.000010
Ep: 48/48	It: 6351/8134	batch_loss: 2.9738	batch_accuracy: 43.12%	lr:0.000010
Ep: 48/48	It: 6401/8134	batch_loss: 3.1190	batch_accuracy: 40.26%	lr:0.000010
Ep: 48/48	It: 6451/8134	batch_loss: 2.9921	batch_accuracy: 42.55%	lr:0.000010
Ep: 48/48	It: 6501/8134	batch_loss: 2.7936	batch_accuracy: 43.60%	lr:0.000010
Ep: 48/48	It: 6551/8134	batch_loss: 3.1484	batch_accuracy: 40.72%	lr:0.000010
Ep: 48/48	It: 6601/8134	batch_loss: 2.9091	batch_accuracy: 43.21%	lr:0.000010
Ep: 48/48	It: 6651/8134	batch_loss: 2.9875	batch_accuracy: 42.82%	lr:0.000010
Ep: 48/48	It: 6701/8134	batch_loss: 3.0402	batch_accuracy: 40.94%	lr:0.000010
Ep: 48/48	It: 6751/8134	batch_loss: 3.1166	batch_accuracy: 40.99%	lr:0.000010
Ep: 48/48	It: 6801/8134	batch_loss: 3.0130	batch_accuracy: 42.41%	lr:0.000010
Ep: 48/48	It: 6851/8134	batch_loss: 2.9218	batch_accuracy: 43.65%	lr:0.000010
Ep: 48/48	It: 6901/8134	batch_loss: 3.0163	batch_accuracy: 42.53%	lr:0.000010
Ep: 48/48	It: 6951/8134	batch_loss: 3.1883	batch_accuracy: 39.79%	lr:0.000010
Ep: 48/48	It: 7001/8134	batch_loss: 2.9698	batch_accuracy: 41.33%	lr:0.000010
Ep: 48/48	It: 7051/8134	batch_loss: 3.0715	batch_accuracy: 41.06%	lr:0.000010
Ep: 48/48	It: 7101/8134	batch_loss: 2.9954	batch_accuracy: 42.09%	lr:0.000010
Ep: 48/48	It: 7151/8134	batch_loss: 3.1277	batch_accuracy: 40.14%	lr:0.000010
Ep: 48/48	It: 7201/8134	batch_loss: 3.0385	batch_accuracy: 41.63%	lr:0.000010
Ep: 48/48	It: 7251/8134	batch_loss: 2.8711	batch_accuracy: 43.63%	lr:0.000010
Ep: 48/48	It: 7301/8134	batch_loss: 2.9427	batch_accuracy: 42.94%	lr:0.000010
Ep: 48/48	It: 7351/8134	batch_loss: 2.9669	batch_accuracy: 42.24%	lr:0.000010
Ep: 48/48	It: 7401/8134	batch_loss: 3.1121	batch_accuracy: 40.06%	lr:0.000010
Ep: 48/48	It: 7451/8134	batch_loss: 2.8860	batch_accuracy: 45.43%	lr:0.000010
Ep: 48/48	It: 7501/8134	batch_loss: 3.0928	batch_accuracy: 40.28%	lr:0.000010
Ep: 48/48	It: 7551/8134	batch_loss: 3.0704	batch_accuracy: 41.19%	lr:0.000010
Ep: 48/48	It: 7601/8134	batch_loss: 2.8731	batch_accuracy: 44.73%	lr:0.000010
Ep: 48/48	It: 7651/8134	batch_loss: 3.0224	batch_accuracy: 42.38%	lr:0.000010
Ep: 48/48	It: 7701/8134	batch_loss: 3.0061	batch_accuracy: 41.31%	lr:0.000010
Ep: 48/48	It: 7751/8134	batch_loss: 3.0279	batch_accuracy: 41.41%	lr:0.000010
Ep: 48/48	It: 7801/8134	batch_loss: 3.0149	batch_accuracy: 41.87%	lr:0.000010
Ep: 48/48	It: 7851/8134	batch_loss: 2.9357	batch_accuracy: 43.95%	lr:0.000010
Ep: 48/48	It: 7901/8134	batch_loss: 3.0561	batch_accuracy: 41.92%	lr:0.000010
Ep: 48/48	It: 7951/8134	batch_loss: 3.0744	batch_accuracy: 40.99%	lr:0.000010
Ep: 48/48	It: 8001/8134	batch_loss: 3.0180	batch_accuracy: 41.82%	lr:0.000010
Ep: 48/48	It: 8051/8134	batch_loss: 2.9859	batch_accuracy: 42.55%	lr:0.000010
Ep: 48/48	It: 8101/8134	batch_loss: 3.0585	batch_accuracy: 41.38%	lr:0.000010
Ep: 48/48	It: 8134/8134	batch_loss: 3.1159	batch_accuracy: 41.37%	lr:0.000010


Generated text for input text "You" is:
You, and in thesis, theological aspects of thesis and the essay are presented. The textbook includes a brief overview of theology of theology, and theological and theologically relevant points of thesis; theological aspects of theology of theology; theology of theology; theological and philosophical texts; theological and epistemological theology of theological and philosophical theology; theological and philosophical concepts of theological theory of theological, theological, theological and theological.
<eot>
<sot>
Evaluation of a Taxable System for the Influence of Government and Regulatory Commission on Political Conflict in India

The article discusses the problem of tax avoidance in India in the form of tax incentives for the protection of the state and the state, as well as the need to make a policy of governments to reduce the risk of economic change. It is important to find a way to mitigate the effect of the crisis. The method of taking a priority is proposed. The method is based on a multi-dimensional example, which can be used in the analysis of the risk of


Ended at 2025-04-20 04:55:27
Duration: 8:36:33.668219
Job finished at Sun Apr 20 04:56:08 CDT 2025
